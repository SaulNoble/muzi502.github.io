<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>分享 kindle 标注的几种方法</title>
    <url>/archives/kindle-note.html</url>
    <content><![CDATA[<p>今儿水一篇博客😋，另外分享一下自己的 kindle 标注 <a href="https://kindle.502.li/" target="_blank" rel="noopener">kindle.502.li</a></p>
<h2 id="muzi’s-kindle-note"><a href="#muzi’s-kindle-note" class="headerlink" title="muzi’s kindle note"></a>muzi’s kindle note</h2><p>最近决定把 kindle 上的标注捣鼓出来分享在博客上，整理了一下折腾的过程。笔记放在了 GitHub page 上并添加了自己的二级域名 <a href="https://kindle.502.li" target="_blank" rel="noopener">kindle.502.li</a> ，一般来讲每天都会更新，因为每天晚上都会捧着 kindle 看书😂，kindle 已经陪着我度过了无数个不眠之夜，从我 kindle 标注的时间来看，经常会有凌晨两单点的标注，那天想必也失眠了吧。</p>
<h2 id="kindle-标注"><a href="#kindle-标注" class="headerlink" title="kindle 标注"></a>kindle 标注</h2><p>刚开始使用 kindle 的时候十分不习惯 kindle 上的标注功能，主要是操作起来太满了，机器的反应速度跟不上手速，所以好长时间就没用。到后来三番五次地使用了几下，就完全依赖上了。就像纸质书的时候，拿着笔在书本上乱涂乱画一样😂。kindle 的笔记功能我是不想使用，主要还是太慢了，所以一直仅仅使用了 kindle 的标注功能。</p>
<h2 id="如何分享"><a href="#如何分享" class="headerlink" title="如何分享"></a>如何分享</h2><h3 id="kindle-内置分享功能"><a href="#kindle-内置分享功能" class="headerlink" title="kindle 内置分享功能"></a>kindle 内置分享功能</h3><ul>
<li>在阅读的时候，遇到需要标注的内容，用手指拖动光标选中需要标注的内容，然后再点击<code>标注</code> 即可。</li>
</ul>
<p><img src="../img/image-20200109191811489.png" alt="image-20200109191811489"></p>
<ul>
<li>标注完之后，标注的内容背景会编程灰色，再点击灰色阴影部分就会弹出选项，点击 <code>分享</code> 按钮，即可通过邮件、微博、微信这三种方式来分享。不过对于咱这种对国内互联网不屑一顾的屁民来说，还是选择通过邮箱发送哈。需要注意的是，我的域名邮箱使用了 <a href="https://improvmx.com/" target="_blank" rel="noopener">improvmx</a> 的泛域名转发功能，也就是我域名下的所有邮件都可以转发到指定的邮箱，随便指定个域名前缀就能发送到我邮箱。但缺点是不能发送邮件，接收邮件没有问题。</li>
</ul>
<p><img src="../img/image-20200109192253050.png" alt="image-20200109192253050"></p>
<ul>
<li>然后邮箱里会收到以下内容的邮件</li>
</ul>
<blockquote>
<p>  ✉️ muzi502 <a href="mailto:&#x6e;&#111;&#45;&#x72;&#x65;&#112;&#x6c;&#121;&#x40;&#97;&#x6d;&#x61;&#122;&#111;&#x6e;&#x2e;&#x63;&#111;&#109;" target="_blank" rel="noopener">&#x6e;&#111;&#45;&#x72;&#x65;&#112;&#x6c;&#121;&#x40;&#97;&#x6d;&#x61;&#122;&#111;&#x6e;&#x2e;&#x63;&#111;&#109;</a></p>
<p>  To: <a href="mailto:&#107;&#105;&#110;&#x64;&#x6c;&#x65;&#x40;&#x35;&#48;&#50;&#46;&#x6c;&#x69;" target="_blank" rel="noopener">&#107;&#105;&#110;&#x64;&#x6c;&#x65;&#x40;&#x35;&#48;&#50;&#46;&#x6c;&#x69;</a></p>
<p>  查看名言</p>
<p>  嗨，我正在读这本书，想跟您分享一句名言。<br>  《奴役关系是通过人与人之间的相互依赖，以及将他们结合在一起的相互需要形成的。如果不先使得一个人陷入不能失去另一个人的境地，那就不可能奴役他。这种情况在自然状态中并不存在，在自然状态中，人人无拘无束，最强者的法则无用武之地。》(摘自由 让-雅克·卢梭 (Jean-Jacques Rousseau), 黄小彦 撰写的《论人类不平等的起源和基础 (译林人文精选)》)</p>
<p>  开始免费阅读: <a href="http://z.cn/hzAc7xd" target="_blank" rel="noopener">http://z.cn/hzAc7xd</a></p>
<p>  出行时免费阅读 - 下载适用于 Android、iOS、PC 和 Mac 等的 Kindle</p>
</blockquote>
<ul>
<li>打开短链接</li>
</ul>
<p><img src="../img/image-20200109192923891.png" alt="image-20200109192923891"></p>
<h4 id="使用体验"><a href="#使用体验" class="headerlink" title="使用体验"></a>使用体验</h4><p>不方便，主要是这些笔记和标注全部在邮箱里，实在是不方便整理。即便使用 kindle 的笔记导出功能，最终邮件收到的是 PDF 格式的文件，也不方便分享。我想要的是像我的博客这样。</p>
<h2 id="其他工具"><a href="#其他工具" class="headerlink" title="其他工具"></a>其他工具</h2><p>kindle 上所有的标注文件都保存在 kindle 内部存储 <code>documents/My Clippings.txt</code> 文件内，所以还是借助其他工具来管理这些标注最为直接，可玩性也高。</p>
<h3 id="Knotes"><a href="#Knotes" class="headerlink" title="Knotes"></a>Knotes</h3><p><a href="https://www.ifanr.com/app/795954" target="_blank" rel="noopener">独家首发：每个用 Kindle 的人，都不能错过它</a></p>
<blockquote>
<p>  大家好，我是Knotes作者贺乙钊。非常感谢ifanr的独家首发报道！🙏 Knotes 1.1.0版本主打印象笔记🐘同步和微信分享功能。在后续的开发中，我会进一步优化分享和写作体验✏️，包括支持更多的分享方式，支持导出Markdown格式等等，也会增加回顾模式📖，按导入时间来回顾笔记，同时也会增加主题、定制等，让Knotes变得更加个性化。 欢迎大家提意见和建议，我会专注Knotes的开发，争取做到完美😊。</p>
</blockquote>
<p>做的很好，不过我仅仅需要把标注转换成 html 即可，遂放弃。</p>
<h3 id="Clippings-Fere"><a href="#Clippings-Fere" class="headerlink" title="Clippings Fere"></a>Clippings Fere</h3><p><a href="https://bookfere.com/post/110.html" target="_blank" rel="noopener">Clippings Fere：让“我的剪贴”变得更易读</a></p>
<p>第一次使用 <a href="https://bookfere.com/post/110.html" target="_blank" rel="noopener">Clippings Fere</a> 相当满意，生成的 html 页面和效果也非常不错。功能单一，十分精简没有杂七杂八的功能。但唯一的缺点就是不支持 Linux ，实在是令人遗憾。咱也不习惯用鼠标点来点去的，还是喜欢用命令行来操作比较舒服。</p>
<p><img src="../img/image-20200109200204852.png" alt="image-20200109200204852"></p>
<p><img src="../img/image-20200109200236874.png" alt="image-20200109200236874"></p>
<h3 id="Klib"><a href="#Klib" class="headerlink" title="Klib"></a><a href="https://toolinbox.net/Klib/" target="_blank" rel="noopener">Klib</a></h3><p>仅支持 MacOS ，咱 Linux (Debian) 党劝退😂，而且高级版还要收费 98￥/年。大哥，kindle 会员一年才 99 块啊。说实在的，这个价格真的不如买一年 kindle 会员的订阅。尤其是对咱这种靠技术搬砖的社畜来讲实在是相当于交了智商税。98￥，我更推荐别人去买一年的 kindle 会员。</p>
<h3 id="kindleNote"><a href="#kindleNote" class="headerlink" title="kindleNote"></a><a href="https://github.com/cyang812/kindleNote" target="_blank" rel="noopener">kindleNote</a></h3><p><a href="https://github.com/cyang812" target="_blank" rel="noopener">cyang812</a>/<strong><a href="https://github.com/cyang812/kindleNote" target="_blank" rel="noopener">kindleNote</a></strong></p>
<p>最终还是找到了个在命令行下操作的工具。用 py 写的，代码也就二百来行，没有杂七杂八的功能，实在是我们 Linux 用户的福音。刚开始我也是使用 shell 脚本直接处理导出来的<code>My Clippings.txt</code> 文件，然后通过替换再转换成 markdown 文件，但全部的书籍都放在一个文本文件里实在不好管理。因为绝大多数的书名有特殊字符，shell 处理起来很麻烦，而这个 Python 脚本正是替代了 <code>Clippings Fere</code>。不过生成的 html 文件效果不是很好，而且并没有对移动端进行优化，再手机上看起来很不方便。</p>
<p>于是寻思着能不能通过这个 Python 脚本生成像 <code>Clippings Fere</code> 生成的效果一样。于是花了一个消逝 xjb 捣鼓，复制粘贴别人的代码最终搞成了。</p>
<p><img src="../img/image-20200109200537555.png" alt="image-20200109200537555"></p>
<p>另外也把 <code>Clippings Fere</code> 导出时不支持总标注数量也解决了。目前来讲还算满意。</p>
<h2 id="截屏"><a href="#截屏" class="headerlink" title="截屏"></a>截屏</h2><p>之前使用 kindle 遇到一些精彩的内容想拍照保存下来，直到有一天推友告诉我可以使用 kindle 自带的截屏功能。操作方法就是，<strong>同时按住屏幕对角线位置即可</strong>，而截屏的图片保存在了 kindle 内部存储的根目录下。需要手动拷贝出来，无法通过 kindle 分享出来，只能通过 USB 连接拷贝出来。</p>
]]></content>
  </entry>
  <entry>
    <title>PSYCHO-PASS 心理测量者小说读后感</title>
    <url>/archives/PSYCHO-PASS-booklist.html</url>
    <content><![CDATA[<h2 id="题记"><a href="#题记" class="headerlink" title="题记"></a>题记</h2><p>呜呜呜，我哭了。最近屁股上起了个火疖子，疼的我哭爹喊娘的。站也不是坐也不是，反正都是疼。走起路来一阵一阵地疼，就像小时候在屁股上打针一样痛。而且远在千里的好基友坐了二十个小时的火车来找我玩儿，无奈周六玩了一天就撑不下去了，屁股上的火疖子走一下疼一下。于是周末一整天都趴在床上了，像乌龟一样老老实实地趴在床上看完《心理测量者》的改编小说。</p>
<p>这本小说没有中文版，大陆也没有出版，只有网上流传的豆瓣读者翻译的版本。在亲小说网站上找到了这本书，于是使用一些命令行工具（<code>curl、grep、sed、awk、pandoc</code>）三下五除二 、一把梭制作成了 kindle 支持的 mobi 格式。有想去想了解如何制作这本电子书的可以翻一下我上一篇博客。<a href="https://blog.502.li/archives/make-e-book-from-html.html">网页小说制作 kindle 电子书</a></p>
<p>自己制作的这本小说，整本小说有 194257 个词，22630 个字符。将近 20 万字，我阅读起来大概花了 6 个小时，主要是在阅读的时候特意地标注和截图了很多内容才花费了这么长的时间，20 万字的小说我一般三四个小时就能看完，因为初中的时候几乎看遍了当时的网络小说，这些小说的字数加起来少说也得有个一千万字。整本小说读完，大概标注了 85 处，以及 100 多张的截图。主要是为了写这篇读后感作参考来用。</p>
<h2 id="读后感"><a href="#读后感" class="headerlink" title="读后感"></a>读后感</h2><p>自由平等博爱的理性王国真的存在吗？也许这只不过是幻想罢了，人类真是一群很可悲可耻可笑可怜的生物，为了争夺权力与金钱、填补无尽的欲望而引发众多惨无人道的战争、犯下众多反人类罪行。更可恨的是，想方设法地从大自然获取商业物质利益，肆意破坏这个美丽的蓝色星球。人类自身虽取得如此辉煌的文明，但人类自身依旧在社会的牢笼中，失去了最原始的自然权力—-自由。无论是共产主义的大清洗、美国的独立战争、南北内战抑或是柏林墙的倒塌、波罗的海之路、匈牙利十月革命、乌克兰的为自由之战……等等。</p>
<p>人类至今仍未能找到一个完美的方法或制度来协调社会的运作，无论是自由民主灯塔的美国、抑或是独裁专制集权暴政下的朝鲜，无论哪个国家的人民，他们都一样吧：都承受着政府强加的危险，而这些危险又巧妙地分散到每个人身上，使他们无法察觉到，即便察觉到也会视而不见吧。</p>
<p>那么小说中的西比拉先知系统真的是我们所追求的社会体制吗？在无知之幕下我们每个人真的平等吗？</p>
<blockquote>
<p>别小看人类，我们无时无刻不向往着更加美好的世界。总有一天会有人来关掉这件屋子的电源，即便那个人不是我，在新时代也一定会有人开拓出全新的道路，修比拉系统，你们根本没有未来。</p>
</blockquote>
<ul>
<li>酝酿中……</li>
</ul>
<h2 id="心理测量者"><a href="#心理测量者" class="headerlink" title="心理测量者"></a>心理测量者</h2><p>《<strong>心理测量者</strong>》（日语：PSYCHO-PASS サイコパス），又译“<strong>心理测量者</strong>”，是<a href="https://zh.wikipedia.org/wiki/Production_I.G" target="_blank" rel="noopener">Production I.G</a>所制作的电视动画系列。故事原案为<a href="https://zh.wikipedia.org/wiki/虛淵玄" target="_blank" rel="noopener">虚渊玄</a>，角色原案为<a href="https://zh.wikipedia.org/wiki/天野明" target="_blank" rel="noopener">天野明</a>，并由盐谷直义和本广克行指导制作。这是一部反乌托邦为题材的动漫作品。故事设定在未来的日本社会建立一套西比拉先知系统（Sibyl System/シビュラシステム）── 一个强大的心灵指数监测網絡──以声像扫描主动监控市民的心智与精神状态，其测量数据被称作“心灵指数”（Psycho-Pass/サイコパス）。其中“犯罪系数”是预测个人犯罪的可能标准，如果超过门槛会被公安局刑警追捕，甚至是就地处决。</p>
<blockquote>
<p>  计算人类的每个心理状态和个性倾向所衡量的值，通称：PSYCHO-PASS（心理测量者）被因而引进未来世界。因此，为让大众达到“理想的人生”这个指标，实现这些数值就变得非常积极。然而，有关犯罪的数值，也就是“犯罪指数”也会被测量，当然犯罪者亦是如此，但既使如说没有犯罪，可是其规定值超过的人也是会被列为潜在犯，将而受到制裁。这个故事是在描写为了维持治安的工作，公安局刑事课第一分队的成员活跃的表现。</p>
<p>  此处引用<a href="https://bangumi.tv/subject/37685" target="_blank" rel="noopener">番组计划–PSYCHO-PASS サイコパス</a></p>
</blockquote>
<h2 id="小说"><a href="#小说" class="headerlink" title="小说"></a>小说</h2><p>小说是由动画改编而来，不过高度还原了第一季的动画，尤其是动画中所提及到的书籍和人物，在小说中都可以找到与其对应的场景。不过就我来看，小说读起来更适合慢慢品尝，拥有思考的时间和空间也比较多。在我读过的众多小说中，很少有能像《心理测量者》这样，在作品中引用提及这么多与作品主题紧密相连的作品。</p>
<h2 id="小说中提到的书籍和人物"><a href="#小说中提到的书籍和人物" class="headerlink" title="小说中提到的书籍和人物"></a>小说中提到的书籍和人物</h2><p><img src="../img/image-20200105100638970.png" alt="image-20200106100538970"></p>
<ul>
<li>由于小说中的书籍都使用了中文《》符号，所以使用正则表达式过滤整本小说中的书籍，有些是影视作品</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@debian ~PSY</span><br><span class="line">╰─$ grep -Eo <span class="string">"《.*》"</span> PSYCHO-PASS.md</span><br><span class="line">《1984》</span><br><span class="line">《人类不平等的起源》</span><br><span class="line">《盗日者》</span><br><span class="line">《再见，电影》</span><br><span class="line">《第十二夜》</span><br><span class="line">《十二夜》</span><br><span class="line">《麦克白》和《泰特斯.安德洛尼克斯》</span><br><span class="line">《泰特斯.安德洛尼克斯》</span><br><span class="line">《泰特斯.安德洛尼克斯》</span><br><span class="line">《女吸血鬼卡蜜拉》</span><br><span class="line">《dear hunter》</span><br><span class="line">《夏威夷特警》</span><br><span class="line">《黑暗的中心》</span><br><span class="line">《黑暗的中心》。然后是司汤达的《红与黑》</span><br><span class="line">《被先行背叛的革命》</span><br><span class="line">《机器人会梦见机器羊吗》</span><br><span class="line">《神经漫游者》 《读数为零》 还有《Mona Lisa Overdrive 》</span><br><span class="line">《不道德的繁荣》</span><br><span class="line">《不道德繁荣》</span><br><span class="line">《格列弗游记》</span><br><span class="line">《不道德的繁荣》</span><br><span class="line">《深夜plus 1》</span><br><span class="line">《格列夫游记》</span><br><span class="line">《我的祖国》里的《莫尔道河》</span><br><span class="line">《1984》和福柯的《监狱的诞生》</span><br><span class="line">《活死人之夜》</span><br></pre></td></tr></table></figure>
<ul>
<li>简书上流传的另一个版本，总结的要比我好一些。但有些书我并没有在小说中找到。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">哲学&amp;政治&amp;社会学&amp;经济学&amp;心理学</span><br><span class="line"></span><br><span class="line">《论道德的谱系 善恶之彼岸》 尼采</span><br><span class="line"></span><br><span class="line">《悲剧的诞生》 尼采</span><br><span class="line"></span><br><span class="line">《查拉图斯特拉如是说》 尼采</span><br><span class="line"></span><br><span class="line">《论人与人之间不平等的起因和基础》 卢梭</span><br><span class="line"></span><br><span class="line">《社会契约论》 卢梭</span><br><span class="line"></span><br><span class="line">《思想录》 布莱兹·帕斯卡尔</span><br><span class="line"></span><br><span class="line">《大众的反叛》 奥尔特加·加塞特</span><br><span class="line"></span><br><span class="line">《经济与社会》 马克思·韦伯</span><br><span class="line"></span><br><span class="line">《道德与立法原理导论》 边沁</span><br><span class="line"></span><br><span class="line">《规训与惩罚》 米歇尔·福柯</span><br><span class="line"></span><br><span class="line">《探求真理的指导原则》 笛卡尔</span><br><span class="line"></span><br><span class="line">《哲学原理》 笛卡尔</span><br><span class="line"></span><br><span class="line">《致死的疾病》 索伦·克尔凯郭尔</span><br><span class="line"></span><br><span class="line">《被背叛的革命》 托洛茨基</span><br><span class="line"></span><br><span class="line">《乌合之众》 古斯塔夫·勒庞</span><br><span class="line"></span><br><span class="line">《非此即彼》索伦·克尔凯郭尔</span><br><span class="line"></span><br><span class="line">《纯粹理性批判》 伊曼努尔·康德</span><br><span class="line"></span><br><span class="line">《论法的精神》 孟德斯鸠</span><br><span class="line"></span><br><span class="line">《形而上学伦》 伏尔泰</span><br><span class="line"></span><br><span class="line">《拿破仑法典》</span><br><span class="line"></span><br><span class="line">《资本论》 卡尔·马克思</span><br><span class="line"></span><br><span class="line">《规训与惩罚：监狱的诞生》 福柯</span><br><span class="line"></span><br><span class="line">《当尼采在哭泣》 欧文·亚隆</span><br><span class="line"></span><br><span class="line">《战争论》 卡尔·冯·克劳塞维茨</span><br><span class="line"></span><br><span class="line">《黑皮肤，白面具》 弗朗茨·法农</span><br><span class="line"></span><br><span class="line">《追寻生命的意义》 维克多·E·弗兰克尔</span><br><span class="line"></span><br><span class="line">反乌托邦政治文学</span><br><span class="line"></span><br><span class="line">《一九八四》 乔治·奥威尔</span><br><span class="line"></span><br><span class="line">《动物农场》 乔治·奥威尔</span><br><span class="line"></span><br><span class="line">《美丽新世界》 赫胥黎</span><br><span class="line"></span><br><span class="line">《我们》 扎米亚京</span><br><span class="line"></span><br><span class="line">《这完美的一天》 艾拉·莱文</span><br><span class="line"></span><br><span class="line">戏剧&amp;文学</span><br><span class="line"></span><br><span class="line">《第十二夜》 莎士比亚</span><br><span class="line"></span><br><span class="line">《泰特斯·安德洛尼克斯》 莎士比亚</span><br><span class="line"></span><br><span class="line">《麦克白》 莎士比亚</span><br><span class="line"></span><br><span class="line">《斐多篇》 柏拉图</span><br><span class="line"></span><br><span class="line">《黑暗的心》 康拉德</span><br><span class="line"></span><br><span class="line">《预先被背叛的革命》 岩上安身 （无中文版）</span><br><span class="line"></span><br><span class="line">《少数派报告》 菲利普·迪克</span><br><span class="line"></span><br><span class="line">《机器人会梦见电子羊吗》 菲利普·迪克</span><br><span class="line"></span><br><span class="line">《神经漫游者》 威廉·吉布森</span><br><span class="line"></span><br><span class="line">《捍卫机密》 威廉·吉布森</span><br><span class="line"></span><br><span class="line">《格列佛游记》 乔纳森·斯威夫特</span><br><span class="line"></span><br><span class="line">《追忆似水年华》 马塞尔·普鲁斯特</span><br><span class="line"></span><br><span class="line">《克苏鲁神话》 霍华德·菲利普斯·洛夫克拉夫特</span><br><span class="line"></span><br><span class="line">《克苏鲁神话II》霍华德·菲利普斯·洛夫克拉夫特</span><br><span class="line"></span><br><span class="line">《再见了，电影》 寺山修司</span><br><span class="line"></span><br><span class="line">《幻想图书馆》 寺山修司</span><br><span class="line"></span><br><span class="line">《道林格雷的画像》 奥斯卡·王尔德</span><br><span class="line"></span><br><span class="line">《钢窟》 艾萨克·阿西莫夫</span><br><span class="line"></span><br><span class="line">《寂静的春天》 蕾切尔·卡森</span><br><span class="line"></span><br><span class="line">《忏悔录》 让·雅克·卢梭</span><br><span class="line"></span><br><span class="line">《理想国》 柏拉图</span><br><span class="line"></span><br><span class="line">《和谐》 伊藤计划</span><br><span class="line"></span><br><span class="line">宗教</span><br><span class="line"></span><br><span class="line">《圣经》</span><br></pre></td></tr></table></figure>
<p>下面就简单地介绍一下小说中提及的书籍和人物</p>
<h3 id="《1984》"><a href="#《1984》" class="headerlink" title="《1984》"></a>《1984》</h3><h4 id="出处"><a href="#出处" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106181920822.png" alt="image-20200106181920822"></p>
<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  《<strong>一九八四</strong>》（英语：<em>Nineteen Eighty-Four</em>），是<a href="https://zh.wikipedia.org/wiki/英國" target="_blank" rel="noopener">英国</a>作家<a href="https://zh.wikipedia.org/wiki/喬治·歐威爾" target="_blank" rel="noopener">乔治·奥威尔</a>所创作的一部<a href="https://zh.wikipedia.org/wiki/反乌托邦" target="_blank" rel="noopener">反乌托邦</a><a href="https://zh.wikipedia.org/wiki/小說" target="_blank" rel="noopener">小说</a><a href="https://zh.wikipedia.org/wiki/一九八四#cite_note-2" target="_blank" rel="noopener">[2]</a><a href="https://zh.wikipedia.org/wiki/一九八四#cite_note-3" target="_blank" rel="noopener">[3]</a>，出版于<a href="https://zh.wikipedia.org/wiki/1949年" target="_blank" rel="noopener">1949年</a>。其重点探讨政府权力过分伸张、极权主义、对社会所有人和行为实施压抑性统治的风险<a href="https://zh.wikipedia.org/wiki/一九八四#cite_note-BenetReader-4" target="_blank" rel="noopener">[4]</a><a href="https://zh.wikipedia.org/wiki/一九八四#cite_note-aaron-5" target="_blank" rel="noopener">[5]</a>。故事发生的时间设于1984年——为当时作者对未来的虚构想像。在其构想中，世界大部分地区都陷入了一场永久的战争、政府监控无处不在、资料记录中满是历史否定主义及<a href="https://zh.wikipedia.org/wiki/政治宣傳" target="_blank" rel="noopener">政治宣传</a>。其为反乌托邦小说类三部代表作之一（另外两部是《<a href="https://zh.wikipedia.org/wiki/我们_(小说" target="_blank" rel="noopener">我们</a>)》和《<a href="https://zh.wikipedia.org/wiki/美麗新世界" target="_blank" rel="noopener">美丽新世界</a>》）。</p>
</blockquote>
<h3 id="《论人类不平等的起源和基础》"><a href="#《论人类不平等的起源和基础》" class="headerlink" title="《论人类不平等的起源和基础》"></a>《论人类不平等的起源和基础》</h3><h4 id="出处-1"><a href="#出处-1" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182021903.png" alt="image-20200106182021903"></p>
<h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  《论人类不平等的起源和基础》为卢梭1753年应法国第戎科学院的征文而撰写的论文，出版于1755年。在书中，卢梭阐发了自身的政治哲学，为《社会契约论》的写作奠定了基础。不同于同时代哲学家的乐观认识，卢梭将人类历史的发展过程视作进步与退化的矛盾统一体。他一方面借助当时有关野蛮人的人类学材料，一方面展开辩证的想象，回顾了人类由自然状态向社会状态过渡的历史进程，指出人类的进步史同时也是人类的堕落史，因为人类每向前发展一步，不平等的程度即加深一步。而私有制的确立，是造成人类不平等及其后果的关键环节。</p>
</blockquote>
<h3 id="《第十二夜》"><a href="#《第十二夜》" class="headerlink" title="《第十二夜》"></a>《第十二夜》</h3><h4 id="出处-2"><a href="#出处-2" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182054337.png" alt="image-20200106182054337"></p>
<h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  《第十二夜》（或《各遂所愿》）是莎士比亚着名喜剧之一，约作于1600年，全剧五幕十八场。主要情节是：伊利里亚公爵奥西诺向奥丽维亚小姐求爱，屡遭拒绝。这时，一对孪生兄妹航海到伊利里亚，在附近海上遇难。妹妹薇奥拉改扮男装，投身奥西诺公爵家中为侍童，并充当了代他向奥丽维亚小姐求爱的使者。奥丽维娅对女扮男装的薇奥拉一见钟情，而薇奥拉却偷偷爱上了公爵。后来，奥丽维亚碰巧遇上薇奥拉的孪生兄长西巴斯辛，两人以误就误地结成夫妇。公爵也和薇奥拉终成眷属。全剧以兄妹相聚，情人结合而告终。</p>
</blockquote>
<h3 id="《麦克白》"><a href="#《麦克白》" class="headerlink" title="《麦克白》"></a>《麦克白》</h3><h4 id="出处-3"><a href="#出处-3" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182147846.png" alt="image-20200106182147846"></p>
<h4 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  《麦克白》内容简介：苏格兰国王邓肯的表弟麦克白将军，为国王平叛和抵御入侵立功归来，路遇三个女巫。女巫对他说了一些预言和隐语，说他将进爵为王，但他并无子嗣能继承王位，反而是同僚班柯将军的后代要做王。麦克白是有野心的英雄，他在夫人的怂恿下谋杀邓肯，做了国王。为掩人耳目和防止他人夺位，他一步步害死了邓肯的侍卫，害死了班柯，害死了贵族麦克德夫的妻子和小孩。恐惧和猜疑使麦克白心里越来越有鬼，也越来越冷酷。麦克白夫人神经失常而自杀，对他也是一大刺激。在众叛亲离的情况下，麦克白面对邓肯之子和他请来的英格兰援军的围攻，落得袅首的下场。</p>
</blockquote>
<h3 id="《泰特斯-安德洛尼克斯》"><a href="#《泰特斯-安德洛尼克斯》" class="headerlink" title="《泰特斯.安德洛尼克斯》"></a>《泰特斯.安德洛尼克斯》</h3><h4 id="出处-4"><a href="#出处-4" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182216263.png" alt="image-20200106182216263"></p>
<h4 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  《泰特斯•安德洛尼克斯(英文版)》是莎士比亚所作最早的悲剧，当时他只有27岁。《泰特斯•安德洛尼克斯(英文版)》是一部罗马式的血腥的复仇剧，当年很流行，现在则很少演出。它是阅读莎士比亚悲剧的一出很好的入门戏，因为它的语言比较容易，而且内容方面包含了许多后来莎士比亚加以发展的因素的萌芽。</p>
</blockquote>
<h3 id="《女吸血鬼卡蜜拉》"><a href="#《女吸血鬼卡蜜拉》" class="headerlink" title="《女吸血鬼卡蜜拉》"></a>《女吸血鬼卡蜜拉》</h3><h4 id="出处-5"><a href="#出处-5" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182224076.png" alt="image-20200106182224076"></p>
<h4 id="简介-5"><a href="#简介-5" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  《女吸血鬼‧卡蜜拉》（CARMILLA）是英國怪異小說作家喬瑟夫‧協利丹‧雷‧法紐在一八七二年所發表的怪異小說。</p>
<p>  愛爾蘭這個國家是經常會出現怪異小說的土地。所謂「怪異小說」是與當地的民俗和傳說有密切的關連。</p>
<p>  在很久以前，吸血鬼的傳說始於羅馬尼亞與南斯拉夫，之後遍傳歐洲各地。以此為基礎，世界各國也開始出現了吸血鬼小說。</p>
<p>  直到二怚@紀，美國仍然發表了許多吸血鬼小說，甚至隔幾年就有一些吸血鬼電影出現，一九九四年由好萊塢英俊小生湯姆‧克魯斯所主演的《夜訪吸血鬼》又一次造成轟動，也風靡了全世界的影迷，吸血鬼的魅力是歷久不衰的……</p>
</blockquote>
<h3 id="《黑暗的心》"><a href="#《黑暗的心》" class="headerlink" title="《黑暗的心》"></a>《黑暗的心》</h3><p>中文译文翻译错误，这里应该是[英] 约瑟夫·康拉德的《黑暗的心》</p>
<h4 id="出处-6"><a href="#出处-6" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182319646.png" alt="image-20200106182319646"></p>
<h4 id="简介-6"><a href="#简介-6" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  本书包括了原书的全文，还由美国文学方面的学者作了详尽的注释，帮助读者理解原文。注释既包括语言方面的内容，又介绍了一些文化背景方面的知识。是公认的二十世纪文学经典、剥葱皮一样把殖民主义者的心态一层层刻画得淋漓尽致。本书具有鲜明的现代主义特色。作者康拉德用了马洛这样一个叙述者，让他以回忆者的身份出现在故事里，他的叙述穿梭于过去与现在、自己和库尔兹及听众之间，让读者分享着他的各种情绪，这种叙述角度的交替，开创了一种新的叙述模式，代替了传统的线性叙述方法。另外，小说中隐喻、象征等修辞手段的运用还使作品极具可读性。“黑暗的心”本身就含有双层寓意：既指地理意义上的黑色的非洲腹地，也指殖民者黑暗的内。本书大量修辞手法的运用大大丰富了作品的意蕴，深化了小说的主题，使小说的思想内容、艺术风格不亚于20世纪任何一部现代主义小说。</p>
</blockquote>
<h3 id="《红与黑》"><a href="#《红与黑》" class="headerlink" title="《红与黑》"></a>《红与黑》</h3><h4 id="出处-7"><a href="#出处-7" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182331036.png" alt="image-20200106182331036"></p>
<h4 id="简介-7"><a href="#简介-7" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  出身平民的青年于连靠着自己的聪明才智和毅力。为了实现自己巨大的野心而在一个等级森严的社会里奋斗。正当他自以为踏上了飞黄腾达的埋途和得到了超越阶级的爱情之时，社会却无情地把他送上了断头台。</p>
</blockquote>
<h3 id="《被先行背叛的革命》"><a href="#《被先行背叛的革命》" class="headerlink" title="《被先行背叛的革命》"></a>《被先行背叛的革命》</h3><p>这里中文译文翻译应该为《预先被背叛的革命》</p>
<h4 id="出处-8"><a href="#出处-8" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182341811.png" alt="image-20200106182341811"></p>
<h4 id="简介-8"><a href="#简介-8" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  20世紀最大の実験、ソビエトは無残に崩壊した。都市に拝金主義が横行しマフィアが跋扈する時、地方では血みどろの民族紛争が激化する。色褪せた理想、剥出しの欲望。モスクワ、グルジア、チェチェンなど歴史的な大転換の現場にとびこみ、渾身の取材でロシアの闇に迫った講談社ノンフィクション賞受賞作。</p>
</blockquote>
<h3 id="《机器人会梦见机器羊吗》"><a href="#《机器人会梦见机器羊吗》" class="headerlink" title="《机器人会梦见机器羊吗》"></a>《机器人会梦见机器羊吗》</h3><p>这里应该翻译为《仿生人会梦见电子羊吗？》</p>
<h4 id="出处-9"><a href="#出处-9" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182352843.png" alt="image-20200106182352843"></p>
<h4 id="简介-9"><a href="#简介-9" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  核战后，放射尘让地球上的动物濒临灭绝，地球已不再适合人类居住。为了鼓励残存的人口移民，政府承诺，只要 移民到外 星球，就可以为每个人自动配备一个仿生人帮助其生活。仿生人不满足于被人类奴役的现状，想方设法逃回地球。</p>
<p>  主人公里克•德卡德是一名专门追捕逃亡仿生人的赏金猎人。在一次 追捕行动中，里克遭遇了新型仿生人前所未有的挑战。九死之后，能否一生？在与仿生人的接触和较量中，里克发现自己对仿生人的看法和态度有了很大的改变。这种改变究竟是福还是祸？</p>
</blockquote>
<h3 id="《神经漫游者》"><a href="#《神经漫游者》" class="headerlink" title="《神经漫游者》"></a>《神经漫游者》</h3><h4 id="出处-10"><a href="#出处-10" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182404447.png" alt="image-20200106182404447"></p>
<h4 id="简介-10"><a href="#简介-10" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  “1923年以来100本最佳英文小说”之一</p>
<p>  “赛博朋克”圣经 • 史无前例的得奖记录：囊括雨果奖、星云奖、菲利普•迪克奖</p>
<p>  这就是催生了《黑客帝国》的那部小说</p>
<p>  它开启了赛博朋克这个文学类型，它给了我们“网络空间”这个词，它将这个世界带到了信息时代，它提供了无数灵感给《黑客帝国》《攻壳机动队》以及所有最先锋的音乐、时尚、游戏……</p>
<p>  而它仍然新鲜得仿佛昨天才刚刚写出来，仍然眩目得可以震撼到未来三十年的人类。</p>
<p>  “这部小说问世十年后，我们才终于认识到它的重大意义。” ——《纽约时报》</p>
<p>  “这里有无数个大千世界，这是写给都市流浪人的歌，它如此耀眼，又如此颓靡……” ——《华盛顿邮报》</p>
<p>  一个天才黑客，一个女杀手，一个特种部队军官，一个意识操控专家。他们受雇去做两件事：偷一把钥匙，获得一个密码。</p>
<p>  他们是职业罪犯，同时也是无可救药的厌世者；他们自我放逐，同时也在下意识寻找一条回家的路。而他们的雇主，则是人类自有文明以来所遇到过的最强大对手……</p>
<p>  …(展开全部)</p>
</blockquote>
<h3 id="《读数为零》"><a href="#《读数为零》" class="headerlink" title="《读数为零》"></a>《读数为零》</h3><p>这里翻译应该为《读数归零》</p>
<h4 id="出处-11"><a href="#出处-11" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182408186.png" alt="image-20200106182408186"></p>
<h4 id="简介-11"><a href="#简介-11" class="headerlink" title="简介"></a>简介</h4><p><a href="https://zh.wikipedia.org/wiki/威廉·吉布森" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E5%A8%81%E5%BB%89%C2%B7%E5%90%89%E5%B8%83%E6%A3%AE</a></p>
<h3 id="《Mona-Lisa-Overdrive-》"><a href="#《Mona-Lisa-Overdrive-》" class="headerlink" title="《Mona Lisa Overdrive 》"></a>《Mona Lisa Overdrive 》</h3><h4 id="出处-12"><a href="#出处-12" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182410724.png" alt="image-20200106182410724"></p>
<h3 id="《不道德的繁荣》"><a href="#《不道德的繁荣》" class="headerlink" title="《不道德的繁荣》"></a>《不道德的繁荣》</h3><p>这个应该不是书籍，能查到的是相关的电影</p>
<h4 id="出处-13"><a href="#出处-13" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182427002.png" alt="image-20200106182427002"></p>
<h3 id="《格列弗游记》"><a href="#《格列弗游记》" class="headerlink" title="《格列弗游记》"></a>《格列弗游记》</h3><h4 id="出处-14"><a href="#出处-14" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182440302.png" alt="image-20200106182440302"></p>
<h4 id="简介-12"><a href="#简介-12" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  《格列弗游记》主要内容：莱缪尔•格列弗是一个对冒险有着特别渴望的外科医生。然而当他登上“羚羊号”航船出航南太平洋时，所发生的一切经历却让他始料不及。一场海难使他流落于遥远而陌生的荒岛，岛上的居民身形微小，甚至连他手指甲的大小也不及！奇妙的冒险刚刚开始。接下来格列弗还会有什么惊心动魄的经历呢？他能安然地回到自己的家乡吗？让我们随着这部历久不衰的小说踏上非凡的冒险之旅，一起寻找心中的答案吧！</p>
</blockquote>
<h3 id="《深夜plus-1》"><a href="#《深夜plus-1》" class="headerlink" title="《深夜plus 1》"></a>《深夜plus 1》</h3><h4 id="出处-15"><a href="#出处-15" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182503132.png" alt="image-20200106182503132"></p>
<h3 id="《我的祖国》里的《莫尔道河》"><a href="#《我的祖国》里的《莫尔道河》" class="headerlink" title="《我的祖国》里的《莫尔道河》"></a>《我的祖国》里的《莫尔道河》</h3><h4 id="出处-16"><a href="#出处-16" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182532220.png" alt="image-20200106182532220"></p>
<h4 id="简介-13"><a href="#简介-13" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  《<strong>我的祖国</strong>》（捷克语：Má vlast）是捷克作曲家<a href="https://zh.wikipedia.org/wiki/贝多伊齐·斯美塔那" target="_blank" rel="noopener">贝多伊齐·斯美塔那</a>在1874年－1879年间完成的<a href="https://zh.wikipedia.org/wiki/交响诗" target="_blank" rel="noopener">交响诗</a>作品，是由六首色彩缤纷而富戏剧性的管弦乐曲所组成。尽管这六部分乐章常被认定为一个整体而演奏（其中包括著名的《伏尔塔瓦河》），它的每个乐章其实是独立作品。每部分在1875年至1880年都独自举办了首演。真正六部分合一的完整“首演”直到1882年11月5日才在<a href="https://zh.wikipedia.org/wiki/布拉格" target="_blank" rel="noopener">布拉格</a>举行。</p>
</blockquote>
<h3 id="《监狱的诞生》"><a href="#《监狱的诞生》" class="headerlink" title="《监狱的诞生》"></a>《监狱的诞生》</h3><h4 id="出处-17"><a href="#出处-17" class="headerlink" title="出处"></a>出处</h4><p><img src="../img/image-20200106182541744.png" alt="image-20200106182541744"></p>
<h4 id="简介-14"><a href="#简介-14" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>  本书旨在论述关于现代灵魂与一种新的审判权力之间相互关系的历史，论述现行的科学—法律综合体的系谱。在这种综合体中，惩罚权力获得了自身的基础、证明和规则，扩大了自己的效应，并且用这种综合体掩饰自己超常的独特性。……如果这意味着写一部关于现在的历史，那才是我的兴趣所在。在我这一代对我们的时代进行诊断的哲学家圈子里，福柯是对时代精神影响最持久的。</p>
</blockquote>
<h2 id="摘抄"><a href="#摘抄" class="headerlink" title="摘抄"></a>摘抄</h2><ul>
<li><blockquote>
<p>乌尔希里·贝克（经常说的话。指社会依赖‘便利但危险’的东西，政/府让我们背负起风险……但风险被巧妙地分散，分配以至于谁也没觉察到，不对，不是没觉察到，而是即使觉察了也当没看见，或许每个人都在睁一只闭一只眼，危险固然存在，但如果不反过来当作其不存在的话就无法保持理智。</p>
</blockquote>
</li>
</ul>
<p>此处相关的书籍为 乌尔希里·贝克的《风险社会：新的现代性之路》</p>
<ul>
<li><blockquote>
<p>“所谓网络，不是像料理东西的刀具，或是为了记录而产生的纸那种等级的东西。这不是好坏的问题。而是‘这是已经存在的东西所以接受吧、使用吧’这种论调。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“虚拟形象和可视影像什么的。建立在社交网络上的社交场……不是把他们当笨蛋，是真的理解不了。好玩到停不下来吗？呼吸的、流汗的、吃东西的，终究还是这个身体啊。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“就是这样，这就是人类的社会性。语言、书信、货币、电话……这个世间所存在的一切交流工具，都是为了强化社会性的。”</p>
</blockquote>
</li>
<li><blockquote>
<p>哲学家柏拉图提出的理想论。所谓理想（idea）是？这个世界不存在“严密的”三角形。但是，我们理解理想的究极的三角形。如果看到歪曲的三角形，就会和自己心中的三角形作比较。理想（idea）就是“究极的理想的存在”。</p>
</blockquote>
</li>
<li><blockquote>
<p>御堂是不仅使用了爆炸物还入侵了投影的犯人——肯定有着什么背景。虽然对宜野座来说还是麻醉更好，但支配者不允许这样做。主张“绝对要杀死”，不听人类话的枪。人类和支配者，到底哪边才是“上”？当然是连接着西比拉系统的支配者。</p>
</blockquote>
</li>
<li><blockquote>
<p>朱在休息室淋浴。朱把水调到能忍受的最热的温度，认为这样全身的血液循环会好一些。洗好澡后她一边喝着休息室冰箱里常备的运动饮料，一边检查色相。饮酒引发的影响几乎没有……不，不如说压力得到了缓解。酒精饮料“只要不过量就对身心有好处”这种说法好像是真的。只是现在喝酒的人基本上没有了，为何上世纪的全体人民都受酒精依存症所苦呢。</p>
</blockquote>
</li>
<li><blockquote>
<p>所有的资料都不是电子化的，而是通过复印制成档案。狡噛有着不信任电子媒体的偏执倾向，不能把重要的东西放在网上。狡噛突然开始反复检索起这些资料来。</p>
</blockquote>
</li>
<li><blockquote>
<p>朱已经什么都说不来了。自己曾经以为理所当然的事其实不过是社会的表象，这种真相赤裸裸的摆在了她面前。</p>
</blockquote>
</li>
<li><blockquote>
<p>“柏拉图曾说过，肉体是灵魂的牢狱。”</p>
</blockquote>
</li>
<li><blockquote>
<p>思想家托马斯霍布斯看来，人类就像被称为心脏的引擎运作的机器。这是机械的运动论。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“因一些机械的故障，虽然只是一时的，但你失去了社会性。明明自己的生活依托电子装置到这种程度，就算说不是义体也没有说服力呢。对你来说携带情报终端已经是第二个脑了。不是吗？”</p>
</blockquote>
</li>
<li><blockquote>
<p>要点。‘英雄般的、预言者般的资质’。还有‘与其共处令人愉快的简单的空间演出能力’。最后是‘可以雄辩万物的知性’。以上三点。狡噛在寻找的人是什么类型的？”</p>
</blockquote>
</li>
<li><blockquote>
<p>“人在面对恐怖之时，可以试出自己的灵魂。追求什么、为何而生，这些本性都会变得明了。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“用生物扫描读取生物场后解析，解明人心之所在……科学的智慧终于到了能暴露灵魂的地步，这个社会发生了激变。”</p>
</blockquote>
</li>
<li><blockquote>
<p>朱的声音在颤抖。——有什么不能理解的事情，正在发生。把到现在为止的自己的常识——不，是动摇了社会的常识的什么东西</p>
</blockquote>
</li>
<li><blockquote>
<p>“西比拉系统不能计算我的罪。如果有能够制裁我的人的话，那一定只有——可以靠自己的意志杀人的人。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“笛卡尔曾说过，不能做出决断的人，是欲望过于巨大而又悟性不足的人。……怎么了？不好好瞄准的话会射偏哦。”</p>
</blockquote>
</li>
<li><blockquote>
<p>混乱时期当然没时间搞文化艺术，在西比拉系统的运营下，思考和想象也受到某种程度的限制。狡嚙经常读的书也是，这么说来都是老书比较合心意。</p>
</blockquote>
</li>
<li><blockquote>
<p>“你……做到这种程度……”宜野座无法去看朱的眼睛。虽然朱仅仅是微笑着，但让他觉得自己受到了责备。她好像镜子一样。用透明的色相，映出窥视她内心的人的心。</p>
</blockquote>
</li>
<li><blockquote>
<p>在这个社会里，不让Psycho=pass恶化是最重要的事情。就算是落下来的狡啮，对这种程度的事也是明白的。——不，正是因为从中退出了，所以了解的更为深刻。想要走监视官这种精英路线，就是一点点和Psycho=pass恶化有关的行为都要回避。但是，朱并不害怕。而宜野座跟她正相反……”</p>
</blockquote>
</li>
<li><blockquote>
<p>“那个孩子原谅、认可、接受这个世界。所以就算是走钢丝也没关系。她毫无怀疑的、坚信着着刑事的意义和价值。那个孩子做不到的，只有无视西比拉系统了。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“是啊。结果可能是我错了。确实，现在这个世代，比我年轻时的那个世代更加和平，更加富庶。认可了这个，变得觉得怎样都好的时候，我的犯罪系数就不再上升了。我好像终于能和这个世界妥协了。……</p>
</blockquote>
</li>
<li><blockquote>
<p>就跟哥伦布的鸡蛋一样，狡嚙想。比起伪造数字，明显是做个假的扫描器简单。</p>
</blockquote>
</li>
<li><blockquote>
<p>“过分的不是我们，而是修比拉系统啊。因为修比拉的判定，我们已经找不到什么像样的工作了。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“可能更像飞利浦·K·迪克吧”慎岛说道 “不像乔治·奥威尔笔下社会那般有支配性，也不像吉布森描写的那样野蛮”</p>
</blockquote>
</li>
<li><blockquote>
<p>“到时候我去下载来看” “去买纸质本吧，电子书籍读起来没有感觉” “是吗” “书这种东西，不止是用来看上面的文字的，也是调整自己感觉的工具”</p>
</blockquote>
</li>
<li><blockquote>
<p>“状态不好时，有时候书的内容会进不到脑子里，这时候就要思考是什么干扰了读书，有些书即使在状态不好时也能顺利的看下去，这时候就想想为什么会这样。—</p>
</blockquote>
</li>
<li><blockquote>
<p>调率的时候最重要的是手指触碰书页时的感觉和哗啦哗啦翻书的瞬间给脑神经的刺激”</p>
</blockquote>
</li>
<li><blockquote>
<p>  nona塔。九十层楼外加数十米的屋顶设施。环境投影全开的nona塔就如近代改修的大圣堂一般。在这只有日本这一唯一“残存的发达国家”的二十二世纪。这座塔毫无疑问处在世界中心的顶点上。 慎岛一行人破坏了入口处的六台警备多隆，强行袭击了位于二楼的一般职员办公室，虽然发生了紧急事件但依然有职员留守，这些人就被用射钉枪和镭射工具杀害了。杰克孙取出笔记本电脑，有线接入职员用电脑，展开投影键盘。直接进行情报收集。“这座塔里电力消费较多的地方，有两处呢，分别靠近顶楼和地下。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“正义会播下争论的种子，而力量却毫无争议，因此，人类未能将力量赋予正义” 狡啮听罢 “抱歉啊，我很久以前就知道‘应该留意引用帕斯卡的话的人’。”</p>
</blockquote>
</li>
<li><blockquote>
<p>知道自己会死——这是种奇妙的心境。就像下落感一样，恐怖，不安，还有一点解放感——各种感觉交织在一起，思考无法集中到一个方向。而最后还想着的，果然还是一科的同伴们。从刚刚遇到朱时的反感，不知何时被信赖感取而代之。是她的率直造成的。托大家的福，度过了短暂但却充实的日子。狡啮，征陆，宜野座，六合冢，唐之杜——。自己眼前所见，没能告诉狡啮和朱真是太可惜了。</p>
</blockquote>
</li>
<li><blockquote>
<p>“安全，完美的社会只是个幻想罢了。我们生活的社会如今还是‘危险社会’” “什么意思……？” “很久以前……德国还算个国家的时候，有个社会学家，乌尔希里·贝克（经常说的话。指社会依赖‘便利但危险’的东西，政/府让我们背负起风险……但风险被巧妙地分散，分配以至于谁也没觉察到，不对，不是没觉察到，而是即使觉察了也当没看见，或许每个人都在睁一只闭一只眼，危险固然存在，但如果不反过来当作其不存在的话就无法保持理智。 “这座城市的市民，会想到这么多么，就连我也算在内。“</p>
</blockquote>
</li>
<li><blockquote>
<p>“……真是让人笑掉大牙，不依靠人类自己，而是依靠机器运行公平的社会，正是如此宣传才让民众接受了修比拉系统”慎岛稍微有些惊呆的说到“那机器的实体，竟是人脑的集合体？迄今为止修比拉系统所进行的社会统治全都是你们肆意妄为的结果？”</p>
</blockquote>
</li>
<li><blockquote>
<p>“成为修比拉系统构成人员的首要资格就是不被社会规范束缚的人格。不感同身受，也不和他人有情感上的交流，从外侧俯瞰人类的行为并作出裁定。系统正是需要这种才能，比如说像我，藤间幸三郎这样的，而槙岛圣护，你也是这样的人。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“啊，就这样成为了系统的一员。最初还有些疑惑，但马上就理解到这样做的伟大了，和他人的脑共有知识，理解力和判断力扩张的全能感，简直就是神话中登场的预言者一样的感觉。无所不知，感觉世间万物都在自己的支配下。一个人的肉体获得的快乐终有限度，但知性所带来的快乐是无限的，圣护君，你应该懂的吧？”</p>
</blockquote>
</li>
<li><blockquote>
<p>“否定修比拉系统的话，如今的社会将不复存在，这次暴动让我又一次体会到人们是多么依靠系统。对付头盔的方法即将应用于全部装置，平静的日常即将回归。——尽管如此，身为刑事的为我们却要帮忙破坏系统吗？在资本主义社主义都衰落的当今世界，我们能否定系统，再提出能够替代系统的东西吗？</p>
</blockquote>
</li>
<li><blockquote>
<p>深爱着秩序，又被秩序深爱的女性。同时具备纯粹的坚强与脆弱的女性。狡啮和朱在很多地方很相似，但朱却真正有着重要的东西。</p>
</blockquote>
</li>
<li><blockquote>
<p>“话说狡啮，反/政/府主义的定义是什么？” “否定支配和权力，但又不等同于混乱和无秩序”</p>
</blockquote>
</li>
<li><blockquote>
<p>“借用马克思·韦伯的话，理想的官僚是“既无愤怒也无不公平”，而且“既无憎恶也无激情”“既无爱也无狂热”，一味的履行“义务”的人。从这点来说，修比系统可能和理想的官僚行政方式最为接近。但是，一切都是以公开的修比拉系统的事情是真的为前提的。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“在稍微引用一下马克思·韦伯的话吧，官僚制的行政指的是依靠知识支配大众，专业只是与实践知识。并通过让这些知识成为秘密来提高优越性。” “槙岛打算剥下这层优越性”</p>
</blockquote>
</li>
<li><blockquote>
<p>“那家伙的话……会在马克思韦伯被抬出来的下一瞬间引用福柯和杰里米·边沁的话回应吧。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“我们过去，还具备独立的人格和肉体的时候，全都是脱出修比拉系统管理的免罪体质者。其中有很多人犯下过远比槙岛圣护更加残忍的罪行”</p>
</blockquote>
</li>
<li><blockquote>
<p>比起不安定且贪婪的人类更值得信赖，无感情的系统——这才是我们在修比拉身上追求的东西。 “首先要通过排除善与恶这种相对价值观，而后即可建立起绝对的系统，重要的是一个完美无瑕的系统，至于它由谁来运营不是重点。”</p>
</blockquote>
</li>
<li><blockquote>
<p>实现消除所有矛盾的合理社会，那才是所有人类所追求的终极幸福。作为完美无瑕的系统，修比拉正体现着这一理想。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“现在你从生理上厌恶我们，从感情上憎恶我们，即便如此依然不能否定修比拉系统的意义和必要性。将没有修比拉系统现在的社会秩序不会成立这一事实当作大前提。你那比起正当性更看重必要性的价值基准，我等给与了很高的评价。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“常守朱和修比拉系统有着共同的目的意识。因此我们认为你暴露我们的秘密将系统至于危险之下的可能性无限低。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“就着这样，想点头却踌躇不前，你所描绘的理想没明确到能否定如今建立起的社会秩序。你觉得现在的和平社会，市民的幸福和制度带来的安逸是最重要的东西。因此无论如何憎恶，否定作为这一制度基石的修比拉系统，你都无法拒绝</p>
</blockquote>
</li>
<li><blockquote>
<p>“常守朱，你也否定着狡啮慎也对槙岛圣护进行个人制裁这件事。你和我等在避免感情用事造成无益牺牲这一价值观上是共同的。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“我只是觉得槙岛的罪孽应该受到正确的裁决，你们也是，有过前科的话就应该付出相应的代价。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“通过解析精神扫描得到的生体数据，人心终于被解明……科学的英知终于揭示了灵魂的秘密，社会因此巨变，但这种判断并不存在人的意志，你们究竟以何基准判别善恶呢？”</p>
</blockquote>
</li>
<li><blockquote>
<p>“耶稣又设个比喻对他们说：‘天国好像人撒好种在田里，及至人睡觉的时候，有仇敌来，将稗子（一种恶性杂草）撒在麦子里就走了。’” 摘自马太福音，十三章·二十五节。</p>
</blockquote>
</li>
<li><blockquote>
<p>槙岛哼起斯美塔那的《我的祖国》里的《莫尔道河》（斯美塔那 捷克作曲家 我的祖国为其创作的交响曲 莫尔道河为其第二段） 斯美塔那不错，槙岛心想，</p>
</blockquote>
</li>
<li><blockquote>
<p>“靠和他人产生联系确立自我的时代早就结束了。每个人都被系统守护着，遵从系统定下的规范生活的世界里，人际圈什么的完全没必要存在。每个人都只是在狭窄的单间里过着自己娇生惯养的小日子而已。</p>
</blockquote>
</li>
<li><blockquote>
<p>人们憎恨邪恶，找寻正确生存之道的意志，这些意志的的累积就是法律，它不是条文，也不是系统，而是每个人心中都有的，脆弱，却无可替代的意志。它和愤怒与仇恨比起来脆弱的不堪一击，简简单单就能毁坏殆尽。</p>
</blockquote>
</li>
<li><blockquote>
<p>“…….留了不少血嘛，有这么多的血说不定都够写一本书了，让我想起了尼采的话” “是那句‘一切文字中,我独爱以血书就者’吗？”狡啮用疲惫的声音问</p>
</blockquote>
</li>
<li><blockquote>
<p>“别小看人类，我们无时无刻不向往着更加美好的世界。总有一天会有人来关掉这件屋子的电源，即便那个人不是我，在新时代也一定会有人开拓出全新的道路，修比系统，你们根本没有未来。”</p>
</blockquote>
</li>
</ul>
<h2 id="个人推荐"><a href="#个人推荐" class="headerlink" title="个人推荐"></a>个人推荐</h2><p>对这些书籍和作品有了大概的了解，看了一下自己喜欢的，发现还有狠多没读过，书单手下啦：</p>
<ul>
<li>1984</li>
<li>论人类不平等的起源和基础</li>
<li>规则与惩罚：监狱的诞生</li>
<li>仿生人会梦见电子羊吗？</li>
<li>红与黑</li>
<li>神经漫游者</li>
<li>风险社会：新的现代性之路</li>
</ul>
]]></content>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>网页小说制作 kindle 电子书</title>
    <url>/archives/make-e-book-from-html.html</url>
    <content><![CDATA[<h2 id="弄啥咧"><a href="#弄啥咧" class="headerlink" title="弄啥咧"></a>弄啥咧</h2><p>上个月看完了<a href="https://zh.wikipedia.org/zh/PSYCHO-PASS" target="_blank" rel="noopener">心理测量者</a>动画第一季和第二季，剧场版还有刚刚完结的第三季。看完之后对这部作品想更加深入地了解一下。对反乌托邦题材的作品也更加感兴趣了，就像之前看的《1984》、《美丽新世界》等等。综合最近读过的书，以及生活中的遭遇，准备写一篇万字左右的感想。（:又挖坑啦😂</p>
<p>去亚马逊 kindle 商店里找了找并没有中文版，搜了一下貌似也没与找到纸质出版的中文版。读原文是不可能的啦，日本语苦手😂。只能去找现有的资源了，在 <a href="http://www.qinxiaoshuo.com/book/PSYCHO-PASS心理测量者" target="_blank" rel="noopener">亲小说</a> 网站上找到了资源😂，但并没有下载全文的选项，对于咱这种靠技术搬砖的社畜来讲，还是拒绝当伸手党，把这些文本抓取下来，自己制作一个 mobi 格式的电子书看吧。</p>
<p><img src="../img/image-20200103094338061.png" alt="image-20200103094338061"></p>
<p>看了一下，心理测量者这本书的 <a href="http://www.qinxiaoshuo.com/book/PSYCHO-PASS心理测量者" target="_blank" rel="noopener">目录页面</a> 包含了所有的章节，就想到了大致思路。</p>
<ul>
<li>从这本书的目录页面过滤出来所有章节的 URL</li>
<li>分析各个章节的源码，过滤出中文小说文本内容</li>
<li>shell 脚本 for 循环，通过 curl 遍历上一步获取到的 URL ，通过关键字过滤出中文文本</li>
<li>获取完全部章节的文本之后，分析一下文本，添加 <code>&lt;h2&gt;</code> 标签二级标题，方便生成目录</li>
<li>完成上述步骤后，生成的文本中还有大量的 html 标签没有去除，需要使用 <code>pandoc</code> 转 <code>.docx</code>，或者转成 <code>markdown</code>来把<code>&lt;br/&gt;</code> 换行符以及 <code>&lt;p&gt;</code> 标签去除掉换成 <code>\n</code> 换行符。</li>
<li>最终得到 <code>.docx</code> 之后，使用 <code>Calibre</code> 将 <code>.docx</code> 转换成 Kindle 支持的 <code>mobi</code> 格式</li>
</ul>
<h2 id="怎么弄"><a href="#怎么弄" class="headerlink" title="怎么弄"></a>怎么弄</h2><h3 id="获取各章节的-URL"><a href="#获取各章节的-URL" class="headerlink" title="获取各章节的 URL"></a>获取各章节的 URL</h3><ul>
<li><code>ctrl + s</code> 另保存 <code>pass.html</code> 这个目录页的源代码，拿到这个页面的源代码之后，仔细分析一下，可以看到，这个页面的各个章节还是比较有规律的。通过简单的  grep 和 sed 替换就很轻松地把这些 URL 提取出来。</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"chapters"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"序"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35056fec85e5b101448.html"</span>&gt;</span>序<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"01 犯罪系数"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35156fec85e5b101449.html"</span>&gt;</span>01 犯罪系数<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"02 有能者"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35156fec85e5b10144a.html"</span>&gt;</span>02 有能者<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"03 饲育的作法"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35156fec85e5b10144b.html"</span>&gt;</span>03 饲育的作法<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"04 谁都不知道的你的假面"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35156fec85e5b10144c.html"</span>&gt;</span>04 谁都不知道的你的假面<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"05 无人知道的你的面孔"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35156fec85e5b10144d.html"</span>&gt;</span>05 无人知道的你的面孔<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"06 狂王子的归还"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35156fec85e5b10144e.html"</span>&gt;</span>06 狂王子的归还<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"07 紫兰的花语"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35256fec85e5b10144f.html"</span>&gt;</span>07 紫兰的花语<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"08 之后是，沉默"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35256fec85e5b101450.html"</span>&gt;</span>08 之后是，沉默<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"09 乐园的果实"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35256fec85e5b101451.html"</span>&gt;</span>09 乐园的果实<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"10 玛土撒拉的游戏"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35256fec85e5b101452.html"</span>&gt;</span>10 玛土撒拉的游戏<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"11 圣者的晚餐"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35256fec85e5b101453.html"</span>&gt;</span>11 圣者的晚餐<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"volume volume_close"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"volume_title"</span> <span class="attr">onclick</span>=<span class="string">"exchange_volume(this)"</span>&gt;</span></span><br><span class="line">第二卷 下</span><br><span class="line"><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"volume_expand"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"volume_info"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"./PSYCHO-PASS心理测量者_轻小说在线阅读_亲小说网_files/1716.jpg"</span> <span class="attr">onerror</span>=<span class="string">"this.src=&amp;#39;http:\/\/static.qinxiaoshuo.com:4000/bookimg/1716.jpg&amp;#39;;this.onerror=null"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span>&gt;</span>第二卷 下<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"chapters"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"XX 消逝的情人节"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35256fec85e5b101454.html"</span>&gt;</span>XX 消逝的情人节<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"12 youthful days"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35256fec85e5b101455.html"</span>&gt;</span>12 youthful days<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"13 深渊来的招待"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35356fec85e5b101456.html"</span>&gt;</span>13 深渊来的招待<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"14 甜蜜的毒"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35356fec85e5b101457.html"</span>&gt;</span>14 甜蜜的毒<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"15 硫磺洒落的城市"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35356fec85e5b101458.html"</span>&gt;</span>15 硫磺洒落的城市<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"16 制裁之门"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35356fec85e5b101459.html"</span>&gt;</span>16 制裁之门<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"17 铁石心肠"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35356fec85e5b10145a.html"</span>&gt;</span>17 铁石心肠<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"18 无果之约"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35356fec85e5b10145b.html"</span>&gt;</span>18 无果之约<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"19 透明的影"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35356fec85e5b10145c.html"</span>&gt;</span>19 透明的影<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"20 正义所在"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35456fec85e5b10145d.html"</span>&gt;</span>20 正义所在<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"21 血的褒奖"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35456fec85e5b10145e.html"</span>&gt;</span>21 血的褒奖<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"22 完美的世界"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35456fec85e5b10145f.html"</span>&gt;</span>22 完美的世界<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"尾声"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35456fec85e5b101460.html"</span>&gt;</span>尾声<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"唐之杜志恩和六合冢弥生"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35456fec85e5b101461.html"</span>&gt;</span>唐之杜志恩和六合冢弥生<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">alt</span>=<span class="string">"涛声响彻的房间"</span> <span class="attr">href</span>=<span class="string">"http://www.qinxiaoshuo.com/read/0/1716/5d77d35456fec85e5b101462.html"</span>&gt;</span>涛声响彻的房间<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>其中 <code>alt</code> 是过滤出每个章节 <code>URL</code> 行的关键字</li>
<li>使用 <code>awk</code> 截取去掉 <code>html</code> 标签，只保留 <code>URL</code> </li>
<li>其实应该用正则表达式来截取这些 URL ，哎咱太菜了，书到用时方恨少啊😥，正则不会 <code>awk</code> 来凑😂</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep alt pass.html | awk -F <span class="string">"href=\""</span> <span class="string">'&#123;print $2&#125;'</span>| awk -F <span class="string">"\""</span> <span class="string">'&#123;print $1&#125;'</span></span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35056fec85e5b101448.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35156fec85e5b101449.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35156fec85e5b10144a.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35156fec85e5b10144b.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35156fec85e5b10144c.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35156fec85e5b10144d.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35156fec85e5b10144e.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35256fec85e5b10144f.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35256fec85e5b101450.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35256fec85e5b101451.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35256fec85e5b101452.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35256fec85e5b101453.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35256fec85e5b101454.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35256fec85e5b101455.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35356fec85e5b101456.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35356fec85e5b101457.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35356fec85e5b101458.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35356fec85e5b101459.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35356fec85e5b10145a.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35356fec85e5b10145b.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35356fec85e5b10145c.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35456fec85e5b10145d.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35456fec85e5b10145e.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35456fec85e5b10145f.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35456fec85e5b101460.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35456fec85e5b101461.html</span><br><span class="line">http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35456fec85e5b101462.html</span><br></pre></td></tr></table></figure>
<h3 id="分析各个章节的源码"><a href="#分析各个章节的源码" class="headerlink" title="分析各个章节的源码"></a>分析各个章节的源码</h3><p><img src="../img/image-20200103095824495.png" alt="image-20200103095824495"></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"chapter_content"</span>&gt;</span></span><br><span class="line">            第一卷 上  序<span class="tag">&lt;<span class="name">br</span>/&gt;</span><span class="tag">&lt;<span class="name">br</span>/&gt;</span>网译版 转自 豆瓣()<span class="tag">&lt;<span class="name">br</span>/&gt;</span><span class="tag">&lt;<span class="name">br</span>/&gt;</span>翻译：クリーオウ<span class="tag">&lt;<span class="name">br</span>/&gt;</span><span class="tag">&lt;<span class="name">br</span>/&gt;</span>……………………</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可见，每个章节的中文文本，全部在 <code>&lt;div id=&quot;chapter_content&quot;&gt;</code> ，而且中文文本全部压缩在了一行里，可以通过 <code>&lt;br/&gt;&lt;br/&gt;</code> 这个关键字来过滤出这一行中文文本。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl http://www.qinxiaoshuo.com/<span class="built_in">read</span>/0/1716/5d77d35056fec85e5b101448.html | grep <span class="string">"&lt;br/&gt;&lt;br/&gt;"</span></span><br></pre></td></tr></table></figure>
<p><img src="../img/image-20200103100302697.png" alt="image-20200103100302697"></p>
<h3 id="遍历各个章节"><a href="#遍历各个章节" class="headerlink" title="遍历各个章节"></a>遍历各个章节</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@debian ~/book</span><br><span class="line">╰─$ grep alt pass.html | awk -F <span class="string">"href=\""</span> <span class="string">'&#123;print $2&#125;'</span>| awk -F <span class="string">"\""</span> <span class="string">'&#123;print $1&#125;'</span>&gt; url.log</span><br><span class="line">╭─root@debian ~/book</span><br><span class="line">╰─$ <span class="keyword">for</span> url <span class="keyword">in</span> $(cat url.log);<span class="keyword">do</span> curl <span class="variable">$&#123;url&#125;</span> | grep <span class="string">"&lt;br/&gt;&lt;br/&gt;"</span> &gt;&gt; pass_book.html;<span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<h3 id="添加-lt-h2-gt-二级标题"><a href="#添加-lt-h2-gt-二级标题" class="headerlink" title="添加 &lt;h2&gt; 二级标题"></a>添加 <code>&lt;h2&gt;</code> 二级标题</h3><p>在每一行的行首添加一个 <code>&lt;h2&gt;</code> 标签，接着使用 sed 替换每一行第一个 <code>&lt;br/&gt;&lt;br/&gt;</code> 匹配项为 <code>&lt;h2/&gt;</code> 一定要添加闭合标签，不然的话在转换成 markdown 或者 .docx 时候会把这一整行当作二级标题。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s/^/&lt;h2&gt;/g'</span> pass_book.html</span><br><span class="line">sed -i <span class="string">'s/&lt;br\/&gt;&lt;br\/&gt;/&lt;h2\/&gt;/'</span> pass_book.html</span><br></pre></td></tr></table></figure>
<h3 id="转换为-markdown-格式"><a href="#转换为-markdown-格式" class="headerlink" title="转换为 markdown 格式"></a>转换为 markdown 格式</h3><p>使用 <code>pandoc</code> 转 <code>markdown</code> 的效果很不理想，其中有大量的 <code>\</code> 需要删除掉，还是转 .docx 的格式合适一些，而且 <code>Calibre</code> 也支持 <code>.docx</code> 格式</p>
<p><img src="../img/image-20200103103719653.png" alt="image-20200103103719653"></p>
<h3 id="转-mobi-格式"><a href="#转-mobi-格式" class="headerlink" title="转 mobi 格式"></a>转 mobi 格式</h3><p>打开 calibre 导入刚刚制作好的 .docx 文件，点击 <code>转换书籍</code> 那里，根据对应的设备设置好参数。</p>
<p><img src="../img/image-20200103104121602.png" alt="image-20200103104121602"></p>
<h3 id="制作完成"><a href="#制作完成" class="headerlink" title="制作完成"></a>制作完成</h3><p><img src="../img/image-20200103105014635.png" alt="image-20200103105014635"></p>
<p><img src="../img/image-20200103105027192.png" alt="image-20200103105027192"></p>
<p><img src="../img/image-20200103105034243.png" alt="image-20200103105034243"></p>
<h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p><img src="../img/image-20200103104618047.png" alt="image-20200103104618047"></p>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li>由于总共文本有 20 万字，转换成 azw3 格式会卡死 kindle，不知道什么原因😥</li>
<li>还有什么更好的办法评论区交流一哈😂</li>
</ul>
]]></content>
      <tags>
        <tag>kindle</tag>
      </tags>
  </entry>
  <entry>
    <title>Dockerfile 搓镜像的小技巧</title>
    <url>/archives/dockerfile-tips.html</url>
    <content><![CDATA[<h2 id="Dockerfile-最佳实践"><a href="#Dockerfile-最佳实践" class="headerlink" title="Dockerfile 最佳实践"></a>Dockerfile 最佳实践</h2><p>关于 Dockerfile 最佳实践的博客，网上已经有很多很多啦，咱在这里就不赘述啦。在这里分享几个搓镜像的小技巧，尤其是针对于咱大陆的用户😂。</p>
<ul>
<li><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/" target="_blank" rel="noopener">Best practices for writing Dockerfiles</a> 推荐看一下官方博客上写的</li>
<li><a href="https://yeasy.gitbooks.io/docker_practice/appendix/best_practices.html#dockerfile-最佳实践" target="_blank" rel="noopener">Dockerfile 最佳实践</a> </li>
<li><a href="https://github.com/docker-library" target="_blank" rel="noopener">docker-library</a>/<strong><a href="https://github.com/docker-library/docs" target="_blank" rel="noopener">docs</a></strong> 官方示例</li>
</ul>
<h2 id="几个搓镜像的小技巧"><a href="#几个搓镜像的小技巧" class="headerlink" title="几个搓镜像的小技巧"></a>几个搓镜像的小技巧</h2><h4 id="构建上下文"><a href="#构建上下文" class="headerlink" title="构建上下文"></a>构建上下文</h4><p>执行 <code>docker build</code> 命令时，当前的工作目录被称为构建上下文。默认情况下，Dockerfile 就位于该路径下。也可以通过 -f 参数来指定 dockerfile ，但 docker 客户端会将当前工作目录下的所有文件发送到 docker 守护进程进行构建。所以来说，当执行 docker build 进行构建镜像时，当前目录一定要 <code>干净</code> ，切记不要在家里录下创建一个 <code>Dockerfile</code>  紧接着 <code>docker build</code> 一把梭 😂。</p>
<p>正确做法是为项目建立一个文件夹，把构建镜像时所需要的资源放在这个文件夹下。比如这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir project</span><br><span class="line"><span class="built_in">cd</span> !$</span><br><span class="line">vi Dockerfile</span><br><span class="line"><span class="comment"># 编写 Dockerfile</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>tips：也可以通过 <code>.dockerignore</code> 文件来忽略不需要的文件发送到 docker 守护进程</p>
</blockquote>
<h4 id="基础镜像"><a href="#基础镜像" class="headerlink" title="基础镜像"></a>基础镜像</h4><p>使用体积较小的基础镜像，比如 <code>alpine</code> 或者  <code>debian:buster-slim</code>，像 openjdk 可以选用<code>openjdk:xxx-slim</code> ，由于 openjdk 是基于 debian 的基础镜像构建的，所以向 debian 基础镜像一样，后面带个 <code>slim</code> 就是基于 <code>debian:xxx-slim</code> 镜像构建的。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">debian                      buster-slim         e1af56d072b8        4 days ago          69.2MB</span><br><span class="line">alpine                      latest              cc0abc535e36        8 days ago          5.59MB</span><br></pre></td></tr></table></figure>
<p>不过需要注意的是，alpine 的 c 库是 <code>musl libc</code> ，而不是正统的 <code>glibc</code> ，另外对于一些依赖 <code>glibc</code> 的大型项目，像 openjdk 、tomcat、rabbitmq 等都不建议使用 alpine 基础镜像，因为 <code>musl libc</code> 可能会导致 jvm 一些奇怪的问题。这也是为什么 tomcat 官方没有给出基础镜像是 alpine 的 Dockerfile 的原因。</p>
<h4 id="国内软件源"><a href="#国内软件源" class="headerlink" title="国内软件源"></a>国内软件源</h4><p>使用默认的软件源安装构建时所需的依赖，对于绝大多数基础镜像来说，在国内网络环境构建时的速度较慢，可以通过修改软件源的方式更换为国内的软件源镜像站。目前国内稳定可靠的镜像站主要有，华为云、阿里云、腾讯云、163等。对于咱的网络环境，华为云的镜像站速度最快，平均 10MB/s，峰值可达到 20MB/s，极大的能加快构建镜像的速度。可以参考我曾经写过的一篇 <a href="https://blog.502.li/archives/mirrors-test.html">国内软件源镜像站伪评测</a></p>
<ul>
<li>对于  alpine 基础镜像修改软件源</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"http://mirrors.huaweicloud.com/alpine/latest-stable/main/"</span> &gt; /etc/apk/repositories ;\</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"http://mirrors.huaweicloud.com/alpine/latest-stable/community/"</span> &gt;&gt; /etc/apk/repositories ;\</span><br><span class="line">apk update ;\</span><br></pre></td></tr></table></figure>
<ul>
<li>debian 基础镜像修改默认原件源码</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s/deb.debian.org/mirrors.huaweicloud.com/g'</span> /etc/apt/sources.list ;\</span><br><span class="line">sed -i <span class="string">'s|security.debian.org/debian-security|mirrors.huaweicloud.com/debian-security|g'</span> /etc/apt/sources.list ;\</span><br><span class="line">apt update ;\</span><br></pre></td></tr></table></figure>
<ul>
<li>Ubuntu 基础镜像修改默认原件源码</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s/archive.ubuntu.com/mirrors.huaweicloud.com/g'</span> /etc/apt/sources.list</span><br><span class="line">apt update ;\</span><br></pre></td></tr></table></figure>
<ul>
<li>对于 CentOS ??? 大哥，你确定要用 220MB 大小的基础镜像？</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                      latest              0f3e07c0138f        3 months ago        220MB</span><br></pre></td></tr></table></figure>
<p>建议这些命令就放在 RUN 指令的第一条，update 以下软件源，之后再 install 相应的依赖。</p>
<h4 id="时区设置"><a href="#时区设置" class="headerlink" title="时区设置"></a>时区设置</h4><p>由于绝大多数基础镜像都是默认采用 UTC 的时区，与北京时间相差 8 个小时，这将会导致容器内的时间与北京时间不一致，因而会对一些应用造成一些影响，还会影响容器内日志和监控的数据。因此对于东八区的用户，最好在构建镜像的时候设定一下容器内的时区，一以免以后因为时区遇到一些 bug😂。可以通过环境变量设置容器内的时区。在启动的时候可以通过设置环境变量<code>-e TZ=Asia/Shanghai</code> 来设定容器内的时区。</p>
<h5 id="alpine"><a href="#alpine" class="headerlink" title="alpine"></a>alpine</h5><ul>
<li>但对于 alpine 基础镜像无法通过 <code>TZ</code> 环境变量的方式设定时区，需要安装 <code>tzdata</code> 来配置时区。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/docke/alpine<span class="comment"># docker run --rm -it -e TZ=Asia/Shanghai alpine date</span></span><br><span class="line">Thu Jan  2 03:37:44 UTC 2020</span><br></pre></td></tr></table></figure>
<ul>
<li>对于 alpine 基础镜像，可以在 RUN 指令后面追加上以下命令</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apk add --no-cache tzdata ;\</span><br><span class="line">cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ;\</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Asia/Shanghai"</span> &gt; /etc/timezone ;\</span><br><span class="line">apk del tzdata ;\</span><br></pre></td></tr></table></figure>
<ul>
<li>通过 tzdate 设定时区</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/docke/alpine<span class="comment"># docker build -t alpine:tz2 .</span></span><br><span class="line">Sending build context to Docker daemon  2.048kB</span><br><span class="line">Step 1/2 : FROM alpine</span><br><span class="line"> ---&gt; cc0abc535e36</span><br><span class="line">Step 2/2 : RUN <span class="built_in">set</span> -xue ;    <span class="built_in">echo</span> <span class="string">"http://mirrors.huaweicloud.com/alpine/latest-stable/main/"</span> &gt; /etc/apk/repositories ;    <span class="built_in">echo</span> <span class="string">"http://mirrors.huaweicloud.com/alpine/latest-stable/community/"</span> &gt;&gt; /etc/apk/repositories ;    apk update ;    apk add --no-cache tzdata ;    cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ;    <span class="built_in">echo</span> <span class="string">"Asia/Shanghai"</span> &gt; /etc/timezone ;    apk del tzdata</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 982041a34dbf</span><br><span class="line">+ <span class="built_in">echo</span> http://mirrors.huaweicloud.com/alpine/latest-stable/main/</span><br><span class="line">+ <span class="built_in">echo</span> http://mirrors.huaweicloud.com/alpine/latest-stable/community/</span><br><span class="line">+ apk update</span><br><span class="line">fetch http://mirrors.huaweicloud.com/alpine/latest-stable/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://mirrors.huaweicloud.com/alpine/latest-stable/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">v3.11.2-11-gd5cdcefa20 [http://mirrors.huaweicloud.com/alpine/latest-stable/main/]</span><br><span class="line">v3.11.2-14-g973431591e [http://mirrors.huaweicloud.com/alpine/latest-stable/community/]</span><br><span class="line">OK: 11261 distinct packages available</span><br><span class="line">+ apk add --no-cache tzdata</span><br><span class="line">fetch http://mirrors.huaweicloud.com/alpine/latest-stable/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://mirrors.huaweicloud.com/alpine/latest-stable/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/1) Installing tzdata (2019c-r0)</span><br><span class="line">Executing busybox-1.31.1-r8.trigger</span><br><span class="line">OK: 9 MiB <span class="keyword">in</span> 15 packages</span><br><span class="line">+ cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">+ <span class="built_in">echo</span> Asia/Shanghai</span><br><span class="line">+ apk del tzdata</span><br><span class="line">(1/1) Purging tzdata (2019c-r0)</span><br><span class="line">Executing busybox-1.31.1-r8.trigger</span><br><span class="line">OK: 6 MiB <span class="keyword">in</span> 14 packages</span><br><span class="line">Removing intermediate container 982041a34dbf</span><br><span class="line"> ---&gt; 3ec89f3e824d</span><br><span class="line">Successfully built 3ec89f3e824d</span><br><span class="line">Successfully tagged alpine:tz2</span><br><span class="line">root@ubuntu:~/docke/alpine<span class="comment"># docker run --rm -it alpine:tz2 date</span></span><br><span class="line">Thu Jan  2 11:12:23 CST 2020</span><br></pre></td></tr></table></figure>
<h5 id="debian"><a href="#debian" class="headerlink" title="debian"></a>debian</h5><ul>
<li>通过启动时设定环境变量指定时区</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/docke/alpine<span class="comment"># docker run --rm -it -e TZ=Asia/Shanghai debian date</span></span><br><span class="line">Thu Jan  2 11:38:56 CST 2020</span><br></pre></td></tr></table></figure>
<ul>
<li>也可以再构建镜像的时候复制时区文件设定容器内时区</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ;\</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Asia/shanghai"</span> &gt; /etc/timezone ;\</span><br></pre></td></tr></table></figure>
<h5 id="ubuntu"><a href="#ubuntu" class="headerlink" title="ubuntu"></a>ubuntu</h5><ul>
<li>通过启动时设定环境变量指定时区，发射失败😂，只能通过时区文件来设定时区了。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/docke/alpine<span class="comment"># docker run --rm -it -e TZ=Asia/Shanghai debian date</span></span><br><span class="line">Thu Jan  2 11:38:56 CST 2020</span><br><span class="line"></span><br><span class="line">root@ubuntu:~/docke/alpine<span class="comment"># ^debian^ubuntu</span></span><br><span class="line">docker run --rm -it -e TZ=Asia/Shanghai ubuntu date</span><br><span class="line">Thu Jan  2 03:44:13 Asia 2020</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在这里有个命令执行的小技巧，通过脱字符 <code>^</code> 来替换上一条命令中的 debian 为 ubuntu 然后执行相同的命令😂</p>
</blockquote>
<ul>
<li>通过时区文件来设定时区</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt </span><br><span class="line">cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ;\</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Asia/shanghai"</span> &gt; /etc/timezone ;\</span><br></pre></td></tr></table></figure>
<h4 id="尽量使用-URL-添加源码"><a href="#尽量使用-URL-添加源码" class="headerlink" title="尽量使用 URL 添加源码"></a>尽量使用 URL 添加源码</h4><p>如果不采用分阶段构建，对于一些需要在容器内进行编译的项目，最好通过 git 或者 wegt 的方式将源码打入到镜像内，而非采用 ADD 或者 COPY ，因为源码编译完成之后，源码就不需要可以删掉了，而通过 ADD 或者 COPY 添加进去的源码已经用在下一层镜像中了，是删不掉滴啦。也就是说 <code>git &amp; wget source</code> 然后 <code>build</code> ，最后 <code>rm -rf source/</code> 这三部放在一条 RUN 指令中，这样就能避免源码添加到镜像中而增大镜像体积啦。</p>
<p>下面以 FastDFS 的 Dockerfile 为例</p>
<ul>
<li>项目官方的 <a href="https://github.com/happyfish100/fastdfs/blob/52ac538a71fc9753c9dbcd4c75f581e9402f39a5/docker/dockerfile_local/Dockerfile" target="_blank" rel="noopener">Dockerfile</a></li>
</ul>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># centos 7</span></span><br><span class="line"><span class="keyword">FROM</span> centos:<span class="number">7</span></span><br><span class="line"><span class="comment"># 添加配置文件</span></span><br><span class="line"><span class="comment"># add profiles</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/client.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/http.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/mime.types /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/storage.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/tracker.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> fastdfs.sh /home</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/nginx.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/mod_fastdfs.conf /etc/fdfs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加源文件</span></span><br><span class="line"><span class="comment"># add source code</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> <span class="built_in">source</span>/libfastcommon.tar.gz /usr/<span class="built_in">local</span>/src/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> <span class="built_in">source</span>/fastdfs.tar.gz /usr/<span class="built_in">local</span>/src/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> <span class="built_in">source</span>/fastdfs-nginx-module.tar.gz /usr/<span class="built_in">local</span>/src/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> <span class="built_in">source</span>/nginx-1.15.4.tar.gz /usr/<span class="built_in">local</span>/src/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install git gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl-devel wget vim -y \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  mkdir /home/dfs   \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/  \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  <span class="built_in">cd</span> libfastcommon/   \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  ./make.sh &amp;&amp; ./make.sh install  \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  <span class="built_in">cd</span> ../  \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  <span class="built_in">cd</span> fastdfs/   \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  ./make.sh &amp;&amp; ./make.sh install  \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  <span class="built_in">cd</span> ../  \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  <span class="built_in">cd</span> nginx-1.15.4/  \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  ./configure --add-module=/usr/<span class="built_in">local</span>/src/fastdfs-nginx-module/src/   \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  make &amp;&amp; make install  \</span></span><br><span class="line"><span class="bash">  &amp;&amp;  chmod +x /home/fastdfs.sh</span></span><br><span class="line"><span class="comment"># export config</span></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /etc/fdfs</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">22122</span> <span class="number">23000</span> <span class="number">8888</span> <span class="number">80</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"/home/fastdfs.sh"</span>]</span></span><br></pre></td></tr></table></figure>
<ul>
<li>经过本人优化后的 <a href="https://github.com/happyfish100/fastdfs/issues/327" target="_blank" rel="noopener">Dockerfile</a></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM alpine:3.10</span><br><span class="line"></span><br><span class="line">RUN <span class="built_in">set</span> -x \</span><br><span class="line">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"http://mirrors.huaweicloud.com/alpine/latest-stable/main/"</span> &gt; /etc/apk/repositories \</span><br><span class="line">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"http://mirrors.huaweicloud.com/alpine/latest-stable/community/"</span> &gt;&gt; /etc/apk/repositories \</span><br><span class="line">    &amp;&amp; apk update \</span><br><span class="line">    &amp;&amp; apk add --no-cache --virtual .build-deps gcc libc-dev make perl-dev openssl-dev pcre-dev zlib-dev git \</span><br><span class="line">    &amp;&amp; mkdir -p /usr/<span class="built_in">local</span>/src \</span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src \</span><br><span class="line">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/libfastcommon.git --depth 1 \</span><br><span class="line">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/fastdfs.git --depth 1    \</span><br><span class="line">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1  \</span><br><span class="line">    &amp;&amp; wget http://nginx.org/download/nginx-1.15.4.tar.gz \</span><br><span class="line">    &amp;&amp; tar -xf nginx-1.15.4.tar.gz \</span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/libfastcommon \</span><br><span class="line">    &amp;&amp; ./make.sh \</span><br><span class="line">    &amp;&amp; ./make.sh install \</span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/fastdfs/ \</span><br><span class="line">    &amp;&amp; ./make.sh \</span><br><span class="line">    &amp;&amp; ./make.sh install \</span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/nginx-1.15.4/ \</span><br><span class="line">    &amp;&amp; ./configure --add-module=/usr/<span class="built_in">local</span>/src/fastdfs-nginx-module/src/ \</span><br><span class="line">    &amp;&amp; make &amp;&amp; make install \</span><br><span class="line">    &amp;&amp; apk del .build-deps \</span><br><span class="line">    &amp;&amp; apk add --no-cache pcre-dev bash \</span><br><span class="line">    &amp;&amp; mkdir -p /home/dfs  \</span><br><span class="line">    &amp;&amp; mv /usr/<span class="built_in">local</span>/src/fastdfs/docker/dockerfile_network/fastdfs.sh /home \</span><br><span class="line">    &amp;&amp; mv /usr/<span class="built_in">local</span>/src/fastdfs/docker/dockerfile_network/conf/* /etc/fdfs \</span><br><span class="line">    &amp;&amp; chmod +x /home/fastdfs.sh \</span><br><span class="line">    &amp;&amp; rm -rf /usr/<span class="built_in">local</span>/src*</span><br><span class="line">VOLUME /home/dfs</span><br><span class="line">EXPOSE 22122 23000 8888 8080</span><br><span class="line">CMD [<span class="string">"/home/fastdfs.sh"</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>构建之后的对比</li>
</ul>
<p>使用项目默认的 Dockerfile 进行构建的话，镜像大小接近 500MB 😂，而经过一些的优化，将所有的 RUN 指令合并为一条，最终构建出来的镜像大小为 30MB 😂。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">fastdfs             alpine              e855bd197dbe        10 seconds ago      29.3MB</span><br><span class="line">fastdfs             debian              e05ca1616604        20 minutes ago      103MB</span><br><span class="line">fastdfs             centos              c1488537c23c        30 minutes ago      483MB</span><br></pre></td></tr></table></figure>
<h4 id="使用虚拟编译环境"><a href="#使用虚拟编译环境" class="headerlink" title="使用虚拟编译环境"></a>使用虚拟编译环境</h4><p>对于只在编译过程中使用到的依赖，我们可以将这些依赖安装在虚拟环境中，编译完成之后可以一并删除这些依赖，比如 alpine 中可以使用 <code>apk add --no-cache --virtual .build-deps</code>  ，后面加上需要安装的相关依赖。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apk add --no-cache --virtual .build-deps gcc libc-dev make perl-dev openssl-dev pcre-dev zlib-dev git</span><br></pre></td></tr></table></figure>
<p>构建完成之后可以使用 <code>apk del .build-deps</code> 命令，一并将这些编译依赖全部删除。需要注意的是，<code>.build-deps</code> 后面接的是编译时以来的软件包，并不是所有的编译依赖都可以删除，不要把运行时的依赖包接在后面，最好单独 add 一下。</p>
<h4 id="最小化层数"><a href="#最小化层数" class="headerlink" title="最小化层数"></a>最小化层数</h4><p>docker 在 1.10 以后，只有 <code>RUN、COPY 和 ADD</code> 指令会创建层，其他指令会创建临时的中间镜像，但是不会直接增加构建的镜像大小了。前文提到了建议使用 git 或者 wget 的方式来将文件打入到镜像当中，但如果我们必须要使用 COPY 或者 ADD 指令呢？</p>
<p>还是拿 FastDFS 为例:</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># centos 7</span></span><br><span class="line"><span class="keyword">FROM</span> centos:<span class="number">7</span></span><br><span class="line"><span class="comment"># 添加配置文件</span></span><br><span class="line"><span class="comment"># add profiles</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/client.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/http.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/mime.types /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/storage.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/tracker.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> fastdfs.sh /home</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/nginx.conf /etc/fdfs/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> conf/mod_fastdfs.conf /etc/fdfs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加源文件</span></span><br><span class="line"><span class="comment"># add source code</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> <span class="built_in">source</span>/libfastcommon.tar.gz /usr/<span class="built_in">local</span>/src/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> <span class="built_in">source</span>/fastdfs.tar.gz /usr/<span class="built_in">local</span>/src/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> <span class="built_in">source</span>/fastdfs-nginx-module.tar.gz /usr/<span class="built_in">local</span>/src/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> <span class="built_in">source</span>/nginx-1.15.4.tar.gz /usr/<span class="built_in">local</span>/src/</span></span><br></pre></td></tr></table></figure>
<p>多个文件需要添加到容器中不同的路径，每个文件使用一条 ADD 指令的话就会增加一层镜像，这样戏曲就多了 12 层镜像😂。其实大可不必，我们可以将这些文件全部打包为一个文件为 <code>src.tar.gz</code> 然后通过 ADD 的方式把文件添加到当中去，然后在 RUN 指令后使用 <code>mv</code> 命令把文件移动到指定的位置。这样仅仅一条 ADD 和RUN 指令取代掉了 12 个 ADD 指令😂</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine:<span class="number">3.10</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> src.tar.gz /usr/<span class="built_in">local</span>/src.tar.gz</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -xe \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add --no-cache --virtual .build-deps gcc libc-dev make perl-dev openssl-dev pcre-dev zlib-dev tzdata \</span></span><br><span class="line"><span class="bash">    &amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \</span></span><br><span class="line"><span class="bash">    &amp;&amp; tar -xvf /usr/<span class="built_in">local</span>/src.tar.gz -C /usr/<span class="built_in">local</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv /usr/<span class="built_in">local</span>/src/conf/fastdfs.sh /home/fastdfs/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv /usr/<span class="built_in">local</span>/src/conf/* /etc/fdfs \</span></span><br><span class="line"><span class="bash">    &amp;&amp; chmod +x /home/fastdfs/fastdfs.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -rf /usr/<span class="built_in">local</span>/src/* /var/cache/apk/* /tmp/* /var/tmp/* <span class="variable">$HOME</span>/.cache</span></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /var/fdfs</span></span><br></pre></td></tr></table></figure>
<p>其他最小化层数无非就是把构建项目的整个步骤弄成一条 RUN 指令，不过多条命令合并可以使用 <code>&amp;&amp;</code> 或者 <code>;</code> 这两者都可以，不过据我在 docker hub 上的所见所闻，使用 <code>;</code> 的居多，尤其是官方的 <code>Dockerfile</code> 。</p>
<h2 id="docker-镜像分析工具"><a href="#docker-镜像分析工具" class="headerlink" title="docker 镜像分析工具"></a>docker 镜像分析工具</h2><p>推荐阅读 <a href="https://www.qikqiak.com/post/docker-image-explore-tool-dive/" target="_blank" rel="noopener">Docker 镜像分析工具 Dive(附视频)</a> ，我就不赘述啦，其实是懒😂</p>
]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>VPS 安全加固之用户登录后向 telegram 发送登录信息</title>
    <url>/archives/linux-login-alarm-telegram.html</url>
    <content><![CDATA[<h2 id="弄啥咧"><a href="#弄啥咧" class="headerlink" title="弄啥咧"></a>弄啥咧</h2><ul>
<li>汝担心自己服务器挂了吗？</li>
<li>汝担心服务器被爆破脱裤？</li>
<li>汝担心非法用户登录服务器😂</li>
<li>汝的服务器使用口令登录，而且还是 123456 的那种😂</li>
</ul>
<p>虽然，咱拿到 VPS 第一件事儿就是禁止密码登录，禁止 root 登录，仅仅允许普通用户使用密钥登录。理论上来讲，只要我的私钥不泄露，想要爆破登录上去，不可能、不可能、不可能😂。AES-256 密钥的机密强度，即便是穷尽最强的超算来破解，也得需要几十年。</p>
<p>那么，有什么办法当用户登录到服务器上时发送个警报信息到咱手机上，来确认是咱本人或者是咱授权的用户登录。发送信息到咱手机，且及时能收到的话，常见的就这三种：</p>
<h3 id="通过-email"><a href="#通过-email" class="headerlink" title="通过 email"></a>通过 email</h3><p>email 发送确实可以，但有些限制，比如 GCP 就 ban 掉了 GCE 的 25 端口，常规手段就无法发送邮件了。而且，Linux 命令行下配置 Email 的发送客户端实在是令人头疼。遂就弃坑啦😂，折腾起来不方便。</p>
<h3 id="通过手机"><a href="#通过手机" class="headerlink" title="通过手机"></a>通过手机</h3><p>之前我是使用 twiio 的短信服务来发送信息的，通过 twiio 的 api 很简单地就能发送，不想 email 那样配来陪去地，使用一条 curl 命令就能完成发送短信到手机。不过 twiio 很有限制，免费用户会有 10$ 的额度，而且需要绑定信用卡，也比较麻烦，遂卒😂</p>
<h3 id="通过-telegram-bot"><a href="#通过-telegram-bot" class="headerlink" title="通过 telegram bot"></a>通过 telegram bot</h3><p>主角上场啦，就是咱们大名鼎鼎的电报机器人啦。不得不说 telegram 真心很好用啊，聊天功能比微信QQ这种狗屎玩意儿高到不知道哪里去了。反正我很讨厌恶心使用微信和QQ，这种毒瘤软件。功能臃肿无比而且最基本的消息同步功能做的跟狗屎一样烂。呵呵，也就这样烂狗屎软件却垄断了国内聊天软件。而 telegram 只把聊天功能做到优秀，其开放的电报机器人更是催生出了无数有趣且实用的机器人。而且啊，你用 telegram bot 不需要实名认证、也不需要你上传身份证。</p>
<p>通过 telegram 的 api ，使用 bot 你可以很轻松地向自己发送消息，比微信QQ 那种狗屎玩意好用的多。</p>
<blockquote>
<p>  需要注意的是，如果是 IOS 用户的话，通过 IOS 的通知消息推送机制，可以不挂梯子就能正常收到 telegram 的通知。包括其他需要挂梯子的应用也是，比如 Google voice。</p>
</blockquote>
<h2 id="怎么弄"><a href="#怎么弄" class="headerlink" title="怎么弄"></a>怎么弄</h2><h3 id="首先有个-telegram-账号"><a href="#首先有个-telegram-账号" class="headerlink" title="首先有个 telegram 账号"></a>首先有个 telegram 账号</h3><p>网上教程很多，在此不赘述。推荐某宝买个 Google Voice 来注册，千万千万不要使用 +86 手机号注册，注册完成之后墙裂建议在 app 或者桌面端 的<code>settings</code> ==&gt; <code>Privacy and  Security</code> 那些设置选项里全部设置为 <code>Nobody</code> 。另外再开启 <code>Local Passcode</code> 以及 <code>Two-setp verification</code> 。千千万万别拿着 +86 的手机号到处冲塔，你快很被安排上的。</p>
<p><img src="../img/image-20200102212730956.png" alt="image-20200102212730956"></p>
<h3 id="注册-bot"><a href="#注册-bot" class="headerlink" title="注册 bot"></a>注册 bot</h3><h4 id="1-打开与-BotFather-的对话框"><a href="#1-打开与-BotFather-的对话框" class="headerlink" title="1.打开与 @BotFather 的对话框"></a>1.打开与 @BotFather 的对话框</h4><p><img src="../img/image-20200102213100935.png" alt="image-20200102213100935"></p>
<h4 id="2-发送-start-开始会话"><a href="#2-发送-start-开始会话" class="headerlink" title="2.发送/start 开始会话"></a>2.发送/start 开始会话</h4><p><img src="../img/image-20200102213250311.png" alt="image-20200102213250311"></p>
<h4 id="3-发送-newbot"><a href="#3-发送-newbot" class="headerlink" title="3.发送/newbot"></a>3.发送/newbot</h4><p><img src="../img/image-20200102213314119.png" alt="image-20200102213314119"></p>
<blockquote>
<p>  Alright, a new bot. How are we going to call it? Please choose a name for your bot.</p>
</blockquote>
<h4 id="4-发送-Bot-的-name-和-username"><a href="#4-发送-Bot-的-name-和-username" class="headerlink" title="4.发送 Bot 的 name 和 username"></a>4.发送 Bot 的 name 和 username</h4><blockquote>
<p>  Good. Now let’s choose a username for your bot. It must end in <code>bot</code>. Like this, for example: TetrisBot or tetris_bot.</p>
</blockquote>
<p><img src="../img/image-20200102213405851.png" alt="image-20200102213405851"></p>
<p>bot 有两个名字，第一个发送的是 <code>first_name</code>: “linuxloginbot”，第二个发送的是”<code>username</code>“: “linuxlogin_bot” 。其中 username 有要求，要 <code>xxx_bot</code> 来命名 比如 <code>linuxlogin_bot</code></p>
<h4 id="5-得到-Bot-的-token，用于标识这个-Bot"><a href="#5-得到-Bot-的-token，用于标识这个-Bot" class="headerlink" title="5.得到 Bot 的 token，用于标识这个 Bot"></a>5.得到 Bot 的 token，用于标识这个 Bot</h4><p><img src="../img/image-20200102214900940.png" alt="image-20200102214900940"></p>
<blockquote>
<p>  Done! Congratulations on your new bot. You will find it at t.me/linuxlogin_bot. You can now add a description, about section and profile picture for your bot, see /help for a list of commands. By the way, when you’ve finished creating your cool bot, ping our Bot Support if you want a better username for it. Just make sure the bot is fully operational before you do this.</p>
<p>  Use this token to access the HTTP API:</p>
<p>  1067765083:AAFjONxxx-F2Y6IRSxxxxxVAAgRxxx89MXpk</p>
<p>  Keep your token secure and store it safely, it can be used by anyone to control your bot.</p>
<p>  For a description of the Bot API, see this page: <a href="https://core.telegram.org/bots/api" target="_blank" rel="noopener">https://core.telegram.org/bots/api</a></p>
</blockquote>
<p>由上面得到的<code>1067765083:AAFjONxxx-F2Y6x89MXpk</code> 格式的字符串为该 bot 的 token，发送信息需要这个 token ，要保存好，不要泄露出去。</p>
<h4 id="6-得到自己的-chat-ID"><a href="#6-得到自己的-chat-ID" class="headerlink" title="6.得到自己的 chat ID"></a>6.得到自己的 chat ID</h4><p>telegram 中每个用户、频道、群组都会有一个 chat ID ，而 telegram bot 的 chat ID 就是你自己，也就是说，bot 机器人想你发送信息是通过你的 ID 来标识的，也可以将 bot 加入到频道或者群组中，向群组中发送信息。</p>
<p>通过 <code>@getidsbot</code> 这个机器人来获取自己的 ID，ID 一般都是 6 开头的。</p>
<p><img src="../img/image-20200102220002156.png" alt="image-20200102220002156"></p>
<h4 id="7-和-bot-对话"><a href="#7-和-bot-对话" class="headerlink" title="7. 和 bot 对话"></a>7. 和 bot 对话</h4><p>这一步非常重要，当 bot 新建完成之后就点击你的 bot 链接，然后在点击下面的 start 按钮。你不点击 start 开始和 bot 会话的话，bot 是无法想你发送信息的。我就在这个坑里爬了很久😂</p>
<p><img src="../img/image-20200102215325530.png" alt="image-20200102215325530"></p>
<h4 id="7-构造-GET-请求"><a href="#7-构造-GET-请求" class="headerlink" title="7.构造 GET 请求"></a>7.构造 GET 请求</h4><p>可以参考 telegram bot api 的官方文档<a href="https://core.telegram.org/bots/api" target="_blank" rel="noopener">Telegram Bot API</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https://api.telegram.org/bot（ 这里加上你的token ）/sendMessage?chat_id=66666666 &amp;text=message</span><br></pre></td></tr></table></figure>
<ul>
<li>例如：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https://api.telegram.org/bot1067796083:AAFjONLJ9-F2Y6IRSmQoBVAAgRhd589MXpk/sendMessage?chat_id=613640483&amp;text=message</span><br></pre></td></tr></table></figure>
<p>把这段 <code>url</code> 复制粘贴到浏览器测试一下即可，或者通过 <code>curl</code> &amp; <code>wget</code>命令也可以。看看你的 telegram 能否正常接受消息。如果出现的话，恭喜你成功了第一步😂</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"ok"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"result"</span>: &#123;</span><br><span class="line">    <span class="attr">"message_id"</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"from"</span>: &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="number">13</span>,</span><br><span class="line">      <span class="attr">"is_bot"</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">"first_name"</span>: <span class="string">"linuxloginbot"</span>,</span><br><span class="line">      <span class="attr">"username"</span>: <span class="string">"linuxlogin_bot"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"chat"</span>: &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="number">13</span>,</span><br><span class="line">      <span class="attr">"first_name"</span>: <span class="string">"木子"</span>,</span><br><span class="line">      <span class="attr">"username"</span>: <span class="string">"muzi_ii"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"private"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"date"</span>: <span class="number">1577973988</span>,</span><br><span class="line">    <span class="attr">"text"</span>: <span class="string">"message"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="../img/image-20200102220642854.png" alt="image-20200102220642854"></p>
<h4 id="8-用户登录后执行脚本"><a href="#8-用户登录后执行脚本" class="headerlink" title="8.用户登录后执行脚本"></a>8.用户登录后执行脚本</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># filename: 00-ssh-login-alarm-telegram.sh</span></span><br><span class="line"><span class="comment"># date: 2019-12-18</span></span><br><span class="line"><span class="comment"># for: ssh login alarm to telegram</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># token 和 id 修改为自己的</span></span><br><span class="line">token=97xxx718:AAExExPY9zxxxxxQ0L7iA2MCGYRQ</span><br><span class="line">id=613420483</span><br><span class="line"></span><br><span class="line">message=$(hostname &amp;&amp; TZ=UTC-8 date &amp;&amp; who &amp;&amp; w | awk  <span class="string">'BEGIN&#123;OFS="\t"&#125;&#123;print $1,$8&#125;'</span>)</span><br><span class="line"></span><br><span class="line">curl -s <span class="string">"https://api.telegram.org/bot<span class="variable">$&#123;token&#125;</span>/sendMessage?chat_id=<span class="variable">$&#123;id&#125;</span>"</span> --data-binary <span class="string">"&amp;text=<span class="variable">$&#123;message&#125;</span>"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>将该脚本放到 <code>/etc/profile.d/</code> 目录下，并 把该脚本的权限设置为<code>555</code> ，即任何用户都可执行。</li>
<li><code>/etc/profile.d/</code> 下的脚本文件会在用户登录成功后自动执行，如还需要其他的操作追加在脚本里即可。</li>
<li>message 需要传递的数据根据自身需求设定即可，通过 <code>&amp;&amp;</code>  将多个命令的执行结果传递到 message 变量。<code>hostname</code> 获取主机名，以区分多台服务器；<code>TZ=UTC-8 date</code> 来获取登录时刻的北京时间；<code>who</code> 用来获取当前用户和 IP 等信息；<code>w</code> 命令用于获取当前用户登录后执行的命令。</li>
</ul>
<h4 id="大功告成啦"><a href="#大功告成啦" class="headerlink" title="大功告成啦"></a>大功告成啦</h4><p>ssh 退出登录，测试一下😋</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Oracle</span><br><span class="line">Thu Jan  2 22:23:33 UTC 2020</span><br><span class="line">ubuntu   pts/0        2020-01-02 09:23 (5.129.16.28)</span><br><span class="line">09:23:33 load</span><br><span class="line">USER WHAT</span><br><span class="line">ubuntu -bash</span><br></pre></td></tr></table></figure>
<p><img src="../img/image-20200102222349027.png" alt="image-20200102222349027"></p>
<h2 id="解锁其他功能？"><a href="#解锁其他功能？" class="headerlink" title="解锁其他功能？"></a>解锁其他功能？</h2><h3 id="监控某个端口是否存活"><a href="#监控某个端口是否存活" class="headerlink" title="监控某个端口是否存活"></a>监控某个端口是否存活</h3><p>这个适用于宿舍，比如，我的笔记本使用 frpc 和服务器端的 frps 保持长连接，如果我的笔记本被盗或者网络挂了，那么服务端的端口会 down 掉的，通过监控这个端口来判断笔记本的状态。只要笔记本和 frps 断掉就发送警报信息到 telegram。</p>
<h3 id="发送-nginx-当日访问量最高的链接"><a href="#发送-nginx-当日访问量最高的链接" class="headerlink" title="发送 nginx 当日访问量最高的链接"></a>发送 nginx 当日访问量最高的链接</h3><p>因为不喜欢 Google Analytics 来在自己的博客上收集读者们的隐私数据，所以就自己手搓脚本，通过 nginx 日志来获取博客访问数据。简单粗暴😂</p>
<h3 id="发送服务器监控信息"><a href="#发送服务器监控信息" class="headerlink" title="发送服务器监控信息"></a>发送服务器监控信息</h3><p>服务器磁盘满了；服务器被日了；服务器被 down 掉了……</p>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>telegram</tag>
      </tags>
  </entry>
  <entry>
    <title>2019 年读书笔记和思考</title>
    <url>/archives/2019-reading-notes.html</url>
    <content><![CDATA[<h2 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h2><ul>
<li>2019-11-10 初步开始写</li>
<li>2019-11-30 补充漫画部分</li>
<li>2019-12-01 补充《童年的消逝》部分</li>
<li>2019-12-30 更新技术垄断、自由与繁荣的国度、苏联的最后一天</li>
</ul>
<p>会持续更新到这个月的最后一天，12 月 31 号那天再发一遍</p>
<h2 id="我青年时代就读过😂"><a href="#我青年时代就读过😂" class="headerlink" title="我青年时代就读过😂"></a>我青年时代就读过😂</h2><p><del>没读过西游记、也没读过马可波罗游记、更没读过左丘明和左传</del></p>
<p>晒一下昨天（11月30日）<del>新买</del>捡垃圾买的 Kindle Oasis 2😂</p>
<p><img src="../img/image-20191201200537133.png" alt="image-20191201200537133"></p>

 <blockquote class="twitter-tweet"><p lang="zh" dir="ltr">啦啦啦，到手啦， 1250￥ 成交，激活时间是 去年九月份，还有半年多的基本部件质保。<br><br>第三个 Kindle 😂 ，从 kindle 入门版到 Kindle Paperwhite3 再到今天的 Kindle Oasis 2。使用体验就是入门版能用，KP3 够用，KO2 满足。果真 KO2 无论在阅读体验和速度上都要比 KP3 高到不知道哪里去了。😂 <a href="https://t.co/CxhB9jKZlE" target="_blank" rel="noopener">https://t.co/CxhB9jKZlE</a> <a href="https://t.co/OYOh4WUr0z" target="_blank" rel="noopener">pic.twitter.com/OYOh4WUr0z</a></p>&mdash; 502 (@muzi_ii) <a href="https://twitter.com/muzi_ii/status/1200678601324032000?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">November 30, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

<h3 id="致读者"><a href="#致读者" class="headerlink" title="致读者"></a>致读者</h3><p>每本书大概可以分为作者、简介、读后感、摘抄四个主要的部分。其中摘抄部分全部提取自我的 Kindle 标注，把自己喜欢的一些段落和句子分享给大家，我相信你会为其中的几句而吸引住，勾引读者们对这本书的兴趣。</p>
<p>摘抄最主要的目的是提醒自己回顾一下读过的书，通过这些摘抄就能回忆起整本书贯穿的内容，其次摘抄也是自己平时所思考的源泉，就像高中时自己写的一本本的阅读摘抄本一样。都值得自己反复咀嚼阅读思考。感觉 Kindle 这个功能非常棒，代替了我读纸质书时抄在笔记本上的功能😂。每隔一段时间就反复读一读摘抄的内容，从而复习一下读过的书。</p>
<h2 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h2><h3 id="1-《1984》"><a href="#1-《1984》" class="headerlink" title="1.《1984》"></a>1.《1984》</h3><h4 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[英] 乔治·奥威尔</li>
</ul>
<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>《1984》是一部杰出的政治寓言小说，也是一部幻想小说。作品刻画了人类在极权主义社会的生存状态，有若一个永不褪色的警示标签，警醒世人提防这种预想中的黑暗成为现实。历经几十年，其生命力益显强大，被誉为20世纪影响最为深远的文学经典之一。</p>
<p><del>引用</del>剽窃自豆瓣</p>
</blockquote>
<h4 id="读后感"><a href="#读后感" class="headerlink" title="读后感"></a>读后感</h4><p>2017 年的时候读过一遍，今年的时候是读的第二遍。</p>
<p>我很喜欢这本书，因为我们就生活在一个 1984 般的社会，所以能在书里找到很多现实中的原型。<br>对未来充满希望的人，往往对历史一无所知，与那些觉着国家越来越富强，祖国越来越繁荣，生活越来越美好的人不同。读完这本书，我觉着未来必定是反乌托邦式的极权社会，一个 1984 和娱乐至死相互交织的社会：无限权力的政府掌控所有资源和技术，人民在征信系统、人工智能、人脸识别、大数据分析、数据挖掘等高科技面前手无缚鸡之力，只能过着娱乐至死般的生活。所有人的思想都整齐划一地被真理部牢牢掌控，任何反对质疑批评质疑的人都要被消灭掉。想过上好日子不是不可以，但你得像胡鞍钢、胡锡进、金灿荣那样对当权者歌功赞德、拍马溜须、谄媚献媚、阿谀奉承才能有立足之地 。或者沉默不语过着蝼蚁一般的生活，每天靠着短视频、假新闻、营销号、娱乐消费等来填补无知和恐惧，在真理部意识形态的控制下放弃对自由的追求等等。那时的人们感到痛苦的不是他们用笑声代替了思考，而是他们不知道自己为什么笑以及为什么不再思考。</p>
<p>在不受约束的权力面前，即便是家财万贯的国民老公都无法保全自己，何况你我这帮如蝼蚁般的屁民呢。所以推荐去读读这本书吧，你或许能从中找到生活中的一些原型，当 1984 那一天到来时你也不会觉得震惊，也不会觉着无法接受。多读读这本书，去思考一下当今社会的种种问题，当社会主义铁拳砸到你身上的时候你也就不会觉得那么疼了。</p>
<h4 id="摘抄"><a href="#摘抄" class="headerlink" title="摘抄"></a>摘抄</h4><p>下面剽窃摘抄自本书原文，大部分都是从我 kindle 上导出来的标注，因为标注的太多了，所以就挑选几条。</p>
<ul>
<li><blockquote>
<p>极权最有效的统治术是仇恨教育，塑造一个远在天边的外在敌人，人们就会忘记身边的痛苦。</p>
</blockquote>
</li>
<li><blockquote>
<p>眼下，已进入仇恨周活动的第六天，大家都受够了游行、演说、呐喊、颂歌、摇旗、招贴、电影、蜡像、擂鼓、鸣号、跺足、坦克轰鸣、飞机盘旋以及枪炮隆隆的折磨了。6天过后，人们已经亢奋到了极点，对欧亚国的仇恨，也已经到了将近走火入魔的地步。如果让那2000名将于活动最后一天被绞死的欧亚国俘虏落在他们手上，他们一定会像野兽一样把他们撕碎。然而就在这时，大洋国政府突然宣布：交战对象不是欧亚国，而是东亚国，欧亚国实则是他们的盟友。</p>
</blockquote>
</li>
<li><blockquote>
<p>他在谩骂老大哥，在诋毁党的专政制度，他要求立即与欧亚国缔结和约，他倡导言论自由、出版自由、集会自由和思想自由，他歇斯底里地奔走呼号：革命已被出卖了！</p>
</blockquote>
</li>
<li><blockquote>
<p>“两分钟仇恨”节目开始还不到半分钟，大堂里的一多半人已迫不及待地想把心中的愤懑倾泻出来，开始大喊大叫。电屏上那张洋洋自得的绵羊脸以及欧亚国军队展现出的强大震慑力，让台下的党员坐不住了。此外，戈斯坦的一个眼神或者想法，都会令观众自动迸发出恐惧与愤怒的情绪。他成了比欧亚国或者东亚国更可憎的对象，因为大洋国和任何一国开战都将与另外一国修好。但是，奇怪的是，尽管戈斯坦遭万千人憎恨和唾弃，尽管他的言辞论调每天数以千次地在讲台、电屏、报纸和书上被抵制、粉碎、嘲弄，他的无知也体无完肤地暴露在公众面前，但他的影响力却不降反增。</p>
</blockquote>
</li>
<li><blockquote>
<p>这样的表达方式，一定程度上是对老大哥智慧与威严的赞美，同时也是一种自我催眠，人们故意用这样有节奏的拍子来抹杀内心理性的波澜。</p>
</blockquote>
</li>
<li><blockquote>
<p>致未来、过去以及思想自由的时代：人人各不相同，不再孤寂一生。献给真理永存的时代，献给事情既已发生而无需篡改的时代。我们这群活在没有自由可言、孤苦潦倒的岁月的人，活在老大哥及双重思想阴影下的人——向你们致敬！</p>
</blockquote>
</li>
<li><blockquote>
<p>如果所有人都听信党这别有用心的谎言，如果所有记录都如是记载这谎言，那么这谎言就会顺理成章地变成历史，变成真理了。于是党的口号，也就变成这样：“谁主宰历史，谁就主宰未来；谁主宰现在，谁就主宰历史。”如此一来，历史也就不容更改了，其实这里的历史就其本质来说，早已被党大肆篡改过了。现在正确的事情，将来也一定是正确的，就是这么一个简单的道理。如此情形之下，你要做的无非只能是顺从所谓的历史，战胜你顽固的记忆罢了。这就是他们所谓的“现实控制”，新语美其名曰“双重思想”。</p>
</blockquote>
</li>
<li><blockquote>
<p>明明知道，却佯装不知；本来对事实心知肚明，去偏要费尽心机去编造谎言；明知两种观点水火不容，却硬要把它们捏合在一起，相信其必能共存共荣；本来已合乎逻辑，却偏偏用逻辑推翻逻辑；明明批判道德，却转而吹嘘道德；民主已是空谈，却偏偏要做民主的守护者；明明已忘却该忘却的一切，却偏偏在需要时把它捡起来，然后在不需要时再把它丢出去。总之，最重要的是将做法用于做法本身——这就是双重思想玄之又玄的地方：有意识地进入无意识状态，然后对刚才的自我催眠装作一无所知，统统抛于脑后。</p>
</blockquote>
</li>
<li><blockquote>
<p>不用说，将双重思想运用到极致的人，恰恰是那些发明双重思想且深知自己在进行一系列有预谋的精神欺骗的人。在我们现今的社会，对实际情况最了如指掌的人，恰恰是那些背离实际看待世界的人。一般而言，他们对世界认识得越透彻，对民众的欺骗与蛊惑就越多，他们显得越聪明，做起事来便也越不靠谱。</p>
</blockquote>
</li>
</ul>
<h3 id="2-《-如果沒有今天，明天会不会有昨天？-》"><a href="#2-《-如果沒有今天，明天会不会有昨天？-》" class="headerlink" title="2.《 如果沒有今天，明天会不会有昨天？ 》"></a>2.《 如果沒有今天，明天会不会有昨天？ 》</h3><h4 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[瑞士] 伊夫·博萨尔特</li>
</ul>
<h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>这本书是 B 站 UP 主 兔肉菌推荐的</p>
<h4 id="读后感-1"><a href="#读后感-1" class="headerlink" title="读后感"></a>读后感</h4><h4 id="摘抄-1"><a href="#摘抄-1" class="headerlink" title="摘抄"></a>摘抄</h4><h3 id="3-《开放社会与敌人》"><a href="#3-《开放社会与敌人》" class="headerlink" title="3.《开放社会与敌人》"></a>3.《开放社会与敌人》</h3><h4 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[英] 卡尔·波普尔</li>
</ul>
<h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><p> 这本书与哈耶克的《通往奴役之路》齐名，是战后反思极权主义、整体主义和法西斯主义等造成人类大灾难的思想根源的力作，更为战后西方社会走出无约束资本主义的渐进改良提供了思想依据。</p>
<blockquote>
<p>波普尔在二战时期所写的这本书首先无疑与他当时的处境密切相关。该书第二版序言开篇即指出，“虽然本书的大量内容在较早的日子就形成了，但最终下定决心写这本书却是在1938年 3 月我接到奥地利被占领消息的那个日子。写作的日期持续到1943年”。20世纪上半叶，整个西方世界处于前所未有的转型阵痛期。马克思和狄更斯笔下的“无约束的资本主义” 因其复杂的内在矛盾而难以为继，在世界大战和经济大萧条中风雨飘摇，在共产主义、社会民主主义和法西斯主义等思潮、运动乃至暴行之间左冲右突、迂回折冲。法西斯主义的暴行促使他对纳粹思想根源进行了深入的检讨和批判。正因为这一背景，波普尔将这本书定位为“一部政治哲学和历史哲学的批判性导言，也是对某些社会重建原则的审查”。</p>
</blockquote>
<h4 id="读后感-2"><a href="#读后感-2" class="headerlink" title="读后感"></a>读后感</h4><h4 id="摘抄-2"><a href="#摘抄-2" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
</blockquote>
</li>
</ul>
<h3 id="4-《历史决定论的贫困》"><a href="#4-《历史决定论的贫困》" class="headerlink" title="4.《历史决定论的贫困》"></a>4.《历史决定论的贫困》</h3><h4 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[英] 卡尔·波普尔</li>
</ul>
<h4 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h4><h4 id="读后感-3"><a href="#读后感-3" class="headerlink" title="读后感"></a>读后感</h4><h4 id="摘抄-3"><a href="#摘抄-3" class="headerlink" title="摘抄"></a>摘抄</h4><blockquote>
<p>为了让读者知道这些最近成果，我拟在这里简单谈谈我对历史决定论的这个反驳。我的论证可以概括为如下五个论题：</p>
<p>（1）人类历史的进程受人类知识增长的强烈影响。（即使把我们的思想，包括我们的科学思想看作某种物质发展的副产品的那些人，也不得不承认这个前提的正确性。）</p>
<p>（2）我们不可能用合理的或科学的方法来预测我们的科学知识的增长。（这个论断可以由下面概述的理由给予逻辑的证明。）</p>
<p>（3）所以，我们不能预测人类历史的未来进程。</p>
<p>（4）这就是说，我们必须摈弃理论历史学的可能性，即摈弃与理论物理学相当的历史社会科学的可能性。没有一种科学的历史发展埋比能作为预测历史的根据。</p>
<p>（5）所以历史决定论方法的基本目的是错误的；历史决定论不能成立。</p>
</blockquote>
<h3 id="5-《通往奴役之路》"><a href="#5-《通往奴役之路》" class="headerlink" title="5.《通往奴役之路》"></a>5.《通往奴役之路》</h3><h4 id="作者-4"><a href="#作者-4" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[英]弗里德利希·奥古斯特·哈耶克</li>
</ul>
<h4 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h4><p>这本书读了一遍没都很懂😂，所以我先引用一下别人写的简介。</p>
<blockquote>
<p>按作者的说法是一本批判的小册子，而批判的对象就是集体主义的思想倾向。 作者用严密的逻辑粉碎了掩盖在集体主义之上的美好设想，论证了集体主义必将导致独裁，最终走向文化崩坏与经济停滞的结局。 逻辑性很强，读起来不容易。相比之下对自由主义的立论较弱，有些偏理想化</p>
<p>核心的论证逻辑其实很简单明了。论证的过程可以分为：</p>
<ul>
<li>为什么人们渴望集体主义？</li>
<li>集体主义为什么走不通？</li>
<li>为什么要坚持自由主义？</li>
</ul>
<p>自由主义社会下，人们很容易产生很多不满，包括：</p>
<ul>
<li>政治混乱，每天都争执不休；</li>
<li>经济混乱，自由竞争下存在大量的浪费；</li>
<li>思想混乱，每个人都有一套自己所认为的说辞；</li>
</ul>
<p>在这些诸多的混乱下，一个有理想有抱负的人，很容易去试图建立起一种“秩序”， 比如针对经济，希望能够建立起一种目光长远的，和谐有序的经济制度，将浪费最小化， 让每个人从无效的浪费和争执中解放出来，专注于有益的共同的目标。</p>
<p>这个理想是非常美好的，几百年来不断有思想家或实践家试图践行这一理想，但是却没有一个人或社会能够成功。 其最终要么全面崩溃，要么建成了如人间地狱一般的极权社会。</p>
<p>到底是哪里错了呢？有些人认为是因为有坏人从中作梗，将原本良善的目标和努力引导到了他的个人野心之上。 而此书对于这一观点也做出了有力的驳斥，并且一针见血地指出，极权主义是集体主义的必然路径。 任何想要发展集体主义的社会，最终必然成为极权社会。而对于任何极权社会，无论当权者用心善良还是险恶， 为了在这一制度中生存下来，他必将会采取一系列在后世看来残忍而又贪婪的举措。</p>
<p>集体主义必将导致极权社会的理由可以非常简单的概括为：</p>
<ul>
<li>集体主义必然需要为社会确定一个最高目标；</li>
<li>但是每个人心目中的目标其实都不一样，为了确定这个目标，必须先要实现高度集权；</li>
<li>只有极权社会，才有可能压倒众人的个人思想，推行一种整齐划一的规划和经济活动。</li>
</ul>
<p>到这里还很容易理解。但是，为什么会说极权社会必然导致文化堕落和经济停滞呢？</p>
<p>这里需要引入几个前提：</p>
<ul>
<li>社会的发展是不可预测的，没有人能够准确的猜测出未来的发展方向和方式；</li>
<li>社会是错综复杂的，每个人都只能看到和他息息相关的一部分信息。</li>
</ul>
<p>所以，我们可以得出这样的推论，因为在极权社会中，是由地位最高的人根据自己的见解， 来制定整个社会的经济计划，所以：</p>
<ul>
<li>一切的社会活动，都会按照最终和“最高目标”间的联系，确定优先级；</li>
<li>一切的社会活动，必须要有明确的目的和产出，否则会被视为无意义的行为；</li>
</ul>
<p>也就是说，计划经济只能对一个“已知的目标”进行计划。 这会导致这种社会制度扼杀一切新形式的创新。 更有甚者，因为没有人能够了解社会的全貌，所以其实这种针对已知目标的“全盘计划”也是不可能的。</p>
<p>为了能够在现实中真正的实施而不是一纸空话，这些计划一定要是含糊的，留有一定随机应变的空间。 让基层领导可以在具体实施的时候再根据自己的意志去变通。</p>
<p>而这又得出了一个新的结论，集体主义的社会中，其法制一定是欠缺的。 因为高度计划之下的计划或法令，必须要给实际的权力人物或机构留出足够的变通的空间。 换言之，集体主义的法制一定是定义模糊可自由解释的。</p>
<p>除了经济和法律的领域之外，集体主义为了推广整齐划一的经济计划， 那么就必须要尽可能的在大多数人的思想中，灌输统一的价值观， 以令大多数人都能够形成一个相对一致的目标。</p>
<p>很讽刺的是，作者为了攻击苏联体制出版了这书，然后却因为苏联的工业化成功而遭受冷遇， 然而几十年后，此书描述的一切都如同预言一般的在苏联上演，此后各个集体主义国家几乎全部都像魔咒一样的把历史一再重演。</p>
<p>此处引用  <a href="https://blog.laisky.com/p/serfdom/" target="_blank" rel="noopener">《通往奴役之路》读后感 &amp; 摘抄</a> </p>
</blockquote>
<h4 id="读后感-4"><a href="#读后感-4" class="headerlink" title="读后感"></a>读后感</h4><p>这本书读起来不容易，逻辑性很强，等以后多读几遍之后，经过大量的思考实践总结之后再专门写一篇博客谈谈读后感。在此推荐各位去读一读另一位的 <a href="https://blog.laisky.com/p/serfdom/" target="_blank" rel="noopener">《通往奴役之路》读后感 &amp; 摘抄 </a> 以及盛洪老师的 <a href="https://www.youtube.com/watch?v=MpJDymF6K-M" target="_blank" rel="noopener">盛洪谈哈耶克之《法、立法与自由》</a> </p>
<h4 id="摘抄-4"><a href="#摘抄-4" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>即使共产主义者们也想必多少已为诸如列宁的老友马克斯·伊斯门先生所作的那类宣言所震撼；他自己不得不承认，“斯大林主义与法西斯主义相比，不是更好，而是更坏，更残酷无情、野蛮、不公正、不道德、反民主、无可救药”，并且它“最好被称为超法西斯主义”；当我们发现同一作者承认“在这样一种意义上，斯大林主义就是社会主义，它是国有化和集体化不可预料但却是不可避免的政冶附属物，而这两者都是他赖以建立一个无阶级社会计划的一部分”，②他的结论明显地具有更广泛的意义。</p>
</blockquote>
</li>
<li><blockquote>
<p>在俄国住了12年的美国记者W·H·张伯伦先生眼见他的全部理想破灭，便将他在那里和德国、意大利所做的研究总结成这种说法：“社会主义者肯定会证实，至少在其开始时，不是通往自由的道路，而是通往独裁和反独裁、通往最惨烈的内战的道路。以民主手段实现并维持的社会主义，看来确实属于乌托邦世界。</p>
</blockquote>
</li>
<li><blockquote>
<p>马克思主义已经导致了法西斯主义和民族社会主义，因为就其全部本质而言，它就是法西斯主义和民族社会主义”。</p>
</blockquote>
</li>
<li><blockquote>
<p>人们从近年来的出版物中，可以挑选出许多有能力做出判断的人所作出的其它类似叙述，特别是由那种人所作的叙述，他们作为现在的极权主义国家的公民，亲历了这种转变，他们的经验迫使他们对许多珍爱的信念加以修正。</p>
</blockquote>
</li>
<li><blockquote>
<p>通过马克思主义可以达到自由与平等的信念的完全崩溃，已经迫使俄国走上德国一直在遵循的相同道路，即通往极权主义的、纯粹消极的、非经济的、不自由不平等的社会。这等于说共产主义和法西斯主义本质上是相同的。法西斯主义是在共产主义已被证实为一种幻想之后所达到的一个阶段，而在斯大林主义的俄国和希特勒之前的德国，共产主义已经同样被证实是一种幻想。</p>
</blockquote>
</li>
<li><blockquote>
<p>在这个意义上，社会主义意味着废除私有企业，废除生产资料私有制，创造一种“计划经济”体制，在这种体制中，中央的计划机构取代了为利润而工作的企业家。</p>
</blockquote>
</li>
<li><blockquote>
<p>社会主义不仅是集体主义或“计划”中最最重要的一种，而且正是社会主义劝说具有自由主义思想的人们再一次屈从对经济生活的管辖，而这种管辖他们曾推翻过，因为照亚当·斯密的说法，这使政府处于“为了维持自身，他们有责任实行压迫和专制”①的地位。</p>
</blockquote>
</li>
<li><blockquote>
<p>问题在于，出于这个目的，强制力量的控制者是否应该将自己限制于笼统地创造条件，以便最充分地发挥每个人的知识和创造力，使他们能成功地做出计划，或者为了合理地利用资源，我们是否必须根据某些有意识构造的“蓝图”对我们的一切活动加以集中的管理和组织。</p>
</blockquote>
</li>
<li><blockquote>
<p>任何控制某些商品的价格或数量的企图，都会使竞争失去它有效地协调个人努力的力量，因为这时价格的变化不再显示客观条件的全部有关变化，也不再对个人的行动提供一个可靠的指南。</p>
</blockquote>
</li>
<li><blockquote>
<p>成功地将竞争用作社会组织的原则，就排除了对经济生活的某种形式的强制性干预，但它承认有时会有助于其运作的其它形式的强制性干预，甚至还必需某种形式的政府行为。</p>
</blockquote>
</li>
<li><blockquote>
<p>法律仅仅承认私有财产和契约自由是根本不够的，它更有赖于对适用于不同事物的财产权的明确限定。对使竞争制度有效运行的种种形态法律制度的系统研究，已经令人痛心地遭到忽视；</p>
</blockquote>
</li>
<li><blockquote>
<p>至少可能想见，在一个非常整齐划一的政府和一个教条主义的多数民主的政府统治下，民主制度也许和最坏的独裁制度同样暴虐。但是，我们的要点与其是独裁必然不可避免地消灭了自由，毋宁是计划导致独裁，因为独裁是强制推行各种理想的最有效工具，而且，集中计划要在很大程度成为可能的话，独裁本身是必不可少的。计划与民主之间的冲突只不过起因于这个事实，即对经济活动管理所需的对自由的压制来说，后者是个障碍。但是，只要民主不再是个人自由的保障的话，那么它也可能以某种形式依然存在于极权主义政体之下。一个真正的“无产阶级专政”，即使形式上是民主的，如果它集中管理经济体系的话，可能会和任何专制政体所曾做的一样完全破坏了个人自由。</p>
</blockquote>
</li>
</ul>
<h3 id="6-《末日时在做什么？有没有空？可以来拯救吗？》"><a href="#6-《末日时在做什么？有没有空？可以来拯救吗？》" class="headerlink" title="6.《末日时在做什么？有没有空？可以来拯救吗？》"></a>6.《末日时在做什么？有没有空？可以来拯救吗？》</h3><h4 id="作者："><a href="#作者：" class="headerlink" title="作者："></a>作者：</h4><ul>
<li>[日] 枯野瑛</li>
</ul>
<h4 id="简介-5"><a href="#简介-5" class="headerlink" title="简介"></a>简介</h4><p>之前看过动画，也是暑假的时候才开始读一下原作的，只不过读完第一部就没心情接着读第二部了。因为第二部的故事主人公都变了，而且第一部的结局读完后很压抑。</p>
<h3 id="7-《切尔诺贝利的悲鸣》"><a href="#7-《切尔诺贝利的悲鸣》" class="headerlink" title="7.《切尔诺贝利的悲鸣》"></a>7.《切尔诺贝利的悲鸣》</h3><h4 id="作者-5"><a href="#作者-5" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[白俄] S·A·阿列克谢耶维奇</li>
</ul>
<h4 id="简介-6"><a href="#简介-6" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>★获得2015年诺贝尔文学奖，真实记录切尔诺贝利核灾难事件</p>
<p>★“她的复调书写，是对我们时代的苦难和勇气的纪念。”</p>
<p>★“每一页，都是感人肺腑的故事。”</p>
<p>-————————————————————————</p>
<p>1986年4月26日，史上最惨烈的反应炉事故发生在切尔诺贝利。这是史上最浩大的悲剧之一。作者访问了上百位受到切尔诺贝利核灾影响的人民，有无辜的居民、消防员、以及那些被征招去清理灾难现场的人员。他们的故事透露出他们至今仍生活在恐惧、愤怒和不安当中。</p>
<p>本书将这些访谈以独白的方式呈现，巨细靡遗的写实描绘，使这场悲剧读起来像世界末日的童话。人们坦白地述说着痛苦，细腻的独白让人身历其境却又难以承受。</p>
<p>-————————————————————————</p>
<p>★《纽约时报》——每一页都是奇异而残忍的故事，就像那些残留在幸存者身上的辐射。</p>
<p>★《伦敦时报》——如同古希腊悲剧表演的合唱团，本书收录了众人的心声。短期之内，我们恐怕不会再有机会读到这般真实记录愤怒、愚昧、英勇和伤亡的文字。</p>
<p>★《每日电讯报》——从受访者的独白中，阿列克谢耶维奇创造了这样一种历史：无论离这些事件有多远，读者都能感同身受，如有切肤之痛。读完这本书，我才知道切尔诺贝利是欧洲的一场海啸，这场海啸不仅是由我们人类所造成的，而且还永无止尽。如果你对未来抱有好奇心，我强烈推荐这本书。书中的切尔诺贝利是个充满极端与未知的地方，一个现代科技发展造就的戏剧世界。</p>
<p>★《出版人周刊》——口语叙述的历史在脑海中挥之不去，充斥着面对命运时的无奈、艰苦卓绝的勇气，以及浓厚的黑色幽默……如同不可磨灭的X光透视着俄国人的灵魂。</p>
<p>★《国家》杂志——阿列克谢耶维奇的这本杰出著作，忠实地记录着她那些白俄罗斯同胞的生命与死亡。本书终于将在美国上架……这是无与伦比的见证。</p>
<p>★《书目杂志》——书中记录着受污染的世界里骇人的生活。这些典型的故事分别传达出不同的声音：愤怒、恐惧、无知、艰苦、英勇、同情和爱。阿列克谢耶维奇冒着损害健康的风险，深入前线收集这些见证，把故事转化成令人难忘的精辟著作，我们只能期盼书中的灾难不会重现。</p>
<p>此处剽窃自豆瓣</p>
</blockquote>
<h4 id="读后感-5"><a href="#读后感-5" class="headerlink" title="读后感"></a>读后感</h4><p>五月份的时候 Netflix 上映了切尔诺贝利的纪录片，之后十月份的时候在博客上认识一位博主，在他的博客里发现了这本书，于是就花了一周的时间读完。建议看完 Netflix 上的纪录片再来看看这本书。读这本书的时候，和《一百个人的十年》一样的感受，心中压抑痛苦的心情无法用言语表达。</p>
<h4 id="摘抄-5"><a href="#摘抄-5" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>我已经身处险境了<br>我们现在都身处险境<br>因为那些机密和谎言<br>基本上成为了我们的一部分<br>当真相浮出水面 ，我们不断用谎言覆盖<br>直到我们都记不起真相是什么<br>但真相依旧在那里<br>我们撒的每一个谎言都是对真相的透支，早晚要还<br>这就是压力管式石墨沸水堆反应堆核心爆炸的原因–谎言<br>此处引用 HBO 切尔诺贝利纪录片 S1E5</p>
</blockquote>
</li>
<li><blockquote>
<p>我看遍了他人的痛苦，但在这里我和他们同样是见证人。这个事件是我人生的一部分，我就活在其中。</p>
<p>我们的国家有三百五十颗核弹。人们还没有注意到是从什么时候开始的，却已经活在后核战的时代了。</p>
<p>现在，人们因为其他的战争来到这里。上千名俄国难民从亚美尼亚、格鲁吉亚、阿布哈兹、塔吉克斯坦、车臣等地涌入。这些人从有枪声的地方来，来到这片被遗弃的土地。这里还有荒废的房屋尚未被特殊部队掩埋。</p>
<p>一共有两千五百万侨胞住在俄国领土外——这已经是一个国家的人口数了——他们无处可归，只能去切尔诺贝利。关于那里的土地、水和空气能够取人性命的传言，对他们来说只是童话故事。这些人有自己的故事，一个古老的故事，他们深信不疑——这个故事是在说人们如何用枪射杀他人。</p>
<p>我是在伟大的俄罗斯文学的浸染中长大的，我认为作品的尺度可以更辽阔，所以我把这一段血肉横飞的情节写了下来。但是在隔离区——那是另一个世界，那个世界与外面的世界不同——那些强烈的感受是文学无法形容的。</p>
<p>三年来，我四处旅行，在人群里访问：包括在核电厂工作的工人，科学家，前共党官僚，医生，士兵，直升机驾驶员，矿工，难民，迁居的人们。他们都有着不同的命运、职业和个性，但是切尔诺贝利却是他们生命里共同的重心。这些人不过是平凡人，却必须面临最艰难的问题。</p>
<p>我时常觉得，简单和呆板的事实，不见得会比人们模糊的感受、传言和想象更接近真相。为什么要强调这些事实呢，这只会掩盖我们的感受而已。从事实当中衍生出的这些感受，以及这些感受的演变过程，才是令我着迷的。我会试着找出这些感受，收集这些感受，并将其仔细保护起来。</p>
<p>书中的人已经见过他人未知的事物。我觉得自己像是在记录着未来。</p>
<p>斯韦特兰娜·阿列克谢耶维奇</p>
</blockquote>
</li>
</ul>
<h3 id="8-《一百个人的十年》"><a href="#8-《一百个人的十年》" class="headerlink" title="8.《一百个人的十年》"></a>8.《一百个人的十年》</h3><h4 id="作者：-1"><a href="#作者：-1" class="headerlink" title="作者："></a>作者：</h4><ul>
<li>冯骥才</li>
</ul>
<h4 id="简介-7"><a href="#简介-7" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>二十世纪历史将以最沉重的笔墨，即在这人类的两大悲剧：法西斯暴行和“文革”浩劫。凡是这两大劫难的亲身经历者，都在努力忘却它，又无法忘却它。文学家与史学家有各自不同的记载方式：史学家偏重于灾难的史实，文学家偏重于受难者的心灵。本书作者试图以一百个普通中国人在“文革”中的西宁历程的真实记录，显现那场旷古未闻的劫难的真相。</p>
<p>口述文学版《一九八四》，也算是当代中国的一代奇书，冯骥才的史学良知与文学功底相得益彰，文学性与纪实性都相当完美，讲述者都带有天津话特色，在“过来人”平静又略带幽默的娓娓道来中极其惊心动魄，揭露了一个民族的黑暗历史，比恐怖小说还恐怖，这才是人性恶与残酷性的百科全书，是让年轻人看清社会真相的暗黑教育手册。</p>
<p>此处剽窃自豆瓣</p>
</blockquote>
<h4 id="读后感-6"><a href="#读后感-6" class="headerlink" title="读后感"></a>读后感</h4><p>1949 年，《1984》出版问世。1950年乔治奥威尔辞世。他没有想到，和他书中预想的一样。十六年后在东方一个意识形态迥异国家会上演和书中一样的闹剧。这本书是冯骥才先生写的，记录了人类历史上最为惨痛的那场长达十年的灾难。 这本书和《切尔诺贝利的悲鸣》写作风格及其相似，都是以都是以采访纪实的方式分别记录了人类历史上两场灾难（文革浩劫和切尔诺贝利事故）中经历者们的遭遇，都承载着普通人的悲苦命运。</p>
<p>读这本书的时候，对书中真实记录的那些人的悲惨命运，几次都忍不住落下眼泪。原来神州大地上也经历过如地狱一般的浩劫。十年的文革浩劫扯碎了中华民族自诩上千年忠孝礼义信传统美德的丑陋外皮，彻彻底底地将人性的邪恶赤裸裸地展现出来。学生告密举报老师，亲朋邻里相互揭发，父子反目成仇，比比皆是疯狂，犹如地狱一般的社会。 不禁感叹，作为一个拥有着五千年悠长文明的古国，几千年前的历史都是历历在目，怎么越到近现代视野就越来越模糊了呢？</p>
<p>读这两本书有一个共感受：绝望无助、愤怒痛恨、压抑沉重的历史让人无法喘息。 历史的过错原本是一宗难得的财富，丢掉这些财富便会陷入新的无知和愚昧。而我们的责任就是将这段历史伴随着人类文明的结晶一代一代传递给未来的后人们，警告他们对自然法则、对生命抱有敬畏之心。 作为中华儿女，我们有责任也有义务铭记这段历史，将这段人类史上悲痛的灾难传递给未来的后辈们。</p>
<p>我们谴责日本忘记历史的时候，自己有没有反省过当年犯下同样的反人类罪行？ 建议那些喊着“不忘初心牢记使命”口号的人，不妨去重温一下这段历史吧。</p>
<h4 id="摘抄-6"><a href="#摘抄-6" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>“文革”是我们政治、文化、民族疯疾的总爆发，要理清它绝非一朝一夕之事；而时代 不因某一事件的结束而割断，昨天与今天是非利害的经纬横竖纠缠，究明这一切依然需要勇 气，更需要时间，也许只有后人才能完成。因此本书不奢望绘读者任何聪明的结论，只想让 这些实实在在的事实说话，在重新回顾“文革”经历者心灵的画面时，引起更深的思索。没 有一层深于一层的不浅尝辄止的思索，就无法接近真理性的答案。没有答案的历史是永无平 静的。</p>
</blockquote>
</li>
<li><blockquote>
<p>二十世纪历史将以最沉重的笔墨，记载这人类的两大悲剧：法西斯暴行和“文革”浩 劫。凡是这两大劫难的亲身经历者，都在努力忘却它，又无法忘却它。我常常悲哀地感到，我们的民族过于健忘。“文革”不过十年，已经很少再见提及。那 些曾经笼罩人人脸上的阴影如今在哪里？也许由于上千年封建政治的高压，小百姓习惯用抹 掉记忆的方式对付苦难。但是，如此乐观未必是一个民族的优长，或许是种可爱的愚昧。历 史的过错原本是一宗难得的财富，丢掉这财富便会陷入新的盲目。</p>
</blockquote>
</li>
<li><blockquote>
<p>若要对这数亿人经验过的生活做出宏观的概括，任何个人都 方不能及。我努力做的，只能在我所能接触到的人中间，进行心灵体验上所具独特性的选 择。至于经历本身的独特，无需我去寻找。在无比强大的社会破坏力面前，各种命运的奇迹 都会呈现，再大胆的想象也会相形见细。但我不想收集各种苦难的奇观，只想寻求受难者心 灵的真实。我有意记录普通人的经历，因为只有底层小百姓的真实才是生活本质的真实。只 有爱惜每一根无名小草，每一颗碧绿的生命，才能紧紧拥抱住整个草原，才能深深感受到它 的精神气质，它惊人的忍受力，它求生的渴望，它对美好的不懈追求，它深沉的忧虑，以及 它对大地永无猜疑、近似于愚者的赤诚。</p>
</blockquote>
</li>
<li><blockquote>
<p>以我的感受，大人物的经历不管多悲惨，也不能和小百姓们相比。大人物的冤枉总容易解决，小百姓们如果没碰对了人，碰巧了机会，也许很难得到命运的晴天，就像梁山的李老师正好碰上我读过使他冤屈的故事那样。我想，至今天下还有多少人含冤未平，无论是活着还是已经死去的？<br>人民的经历，才是时代的经历。</p>
</blockquote>
</li>
</ul>
<h3 id="9-《娱乐至死》"><a href="#9-《娱乐至死》" class="headerlink" title="9.《娱乐至死》"></a>9.《娱乐至死》</h3><h4 id="作者：-2"><a href="#作者：-2" class="headerlink" title="作者："></a>作者：</h4><ul>
<li>[美] 尼尔·波兹曼</li>
</ul>
<h4 id="简介-8"><a href="#简介-8" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>这本书表达了作者对印刷业衰落的叹惋和对全美沉迷电视娱乐的忧心。Neil Postman 认为，不同的媒介会影响公共话语（public discourse）的形态——印刷机统治下的美国，公共话语是思辨的；而在电视娱乐时代，观众被连续、琐碎、无关联的信息洪流冲击，根本无法思考，更别提发表自己的意见了。以新闻节目为例，主持人刚播报完某政治人物因为丑闻被弹劾，立刻就「好，现在来看下一条消息」（<em>Now … this</em>），开始播报某明星要在哪里开演唱会了。设想如果电视节目主持人让观众「停下来思考五分钟」，这是会打击收视率的。更可怕的是，这些碎片化的、反思考的电视节目（尤其是电视广告）不仅对成年人造成冲击，更深深地影响着下一代（看电视长大的一代），甚至是学校。</p>
</blockquote>
<blockquote>
<p>这书出版于 1985 年，当时互联网还没有发展起来。2006 年 YouTube 重新定义了电视（tube），2007 年 iPhone 开启了智能手机时代。2010 年之后出生的孩子（一零后？），是真正的移动互联网原住民，他们根本不需要坐到电视机前，而是伸手就可以摸到智能手机和平板电脑，沉浸到碎片化娱乐之中。若是 Neil Postman 老人家看到了 2018 年的互联网娱乐，怕是要气得从坟墓里爬出来吧。</p>
<p>此处引用自  <a href="https://wzyboy.im/post/1264.html" target="_blank" rel="noopener">wzyboy</a></p>
</blockquote>
<h4 id="读后感-7"><a href="#读后感-7" class="headerlink" title="读后感"></a>读后感</h4><p>可以结合作者的另一本书《童年的消逝》来读，作者对批判电视所带来的危害，在当今把电视换成抖音快手这类的短视频也好不过是。在我看来抖音快手短视频就是《娱乐至死》里所批判的电视的升级版。甚至短视频更进一步粉碎了使用者的注意力。所以我极度讨厌这些短视频，他们所带来的都是空荡荡的商业消费。但未来短视频会沦为真理部洗脑宣传一次来控制人民的工具。</p>
<p>我觉着那些是使用抖音的人都像在吃屎一样，首先字节跳动这种毫无底线的无耻流氓公司宣称 <strong>通讯录不是个人隐私</strong> 。虽然我从不使用今日头条旗下的任何一款产品和服务在此我只想骂一句粗话，草拟玛丽隔壁去年狗娘养的抖音短视频。这种狗娘养的公司比百度还恶毒，没想到在天朝居然那么多人在使用。呵呵，其实每次看到有人在刷抖音短视频就像看到他在吃屎一样，居然吃的那么香。</p>
<blockquote>
<p>据澎湃6月20日报道，用户刘先生认为“今日头条”APP在《用户协议及隐私条款》中未明确将收集用户个人信息，却擅自上传并保存其通讯录，严重侵犯了用户隐私权，违反了信息收集的“合理、必要”原则，请求法院判令被告停止侵权、赔礼道歉并支付精神赔偿金1元。然而在法庭上，今日头条公司却辩称：通讯录并非是原告本人的信息，而是其社会网络成员的信息，不属于个人隐私，不但不应保密，反而需要向他人告示。 </p>
<p>此处引用 <a href="https://www.ittime.com.cn/news/news_28229.shtml" target="_blank" rel="noopener">通讯录不属于个人隐私？</a></p>
</blockquote>
<h4 id="摘抄-7"><a href="#摘抄-7" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>电视上会话的表现形式是形象而不是语言。</p>
</blockquote>
</li>
<li><blockquote>
<p>电视需要的内容和其他媒体截然不同。电视无法表现政治哲学，电视的形式注定了它同政治哲学是水火不相容的。</p>
</blockquote>
</li>
<li><blockquote>
<p>信息、内容，或者如果你愿意，可以称之为构成“今日新闻”的“素材”，在一个缺乏媒介的世界里是不存在的——是不能存在的。</p>
</blockquote>
</li>
<li><blockquote>
<p>因为这样两种截然不同的媒介不可能传达同样的思想。随着印刷术影响的减退，政治、宗教、教育和任何其他构成公共事务的领域都要改变其内容，并且用最适用于电视的表达方式去重新定义。</p>
</blockquote>
</li>
<li><blockquote>
<p>媒介的形式偏好某些特殊的内容，从而能最终控制文化。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们的文化正处于从以文字为中心向以形象为中心转换的过程中，思考一下摩西的训诫对我们也许是有益的。</p>
</blockquote>
</li>
<li><blockquote>
<p>某个文化中交流的媒介对于这个文化精神重心和物质重心的形成有着决定性的影响。</p>
</blockquote>
</li>
<li><blockquote>
<p>人们怎样看待时间和空间，怎样理解事物和过程，都会受到语言中的语法特征的重要影响</p>
</blockquote>
</li>
<li><blockquote>
<p>和语言一样，每一种媒介都为思考、表达思想和抒发情感的方式提供了新的定位，从而创造出独特的话语符号。这就是麦克卢汉所说的“媒介即信息”。但</p>
</blockquote>
</li>
<li><blockquote>
<p>分分秒秒的存在不是上帝的意图，也不是大自然的产物，而是人类运用自己创造出来的机械和自己对话的结果。</p>
</blockquote>
</li>
<li><blockquote>
<p>因为在一个由分分秒秒组成的世界里，大自然的权威已经被取代了。</p>
</blockquote>
</li>
<li><blockquote>
<p>用书面文字记录哲学观点，不是这些观点的终结，而是这些观点的起点</p>
</blockquote>
</li>
<li><blockquote>
<p>我们的语言即媒介，我们的媒介即隐喻，我们的隐喻创造了我们的文化的内容。</p>
</blockquote>
</li>
<li><blockquote>
<p>首先，我想证明，在印刷机统治下的美国，话语和现在有很大不同——清晰易懂，严肃而有理性；</p>
</blockquote>
</li>
<li><blockquote>
<p>在学术界里，出版的文字被赋予的权威性和真实性远远超过口头语言。人们说的话比他们写下来的话要随意。书面文字是作者深思熟虑、反复修改的结果，甚至还经过了专家和编辑的检查。这样的文字更加便于核对或辩驳，并且具有客观的特征。</p>
<p>但是，控制你的身体是最低限度的要求。你还必须学会注意书本上文字的形状。你必须看穿它们，这样你才能直接了解这些形状所代表的意思。如果你仅仅专注于文字的形状，那么你就是一个让人不能容忍的低效读者，会被人当作傻子。如果你已经学会了怎样不受外观的干扰去理解意义，那么你就应该采取一种超然而客观的态度，这包括你要能够区分文字的感官愉悦、魅力或奉承语气（如果有的话）和文字所表达的观点之间的逻辑。同时，你还必须能够根据语言的语气去判断作者对于所写内容和读者的态度。换句话说，你必须知道笑话和观点之间的区别。</p>
</blockquote>
</li>
<li><blockquote>
<p>18世纪和19世纪的美国也许是有史以来最以铅字为中心的文化，我相信电视创造出来的认识论不仅劣于以铅字为基础的认识论，而且是危险和荒诞的。</p>
</blockquote>
</li>
<li><blockquote>
<p>符号环境中的变化和自然环境中的变化一样，开始都是缓慢地累积，然后突然达到了物理学家所说的临界点。</p>
<p>在这种情况下，电子媒介决定性地、不可逆转地改变了符号环境的性质。</p>
<p>我说的只是以电视为中心的认识论污染了大众交流和相关活动，而不是说它污染了一切。</p>
</blockquote>
</li>
<li><blockquote>
<p>电视给那些老弱病残以及在汽车旅馆里饱尝孤独寂寞的人带来了无尽的安慰和快乐。</p>
</blockquote>
</li>
<li><blockquote>
<p>印刷书籍比任何其他方式都更有效地把人们从现时现地的统治中解放出来……铅字比实际发生的事实更有威力……存在就是存在于铅字之中：其他的一切都将渐渐地成为虚无。所谓学习就是书本的学习。”</p>
</blockquote>
</li>
<li><blockquote>
<p>报纸是知识的源泉， 是现代人每一次对话的灵感来源。</p>
</blockquote>
</li>
<li><blockquote>
<p>枪炮的发明使奴隶和贵族得以在战场上平等对峙；印刷术为各阶层的人们打开了同样的信息之门，邮差把知识一视同仁地送到茅屋和宫殿前。</p>
</blockquote>
</li>
<li><blockquote>
<p>从一开始到19世纪，美国比任何一个社会都痴迷于铅字以及建立在铅字基础上的演讲术。</p>
</blockquote>
</li>
<li><blockquote>
<p>理查德·霍夫施塔特[40]提醒我们，美国是一个由知识分子建立的国家，这些开国元勋都是智者、科学家、学养高深之人，他们中的很多人都精于古典学问，善于借助熟知的历史、政治和法律来解决当时紧迫的问题。</p>
</blockquote>
</li>
<li><blockquote>
<p>在书本里，这个世界是严肃的，人们依据理性生活，通过富有逻辑的批评和其他方式不断地完善自己。</p>
</blockquote>
</li>
<li><blockquote>
<p>对于他们来说，没有高深的文化程度，要想成为一个成熟的公民是不可能的，这就是为什么美国大多数州将选举年龄定为21岁，为什么杰弗逊认为普及教育是美国最大希望的原因。</p>
</blockquote>
</li>
<li><blockquote>
<p>两个世纪以来，美国人用白纸黑字来表明态度、表达思想、制定法律、销售商品、创造文学和宣扬宗教。这一切都是通过印刷术实现的，也正是通过这样的方式，美国才得以跻身于世界优秀文明之林。</p>
</blockquote>
</li>
<li><blockquote>
<p>通过生产大量无关的信息，它完全改变了我们所称的“信息—行动比”。 不管是在口头文化还是在印刷术文化中，信息的重要性都在于它可能促成某种行动。</p>
</blockquote>
</li>
<li><blockquote>
<p>电报带给我们的是支离破碎的时间和被割裂的注意力。电报的主要力量来自它传播信息的能力，而不是收集信息、解释信息或分析信息。在这方面，电报和印刷术截然相反。</p>
</blockquote>
</li>
<li><blockquote>
<p>书籍就是收集、细察和组织分析信息观点的绝好容器。写书、读书、讨论书的内容、判断书的价值（包括书的版面安排），都是需要花费大量时间的。写书是</p>
</blockquote>
</li>
<li><blockquote>
<p>电报只适合于传播转瞬即逝的信息，因为会有更多更新的信息很快取代它们。这些信息后浪推前浪地进出于人们的意识，不需要也不容你稍加思索。</p>
</blockquote>
</li>
<li><blockquote>
<p>描绘过的世界开始变得无法控制，甚至无法解释了。报纸上一行行有序而连贯的文字渐渐失去了帮助我们获得知识和了解这个世界的能力。</p>
</blockquote>
</li>
<li><blockquote>
<p>这种巧合说明现代技术彻底改变了人们对于信息的态度：过去人们是为了解决生活中的问题而搜寻信息，现在是为了让无用的信息派上用场而制造问题。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们不再只把电视机放在某些特定的房间里；我们不再怀疑在电视上看到的一切，根本不会意识到电视提供给我们的特殊视角，甚至连“电视是如何影响我们的”这个问题也被我们抛到了九霄云外。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们不再只把电视机放在某些特定的房间里；我们不再怀疑在电视上看到的一切，根本不会意识到电视提供给我们的特殊视角，甚至连“电视是如何影响我们的”这个问题也被我们抛到了九霄云外。</p>
</blockquote>
</li>
<li><blockquote>
<p>大脑和技术都是物质装置，思想和媒介都是使物质装置派上用场的东西。一旦技术使用了某种特殊的象征符号，在某种特殊的社会环境中找到了自己的位置，或融入到了经济和政治领域中，它就会变成媒介。换句话说，一种技术只是一台机器，媒介是这台机器创造的社会和文化环境。</p>
</blockquote>
</li>
<li><blockquote>
<p>在我所指的那些地方，大多数人还没有电视机，拥有电视机的人也只有一台，他们只有一个电视台，他们没有全天24小时播放的电视节目，大多数节目都以推进政府的意识形态和政策为首要目的。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们看见的不仅是零散不全的新闻，而且是没有背景、没有结果、没有价值、没有任何严肃性的新闻，也就是说，新闻成了纯粹的娱乐。</p>
</blockquote>
</li>
<li><blockquote>
<p>我必须指出，掩藏在电视新闻节目超现实外壳下的是反交流的理论，这种理论以一种抛弃逻辑、理性和秩序的话语为特点。在美学中，这种理论被称为“达达主义”；在哲学中，它被称为“虚无主义”；在精神病学中，它被称为“精神分裂症”；如果用舞台术语来说，它可以被称为“杂耍”。</p>
</blockquote>
</li>
<li><blockquote>
<p>假信息并不意味着错误的信息，而是意味着使人产生误解的信息——没有依据、毫无关联、支离破碎或流于表面的信息——这些信息让人产生错觉，以为自己知道了很多事实，其实却离事实的真相越来越远。包装成一种娱乐形式时，它就不可避免地起到了蒙蔽作用。我前面说过，电视新闻节目提供给观众的是娱乐而不是信息，这种情况的严重性不仅在于我们被剥夺了真实的信息，还在于我们正在逐渐失去判断什么是信息的能力。无知是可以补救的，但如果我们把无知当成知识，我们该怎么做呢？</p>
</blockquote>
</li>
<li><blockquote>
<p>我的意思是，电视是我们了解公众信息的样板。和早些时候的印刷机一样，电视已经获得了定义新闻存在形式的力量，而且它还决定了我们如何对新闻做出反应。</p>
</blockquote>
</li>
<li><blockquote>
<p>通过用图像代替语言，图像广告使感染力成为消费者选择商品的依据，而不再是实践的检验。理性和广告早已背道而驰，我们几乎已经忘记它们之间曾经还存在着某种联系。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们要担心的是电视信息的过剩，而不是政府的限制；在公司国家美国传播的信息面前，我们根本无力保护自己，所以这场为自由而战的战斗要在和以往完全不同的阵地上进行。</p>
</blockquote>
</li>
<li><blockquote>
<p>它想尽一切办法让我们不断地看电视，但是我们看到的是使信息简单化的一种媒介，它使信息变得没有内容、没有历史、没有语境，也就是说，信息被包装成为娱乐。在美国，我们从来没有缺少过娱乐自己的机会。</p>
</blockquote>
</li>
<li><blockquote>
<p>总而言之，如果人民蜕化为被动的受众，而一切公共事务形同杂耍，那么这个民族就会发现自己危在旦夕，文化灭亡的命运就在劫难逃。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们的生活经历已经能够让我们认识监狱，并且知道在监狱大门即将关上的时候要奋力反抗。</p>
</blockquote>
</li>
<li><blockquote>
<p>但是，如果我们没有听到痛苦的哭声呢？谁会拿起武器去反对娱乐？当严肃的话语变成了玩笑，我们该向谁抱怨，该用什么样的语气抱怨？对于一个因为大笑过度而体力衰竭的文化，我们能有什么救命良方？</p>
</blockquote>
</li>
<li><blockquote>
<p>到了这个时候，如果你还不能意识到技术必然会带来社会变迁，还在坚持技术是中性的，仍然认为技术始终是文化的朋友，那么你实在是太愚蠢了。从很多例子中我们已经看出，通讯模式中的技术变化比交通模式中的技术变化更能影响人们的意识形态。把字母带入一种文化，会改变这种文化的认知习惯、社会关系、社会概念、历史和宗教。</p>
</blockquote>
</li>
<li><blockquote>
<p>什么是信息？它有哪些不同形式？不同的形式会给我们带来什么不同的知识、智慧和学习方法？每一种形式会产生怎样的精神作用？信息和理性之间的关系是什么？什么样的信息最有利于思维？不同的信息形式是否有不同的道德倾向？信息过剩是什么意思？我们怎么知道存在信息过剩？崭新的信息来源、传播速度、背景和形式要求怎样重新定义重要的文化意义？</p>
</blockquote>
</li>
<li><blockquote>
<p>我们正处于教育和灾难的竞赛之中，他不懈地著书强调理解媒介政治和媒介认识论的必要性。最后，他试图在《美丽新世界》中告诉我们，人们感到痛苦的不是他们用笑声代替了思考，而是他们不知道自己为什么笑以及为什么不再思考。</p>
</blockquote>
</li>
</ul>
<h3 id="10-《浅薄：互联网如何毒化了我们的大脑》"><a href="#10-《浅薄：互联网如何毒化了我们的大脑》" class="headerlink" title="10.《浅薄：互联网如何毒化了我们的大脑》"></a>10.《浅薄：互联网如何毒化了我们的大脑》</h3><h4 id="作者-6"><a href="#作者-6" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[美] 尼古拉斯·卡尔</li>
</ul>
<h4 id="简介-9"><a href="#简介-9" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>在我们跟计算机越来越密不可分的过程中，我们越来越多的人生体验通过电脑屏幕上闪烁摇曳、虚无缥缈的符号完成，最大的危险就是我们即将开始丧失我们的人性，牺牲人之所以区别于机器的本质属性。——尼古拉斯•卡尔“谷歌在把我们变傻吗？”当尼古拉斯•卡尔在发表于《大西洋月刊》上赫赫有名的那篇封面文章中提出这个问题的时候，他就开启了人们热切渴望的期盼源泉，让人急于弄清楚互联网是在如何改变我们的。卡尔同时也明确回答了我们这个时代面临的一个重要问题：在我们尽情享受互联网慷慨施舍的过程中，我们正在牺牲深度阅读和深度思考的能力吗？</p>
</blockquote>
<h4 id="读后感-8"><a href="#读后感-8" class="headerlink" title="读后感"></a>读后感</h4><p>感觉这本书写的并不好，在大二的时候我们学校图书馆里不小心被我找到了。我记得还是上毛概课的时候我就拿着这本书来读。PS：毛概课实在是太枯燥了，干听都听不进去。所以我就拿别的书来看了😂</p>
<p>这本书写的不如《娱乐至死》那样薅，没有一个中心论点。一会儿讲谷歌搜索是如何成功崛起的，解析来又接着讲记忆又是如何形成的。内容很杂乱而不如《娱乐至死》那样有一条很明确的论证路线，从信息传播的媒介来对当下电视机对读书多带来的冲击。</p>
<p>所以这本书不推荐，不如去读一下《娱乐至死》</p>
<h4 id="摘抄-8"><a href="#摘抄-8" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>作者指出思维正在碎片化这一基本事实：“互联网多媒体技术融多种不同类型的信息于一屏，从而进一步加剧了内容的碎片化，也进一步分散了我们的注意力。</p>
</blockquote>
</li>
<li><blockquote>
<p>“较之历史上所有可以与之相提并论的技术，互联网给我们带来的让人分神的内容实在是太多了。就在互联网向我们呈上信息盛宴的同时，它也把我们带回了彻头彻尾的精力分散的天然状态。” 碎片化使我们的思维无法再“深刻”下去，因为显然，我们不再拥有保持深刻所需要的注意力：“必将对我们的思维方式产生长远影响的一个最大的悖论是：互联网吸引我们的注意力，只是为了分散我们的注意力。”</p>
</blockquote>
</li>
<li><blockquote>
<p>　以前我很容易就会沉浸在一本书或者一篇长文当中。观点的论证时而平铺直叙，时而急转直下，二者交织推进，把我的思绪紧紧抓住。即使是索然无味的长篇大论，我也能花上几个小时徜徉其间。但现在这种情形已经很少见了。现在看上两三页，注意力就开始游移不定，我就会感到心绪不宁，思路不清，于是开始找点别的事做。我感觉就像拼命把自己天马行空的思绪拉回到文本上来一样。过去那种自然而然的精读如今已经变成了费力挣扎的苦差事。”</p>
</blockquote>
</li>
<li><blockquote>
<p>我当时就陷入沉思，在我们的教育体制内，哪种教材和考试能让小孩子具备这种快速反应下的手眼协调素质呢？我从来不反对我的孩子玩游戏，一个重要原因就是工业化的现代教育对高科技条件下所需“更原始的大脑功能”开发不足，玩游戏可以补充小学教育甚至大学教育在这一关键素质方面的不足。</p>
</blockquote>
</li>
<li><blockquote>
<p>既然传媒即信息，媒介的技术性变革会决定性地改变人的思维方式。这件事会不会做过头，结果让媒介技术最终支配了人本身？</p>
</blockquote>
</li>
<li><blockquote>
<p>卡尔认为，“信息过载”已经不是虚张声势的提醒，而是令人烦躁不安的事实。这个事实不但在吞噬着你我的注意力，更重要的是我们已经“失去了以前的大脑”</p>
</blockquote>
</li>
<li><blockquote>
<p>从纸面转到屏幕，改变的不仅是我们的阅读方式，它还影响了我们投入阅读的专注程度和沉浸在阅读之中的深入程度。</p>
</blockquote>
</li>
<li><blockquote>
<p>卡尔认为，古腾堡发明的活字印刷术唤醒了人们，深度阅读随之成了普遍流行的阅读习惯，在这种深度阅读活动中，“寂静是书中含义的一部分，寂静是读者思想的一部分”</p>
</blockquote>
</li>
<li><blockquote>
<p>知识记忆的功能，使得人的大脑对博闻强记的依赖迅速减弱；此外，图书馆、书籍所培育出来的“宁静的阅读”和“深邃辽远的对话”，在社交媒体的喧嚣声中，也成为无法还原的田园景象。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们已经抛弃了孤独宁静、一心一意、全神贯注的智力传统，而这种智力规范正是书籍赠与我们的。我们已经把自己的命运交到了杂耍者的手上。我们正在彻底颠覆图书好不容易缔造出来的“深阅读”、独处阅读的氛围和神经系统。”</p>
</blockquote>
</li>
<li><blockquote>
<p>现在看上两三页，注意力就开始游移不定，我就会感到心绪不宁，思路不清，于是开始找点别的事做。我感觉就像拼命把自己天马行空的思绪拉回到文本上来一样。过去那种自然而然的精读如今已经变成了费力挣扎的苦差事。</p>
</blockquote>
</li>
<li><blockquote>
<p>信息过载”的感觉。在那些图书的静默不语中，有一种沉稳宁静的东西，为了等待合适的读者出现，把它们取走，它们愿意一等数年，甚至数十年。那些书用它们布满灰尘的模糊声音跟我窃窃私语：“不要着急，我们哪里也不去。”</p>
</blockquote>
</li>
<li><blockquote>
<p>“一旦发现值得记下的内容，随时都可以将其写在适当的位置上”。抄写摘录精彩内容，然后定期进行背诵，有助于牢记不忘。摘录引用的段落可以看做从书页当中采撷的“各种花朵”，它们可以在记忆的页面中保存下来。</p>
</blockquote>
</li>
<li><blockquote>
<p>“我们应该效仿蜜蜂。通过各种阅读采集而来的不管是什么东西，我们都应该分别收藏在不同的空间内，因为东西分别存放会更好。然后，我们应该勤勤恳恳地运用所有的聪明才智，把我们品尝过的各种各样的花粉混合起来，将其酿成甜美的蜂蜜。通过这样一种方式，即使外观表象还跟原来一样，其内在本质已经迥然不同于初始状态。</p>
</blockquote>
</li>
<li><blockquote>
<p>极大地拓展了“人工记忆”的范围和可用程度。把信息装进自己脑袋的重要性似乎越来越低。在互联网上，无穷无尽的数据可以轻松检索，这项技术的出现不仅引起了我们对记诵的看法进一步的改变，也引起了我们对记忆本身看法的进一步改变。</p>
</blockquote>
</li>
<li><blockquote>
<p>只要我们一上网，信息流就会奔涌而来，这不仅会给我们的工作记忆带来过重的负荷，而且还会导致大脑颞叶难以聚精会神地关注任何一件事。</p>
</blockquote>
</li>
<li><blockquote>
<p>而且，因为神经通路具有可塑性，我们上网越多，对大脑适应精力分散状态的训练就越多 非常迅速、高效地处理信息，可是注意力不会持续太久。之所以有那么多人觉得即便远离计算机，我们也难以全神贯注，原因就在于此。我们的大脑变得善于遗忘而不善于记忆了。</p>
</blockquote>
</li>
<li><blockquote>
<p>由于对网络的使用导致我们在生物记忆中保存信息的难度加大，我们被迫越来越依赖互联网上那个容量巨大、易于检索的人工记忆，哪怕它把我们变成了肤浅的思考者。</p>
</blockquote>
</li>
<li><blockquote>
<p>学会如何思考 的真正含义就是要学会训练对思考方式和思考内容加以控制的能力。这就意味着，对于你选择关注的对象以及你如何从经验当中构建意义，你要有足够的意识和了解。”放弃这种控制，就会陷入“无穷无尽的得而复失造成的永恒痛苦”之中。</p>
</blockquote>
</li>
<li><blockquote>
<p>网络上把在线数据对应的一个个比特连成一体的超链接完全不同于我们大脑当中的神经突触。网络链接只是个地址，只是些简单的软件标签，它只能引导浏览器载入另一个离散的信息页面。它们根本不具备我们的神经突触所具有的有机性和灵敏性。艾瑞·舒尔曼写道，大脑中的神经连接“并非仅仅提供对记忆的访问路径，从很多方面来讲，它们构成记忆”</p>
</blockquote>
</li>
<li><blockquote>
<p>人类文明要保持勃勃生机，就必须在每一代人所有成员的头脑当中重建。记忆外包，文明消亡。</p>
</blockquote>
</li>
</ul>
<h3 id="11-《学会提问：-批判性思维指南》"><a href="#11-《学会提问：-批判性思维指南》" class="headerlink" title="11.《学会提问： 批判性思维指南》"></a>11.《学会提问： 批判性思维指南》</h3><h4 id="作者-7"><a href="#作者-7" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[美]托尼·瓦格纳</li>
</ul>
<h4 id="简介-10"><a href="#简介-10" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>本书作者应用批判性思维领域的最新研究成果，列举科学研究和日常生活中的大量实例，教授人们富有理性、逻辑性和批判性地提出、思考、判断和解决问题的方法。</p>
</blockquote>
<h4 id="读后感-9"><a href="#读后感-9" class="headerlink" title="读后感"></a>读后感</h4><p>这本书值得多读几遍，相关笔记去年读的时候写在了纸质日记本上，有空了再整理出来。</p>
<h4 id="摘抄-9"><a href="#摘抄-9" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>当面临种种广告或推销时，最好的策略或许就是持怀疑的态度。</p>
</blockquote>
</li>
<li><blockquote>
<p>广告公司不仅对我们的担忧和渴望了如指掌，而且他们以专业技能利用我们的担忧和渴望来谋取利益。</p>
</blockquote>
</li>
<li><blockquote>
<p>广告人斥巨资用于制造我们新的渴望和新的担忧——并因此创造.</p>
</blockquote>
</li>
<li><blockquote>
<p>即购买广告的产品来满足那些渴望或消除那些担忧，以此改善我们的生活。</p>
</blockquote>
</li>
<li><blockquote>
<p>别人可以通过文字和图像令我们对从前并不渴望的某物产生渴望，这也许是令人不快的事，但这显然是事实。</p>
</blockquote>
</li>
<li><blockquote>
<p>广告中的宣传之所以臭名昭著，不仅因为其模糊性，而且因其模棱两可、误导、夸张有时甚至是低级错误。</p>
</blockquote>
</li>
<li><blockquote>
<p>需要记住的是，广告的设计总是为了服务于支付广告费的人，如果广告说得天花乱坠，更需要我们警惕这一点。</p>
</blockquote>
</li>
<li><blockquote>
<p>值得强调的是，广告本来就不是用于论证购买产品的合理性的，广告是为了销售产品。</p>
</blockquote>
</li>
<li><blockquote>
<p>利益相关方比利益无关方更值得质疑。 ·对信息来源的质疑一般有两类，一类是质疑信息来源的知识或专业技能，一类是质疑信息来源的诚实性、客观性和正确性。</p>
</blockquote>
</li>
<li><blockquote>
<p>依然不是。只有在能引发你思考理由这个意义上，广告图片才“给你提供理由”去购买。在任何意义上，图片都不是也不可能是论证。</p>
</blockquote>
</li>
</ul>
<h3 id="12-《少有人走的路》"><a href="#12-《少有人走的路》" class="headerlink" title="12.《少有人走的路》"></a>12.《少有人走的路》</h3><h4 id="作者：-3"><a href="#作者：-3" class="headerlink" title="作者："></a>作者：</h4><ul>
<li>[美] M·斯科特·派克</li>
</ul>
<h4 id="简介-11"><a href="#简介-11" class="headerlink" title="简介"></a>简介</h4><h4 id="读后感-10"><a href="#读后感-10" class="headerlink" title="读后感"></a>读后感</h4><h4 id="摘抄-10"><a href="#摘抄-10" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>罪恶感就像是一盏灯，有了罪恶感，人才能看清自己身上的“恶”，从而走向善；而逃避罪恶感，不愿意承受良心的谴责，心灵就会一片漆黑。这样的心灵不仅无法燃烧出生命的光芒，还会吹熄别人的灯，扼杀别人的生命力。</p>
</blockquote>
</li>
<li><blockquote>
<p>来看心理医生的人大多数都是敢于面对自己内心的人，因为看心理医生的行动本身就证明他们觉得自己有问题，与正常的人不同，他们敢于质疑自己，敢于承认自己的不正常，最后才能变得正常。所以，寻求心理治疗的人是勇敢的人，也是令人敬佩的人。</p>
</blockquote>
</li>
<li><blockquote>
<p>在没有正视自己的内心之前，每个人都害怕自己的思想及情感遭到窥视。</p>
</blockquote>
</li>
<li><blockquote>
<p>自律是解决人生问题最主要的工具，也是消除人生痛苦最重要的方法。</p>
</blockquote>
</li>
</ul>
<h3 id="13-《上帝笑了-99-次：哲学悖论里的大思考-》"><a href="#13-《上帝笑了-99-次：哲学悖论里的大思考-》" class="headerlink" title="13.《上帝笑了 99 次：哲学悖论里的大思考 》"></a>13.《上帝笑了 99 次：哲学悖论里的大思考 》</h3><h4 id="作者-8"><a href="#作者-8" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[英]彼得·凯弗</li>
</ul>
<h4 id="简介-12"><a href="#简介-12" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>一只美洲羊驼会坠入爱河吗？机器人能变成人吗？怎样才能不赢得公主青睐？人类一思考，上帝就发笑。在99个奇妙、怪诞、滑稽的问题背后，其实是99个烧脑的哲学、道德、法律领域的经典悖论，也是99道极富挑战性的大思考测试。本书内容覆盖了大多数常见哲学话题，包括形而上学、逻辑学、伦理学、语言哲学、政治哲学、自我认知、人际关系、美学、存在主义等，还配有20多幅漫画插图。在锻炼思维之外，本书也能帮我们建立个性化的哲学知识体系。</p>
</blockquote>
<h4 id="读后感-11"><a href="#读后感-11" class="headerlink" title="读后感"></a>读后感</h4><p>这本书和《 如果沒有今天，明天会不会有昨天？ 》一样，里面都是一些思想实验，而这本书里有 99 个思想实验。不过读完后感觉没有《 如果沒有今天，明天会不会有昨天？ 》这本书思考论证的精彩。所以读完《 如果沒有今天，明天会不会有昨天？ 》这本书真的没有必要再看这本书了。</p>
<p>不过读这本书的时候思考清楚了一件事情 <code>也许无论整体结果如何，忠于原则的行为，都有其本身的道德价值。</code></p>
<h4 id="摘抄-11"><a href="#摘抄-11" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>人的生命在经历一段时间后仍是同一条生命—你的价值观、记忆和意愿，你的个性、体征和能力，又是如何玄妙地结合为一个整体的呢？</p>
</blockquote>
</li>
<li><blockquote>
<p>对人的尊重，应当包括把他们当作理性的主体来对待，让他们有权同意或不同意自身如何被利用。</p>
</blockquote>
</li>
<li><blockquote>
<p>也许无论整体结果如何，忠于原则的行为，都有其本身的道德价值。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们的共同理性和共同利益，必将引导我们去看待、接受构成所有公平法则、利益和权利的东西。在无知之幕背后，我们认可了一个容许基本自由的社会，不以无谓的理由歧视个人，并在个人遇到困难时提供救济。这似乎是理性的选择。</p>
</blockquote>
</li>
</ul>
<h3 id="14-《疯狂的投资：跨越大西洋电缆的商业传奇》"><a href="#14-《疯狂的投资：跨越大西洋电缆的商业传奇》" class="headerlink" title="14.《疯狂的投资：跨越大西洋电缆的商业传奇》"></a>14.《疯狂的投资：跨越大西洋电缆的商业传奇》</h3><h4 id="作者-9"><a href="#作者-9" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[美]约翰.S.戈登</li>
</ul>
<h4 id="简介-13"><a href="#简介-13" class="headerlink" title="简介"></a>简介</h4><p>这本书讲的内容几年前就听说过。高二下学期，在语文课课前十分钟演讲的时候，我们班的一个同学讲过。 赛勒斯·菲尔德铺设第一条跨越大西洋的电缆的故事，而这一条电缆为一个世纪后的互联网地球村打下了坚实的技术基础。 虽然写得有些流水账，虽然是一百多年前的故事，但读起来依然波澜壮阔，总之是一个不错的励志的商业传奇故事。</p>
<h3 id="15-《乌合之众》"><a href="#15-《乌合之众》" class="headerlink" title="15.《乌合之众》"></a>15.《乌合之众》</h3><h4 id="作者-10"><a href="#作者-10" class="headerlink" title="作者"></a>作者</h4><p>[法] 古斯塔夫·勒庞</p>
<p>这本书在 2017 年的时候读过一遍，今年暑假回家坐火车的时候拿来读了一路子。</p>
<h3 id="16-《独裁者手册》"><a href="#16-《独裁者手册》" class="headerlink" title="16.《独裁者手册》"></a>16.《独裁者手册》</h3><h4 id="作者-11"><a href="#作者-11" class="headerlink" title="作者"></a>作者</h4><ul>
<li><p>[美] 布鲁诺·德·梅斯奎塔</p>
</li>
<li><p>[美] 阿拉斯泰尔·史密斯</p>
</li>
</ul>
<h4 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h4><p> 今年年初的时候，在栋叔（软件那些事儿电台博主、绿帽子大学校长、钢管舞演员、滴滴车司机）电报群里见到他推荐的这本书《独裁者手册》。这是一本小册子，内容不多，静下心来 10 个小时就能读完了它。这本书最主要的还是从统治的三个维度来分析专制国家和民主国家的区别，以及一些企业上对管理层权力斗争的原则。介绍一个理解政治的三维视角，即名义选择人、实际选择人、致胜联盟。</p>
<p>另外读这本书的时候，那一个星期恰好全球最长寿独裁统治者，津巴布韦前总统罗伯特·穆加贝去世 ，这本书中有一个章节专门讲述穆加贝是如何独裁统治的😂。不得不提一句，穆加贝也是中国人民的老朋友好朋友哦😉。呵呵，果然是趣味相投的狐朋狗友，个个都是极权专制独裁暴政的代名词。</p>
<blockquote>
<p>津巴布韦总统埃默森·姆南加古瓦当天通过自己的推特宣布了穆加贝去世的消息。1980年，随着津巴布韦宣告独立，穆加贝登上权力宝座，他在当地被视为独立运动的标志，但他当上总统后公开发表”津巴布韦是我的”“只有上帝才能把我拉下马”的言论，对津巴布韦进行了铁腕统治。据悉，穆加贝平时非常羡慕朝鲜的世袭统治。</p>
</blockquote>
<h4 id="摘抄-12"><a href="#摘抄-12" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>在美国，名义选择人和实际选择人相当紧密地结合在一起。这就是为什么尽管你只是与他人可相互替代的无数选民中的一员，却仍感觉你的那一票很有影响—它有价值，也算数。</p>
</blockquote>
</li>
<li><blockquote>
<p><strong>独裁制：</strong>这个术语在我们这里的真正意思是，政府建立在极少数不可或缺者的基础上，而他们是从数量非常庞大的可相互替代者以及通常相对较少的一群有影响者当中产生出来的。</p>
<p><strong>民主制：</strong>政府建立在数量庞大的不可或缺者和可相互替代者的基础上；同时，有影响者的数量几乎与可相互替代者一样多。</p>
</blockquote>
</li>
<li><blockquote>
<p>以不可或缺者、有影响者和可相互替代者这样的概念来看待各类组织的优点是，这些范畴使我们能克制自己，避免在各种政府形式之间武断地划线，宣称这个国家是“民主国家”，那个国家是“专制国家”，或这个国家是大共和国，那个国家是小共和国，也避免了一些历史上主要政治哲学家们持有的一维政治观。政府之间和组织之间更具重要意义和可观察到的行为差异取决于可相互替代者、有影响者和不可或缺者这三个集团的绝对和相对规模。</p>
</blockquote>
</li>
<li><blockquote>
<p>任何一个有能力的领导人都希望掌握尽可能多的权力，并尽可能长久地掌握权力。设法利用可相互替代者、有影响者和不可或缺者来达到自己的目的，这就是统治的行为、艺术和科学。</p>
<p>民主国家或任何一个致胜联盟很庞大的体系内，通过私人回报的方式来收买忠诚代价太大。钱会被极大摊薄。所以，依赖大型致胜联盟的、较民主的政府趋向于着重把钱花在能增进普遍福利的有效公共政策上，这很接近詹姆斯·麦迪逊倡导的理念。</p>
<p>与此形成对照的是，独裁者、君主、军政府领导人以及大部分企业首席执行官只依赖一小撮不可或缺者。正如马基雅维利所言，他们通过大慷公家之慨、以私人回报的方式收买致胜联盟的忠诚，这种统治方式更有成效，尽管这意味着要牺牲广大纳税人或千百万小股民的利益。因此，小型致胜联盟助长了稳定、腐败、以私人物品为导向的体制。</p>
</blockquote>
</li>
<li><blockquote>
<p>对一个统治者来说，与其拥有一张让人民可以喂饱自己的更大的饼，永远不如他能够决定谁吃这张饼。对领导人来说，最有效的资金分配方式是让很多人受穷，通过重新分配让挑选出来的支持者发财。</p>
</blockquote>
</li>
<li><blockquote>
<p>一名成功的领导人总是把核心支持者的需要置于人民的需要之上。没有他的致胜联盟的支持，一名领导人什么都不是，很快就会被对手横扫出局。但如果领导人的统治权只依赖于少数人，让联盟满意是得花钱的。通常来说，联盟成员获得的酬劳以牺牲社会其他部分的利益为代价。没错，是有一些独裁者让人民生活过得更好而成了名人堂成员。大多数独裁者不这么做。那些不这么做的独裁者将坐在办公室里为了自己和联盟的利益将国家的经济搞得一蹶不振。最终形势发展到足够恶化的地步，导致一些人民开始厌倦身上的重负。他们也会对领导人的生存产生威胁。</p>
</blockquote>
</li>
<li><blockquote>
<p>在一个民主国家，抗议相对便宜和简单。人民有集会的自由，事实上这是权利。他们也有很方便的协调组织手段。我们已从先前几章了解到，依赖大型联盟的政府创造了大量公共物品，包括统称为自由的一揽子特殊公共物品，包括新闻自由、言论自由和集会自由。这些自由权利使数量巨大的人民交换对于政府的看法、表达对任何不喜欢政策的反对意见变得容易得多</p>
<p>独裁者有两种截然相反的方法应对革命的威胁。他可以提升民主，大大改善人民的待遇，使他们不再想着反叛。他也可以加强专制独裁，让人民的境遇变得更加悲惨，同时一举扼杀人民造反成功的机会。</p>
</blockquote>
</li>
<li><blockquote>
<p><img src="../img/176047.jpg" alt="img"></p>
</blockquote>
</li>
<li><blockquote>
<p>尽管诸如言论自由、集会自由、新闻自由这样至关重要的自由权利很便宜就能提供，独裁者们却视之为瘟疫，避之唯恐不及。毫无疑问，民主领导人也巴不得避开这些自由权利，因为正是这些公共物品使得竞争对手组织起来推翻他们变得容易。但依赖大型联盟的领导人无法规避这些自由，因为如果他们无法保证很大数量的人们拥有自由言说、阅读、书写的权利、能够聚到一起自由探讨和辩论，他们将不可能聚集起一个致胜联盟。民主领导人必须倾听选民的声音，回应选民的期望，不然就有别人会上台来做。</p>
</blockquote>
</li>
</ul>
<h3 id="17-《肠子的小心思》"><a href="#17-《肠子的小心思》" class="headerlink" title="17.《肠子的小心思》"></a>17.《肠子的小心思》</h3><h4 id="作者-12"><a href="#作者-12" class="headerlink" title="作者"></a>作者</h4><ul>
<li>【德】朱莉娅·恩德斯</li>
</ul>
<h4 id="简介-14"><a href="#简介-14" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>《肠子的小心思》是德国图书界的黑马，口嫌体正直的德国人，一面对粑粑说着“不要不要”，一面看得好污好欢乐。原来，德国人觉得理所当然的马桶竟是痔疮的罪魁祸首；如此现代化的今天，蹲坑这种看似原始的行为竟然还在全世界一半以上的地区保留着，而且这才是大便的正确解锁方式；跟肠子相关的事，不仅有趣，还密切关系到人体的健康状况，一个感觉不好的肠道会让我们感到沮丧，而一个健康的、营养良好的肠道会大大地改善我们的情绪……谁能想到这些奇葩欢乐的内容，竟是一位软萌妹子所写，还一举俘获36个国家和地区读者的心。让我们跟着这本新鲜出炉带着屎味的书，一起开启神奇的消化道之旅吧。</p>
</blockquote>
<h4 id="读后感-12"><a href="#读后感-12" class="headerlink" title="读后感"></a>读后感</h4><p>这本书用一个字来形容的话就是 <strong>萌</strong> ，是我读过所有科普书籍中最有趣，语言最为幽默的一本书。虽然书名是肠子的小心思，但它包含的内容不仅仅是肠子哦，不要被书名误导了。它是从口到菊花，整个消化系统讲了一遍😂。另外还穿插讲了婴儿刨腹产和自然分娩对婴儿肠道菌落以及免疫系统的影响😂。</p>
<h4 id="摘抄-13"><a href="#摘抄-13" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>他们让实验对象吞下一些荧光试剂，然后用不同的姿势上厕所，同时接受X光照射。实验结果如下：一、没错，在蹲坑状态下，肠道确实变得笔直，排便通畅彻底；二、这世界上还真有这么为科学献身的人，吞下荧光剂不说，居然还能忍受拉荧光粑粑时让人全程X光跟拍！我不得不说，这两点都让人印象深刻。</p>
</blockquote>
</li>
<li><blockquote>
<p>痔疮和肠道内憩室这样的肠道疾病，还有便秘，似乎只集中爆发于那些习惯用坐便器的国家。肌肉组织松弛并非罪魁祸首，原因另有所在，尤其是对于年轻人来说，很多人发病的原因是肠道受到的压力过大。有些人在压力大、精神紧张的情况下就会绷紧腹肌，有时绷了整整一天自己还对此毫不察觉，痔疮自然不愿意待在压力过大的地方，还是溜到身体外面轻松自在。同理，肠子内部的组织如果不堪压力也只好向外边跑，于是肠壁上冒出一个个灯泡状的外翻小瘤子，就形成了肠内憩室。</p>
</blockquote>
</li>
<li><blockquote>
<p>一个朋友在法国度假时给我发了条短信：“法国真是变态，有小偷专门偷高速公路上的马桶，连着三个厕所里的马桶都被偷了！”我忍不住哈哈大笑，因为，一、他居然真的以为法国的蹲坑厕所是被小偷洗劫的结果；二、这让我回想起第一次在法国见到蹲坑时，地上的大洞把我吓得眼泪汪汪、左右为难：亲，在这个坑上面架个马桶就这么难吗？</p>
<p>其实没那么夸张啦，坐在马桶上我们也可以达到蹲坑的顺畅排便效果——只要脚下垫个小板凳，上半身微微向前倾，找好角度——成了！就这么简单，现在你又可以在大便的时候读书、折纸或者专心发呆，妈妈再也不用担心你得痔疮了。</p>
</blockquote>
</li>
<li><blockquote>
<p>当然不是每个阑尾都会发炎。如果阑尾正常工作的话，危险的病菌应该都会被消灭掉，只有那些好的细菌才会存活下来。换句话说，健康的阑尾里就应该只有精挑细选的优质好细菌啰。美国研究人员威廉·帕克（William Parker）和兰迪·布林格（Randy Bollinger）就是这么想的。他们在2007年提出这个理论，之后又通过实验验证了这个理论。当我们经历了一轮严重腹泻后，肚子里的很多“肠道居民”都会被连带着扫地出门，大肠壁上处处人去楼空，这对于新的菌群来说是抢占地盘的绝佳时机。我们当然不愿意谁抢着就归谁，万一住进来坏人怎么办呀。别怕！根据帕克和布林格的实验结果，这时阑尾会成为救世英雄，它会把自己圈养的菌群放出来，派往大肠各处保卫家园。</p>
</blockquote>
</li>
<li><blockquote>
<p>大肠的最后一米负责精确调节体内水和盐分的平衡：残渣中的水分会被重新吸收，剩下的残渣会被“烘焙”成大便。在这里被吸收的水量相当可观，差不多有整整1升。要是少了这一步，我们每天要额外多喝整整一升的水呢。还有，因为大肠调节盐分的结果，我们的大便总是咸的。当然，我可没有鼓励你去尝尝的意思哦。😂</p>
</blockquote>
</li>
<li><blockquote>
<p>正常的便便都是屎黄或者屎棕色的。就算我们吃的饭里没有这个颜色的食物，最后拉出来的也还是这个颜色。就好像它的好朋友小便也是，总是一个黄色的调调。这个黄色来自于身体每天都努力生产的重要产品—— 血液。身体每秒钟都有240万个血细胞诞生，但同时也有这么多的血细胞作废—— 血细胞中的红色素先会变成绿色，然后再变成黄色，这个颜色渐变的过程在你撞青了胳膊或者腿的时候就可以观察得到。黄色素的一小部分可以通过小便被排出体外，而大部分则是通过肝脏到达肠道，然后被细菌再加工成棕色。如果便便不是棕黄色的，那你就要引起重视了。</p>
</blockquote>
</li>
<li><blockquote>
<p>肠神经注意到了这种不同寻常的情况，它们有点晕了：这是怎么个情况？还是先观察一段时间吧。就算在如此混乱的一天里，肠道还是坚持完成了工作，向我们发出了去厕所的信号，但是因为我们在路上一时不方便去厕所，所以便硬生生地忽视了它的信号，把便便堵在门口。而经常所谓的“一时不方便”，你不如就坦白承认了吧，其实根本就是因为你是“不是我家厕所不能忍星人”。此星球的人不是自己家的厕所一般都不太能坐得下去。最恐怖的是公共厕所，要拿出十二分的勇气才能进去，进去了以后先要花若干时间用厕纸把马桶圈一层一层地垫起来，就这样坐下去的时候基本上还要动用“水上漂”的轻功，坚决不能坐实。要是再硌硬点的连这个都不行。对于此星球的居民来说，旅游简直就是对肠子的惩罚，请你们在旅途中务必找一个你家厕所的代替品，让肠子安静舒心地干完大事。</p>
</blockquote>
</li>
<li><blockquote>
<p>新生的小婴儿肚子里面还没几个细菌，理论上来说，给他们输不同血型的血时是不会有排异反应的。（因为小婴儿的血液里会有从妈妈那里得到的抗体，所以医院为了安全起见，一般都用和妈妈同一血型的血液进行输血。）一旦免疫系统和肠道菌群基本发育完成，人们就只能兼容同一种血液类型了。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们出生前还在妈妈的子宫里的时候，是完全无菌的。除了和妈妈的互动，9个月以来我们都处于与世隔绝的状态。我们摄取的是妈妈已经消化过了的食物，我们呼吸的氧气妈妈也提前过滤过了。妈妈通过血液把这些食物和氧气传送给我们，而她的血液已经经过了免疫系统的杀菌消毒。我们被羊膜包裹着，外面又套着肌肉发达的子宫，子宫颈又被牢牢密封着。我们就像在一个层层包裹的保险箱里，这里没有寄生虫，没有病毒，没有细菌，没有真菌，更不要说会有第二个人能碰到我们。我们比消毒过的手术台还要干净。</p>
<p>这辈子我们再也不会有像在子宫里的时间，那样被保护着，但也是那样的孤独。一旦出生来到这个世界，我们便会立刻融入到熙熙攘攘的众生中去。在这个世界上，每一个大一点的生物都会有至少一种小生物去陪伴它、帮助它，作为回报，这个小生物可以寄居在它身上。一旦我们出生来到这个世界，也会自动遵守这个规律，因为我们的身体结构就是这样设计好了的。我们的细胞表面很适合细菌依附，它们就这样依附着我们，千百年来和我们一起共同进化。</p>
<p>一旦保护膜不再密封，哪怕只开了个小口，细菌就立刻浩浩荡荡迁居过来了。我们刚才还是100%由人类细胞组成的，一瞬间就会被数不清的微生物占领，以至于最后我们浑身上下所有的细胞里，只有10%是人类细胞，而剩下的90%都是其他各种微生物的细胞。因为人类的细胞比这些小寄居客的细胞要大太多了，所以我们根本感觉不到自己已经完全被占领了。在我们第一次看妈妈温柔的眼神之前，妈妈子宫里的细菌们已经过来和我们一一打过招呼了。首先打招呼的是阴道里的保护菌，它们是这块圣地的守卫者。它们通过制造酸性物质将其他细菌全部驱赶干净，以确保通向子宫的圣路每向前走一步都更洁净。</p>
<p><img src="../img/PIC.png" alt></p>
</blockquote>
</li>
<li><blockquote>
<p>皮肤菌群的自我管理可比产道菌群要松散得多，因为它太容易受到周围环境的影响。通过皮肤接触，这些皮肤上的细菌很可能很快也会出现在小宝宝的肠道里，病原体和其他轻量级危险分子都可以大摇大摆地通过这种方式去逗逗小宝宝的免疫系统，陪它练练手。剖腹产出生的宝宝，他们的肠道菌群需要几个月甚至更长的时间才能调整到正常状态，所以抵抗力相较于顺产的宝宝会弱一些。比如被医院里的细菌感染到的新生儿中，有3/4都是剖腹产出生的。除此之外，剖腹产出生的婴儿以后患过敏症或者哮喘的风险要比顺产的婴儿高不少。不过一项美国的研究表明，如果给剖腹产的新生儿口服一种特定的乳杆菌，可以把他们患过敏的概率降低。正常分娩的婴儿这种担心就要少多了，因为他们在出生的过程中已经在益生菌的圣水中浸泡过了。</p>
</blockquote>
</li>
</ul>
<h3 id="18-《民主的奇迹：-美国宪法制定的127天-》"><a href="#18-《民主的奇迹：-美国宪法制定的127天-》" class="headerlink" title="18.《民主的奇迹： 美国宪法制定的127天 》"></a>18.《民主的奇迹： 美国宪法制定的127天 》</h3><h4 id="作者-13"><a href="#作者-13" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[美]凯瑟琳·德林克·鲍恩</li>
</ul>
<h4 id="简介-15"><a href="#简介-15" class="headerlink" title="简介"></a>简介</h4><h4 id="摘抄-14"><a href="#摘抄-14" class="headerlink" title="摘抄"></a>摘抄</h4><h3 id="19-《Kubernetes-指南第四版》"><a href="#19-《Kubernetes-指南第四版》" class="headerlink" title="19.《Kubernetes 指南第四版》"></a>19.《Kubernetes 指南第四版》</h3><h3 id="20-《程序员的自我修养：-链接、装载与库-》"><a href="#20-《程序员的自我修养：-链接、装载与库-》" class="headerlink" title="20.《程序员的自我修养： 链接、装载与库 》"></a>20.《程序员的自我修养： 链接、装载与库 》</h3><h4 id="作者：-4"><a href="#作者：-4" class="headerlink" title="作者："></a>作者：</h4><ul>
<li>俞甲子</li>
<li>石凡</li>
<li>潘爱民</li>
</ul>
<h3 id="21-《程序员的英语》"><a href="#21-《程序员的英语》" class="headerlink" title="21.《程序员的英语》"></a>21.《程序员的英语》</h3><h4 id="作者-14"><a href="#作者-14" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[韩]朴栽浒</li>
<li>[韩]李海永</li>
</ul>
<p>这本书是在图灵社区兑换的，反正不要白不要。其实这本书徒有虚名，就是三十多篇阅读理解一样文章，然后拿来帮你分析和短句。就当拿来练练英语阅读理解海星。不过作者排版方面确实很用心。文章引用的链接都是使用的 Google 的短链接，这一点倒是比较方便读者查看浏览引用的那些文章，总之不建议读。</p>
<h3 id="22-《第二性》"><a href="#22-《第二性》" class="headerlink" title="22.《第二性》"></a>22.《第二性》</h3><h4 id="作者-15"><a href="#作者-15" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[法] 西蒙娜·德·波伏娃</li>
</ul>
<h3 id="23-《过去与未来之间》"><a href="#23-《过去与未来之间》" class="headerlink" title="23.《过去与未来之间》"></a>23.《过去与未来之间》</h3><h4 id="作者-16"><a href="#作者-16" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[德] 汉娜·阿伦特</li>
</ul>
<h3 id="24-《论革命》"><a href="#24-《论革命》" class="headerlink" title="24.《论革命》"></a>24.《论革命》</h3><h4 id="作者-17"><a href="#作者-17" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[德] 汉娜·阿伦特</li>
</ul>
<h4 id="简介-16"><a href="#简介-16" class="headerlink" title="简介"></a>简介</h4><p><img src="../img/image-20191127190459402.png" alt="image-20191127190459402"></p>
<p>这本书是双十一的时候买的纸质版图书，因为搬家不方便所以毕业后就很少再买纸质书了。Kindle 商店里也有电子版，Kindle  Unlimited 会员可以免费借阅。</p>
<p>拿到书后大致读了半个小时，刚开始读的时候我觉着这本书和《民主的奇迹》一块看是不错滴。《民主的奇迹》这本书是讲述了美国宪法制定的 128 天的历程。在这当中的历程中对宪法指定的方方面面讲述的都很详细。而《论革命》这本书也讲到了美国宪法的一些方面，但要比《民主的奇迹》讲的更为广泛。不仅仅在书中对比了法国大根名和美国革命的本质，还涉及到一些制度权力等思想。</p>
<h4 id="摘抄-15"><a href="#摘抄-15" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><img src="../img/image-20191127190849806.png" alt="image-20191127190849806"></li>
<li><img src="../img/image-20191127190914310.png" alt="image-20191127190914310"></li>
<li><img src="../img/image-20191127190945249.png" alt="image-20191127190945249"></li>
<li><img src="../img/image-20191127191005006.png" alt="image-20191127191005006"></li>
<li><img src="../img/image-20191127191050123.png" alt="image-20191127191050123"></li>
<li><img src="../img/image-20191127191116424.png" alt="image-20191127191116424"></li>
<li><img src="../img/image-20191127191152146.png" alt="image-20191127191152146"></li>
<li><img src="../img/image-20191127191222289.png" alt="image-20191127191222289"></li>
<li><img src="../img/image-20191127191308757.png" alt="image-20191127191308757"></li>
<li><img src="../img/image-20191127191332749.png" alt="image-20191127191332749"></li>
<li><img src="../img/image-20191127191437853.png" alt="image-20191127191437853"></li>
</ul>
<h3 id="25-《极权主义的起源》"><a href="#25-《极权主义的起源》" class="headerlink" title="25.《极权主义的起源》"></a>25.《极权主义的起源》</h3><h4 id="作者-18"><a href="#作者-18" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[德] 汉娜·阿伦特</li>
</ul>
<p>这本书纸质版已经绝版了，淘宝上只能买到影印版，正版的旧书价格至少在 250￥。月末的时候我姐给我买了一本送给我😍。</p>
<h4 id="简介-17"><a href="#简介-17" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>有关极权主义的起源，阿伦特的分析最具特色之点在于：全面恐怖的极权主义之所以能够大行其道，它所针对的是切断了与他人联系的原子化的个人，“恐怖只有对那些互相隔离的人才能实施绝对统治。”这种“孤独”带来一系列的后果：不能与他人分享自己的感受和经验，从而丧失判断事物的基本常识，将反常视为正常；不能感到和他人呼吸在同一个天地之中，于是造成对于他人莫名其妙的仇恨，感到这个世界正在联合起来反对自己，同时也把自己放到反对一切人的位置上。在感到自身无根、缺少意义的焦虑时，一方面，丧失了对于自己的信心，失去对于自身行动的任何信心和力量；另一方面，由于某种虚无所造成的真空，十分容易被他人乘虚而入，灌输进“假大空”的意义，以某种反常的、不可思议的举动来证明自己。一个恶性循环就是这样形成了：极权政权想尽一切办法造成这种孤独和虚无；而孤独和虚无又在滋生极权因素和强化极权政府。在阿伦特的表述中，包含了极权政权和这种政权之下的人们互相之间不可分割的看法。 </p>
</blockquote>
<p>推荐大家读一读 <a href="https://www.chinesepen.org/blog/archives/90388" target="_blank" rel="noopener">崔卫平：后极权主义及其反抗</a>文章</p>
<h4 id="读后感-13"><a href="#读后感-13" class="headerlink" title="读后感"></a>读后感</h4><p>到目前为止我仅仅读完了三十多页的序言，不过读完序言也就对这本书有了大致的了解。这本书大概 500 多页，以我的读书进度大概需要两周的时间。所以要放到 2020 年再去写读后感和摘抄了。</p>
<h3 id="26-《童年的消逝》"><a href="#26-《童年的消逝》" class="headerlink" title="26.《童年的消逝》"></a>26.《童年的消逝》</h3><h4 id="作者-19"><a href="#作者-19" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[美] 尼尔·波兹曼</li>
</ul>
<h4 id="简介-18"><a href="#简介-18" class="headerlink" title="简介"></a>简介</h4><p><img src="../img/image-20191127190608896.png" alt="image-20191127190608896"></p>
<blockquote>
<p>在《童年的消逝》里，波兹曼运用他对心理学、历史学、语义学和麦克卢汉学说的深刻见解以及常识，非常有说服力地阐述了一个触目惊心而且颇具独创的论题，即童年的诞生，是因为新的印刷媒介在儿童和成人之间强加了一些分界线，而在电视之类媒体的猛烈攻击下分界线变得越来越模糊，成人的性秘密和暴力问题转变为娱乐，新闻和广告定位在10岁孩子的智力水平。这也是一份内容翔实、令人震惊的警世书。</p>
</blockquote>
<p><img src="../img/image-20191127190621622.png" alt="image-20191127190621622"></p>
<h4 id="读后感-14"><a href="#读后感-14" class="headerlink" title="读后感"></a>读后感</h4><p>在书中作者通过历史论证了<code>童年的概念是文艺复兴的伟大发明之一</code>，也许是最具人性的一个发明。我感觉童年的诞生与印刷媒介之间的联系有些牵强了，或许是我知识水平不足，回头再多读几遍。</p>
<p>乔治•奥威尔曾在《一九八四》中预言人们将会遭受外来压迫的奴役，失去自由，我们的文化成为受制文化，赫胥黎则在《美丽新世界》中表达了另外一种忧虑，人们会渐渐爱上压迫，崇拜那些使他们丧失思考能力的工业技术。读完《娱乐至死》与《童年的消逝》 后我觉着未来能成为现实的是 1984 和娱乐至死相互交织的社会。尤其是对于某些摸着石头过河的国家来说，当前的现状也正是 1984 和娱乐至死共同存在的社会。不关心政治的人岁月静好地刷着抖音短视频，逛着淘宝看这电影娱乐消费觉着自己生活在岁月静好的美好社会。而遭遇过社会主义铁拳打击的人在对这个社会痛恨和绝望的同时也依靠着被真理部牢牢掌控的媒体所洗脑控制。</p>
<p>抱歉，扯得有点远了😝。其实我对抖音快手短视频有一种近乎疯狂的憎恨，在我看来，抖音记录的不是生活，而是空荡荡无知的内心。所以我一向抵制短视频，并对短视频文化憎恶痛恨。</p>

<blockquote class="twitter-tweet"><p lang="zh" dir="ltr">在公交车和地铁上见到小学生刷短视频越来越多了。<br>小孩儿也变得和大人一样习惯了刷短视频，沉浸到碎片化娱乐之中。若是 Neil Postman 老人家看到了如今男女老少都碰着手机刷短视频的移动互联网时代，怕是要气得从坟墓里爬出来，棺材板都压不住了吧。<a href="https://twitter.com/hashtag/%E7%AB%A5%E5%B9%B4%E7%9A%84%E6%B6%88%E9%80%9D?src=hash&amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener">#童年的消逝</a> <a href="https://t.co/durMqylvkd" target="_blank" rel="noopener">https://t.co/durMqylvkd</a> <a href="https://t.co/V5g8q2AE6b" target="_blank" rel="noopener">pic.twitter.com/V5g8q2AE6b</a></p>&mdash; 502 (@muzi_ii) <a href="https://twitter.com/muzi_ii/status/1199726295145484288?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">November 27, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

<h4 id="摘抄-16"><a href="#摘抄-16" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>童年作为一种社会结构和心理条件，与科学、单一民族的独立国家以及宗教自由一起，大约在16世纪产生，经过不断提炼和培育，延续到我们这个时代。</p>
<p>它们大多是通过观察传播媒介如何影响社交过程而产生的一系列推测；尤其是印刷术如何创造了童年，电子媒介又如何使之“消逝”。</p>
</blockquote>
</li>
<li><blockquote>
<p>不得不眼睁睁地看着儿童的天真无邪、可塑性和好奇心逐渐退化，然后扭曲成为伪成人的劣等面目，这是令人痛心和尴尬的，而且尤其可悲。</p>
</blockquote>
</li>
<li><blockquote>
<p>因此，希腊人发明了“学校”这个概念是毫无疑问的。在希腊语中，“学校”一词的意思是“闲暇”。这反映了一种典型的雅典式的信仰：他们认为闲暇时，一个文明人自然会花时间思考和学习。</p>
</blockquote>
</li>
<li><blockquote>
<p>放眼望去，人们不难发现，成人和儿童在行为举止、语言习惯、处世态度和需求欲望上，甚至身体的外表上，越来越难以分辨了。</p>
</blockquote>
</li>
<li><blockquote>
<p>希腊人为我们预示了“童年”这个概念。我们常常理所当然地把许多观念的产生看作人类智力开化的结果。对于童年的诞生，我们应当感谢希腊人的贡献。他们虽然没有创造出童年，但是他们已经走得很近了，以至于在2000年以后，当童年产生时，我们便能识别它的希腊之源。</p>
</blockquote>
</li>
<li><blockquote>
<p>那就是古代纸莎草纸和羊皮纸的来源变得稀少；若不是那样的话，那么就是严酷的生活现实不允许人们花费精力去生产这些东西。我们都知道，纸张是到了13世纪才出现在中世纪欧洲的。这时，欧洲人立即开始生产纸张。不过，他们不是用手和脚这样古老的方式造纸，而是用水能驱动的工厂来造纸。[17]中世纪一些优秀的大学纷纷建立，与之相呼应的是人们对识字又旧情复燃，这恰好跟引进纸张和生产纸张同时发生。</p>
</blockquote>
</li>
<li><blockquote>
<p>罗马教会并不是没有看到工匠识字文化的好处，因为它是一种能够控制数量众多而且多元化的人口的工具，也就是说，它能控制数量众多而且多元化的人民的思想、组织和忠诚。也完全是符合教会的利益的。</p>
</blockquote>
</li>
<li><blockquote>
<p>孤立的读者和他自己的眼睛。口腔无须再发声音，读者及其反应跟社会环境脱离开来，读者退回到自己的心灵世界。整个阅读的过程，作者和读者仿佛达成共谋，对抗社会参与和社会意识。简而言之，阅读成为反社会的行为。</p>
</blockquote>
</li>
<li><blockquote>
<p>可以说，印刷给予我们自我，使我们以独特的个体来思索和谈话。而这种强化了的自我意识便是最终导致童年开花结果的种子</p>
</blockquote>
</li>
<li><blockquote>
<p>哈罗德·英尼斯提出的原则：新的传播技术不仅给予我们新的考虑内容，而且给予我们新的思维方式。书籍的印刷形式创造了一种全新的组织内容的方式，从而推动了一种新的组织思想的方式。印刷书籍所具有的一成不变的线性特点——一句一句排列的序列性，它的分段，按字母顺序的索引，标准化的拼写和语法——导致一种詹姆斯·乔伊斯[29]戏称为“ABC式”的思维习惯，即一种跟排版结构非常相似的意识结构</p>
</blockquote>
</li>
<li><blockquote>
<p>我们绝不能低估语言从耳朵转移到眼睛、从口语转移到排版这个过程对人类心理造成的撞击。能够看到自己的语言持久存在、反复印刷，而且以标准的形式出现，这使人类与语言产生了最深厚的关系。</p>
</blockquote>
</li>
<li><blockquote>
<p>首先，印刷不仅创造了新的收集数据的方法和来源，而且极大地增加了大陆范围内科学家之间的交流。其次，标准化的印刷形式导致了统一的数学符号，包括用阿拉伯数字取代罗马数字。此外，标准化的印刷大半消除了文本中的模糊不清，并减少了图解、图表、表格和地图上的错误。印刷使直观教具现成可用，这样也使大自然显得更加千篇一律，因此更通俗易懂。</p>
<p>自从有了印刷术，成年就变得需要努力才能挣来了。它变成了一个象征性的成就，但不是生物学意义上的成就。自从有了印刷术，未成年人必须通过学习识字、进入印刷排版的世界，才能变成成人。为了达到这个目的，他们必须接受教育。因此，欧洲文明重新创造了学校，从而使童年的概念也变成社会必需的了。</p>
</blockquote>
</li>
<li><blockquote>
<p>书本和书本学习的世界几乎算不上我们超越动物本能的胜利；一个识字社会的要求使一种精雕细琢的羞耻感变得非常必要。若稍加引申，我们便可以说，由于印刷将信息和送信人分开，由于印刷创造了一个抽象思维的世界，由于印刷要求身体服从于头脑，由于印刷强调思考的美德，所以，印刷强化了人们对头脑和身体二元性的看法，从而助长了对身体的蔑视。印刷赋予我们的是脱离躯壳的头脑，但却留下了一个我们该如何控制身体的其余部分的问题。羞耻心正是这种控制得以实现的途径。</p>
</blockquote>
</li>
<li><blockquote>
<p>电视向人们提供了一个相当原始而又不可抗拒的选择，因为它可以取代印刷文字的线性和序列逻辑的特征，所以往往使文字教育的严谨显得没有意义。</p>
<p>电视侵蚀了童年和成年的分界线。这表现在三个方面，而它们都跟电视无法区分信息使用权密切相关：第一，理解电视的形式不需要任何训练；第二，无论对头脑还是行为，电视都没有复杂的要求；第三，电视不能分离观众。借助其他电子的、非印刷的各种媒介，电视又重新创造出14、15世纪就存在的传播条件。</p>
<p>例如，希腊悲剧诗人索福克勒斯（Sophocles）对人们企图在电视上“略谈”乱伦会有何种看法？弗洛伊德对人们把心理分析当作杂耍剧又会做何感想？为什么人们本应在心理学家的沙发上和忏悔室里交流的话题，要恬不知耻、堂而皇之地成为公开讨论的话题？</p>
<p>羞耻是野蛮行为得以控制的机制，如切斯特顿所认为，它的主要力量来自于围绕着各种行为的神秘感和敬畏感</p>
</blockquote>
</li>
<li><blockquote>
<p>儿童之所以好奇，是因为他们还不知道将要知道的东西；成人之所以有权威，主要是因为他们是知识的主要来源。权威和好奇之间的微妙平衡，正是玛格丽特·米德的重要著作《文化与承诺：一项有关代沟问题的研究》的主题。在书中，她指出，我们正在进入一个日新月异、信息公开的世界。在这个世界中，成人已经不能扮演年轻人的导师的角色，因此导致了一种危机，她称之为“信仰危机”。“我相信这种信仰危机，”她写道，“可以归因于……现在长辈对年轻人的经历，没能比年轻人自己有更多的了解。</p>
<p>但是我相信，很清楚的是，由于电子媒体肆无忌惮地揭示一切文化秘密，它已对成人的权威和儿童的好奇构成了严重的挑战。在某种程度上，好奇心是儿童的天性，但它的发展却有赖于人们日益清楚地了解通过秩序井然的问题来揭示各种秘密的重要性。已知的世界和未知的世界是通过好奇来连接的，但好奇大半发生在儿童世界，和成人世界是分离的，儿童必须通过提问寻求进入成人的世界。</p>
<p>由于媒介将两个世界合二为一，保持秘密所产生的张力在谜底被揭开时势必减弱，所以好奇的演算方法也随之发生了变化。好奇被愤世嫉俗——或者更糟——被狂妄自大所取代。于是，我们的孩子不能依靠有权威的成人，而是依赖不知从哪里来的新闻来获取知识。我们的孩子还没有提问，就被给予一大堆的答案。简言之，我们身边没有儿童了。</p>
</blockquote>
</li>
<li><blockquote>
<p>例如，还有购物这样的生存快乐。在儿童还很小的时候，电视就向他们揭示消费主义的快乐和购买几乎任何东西后所产生的满足感：从地板蜡到汽车。到牙买加或夏威夷旅行一次可以消除工作的疲劳；购买克莱斯勒汽车可以提高一个人的社会地位；使用某种洗涤剂有助于提高一个人的能力；使用某种漱口水。了解这些都是令人安慰的。这些都是美国文化给人们的承诺。它们正好迎合了成人在现实生活中的各种动机。儿童3岁时就已经被灌输这样的动机，因为电视欢迎大家一起来分享一切。我并不认为那些是一个成熟意义上的成人的动机。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们的孩子比以往任何时候都要消息灵通，究竟是什么意思？他们知道长辈知道的一切又意味着什么？这意味着他们已经变成成人，或者至少像成人一样。用我自己的一个比喻，这意味着当儿童有机会接触到从前密藏的成人信息的果实时，他们已经被逐出儿童这个乐园了。</p>
<p>通过政府干预来控制电视，并由此控制可供大家享用的信息内容是可能做到的。其实，在世界上大多数国家，情况正是如此。但是，无论何时，无论何地，只要电视节目不受政府严格的限制，美国的模式就会被仿效。</p>
</blockquote>
</li>
<li><blockquote>
<p>自制能力，对延迟的满足感的容忍度，具备抽象、有序思维这样高一级的能力，关注历史的延续性和未来的能力，高度评价说理和等级秩序的能力。由于电子媒介将识字能力推至文化的边缘，进而占据了文化的中心地位，各种不同的态度和性格特征开始受到重视，同时一个缩小了内涵的新的成人定义开始出现。</p>
</blockquote>
</li>
<li><blockquote>
<p>电视不能把人的注意力集中到思想上来，因为思想是抽象的、有距离的、复杂的和有秩序的，而电视总是把人的注意力吸引到人物身上，因为人物是具体的、生动的和完整的。</p>
<p>这意味着电视已经彻底改变了政治信息的符号形式。在电视时代，政治判断从对提议的知识评判转化为对整个人物形象的直观而情绪化的反映。在电视时代，人们赞成或不赞成这些政客，如同喜欢或不喜欢他们一样。电视重新定义了“正确的政治判断”，它把政治判断从一个逻辑判断转变成了一个审美判断。这是电视的催眠作用，它使人们的理智和情感变得迟钝了。</p>
<p>一个节目[5]是一种娱乐，一个虚假和幻想的世界，经小心筹划后拼接在一起以期产生一系列具体的效果。这样可以让观众欢笑、哭泣或目瞪口呆，这就是新闻节目所做的事。</p>
</blockquote>
<blockquote>
</blockquote>
</li>
<li><blockquote>
<p>也就是说，电视广告已经摒弃了商业主义的一个关键假设，即购买者和行销者都是根据自我利益，经过理性考虑之后达成交易。</p>
<p>它们不向消费者提供各种各样的事实，它们提供的是偶像，这样成人和儿童都能以同等的感情投入，同时也避免了逻辑或核实的麻烦。</p>
<p>在电视广告寓言里，邪恶的根源是“技术无知”（technological innocence），即对工业进步所带来的种种益处一无所知。这是造成现实生活中不幸福、羞辱和不和谐的主要根源。而且，人们绝不能自满——或者更糟——沾沾自喜。企图简单地生活，不关心技术进步，这样总是很危险的，因为这种人的天真幼稚在那些对技术警觉的人眼里是非常触目惊心的。而那些警觉的人可能是服务员、朋友、邻居或者一个光谱形象，如精灵，它不知从何而来地突然在你的厨房里显现，见证你的懒惰无知。</p>
<p>“狂喜”在此是个关键的概念，因为广告寓言极其详细地描绘过形形色色的欣喜若狂，这在任何宗教文献里都不乏其例。在《有斑渍的玻璃器皿的寓言》（The Parable of the Spotted Glassware）里，一个丈夫和一个妻子都认为这种心醉神迷的表情只能用“美化”（beautification）这个词来形容。</p>
</blockquote>
</li>
<li><blockquote>
<p>电视以视觉形象的形式而不是语言，来表达大多数的内容，所以，它势必放弃文字阐述，而使用叙事的模式。正因为如此，电视供人娱乐的能力几乎用之不竭。</p>
</blockquote>
</li>
<li><blockquote>
<p>唯一具备这种能力的技术是电脑。为了设计电脑编程，人们基本上必须学习一种语言。这意味着人们必须掌握复杂的分析技能，类似于一个完全有文化的人需要具备的技能。这就要求进行特殊的训练。如果人人都需要了解电脑如何运作，如何将它们的世界观强加于我们，如何改变我们对判断的定义，也就是说，如果一个全球性的电脑文化被视为必需，那么，可以想见，年轻人的教育会变得非常重要，年轻人的文化必须与成人文化不同的想法也会被保存下来。</p>
</blockquote>
</li>
<li><blockquote>
<p>而且，要保证孩子们努力学习，成为识字有文化的人，出奇地耗费时间，甚至代价昂贵。然而，最具反叛意义的是努力控制子女接触媒介的机会。事实上，要这么做有两种方法：一是限制子女暴露在媒介前的时间；二是仔细监督子女接触的媒介的内容，并持续为他们提供有关媒介内容的主题和价值方面的批评。要做到这两点绝非易事。而且，这么做，需要家长在抚养子女方面付出极大的关注，这是多数家长都不准备做的。</p>
</blockquote>
</li>
<li><blockquote>
<p>虽然声称识字文化纯粹是一种恩赐，会让人觉得既天真也不准确，但是书写文字，然后是印刷文字，的确为人类文明带来了一种新的社会组织。它带来了逻辑、科学、教育和礼仪，诚然也带来了戈登森先生所掌管的技术。因此，我们可以说，识字的头脑为识字文化播下了毁灭的种子，因为识字的头脑创造了新的媒介，而这些媒介又使识字文化所依赖的“传统的技能”变得毫无意义。</p>
</blockquote>
</li>
</ul>
<h3 id="27-《永久记录》"><a href="#27-《永久记录》" class="headerlink" title="27.《永久记录》"></a>27.《永久记录》</h3><h4 id="作者-20"><a href="#作者-20" class="headerlink" title="作者"></a>作者</h4><ul>
<li>爱德华·斯诺登</li>
</ul>
<h4 id="简介-19"><a href="#简介-19" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>国安局的逻辑是，收集来的情资一定得储存起来，日后才能方便运用。但没人能预测这些情资何时能派上用场。这样的观念助长国安局的终极目标，那就是将收集、制造的情资永远储存下来，创造出一个完美的记忆库、一份永久的纪录档案。</p>
</blockquote>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p><img src="../img/image-20191127190747747.png" alt="image-20191127190747747"></p>
<p>看了斯诺登的推特说他的中文版自传被删除一些敏感的内容，并表示了强烈的抗议😂。真是讽刺，这就是历害国所谓的 <code>四个自信</code> 。呵呵，自信就是删帖封号搞言论审查，呸。对于咱这种叛逆心极强的屁民来说这本书当然要读啦。</p>
<p>正如斯诺登在书中描述的那样美国政府确实存在大规模监控，但美国人民是有能力反抗政府的是这种严重侵犯人权的行为滴。电子前哨基金会就是一个这样的存在，细数一下美国历史上的有关网络审查的法案，绝大多数无法通过的原因就是，在美国是有像电子前哨基金会以及自由软件基金会这样的而非营利性组织来对抗来自政府和商业公司的监控和审查的。</p>
<blockquote>
<p>电子前哨基金会（EFF）告诉联邦上诉法院，必须追究思科公司帮助中国侵犯人权的责任。思科帮助中国建造了防火长城系统，EFF称，思科知道它在美国开发的技术会被专制政府用于侵犯人权，但仍然有意识的帮助中国建造了这套系统。思科只是越来越多的帮助专制政府更有效实施人权侵犯的美欧科技公司之一，EFF认为应该追究这些公司在迫害行为中的责任。<br>此处引用 <a href="https://www.solidot.org/story?sid=46859Yaf" target="_blank" rel="noopener">EFF称必须追究思科帮助中国的责任</a></p>
</blockquote>
<blockquote>
<p>美国麻省地区法院法官 Denise Casper 裁决，美国政府无理由搜查国际游客的手机和笔记本电脑违反了宪法第四修正案。此案由 ACLU 和 EFF 代表 10 名美国居民和 1 名合法永久居民起诉美国政府，他们在入境时被无理由搜查了手机和笔记本电脑。根据这一裁决，美国海关官员现在在搜查游客的设备前需要提供怀疑的正当理由，而游客在跨境时将不用担心政府没有理由就搜查设备上的敏感个人信息。不过美国政府可以对这一裁决提起上诉。<br>此处引用<a href="https://www.solidot.org/story?sid=62589" target="_blank" rel="noopener">法官裁决无理由搜查手机违宪</a></p>
</blockquote>
<p>在美国的确存在如斯诺登所描述的大规模监控，但和某些摸着石头过河的国家相比简直就是小巫见大巫。国内社交平台删帖封号早已经是家常便饭，甚至这种人们已经默许了这种删帖封号的行为，早已经在自己心里进行自我审查，无可奈何地适应了删帖封号。但在美国不同的是，人家是有力量反对这种大规模监控的。甚至不惜一切代价阻止政府试图通过某些限制互联网自由的法律。</p>
<p>在美国，人民是有能力反对这种侵犯人权的大规模监控的，而历害国呢？你在国内听到过反对人脸识别的声音吗？呵呵呵，还对人脸识别、人工智能、实名认证、网络封锁等乐此不疲，拍手称快呢。人家美国人民不仅知道反抗政府来监控和审查自己，而且也知道隐私保护，尊重人权这是一种普世价值，任何政府都无权监控和审查互联网。</p>
<blockquote>
<p>Aaron死了以后，Aaron朋友和合作者，哈佛大学法学院教授Laurence Lessig，回忆说，他当年和仅15岁的Aaron 有过一次谈话。Aaron问他：“您刚才讲到网络审查和管制的这些弊病，那您有没有什么实际的方案来解决这些问题呢？”Lessig有点尴尬地说：“没有。我是个学者，我只负责做研究，解决问题不关我的事儿。”Aaron接着问：“您是个学者，所以解决问题不关你的事儿。那，您作为一个公民，又该如何呢？”</p>
</blockquote>
<p>人家美国十六七岁的青少年都在思考网络审查和监管的弊病，而历害国呢？</p>
<h4 id="摘抄-17"><a href="#摘抄-17" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>唯有对于人民权利的尊重才能衡量一个国家的自由，而我相信这些权利实际上是国家权力的界线，明确界定一个政府到何种程度不得侵犯个人领域或个人自由，在美国革命时期所谓的“自由”，在网络革命时期所谓的“隐私”。</p>
</blockquote>
</li>
</ul>
<ul>
<li><blockquote>
<p>这些人当中，包括三亿二千万美国同胞，他们日常生活的一举一动都遭到监视，不仅严重违反美国宪法，更是违背自由社会的基本价值。在暗地里，政府掌握全民监视的权力，这种权威就定义上而言，对无辜者的伤害远大于对犯罪者的伤害。<br>在你产生反感、明白网际网络疯狂毒害我们这个时代之前，请谅解，对我来说，当我认识网际网络之时，那是很不一样的东西。网络既是朋友，也是父母，是一个无边界、无限制的社群，既是单一、也是无数的声音，一个已经有人垦殖但尚未遭到剥削的共同边境，各式各样的部落和睦相处，每个成员都能自由选择自己的姓名、历史和风俗习惯。每个人都戴着面具，然而这种多数匿名造就的文化所产生的事实多于造假，因为重点在于创造与合作，而不是商业与竞争。当然这之间也会有冲突，但善意与善念会胜过冲突——而这正是真正的先驱精神。</p>
</blockquote>
</li>
<li><blockquote>
<p>便利性的承诺让大家关掉自己的个人网站，因为那需要不断、辛苦的维护，改换成脸书网页和Gmail帐号。所有权的表象让人容易搞错现实。很少人在当下即明白，我们所分享的一切都将不再属于我们。以前电子商务公司因为找不到让我们有兴趣购买的东西以致倒闭，其后继者现在找到可以贩售的新产品了。</p>
</blockquote>
</li>
<li><blockquote>
<p>父亲坚称，从他的童年到我的童年之间，美国已遗忘这个原则。美国这个国家已变成买新机器取代故障机器比找专家修理来得便宜，而且一定比自己去找零组件设法修理来得便宜。单凭这项事实便几乎保证会出现科技暴政，助纣为虐的不是科技本身，而是每天使用却不了解的所有人。拒绝让自己了解你所依赖的设备运作与维修，即是被动接受暴政及其条件：当你的设备正常运作时，你也正常运作，但是当你的设备故障，你也会故障。你拥有的物品反过来拥有了你。</p>
</blockquote>
</li>
<li><blockquote>
<p>这台电脑时常陪伴着我，像是我第二个手足或是初恋情人。它在我发展独立自我人格的时刻走进我的生命，让我了解到网络世界无限广阔。这种探索的过程相当刺激，令我有一阵子忽略其他家人与家庭生活。换个说法，我当时正经历叛逆的青春期，只不过这是科技引起的青春期。这令我产生巨大的变化，而各地所有接触电脑的人也都有着同样经历。</p>
</blockquote>
</li>
<li><blockquote>
<p>随着千禧到来，网络世界变得越来越中心化、集中化，政府与商业力量加速介入这个原本应是对等式的网络（P2P）。但幸好网络有段时期是由人民所拥有、管理并为其服务的，而这段短暂而美好的日子恰巧与我的青少年岁月重叠。网络的目的应该是启发人心，而不是追求赚钱。它的规则应由大家约定俗成且随时更动，而非采取全球一致、剥削性十足的服务性协议。一直到今日，我都认为一九九○年代网络是我经历过最愉悦、最成功的无政府状态。</p>
</blockquote>
</li>
<li><blockquote>
<p>但在千禧年过后，网络科技变得非常不同：所有记忆必须忠实、身分维持一致，意识形态也得正确。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>所谓的“长大”代表的是你体会到：你的存在受制于成套的规范、仿真两可的规则以及毫无根据的常规。这些规定未经过你的同意便强加在你身上，而且随时随地都有可能改变，甚至在你违反规则时，你才意识到它们的存在。</p>
</blockquote>
<ul>
<li><blockquote>
<p>而这也代表着，我们最终必须得面对自己，纵容屠杀与漤用权力并非专属于美国行政机关与情报单位，而是存在于美国所有民众的心中，包括我个人在内。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>现在回过头来看，我的国家当时可以利用这个机会做出更多的改变。美国可以不要宣称恐怖主义是特定信仰，而是犯罪本身。美国可以利用这个难得时刻巩固强化民主价值、培养抵抗挫折的韧性，同时凝聚各国人民的向心力。 但美国当时却选择开战。</p>
</blockquote>
<ul>
<li><blockquote>
<p>不过删除贴文的可能后果让我心烦意乱，那么做只会徒然强化网络生活一些最腐蚀人心的训诫：没人有犯错空间、凡是犯错者得一辈子为自己的错误负责。我在意的倒不是文字记录是否完美无缺，而是灵魂的完整性。我不想活在一个人人必须假装完美的世界，那样的世界没有我和朋友的容身之处。抹掉在网上的评论，等于抹煞我是谁、我从哪里来、我走了多远。否定年少时候的我，等于否定现在的我的合法性。</p>
</blockquote>
</li>
<li><blockquote>
<p>既然抹不掉网络上那些令我们丢脸羞愧的言行，我们能做的只有控制自己的反应，看是要为了这些过去自我折磨，还是接受过去带给我们教训，然后成长、前进。 那是我在赋闲蛰伏时期想到的第一件事，你或许称之为原则，尽管执行不易，我仍努力靠它过活。</p>
</blockquote>
</li>
<li><blockquote>
<p>我成长过程中被灌输的价值，我在网络世界邂逅的理想，全都捣碎在一起成了我现在的思想。我直到即将迈入三十岁之际才终于明白，我所信仰的，我以为自己深信不疑的，大多是年轻时候的印记。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>有一段时间，特别是在我准备入伍阶段，我的世界观就像天真的电玩游戏那样二元对立，电玩世界中善与恶泾渭分明，而且不容怀疑。</p>
</blockquote>
<ul>
<li><blockquote>
<p>求学的时候，我必须背出美国宪法前言，这虽然还留存在我的记忆中，但现在多了网络自由先驱约翰．佩里．巴洛（John Perry Barlow）的《网络空间独立宣言》（A Declaration of the Independence of Cyberspace），同样也用了不言而喻且自我选定的复数名词：“我们要打造人人都能进入的世界，摒除因种族、经济实力、军事力量、家庭背景产生的特权与偏见。我们打造的这个世界，无论何人在何地都能表达自己的信念，即便是多么特立独行，不用担心会被迫噤声或强迫当顺民。”</p>
</blockquote>
</li>
<li><blockquote>
<p>凭借Tor的通讯协定，网络流量从一个服务器到另一个服务器创造的路径随机反弹，目的在于取代使用者的身分。实际上没有任何一台服务器能辨识网络流量的来源信息。在天才的眼中，其中有一台服务器知道来源，那是整个服务器链的第一台，但却不知道网络流量去处。更简单来说，第一台链接到Tor网络的服务器称为闸道，知道你是传送要求的人，但因为它无法读取要求，因此对你寻求的信息一无所知。最后一台服务器称为出口，知道你所寻找的内容，却不知道你的身分。 这种分层方式为洋葱路由，因此Tor被称为洋葱路由器。</p>
<p>就我个人而言，Tor改变我的生命，给我免于被监测的自由，带我回到童年时期的自由。</p>
</blockquote>
</li>
<li><blockquote>
<p>在这本书出版时，该局能储存情资的时间或许已达数十年。国安局的逻辑是，收集来的情资一定得储存起来，日后才能方便运用。但没人能预测这些情资何时能派上用场。这样的观念助长国安局的终极目标，那就是将收集、制造的情资永远储存下来，创造出一个完美的记忆库、一份永久的纪录档案。</p>
</blockquote>
</li>
<li><blockquote>
<p>当我读着关于中国的机密资料时，我看到的是美国的倒影。换句话说，中国光明正大对人民做的监控行径，美国可能背地里也对其他国家这么做。</p>
</blockquote>
</li>
<li><blockquote>
<p>小布什总统在九一一事故后授权国安局展开无数监控，其中最具争议的是“总统监控计划”</p>
<p>PSP让国安局得以收集美国与境外的电话、网络通讯情资。最引人注意的是，PSP允许国安局不必取得外国情报监控法院（FISC）搜查令便能实施监控。FISC是成立于一九七八年的秘密联邦法院，负责审查情报单位提出的监控要求，借此防范反越南战争与民权运动期间非法监听情事再度上演。</p>
<p>《纽约时报》披露此消息后引起广大回响，加上美国公民自由联盟（ACLU）在公开法庭质疑PSP违反宪法，小布什政府于是宣称该计划将于二○○七年终止。</p>
</blockquote>
</li>
<li><blockquote>
<p>如果这些先进愿意赌上自己的工作、家庭与生命，那这背后必定存在比非法监听更严重的状况。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们的法律通常落后科技至少一个世代，但如今对于通讯内容的保障却高于后设数据，这真是极大的讽刺。事实上，情报单位对于取得后设数据有着更高兴趣，因为这些活动记录能让他们见树又见林，一方面赋予他们分析大量数据的能力、得以拼凑出事物全貌，另一方面又给予他们窥探个人私生活的机会、得以推断这些人的行为模式。简言之，监视者透过后设数据能得知你的所有一切，除了你的大脑在想什么之外。</p>
</blockquote>
</li>
<li><blockquote>
<p>科技全然不受限制，不像医生必须遵守希波克拉布底誓词。自工业革命以来，学术界、业界、军方与政府的科技人才做出许多决定，这些决定立基于“我们能够做什么”，而非“我们应该做什么”。推动科技进步的人，不太会限制它的应用与使用。</p>
</blockquote>
</li>
<li><blockquote>
<p>回顾这段历史，不仅令我们更加确信美国情报体系在科技上头的主导优势，更让我们担忧这些技术对于民主统治带来的巨大威胁。距离那时普查已经过一世纪的时间，科技出现惊人进展，但人类的警觉或法律规范却仍远远落后。</p>
<p>待在日本的这段时间令我恍然大悟。在那时，我真正了解到这些新科技可能造成的危害。若我们这个世代不介入的话，那未来的情况只会更严重。我并不希望看到，当我们终于决定挺身而出时，一切抵抗却是徒劳无功，若真是如此的话，那将是一大悲剧。未来的一代可能得面对充满监控的环境，政府违法监控行为并非偶一为之、针对特定危险目标，而是持续性、无差别地扩及全国民众。这就像是：你说的话逃不过政府耳朵，你做的事逃不过政府法眼，而你的纪录档案永远留存在政府手里。 一旦政府拥有四处收集情报的能力，加上情资得以永久储存的系统，那他们便能随便找个人或团体陷害，反正资料库一定搜寻得到证据（如同我寻找机密档案一样），绝对能替他们安上合适罪名。</p>
<p>对我来说，政府漤用监控特权，代表的是一个可怕的未来。所有人都遭到完全监控的世界，将变成一个全由电脑自动执法的世界。毕竟，若一个AI装置能够追踪民众违法行径，怎可能让他逃过法律制裁。即使技术上可行，我们也不可能设定一个纵容犯罪的监控程序。</p>
</blockquote>
</li>
<li><blockquote>
<p>美国基本法的存在，令执法单位更难执行工作。这并不是瑕疵，而是民主的真谛。按照美国法律规定，执法单位理应保护所有国民。当执法单位漤权时，法院应约束并纠正他们的行为，毕竟他们是社会上唯一能够羁押、逮捕民众并使用武力（包括致命武器）的人。而其中最重要的约束是，执法单位不得监控国民在家活动，也不能在未取得搜查令的情况下收集个资。但法律对于公众场所的监控行为宽松许多，其中当然也包含多数人在街头与人行道的活动。</p>
</blockquote>
</li>
<li><blockquote>
<p>过去十年来，我们看到美国制造一系列的悲剧：阿富汗战争永无止尽、伊拉克政权不断更迭、关押恐怖分子的关塔那摩湾监狱人满为患，美国政府非常规引渡、拷问并发动无人机袭击杀害平民（包括美国民众在内）。而在美国境内，国土安全部严格审查一切事物，每日发布恐攻威胁层级（红色代表严重、橙色高度警戒、黄色则是威胁升高），而自《美国爱国者法案》实施后，公民自由逐渐遭到侵害，讽刺的是，这是我们过去自称誓死捍卫的权利。这些加总的伤害（掌权者违法乱纪）无比巨大且难以逆转，但我们却还在按喇叭、闪车灯举国欢腾庆祝。</p>
<p>但其实恐惧才是真正的恐怖主义，而乐于编造借口授权使用武力的政治体制则是最大帮凶。比起恐怖主义，美国政客更害怕示弱、背叛自己的政党，或是惹火捐款给他们的支持者（这些人对于承揽政府合约、取得中东石油利益充满兴趣）。因恐惧衍生的政治凌驾于恐惧之上，催生出各种“反恐”作为：无人能敌的美国慌了手脚，行动不受政策规范、公然违反法治精神。在九一一事件后，情报单位的指令向来是“绝不能再出差错”，但这根本是做不到的。过了十年后，我看得更加清楚了。这群政治菁英阶级反复以恐惧作为号召，对应的并非是任何特定威胁或担忧，而是试图操弄情感、将恐惧化为永久性危险，借此合理化政府长久提高警觉的作为、不容民众质疑正当性。</p>
</blockquote>
</li>
<li><blockquote>
<p>在真正富有正义的社会里，人民才是政府的头家。虽然不同城市的民众各有特定动机与目标，但这群人的共同点在于，他们都拒绝独裁主义、重申“人权与生俱来、不可剥夺”的人道原则。 在独裁的国家，国家拥有权利授与给人民。而在自由国家，人民拥有权利授与给国家。在前者，由于政府的允许，身为国民（subject）的人民才能拥有财产、受教、工作、宗教以及言论的权利。而在后者，人民拥有公民（citizen）身分，同意在一定时间内接受统治，但能定期透过选举等制度更换政府。我认为，独裁统治与自由民主间的差异，才是我们这个时代最主要的意识形态冲突来源，而不是东方与西方间的分歧（这是人为捏造并且充满偏见），或是基督教对决伊斯兰的宗教冲突。</p>
<p>独裁国家通常都不是法治政府，而是以统治者意见为主。统治者要求国民服从政府，同时对异议分子极具敌意。相反的，自由民主国家不会或很少做出这样的要求，反而是仰赖每位公民自愿担负起保护周遭所有人自由的责任，这是不分种族、肤色、信仰、能力、性倾向或性别的。任何集体保障并非取决于血统而是共识，最终导向平等主义的结果。虽然现实的民主经常无法达到理想状态，但我仍坚信，这是最能“让不同背景的人共同生活、在法律之前人人平等”的统治形式之一。 这种平等不仅由权利组成，更包含自由在内。事实上，民主国家的公民所珍惜的许多权利，在法律上都是以限制的方式来保障。透过限制政府权力创造出来的自由空间，使得这些权利得以存在。举例来说，美国民众之所以拥有言论“自由”，这是因为禁止政府不得制定限制该自由的法律；而新闻“自由”则是禁止政府不得制定法律限缩该自由。同样的，宗教“自由”是禁止政府不得制定确立国教的法律；而和平集会与抗议的“自由”，是禁止政府不得制定任何</p>
</blockquote>
</li>
<li><blockquote>
<p>说到底，你声称自己不在乎隐私，因为没有事情好隐瞒，这就像是在说，你不在乎言论自由，因为你没有意见。或是，你不在乎新闻自由，因为你不爱阅读。你不在乎宗教自由，因为你不相信神。或是，你不在乎和平集会自由，因为反社会的你天性懒散、害怕人群。以上种种自由，今日对你来说也许不重要，但这不代表明日对你不重要，或对你的邻居不重要，或是对于世界另一端的异议分子不重要。我用手机追踪这群抗议群众的动态，他们希望争取到一点点的自由，而我的国家却对于这些自由必欲除之而后快。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们不能放任自己受到这样的利用，被利用来对抗未来。我们不能允许自己的资料被用来向我们推销绝对不可以出卖的东西，例如新闻。如果袖手不管，所看到的新闻将只是我们想要的新闻，或是当权者希望全民看到的新闻，而不是必要的坦白共同对话。不能放任我们所受到的全面监控，以之来“计算”我们的公民分数，或是“预测”我们的犯罪行为；我们会受什么教育，会找到什么工作，或是能否受教育或找工作；依据金融、法律和医疗纪录来歧视我们，更别说还有族群或种族，这些都是我们的资料的构成因素。至于个人最私密的资料，我们的基因信息：如果坐视这种信息被用来辨识我们，那么它也会被用来加害我们，甚至修改我们，按照试图控制全民的科技概念，重新塑造我们的人性本质。 当然，以上种种全部都已经发生了。</p>
</blockquote>
</li>
</ul>
<h3 id="28-《沃兹传：与苹果一起疯狂》"><a href="#28-《沃兹传：与苹果一起疯狂》" class="headerlink" title="28.《沃兹传：与苹果一起疯狂》"></a>28.《沃兹传：与苹果一起疯狂》</h3><h4 id="作者-21"><a href="#作者-21" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[美] 史蒂夫•沃兹尼亚克（Steve Wozniak）</li>
<li>[美] 吉娜•史密斯(Gina Smith)</li>
</ul>
<h4 id="简介-20"><a href="#简介-20" class="headerlink" title="简介"></a>简介</h4><p>怎么说呢。我觉着我读的每一本书都与我有着千丝万缕的联系。这本书是我上大二的时候读的，那时候只知道苹果的创始人是乔布斯，而不知道另一位沃兹。那时候的确读了很多人的传记，像 Linus 的《只是为了好玩儿》、RMS 的《若为自由故》、互联网之子、 埃里克·斯蒂芬·雷蒙 、奔腾的代码、操作系统革命等。后来听了软件那些事儿上讲的 <a href="https://liuyandong.com/2018/01/20/136/" target="_blank" rel="noopener">苹果双核之史蒂夫•沃兹</a>  又对沃兹有了进一步的熟悉和了解。</p>
<h4 id="读后感-15"><a href="#读后感-15" class="headerlink" title="读后感"></a>读后感</h4><p>沃兹能取得这么大的成就和他小时候的而家庭教育密不可分。尤其是沃兹父亲工程师的品格深深影响到了沃兹的成长。一个从小就和电子打交道的男孩。</p>
<p>这本书里搜索 <code>电子</code> 二字的结果竟然有 179 个，可想而知沃兹成长过程中与电子世界是密不可分的。</p>
<p><img src="../img/image-20191126154018148.png" alt="电子"></p>
<p>十分建议家长们读一下这本书。应该向沃兹的父亲那样在生活的点点滴滴培养孩子的兴趣。使得小孩从小就知道自己未来要做一个什么样的人，并对这份职业保佑崇高的敬仰。不要再将我们这代人的悲剧发生在下一代人身上，以至于直到上大学选专业都不知道自己要做什么。还有一点就是从现实中给孩子找到乐趣，而不是为了哄孩子就让他们耍手机。</p>
<p>另外值得一提的是沃兹还是电子前哨基金会的创始人之一</p>
<blockquote>
<p>电子前线基金会，由卡普尔、<a href="https://zh.wikipedia.org/w/index.php?title=约翰·吉尔摩&amp;action=edit&amp;redlink=1" target="_blank" rel="noopener">约翰·吉尔摩</a>和巴洛，正式成立于1990年7月10日。初始资金由卡普尔，<a href="https://zh.wikipedia.org/wiki/斯蒂夫·沃兹尼亚克" target="_blank" rel="noopener">斯蒂夫·沃兹尼亚克</a>和一个匿名人士提供</p>
<p>此处引用<a href="[https://zh.wikipedia.org/wiki/%E7%94%B5%E5%AD%90%E5%89%8D%E5%93%A8%E5%9F%BA%E9%87%91%E4%BC%9A](https://zh.wikipedia.org/wiki/电子前哨基金会">电子前哨基金会维基百科</a> )</p>
</blockquote>
<p>看完这本书想到沃兹是其中之一的创始人一点都不感到意外了，关于电子前哨基金会的事迹，以后我会多写点内容。</p>
<h4 id="摘抄-18"><a href="#摘抄-18" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>我写这些，是想表明我爸爸对诚信特别重视。他把最高的诚信和道德水平作为人生信仰。这是他教给我的最重要的东西，他总是告诉我，在法庭宣誓后撒谎掩饰罪行比杀人放火这样的恶行更为罪恶。这对我影响深远，直到今天，我也从不撒谎。即使是再小的事情我也绝不撒谎，除非你算上恶作剧。但我认为恶作剧并不算谎言，它们是娱乐、是搞笑，尽管两者的区别有时稍显微妙，但仍有质的区别。</p>
</blockquote>
</li>
<li><blockquote>
<p>爸爸还是我电子学的启蒙老师。噢，我能在日后的工程师生涯中取得如此多的成就，与他的耐心教导是分不开的。从我很小的时候开始——甚至在我四岁前，爸爸就把我领入了电子学的世界，向我描述、解释与电子有关的种种事情。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们的世界并不是一个非黑即白的世界，这个世界是灰度的。作为一个发明家，你必需要用灰度的眼光来看世界。你必须思想开放，千万不要随大流。事实上，你应该忘记那些所谓的“公认准则”。你应该始终保持绝对客观，忘记你所听到的各种观点和声音，像科学家一样考察事实。当你探索时，不要太早有所偏向，不要太早下结论，否则你就会变得偏激，客观的探索也会因为寻找各种证明自己观点的证据而变味。谁想要花时间证明一个错误的观点？沉浸在自我膨胀中毫无意义也毫无价值。你并不需要为证明自己的观点找一个借口。</p>
</blockquote>
</li>
<li><blockquote>
<p>当时的我还太小，无从决定自己以后是不是要当一名工程师。想当工程师的念头是在几年后才萌发的。在还没接触科幻世界和发明家的故事之前，小小的我就被带入了爸爸的技术世界，已经模模糊糊地感受到了技术的重要性和魅力。这算是我后来职业选择的最初渊源吧。</p>
</blockquote>
</li>
<li><blockquote>
<p>爸爸教给我许多重要的东西，我最想跟你分享的是在我看来他教给我的最重要的一课——他训练我如何做一名工程师。这对我的一生影响深远，甚至比爸爸的诚信观对我的影响还深。这里说的“工程师”指的是真正的工程师，或者说是工程师中的工程师。我清楚地记得爸爸坚定地告诉我，工程师是世界上最高尚、最重要的职业，作为一名工程师，你可以用自己的智慧创造出新的仪器，让人们活得更幸福，让世界变得更美好。他告诉我，工程师的工作能改变世界，能改变许多人的生活。</p>
</blockquote>
</li>
</ul>
<h3 id="29-《公正：该如何做是好-》"><a href="#29-《公正：该如何做是好-》" class="headerlink" title="29. 《公正：该如何做是好?》"></a>29. 《公正：该如何做是好?》</h3><h4 id="作者-22"><a href="#作者-22" class="headerlink" title="作者"></a>作者</h4><p>[美]迈克尔·桑德尔</p>
<h4 id="简介-21"><a href="#简介-21" class="headerlink" title="简介"></a>简介</h4><p>大二的时候看过公开课，而这本书正是这门公开课所讲述的内容</p>
<h4 id="读后感-16"><a href="#读后感-16" class="headerlink" title="读后感"></a>读后感</h4><h4 id="摘抄-19"><a href="#摘抄-19" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>那些维护和反对价格欺诈的论证，都围绕着三种观念展开：使福利最大化、尊重自由和促进德性。其中的每一种观念都引向了一种不同的思考公正的方式。<br>维护自由市场的基本理由基于两种主张—一种有关福利，另一种有关自由。</p>
</blockquote>
</li>
<li><blockquote>
<p>要看一个社会是否公正，就要看它如何分配我们所看重的物品—收入与财富、义务与权利、权力与机会、公共职务与荣誉等等。一个公正的社会以正当的方式分配这些物品，它给予每个人以应得的东西。</p>
</blockquote>
</li>
<li><blockquote>
<p>在当代政治语境中，公正意味着尊重自由和个体权利这一观念与功利主义使幸福最大化的观念，至少同样为人们所熟知。</p>
</blockquote>
</li>
<li><blockquote>
<p>那么，我们怎么能够通过这些相互对立的关于公正和不公正、平等和不平等、个人权利和共同利益的争论，进行独立的思考呢？本书将试图解答这一问题。</p>
</blockquote>
</li>
<li><blockquote>
<p>边沁是英国道德哲学家和法律改革者，创立了功利主义学说。其主要观点很简单，并对人具有直觉上的吸引力：道德的最高原则就是使幸福最大化，使快乐总体上超过痛苦。对边沁而言，正当的行为就是任何使功利最大化的行为。他所说的“功利”，意指任何能够产生快乐或幸福，并阻止痛苦或苦难的东西。</p>
</blockquote>
</li>
<li><blockquote>
<p>功利主义声称能够提供一种基于衡量、合并和计算幸福的道德科学。它不加评判地衡量各种偏好，每个人的偏好都同等重要。这种不加评判的精神是其吸引力的一个主要源泉；同时，它许诺要将道德选择变成一门科学，这也影响了很多当代经济学的理论。然而，为了使各种偏好能够相加，我们有必要用同一个尺度来衡量它们。边沁的功利思想便提供了这样一种通用价值货币。</p>
</blockquote>
</li>
<li><blockquote>
<p>为什么我们应当假设维护个人的自由和表达异议的权利会从长远上促进社会福利呢？密尔提出了几种理由：反对性的意见可能是正确的，或部分正确，因而能给正统的观点提供纠正。即使它不正确，那么使正统的观点接受一些观念的有力挑战，将会防止它变成硬性的教条和偏见。最后，一个强迫其成员接受习俗和传统的社会很可能会陷入一种荒谬的一致性，从而剥夺了自身促进社会进步的能量和活力。</p>
</blockquote>
</li>
<li><blockquote>
<p>从长远来看，尊重个体自由会导向最大的人类幸福。允许大多数人使持异议者保持沉默或抑制自由思考者，可能会使目前的功利最大化，可是从长远来看，这会使社会变得更坏—更加缺乏快乐。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们已经考察了两种对边沁“最大幸福”原则的反驳—一种认为它没有给予人类尊严和个体权利足够的重视，另一种认为它错误地将一切具有道德重要性的事物都用单一的快乐与痛苦的尺度衡量。</p>
</blockquote>
</li>
<li><blockquote>
<p>在本书的引言中，我区分了三种公正进路。那种功利主义的进路认为，界定公正和判断何谓正当之事的方法就在于询问什么将会使福利或社会总体幸福最大化。第二种进路将公正与自由联系起来，自由至上主义者为这一进路提供了例证。他们认为，关于收入和财富的正当分配就是任何一个在不受约束的市场中自由交换商品和服务所产生的分配。他们坚持认为，调节市场是不公正的，因为这侵犯了个体的选择自由。第三种进路认为，公正就是给予人们在道德上所应得的—以分配物品来奖励和促进德性。</p>
</blockquote>
</li>
<li><blockquote>
<p>康德反对第一种进路（使福利最大化）和第三种进路（促进德性）。他认为，这两种进路都没有尊重人类自由。因此，康德是第二种进路—将公正与道德同自由联系起来—的强有力的倡导者。然而，他所提出的自由观念要求更为苛刻—比我们在市场上买卖东西时所行使的选择自由要更加苛刻。康德认为，我们日常所认为的市场自由或消费自由并不是真正的自由，因为它仅仅满足我们事先并没有选择的各种欲望。</p>
</blockquote>
</li>
<li><blockquote>
<p>康德的推理如下：当我们像动物一样追求快乐或避免痛苦时，我们并不是真正自由地行动，而是作为欲望和渴求的奴隶而行动。为什么呢？因为无论何时，只要我们是在追求欲望的满足，那么我们所做的任何事情，都是为了某种外在于我们的目的。我以这种方式来充饥，以那种方式来解渴。根据康德的思想，自由地行动就是自律地行动，自律地行动就是根据我给自己所立的法则而行动—而不是听从于本性或社会传统的指令。当我们评价一个行为的道德价值时，我们要评价产生这一行为的动机，而不是它产生的后果。</p>
</blockquote>
</li>
<li><blockquote>
<p>由于人们“在幸福的经验性目的及其构成上，有着不同的观点”，因此，功利不能作为公正和权利的基础。为什么呢？因为如果将权利建立在功利的基础之上，那么，就会要求这个社会来肯定或接受某一种幸福观而不接受另外一些；将整个宪法都建立在一种特定的幸福观（如大多数人的幸福观）之上，就会给其他人强加一些价值观，这就没有尊重每个人追求他自己目的的权利。“没有人能够强迫我的幸福必须与他那种关于他人福利的观念相一致，”康德写道，“因为每个人都能够以他自己认为合适的方式去追求幸福，只要他不侵犯他人也这样做的自由。”</p>
</blockquote>
</li>
</ul>
<h3 id="30-技术垄断-文化向技术投降"><a href="#30-技术垄断-文化向技术投降" class="headerlink" title="30. 技术垄断: 文化向技术投降"></a>30. 技术垄断: 文化向技术投降</h3><h4 id="作者-23"><a href="#作者-23" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[美国]尼尔·波兹曼</li>
</ul>
<h4 id="简介-22"><a href="#简介-22" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>技术垄断:文化向技术投降》认为，人类技术的发展可分为三个阶段：工具使用、技术统治和技术垄断三个阶段；人类文化大约也分为相应的三种类型：工具使用文化、技术统治文化和技术垄断文化。和其他学者一样，波斯曼认为，技术和人的关系是亦敌亦友的关系，但他死死地盯着技术的阴暗面，以免技术对文化造成伤害。他认为：在工具使用文化阶段，技术服务、从属于社会和文化；在技术统治文化阶段，技术向文化发起攻击，并试图取而代之，但难以撼动文化；在技术垄断文化阶段，技术使信息泛滥成灾，使传统世界观消失得无影无形，技术垄断就是集权主义的技术统治。《技术垄断》认为，“信息革命”经历了印刷术、电报、摄影术、广播和电脑等五个阶段。在技术垄断到来之前，信息控制机制帮助人驾驭技术，这些机制有：法庭、学校、家庭、政党、国家和宗教。到了技术垄断阶段，抵御信息泛滥的多重堤坝和闸口土崩瓦解，世界就难以驾驭、难以把握了。《技术垄断》揭示技术垄断阶段各种“软”技术的欺骗作用，挞伐所谓的社会“科学”，谴责唯科学主义，它辨析自然科学、社会“科学”和文学的异同，它为传统符号的耗竭扼腕痛惜，它号召人们以强烈的道德关怀和博爱之心去拼死抵抗技术垄断，并坚决反对文化向技术投降。</p>
</blockquote>
<p>这本书和《娱乐至死》、《童年的消逝》三本并成为媒介批评三部曲，总之值得读一下，尤其是那些手机控、刷抖音短视频的人😂，虽然这几本书写于上世界八十年代之前，但尼尔·波兹曼老人家早就预言了信息流轰炸带来的种种弊病，以及技术垄断控制文化等问题。不过书中有些观点我是不赞同的，因为我是技术出身，毕竟是要靠技术吃饭的。</p>
<h4 id="摘抄-20"><a href="#摘抄-20" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>1982年，波斯曼在《童年的消逝》里抨击电视文化，捍卫印刷文化，叹息电视文化抹杀成人和儿童的界限。于是人们说，他是悲观主义者。 1985年，他在《娱乐至死》里控诉电视对读写能力的戕害，映射电视掏空了人的头脑和心灵。人们似乎更有理由说，他是悲观主义者。 1992年，他在《技术垄断：文化向技术投降》里高呼“狼来了”，揭示唯科学主义和信息失控的现实危险，指控技术垄断对美国文化和人类文化的危害。你能说他主张“技术决定论”吗？</p>
</blockquote>
</li>
<li><blockquote>
<p>在这里，波斯曼提出4条人文主义原则，用以指导媒介研究和传播研究：（1）媒介在多大程度上对理性思维的发展做出了贡献？（2）媒介在多大程度上对民主进程的发展做出了贡献？（3）新媒介在多大程度上使人能够获取更多有意义的信息？（4）新媒介在多大程度上提高或有损我们的道德感、我们向善的能力？</p>
</blockquote>
</li>
<li><blockquote>
<p>他提醒我们注意科学技术进步的副作用： 倘若铁路没有克服空间距离，我的孩子就不会离开故乡，我就不需要打电话听他说话；倘若跨洋旅行的技术没有开发，我的朋友就不会坐海船旅行，我就不需要打电报来舒缓对他是否平安的担心。婴儿死亡率的降低给我们的生儿育女强加了诸多限制，以至于在考虑各种因素的情况下，我们生育的孩子并不比讲究卫生之前多。与此同时，这又给我们婚后的性生活造成诸多困难……最后要问，倘若生活困难，罕有欢乐；倘若生活充满苦难，以至于我们只能够把死亡当作解脱来欢迎，那么，长寿对我们又有什么好处呢？</p>
</blockquote>
</li>
<li><blockquote>
<p>控制技术运行机制的人积累权力，必然要密谋防备那些无法获取专门技术知识的人。在《传播的偏向》里，伊尼斯提供了许多历史事例，说明新技术如何摧毁传统的知识垄断，造成一种新的知识垄断，即由另一群人来把持的知识垄断。换句话说，一种新技术的利弊长短不会势均力敌。仿佛是游戏，有输家也有赢家。在许多情况下，输家出于无知为赢家欢呼雀跃，现在的情况依然如此；这实在是令人困惑，让人心酸。</p>
</blockquote>
</li>
<li><blockquote>
<p>他们的隐私更容易被强大的机构盗取。他们更容易被人追踪搜寻、被人控制，更容易受到更多的审查，他们对有关自己的决策日益感到困惑不解；他们常常沦为被人操弄的数字客体。他们在泛滥成灾的垃圾邮件里苦苦挣扎。他们容易成为广告商和政治组织猎取的对象。技术赋予谁更大的权力、更多的自由？谁的力量和自由又会被削弱？</p>
</blockquote>
</li>
<li><blockquote>
<p>每一种工具里都嵌入了意识形态偏向，也就是它用一种方式而不是用另一种方式构建世界的倾向，或者说它给一种事物赋予更高价值的倾向；也就是放大一种感官、技能或能力，使之超过其他感官、技能或能力的倾向。</p>
</blockquote>
</li>
<li><blockquote>
<p>学龄儿童已经习惯了电视的偏向，上学以后他们遭遇的却是印刷词语的世界。一种心理战随之发生，造成惨重的伤亡；不能或不愿学习读书写字的儿童，在简单的段落里都不会以逻辑结构组织思想的儿童，不能静下来听老师讲解的儿童，就是这场战争的受害者。这些儿童之所以打败仗，并不是因为他们愚笨，而是因为他们背后正在进行的媒介之战，是因为他们站到了错误的一方，至少是暂时站错了队。</p>
</blockquote>
</li>
<li><blockquote>
<p>具有讽刺意味的是，培根本人并不是科学家，至少不太像科学家。他并没有在任何一个研究领域做过任何拓荒的工作。他并未揭示任何新的自然定律，也没有提出一个新鲜的假设。他甚至对当时的科学研究并不通晓。他自认为开创了科学方法的革命性进步，并为此而感到自豪。但后人并不容许他享受这个美名。实际上，他最著名的科学实验之所以引起我们的注意，那是因为这一次实验要了他的命。在一个风雪天，他与好友威瑟尔博恩（Witherborne）博士乘马车出游，看见地上的积雪时，他就自问：冻雪能否像食盐那样保存鲜肉呢？两人决定立即实验。他们买了一只鸡，掏空内脏，把雪塞进去。可怜的培根未能等到实验的结果，因为他当即受冻病倒，很可能患了气管炎，三天以后就不幸去世。有的时候，他因此而被认为是实验科学的殉道者。😂</p>
</blockquote>
</li>
<li><blockquote>
<p>技术统治文化解决了信息稀缺的问题，信息稀缺的不利因素是显而易见的。但是，对信息泛滥的危险，它却不给人警示，因为信息泛滥的弊端并不是那么明显。信息泛滥的长远结果就是信息混乱，由此产生的文化仿佛是打乱了顺序的一副牌。奇怪的是，很少人注意到自己苦恼的根源，或者说即使注意到了，他们也不承认。</p>
</blockquote>
</li>
<li><blockquote>
<p>事实上，政治问题、社会问题尤其个人问题，很少是由信息不足引起的。然而，随着难以理解的问题增加，随着进步观念的淡出，由于意义本身成为令人生疑的对象，技术垄断论者坚定不移地相信，世界需要的是更多的信息.</p>
</blockquote>
</li>
<li><blockquote>
<p>一切现代事物的许多特征都可以追溯到千百年之前，同理，信息充斥的源头也可以回溯千百年。有人说计算机技术开创了信息时代，在误导人的言论中，莫此为甚。早在16世纪初，印刷机就开创了信息时代。</p>
</blockquote>
</li>
<li><blockquote>
<p>第一修正案的措辞设定并坚持公众的权利：公众不仅要获取信息，而且要控制信息，人民要知道如何用信息为自己谋福利。这并不是说，“建国之父”们认为，信息不可能作假、误导或离题。但是他们相信，信息和思想的市场井井有条，公民足以弄懂耳闻目睹的东西。足以用理性评判信息和思想对他们生活的用处。</p>
</blockquote>
</li>
<li><blockquote>
<p>信息已经成为一种垃圾，它不能回答人类面对的大多数根本问题；对平常的问题，信息也只能勉强提供解答的方向。再换一种方式说，在技术垄断盛行的环境里，信息和人的意旨之间的纽带已经被切断了；也就是说，信息杂乱无章地出现，并不指向具体的人，数量难测，速度惊人，但从理论、意义或宗旨上看却是断裂分割的。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们的目的不是减少愚昧、迷信和苦难，而是让我们自己去适应新技术的需要。当然，我们对自己说，这样的调适能够改善生活；然而那仅仅是正在消亡之中的技术统治文化的逻辑残存。我们的文化正在用信息自我消耗，而且许多人还不知道如何驾驭这个过程。我们的假设是，信息是我们的朋友，如果信息不足，文化受到的损害可能会令人扼腕，这个假设当然有一定的道理。另一方面，如果信息过剩，信息无意义，信息失去控制机制，文化也可能会吃尽苦头；可惜人们才刚刚开始明白这个道理。</p>
</blockquote>
</li>
<li><blockquote>
<p>随着信息供应量的增加，信息控制机制就受到很大的压力。为了对付新的信息，就需要增补控制机制。但新的控制机制本身就是技术，它们又反过来增加信息的供应量。当信息的供应量无法控制时，个人的心宁神静和社会生活的宗旨就必然会普遍崩溃而失去防卫。防线崩溃之后，人们就无法寻觅经验中的意义，就失去记忆力，就难以想象合理的未来了。</p>
</blockquote>
</li>
<li><blockquote>
<p>可以肯定，技术对医疗实践的控制，很少有医生会感到满意。许许多多的患者因为技术对医疗的控制而受到严重的伤害。由此我们可以得出什么结论呢？第一，技术在医疗实践中并不是中性的因素：医生不仅使用技术，而且被技术利用。第二，技术产生对人的强制性要求，同时还产生广泛的社会系统来贯彻其强制性要求。第三，技术重新界定医生的身份，使医生的注意力重新定向，对医生看待病人和疾病的观点进行重构。</p>
</blockquote>
</li>
<li><blockquote>
<p>民意测验是统计学用于误测的另一种方式。正如统计学产生了一个庞大的测试产业一样，民意测验为“公共舆论”造就了庞大的产业。你也许一开始就承认，这样的调查可以说是可靠的，尤其是在问题非常受限的条件下，调查的方法可能是可靠的。比如，你准备投票选X还是Y？但说一种方法可靠并不等于判断它有用。对投票倾向的了解究竟使选举过程丰富多彩了还是意义降格了？这个问题尚待解决。然而，当民意调查被用来指引公共政策时，我们就遇到了一个截然不同的问题。</p>
</blockquote>
</li>
<li><blockquote>
<p>想法。“意见”不是特定时刻呈现出来的一个事物，而是一个思考的过程，由不断获取知识以及考问、讨论和辩论形成的思维过程。一个问题可能“招引”（invite）一种想法，但也能修正并重构这个“意见”；我们最好说，人们并不是真正“抱有”（have）什么想法，而是处在“形成想法的过程中”（involved in opinioning）。把“意见”当作可以测量的事物就歪曲了这个过程；实际上，人们参与形成舆论的过程；如何参与这个过程就深入到民主社会意义的核心了。民意调查并没有向我们提供这个过程的任何信息，相反，它往往掩盖了这个过程，使我们看不见这个过程。</p>
</blockquote>
</li>
<li><blockquote>
<p>我们掌握的事实可能就有助于认清其中的因果关系，并进而行动起来解决问题。不过，像一切技术一样，统计数字往往会失去控制，在我们的头脑里占据过多的位置，侵犯我们的话语，造成语言的浩劫。统计数字失控时，我们需要知道的东西就被埋葬在鸡毛蒜皮的信息堆里了。</p>
</blockquote>
</li>
<li><blockquote>
<p>美国过去和将来始终在进行不断的试验，世人正以惊异的目光注视着美国。有三场试验特别重要。第一场试验发生在18世纪末，时人提出的问题是：如果一个国家允许最大限度的政治自由和宗教自由，它还能够维持相同的认同感和宗旨吗？第二场伟大的试验发生在19世纪中叶，那时的问题是：如果一个国家允许世界各地的移民进入，它还能够保持整合一体和全国一家的感觉吗？目前正在进行的第三场试验是技术垄断的试验，现在的问题是：如果一个国家完全屈从于技术思想世界（technological thought-world）至高无上的地位，它还能够保存自己的历史、原创精神和人文情怀吗？</p>
</blockquote>
</li>
<li><blockquote>
<p>抵抗美国技术垄断的斗士应该： （1）除非知道民意测验里设计的是什么问题并为何这样问，否则就不理睬民意测验； （2）不接受效率是人际关系最优先目标的思想； （3）摆脱对数字魔力的迷信，不把计算当作替代评判的充足根据，也不把精确的计算和真理画等号； （4）不让心理学或任何“社会科学”占据优先的地位，不让它们排挤常识里的语言和思想； （5）至少对所谓“进步”观念抱怀疑态度，不把信息和理解混为一谈； （6）不认为老年人无关紧要； （7）认真对待家庭忠诚和荣誉的意义，准备伸手去接触人时，期待他人也有同样的需要； （8）认真对待宗教的宏大叙事，不相信科学是产生真理的唯一体系； （9）理解神圣和世俗的差别，不会为了追求现代性而漠视传统； （10）钦慕技术独创，但不认为技术代表了人类成就的最高形式。</p>
</blockquote>
</li>
</ul>
<h3 id="31-自由与繁荣的国度"><a href="#31-自由与繁荣的国度" class="headerlink" title="31. 自由与繁荣的国度"></a>31. 自由与繁荣的国度</h3><h4 id="作者-24"><a href="#作者-24" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[奥]路德维希·冯·米瑟斯</li>
</ul>
<blockquote>
<p>他还被誉为是“奥地利经济学派的院长”。他的理论也影响了之后的经济学家如弗里德里克·哈耶克、穆瑞·罗斯巴德等人。</p>
</blockquote>
<h4 id="简介-23"><a href="#简介-23" class="headerlink" title="简介"></a>简介</h4><p>这也是我 2019 年读完的最后一本书，感谢这本书让我对自由主义思想有了认识，打破的以前对自由主义的理解。这本书篇幅不长，主要是对自由主义的理想的阐释顺带着鄙视了一下无政府主义，是研究哈耶克思想的重要文献之一。</p>
<h4 id="摘抄-21"><a href="#摘抄-21" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>如果把他们放在生活的谎言和逻辑思维两者之间，让他们去选择的话，他们宁可牺牲逻辑。这是因为，他们如果放弃了在社会主义思想中找到的安慰，或曰离开了这种安慰，生活就会变得更加不堪忍受。社会主义思想告诉他们，导致失败的原因不在于他们自身的过错，而在于社会。</p>
</blockquote>
</li>
<li><blockquote>
<p>如果把他们放在生活的谎言和逻辑思维两者之间，让他们去选择的话，他们宁可牺牲逻辑。这是因为，他们如果放弃了在社会主义思想中找到的安慰，或曰离开了这种安慰，生活就会变得更加不堪忍受。社会主义思想告诉他们，导致失败的原因不在于他们自身的过错，而在于社会。因此，社会主义思想抬高了他们低落的自我意识，并将他们从难以忍受的压抑感中解脱出来。</p>
</blockquote>
</li>
<li><blockquote>
<p>对于照顾社会的整体利益及其意义的问题，人们存在着多方面的误解。他们认为，道德的价值就是牺牲个人利益，放弃享乐。这种看法忽视了一个最重要的问题，即道德的真正价值不是牺牲本身，而是这种牺牲所要达到的目的。也就是说，只有在为一个道德的目的而牺牲个人利益的前提下，这种牺牲才是合乎道德的。有些人为了一件正义的事业敢于舍去自己的一切、直至财产和鲜血；而另一些人却愿作出某些不给社会带来任何好处的无谓牺牲，这两者之间有着天壤之别。</p>
</blockquote>
</li>
<li><blockquote>
<p>无政府主义者认为，在一个真正为全体人民、而不是仅为特权阶层的特殊利益服务的社会里、国家、法律和政府都是不必要的多余机构。仅仅是由于目前的社会制度承认生产资料的私有制，才需要人们用强制和暴力来保护它。一旦消灭了私有制，人们就会自发地遵守社会生活的共同准则。</p>
</blockquote>
</li>
<li><blockquote>
<p>无政府主义者不否认，在实行劳动分工的社会里人们共同生活的每种形态都必须遵守某种规则，这些规则要求人们不得不作出某种尽管是暂时的，但毕竟是一种眼前利益的牺牲。但无政府主义者错就错在他们认为所有的人都会毫无例外地、自觉地遵守这个规则。</p>
</blockquote>
</li>
<li><blockquote>
<p>自由主义不是无政府主义，自由主义与无政府主义这两者之间毫无关系。自由主义的观点十分鲜明，这就是，没有强制措施，社会就会面临危险；为了保障人们的和平与合作，必须制定人们共同遵守的规则，必须保留暴力和威慑手段，只有这样才不致于使任何人破坏社会秩序。人们必须拥有足够的力量，迫使那些无视他人的生命、健康、个人自由和私有财产的人遵守社会生活的共同准则，必要时必须使用暴力。</p>
</blockquote>
</li>
<li><blockquote>
<p>自由主义关于国家职能的主张是它赞成生产资料的私有制这一根本性主张的延伸。如果我们赞同生产资料的私有制，那么，我们当然不同意将它改变成公有制的形式。也就是说，政府不应当成为生产资料的所有者。基于这一立场，自由主义者关于生产资料私有制的要求，明确无误地界定了政府的职能范围。</p>
</blockquote>
</li>
<li><blockquote>
<p>在德国人民中享有崇高声誉的作家、学者或艺术家，他们在其家乡得到的敬重和礼遇仅相当于政府的官僚等级制度中一位级别不高的官吏。那些在机关的写字间听差打杂的官吏被如此高估，实在是没有什么明智的理由。这种现象是以往诸侯统治时期遗传下来的后遗症，或者也可以说是遗传学中所说的一种隔代返祖现象。在那个时代里，公民畏惧公侯君主和他们的仆人，因为他们在任何时候都有可能被这些人洗劫一空。从这个意义上看，没有什么东西比把这些官吏们从写字间里轰出来，改变他们打发案卷、消磨时光的生活，把他们送到机器制造厂的绘图室去干活更美好、更高贵、更光荣了。税务官的职业不应当比那些直接创造财富、并向政府纳税、供其花费的人更高贵。</p>
</blockquote>
</li>
<li><blockquote>
<p>民主的社会功能。民主是一种国家的宪法形式，即它可以保证在不使用暴力的前提之下使政府符合被统治者的意愿。假如一个按照民主的原则组成的政府不遵照大多数人的意愿执政，人们不用打内战就可以将它推翻，并将那些受到大多数人拥护的人推到政府的执政地位。民主的国家体制中的选举机构和议会就专司此职，它们使政府的更迭得以平稳、无磨擦、不用武力以及不流血地加以完成。</p>
</blockquote>
</li>
<li><blockquote>
<p>人民是单个公民集合而成的整体，每个公民就其个体而言，其聪明才智和品德高尚与否尚且参差不齐，那么，由这些参差不齐的个体组成的整体势必是有差异的。</p>
</blockquote>
</li>
<li><blockquote>
<p>毋庸讳言，现实生活中，那些背离自由主义的民主原则，依靠欺骗和诱惑上台掌权的现象是有的，而且为数不少。此外，还有一些聪明睿智的人，当发现自己的人民或全世界人民在通往毁灭的道路上徘徊，而他们此时又没有力量说服人们接受其正确的思想，而允许他们采用的方法又不足以解决问题时，他们就会产生一种采取断然措施、拯救全体人民非我莫属的念头。此时此刻，强人政治、暴力统治以及少数派掌权的独裁主张就会冒头，而且可以立即找到其支持者。但自由主义认为，暴力从来就不是解决危机问题的手段。</p>
</blockquote>
</li>
<li><blockquote>
<p>  社会主义经济的领导者缺少一个为市场提供一切经济活动的市场价格的标准尺度。在资本主义条件下，这种标准尺度的形成过程是，在市场上对所有的商品和劳务进行交换，由此确定每种商品的交换比例，并用货币的形式表现出来。在以财产私有制为基础的社会制度中，人们可以将所有经济活动的结果用核算的方式加以控制。通过会计核算和利润核算的方法，审核每一种经济活动利润。事实表明，对大部分国营企业进行的利润核算都不能采用同私营企业的利润核算相同的方法进行。</p>
<p>  类似的核算在社会主义制度下则不可能进行，因为它不可能将所涉及的各种不同的商品和劳务的质量和数量简化成一个统一的衡量尺度。社会主义制度对经济生活中通常或每天遇到的问题束手无策，因为它不具备计算、核算的手段和能力。</p>
</blockquote>
</li>
<li><blockquote>
<p>  资本主义生产方式已经经历了相当长时间的考验。仅就物质福利和人们的富裕程度而言，它使得今天的地球能够养活比资本主义早期多得多的人口。这种制度需要社会主义制度所不理解的货币核算。鼓吹社会主义的作家们的一切努力，即，人们如何在没有货币核算和价格核算的情况下也能生活的论调，证明都是徒劳的。他们在这一方面的一切尝试均以失败而告终。</p>
</blockquote>
</li>
<li><blockquote>
<p>  自由主义认为，国家机器的任务只有一个，这就是保护人身安全和健康；保护人身自由和私有财产；抵御任何暴力侵犯和侵略。一切超出这一职能范围的政府行为都是罪恶。一个不履行自己的职责，而去侵犯生命、健康，侵犯自由和私有财产的政府，必然是一个很坏的政府。</p>
</blockquote>
</li>
<li><blockquote>
<p>  自由主义不是宗教，不是世界观，也不是代表特殊利益的党派。它不是宗教，因为它既不要求信仰，也不要求牺牲，因为它的周围没有任何神秘主义的东西，还因为它没有什么教义；它不是世界观，因为它不想解释宇宙，因为它什么也没有对我们说，也不想说关于人的存在的意义和目的这种事情；它不是一种利益党派，因为它没有向任何个人和团体许诺某种特殊好处，它不想，也没有去营造这种好处。它是一种完全不同的东西。它是意识形态，是关于社会上各种事物内在联系的学说，同时又是关于如何将这种学说应用到人在社会事务中的行为上面的学问。它不允诺任何超出社会和通过社会力所能及的东西。它只想给人们一样东西，和平地、不受干扰地提高所有人们的物质富裕程度，从而——只要社会机构有这个力量——使他们远离苦难的外在根源。减少痛苦，增加欢乐，这就是它的目标。</p>
<p>  ﻿没有一个宗教派别、没有一个政党曾相信过，可以不用打动人们的意识感情来维护自己的事业。华丽的辞藻、音乐和歌声响起来了，旗帜飘荡起来了，鲜花和色彩构成了某种象征，这是领袖们在寻求人们对他们个人的顺从。自由主义不跟着做这种事情。它没有党的鲜花，没有党的色彩，没有党歌，没有党的偶像，没有标志，没有口号。它只有事业和论据，而它们必定把它引向胜利。</p>
<p>  自由主义是一种比较博大的观念，它表示一种囊括全部社会生活的意识形态。而民主只表示一种仅仅包括社会关系一部分领域——国家政体——的意识形态。为什么自由主义必定要在国家中要求民主，本书在第一部分己经对此作了说明。为什么所有反自由主义的流派，也包括社会主义在内，都必然是反民主的，要说明这一点，则是详细研究这些流派本质的人们的任务。对社会主义，我在我的书中试图用“公有制经济”解释之。</p>
</blockquote>
</li>
<li><blockquote>
<p>  马克思主义理论可以归纳为三条教义： （1） 只要社会主义还没有出现，人类就会分裂为彼此间利益不可调和地相互对立的社会阶级。 （2） 人的思维总是要受其阶级关系所支配。人的思想反映其所属阶级的特殊利益，并与所有其他各阶级成员的利益处于不可调和的对立之中。[1] （3） 阶级利益的冲突导致了无情的阶级斗争，从而不可避免地导致了最广大的、最受虐待的阶级，即无产阶级的胜利。于是，光明的社会主义时代就将永久存在下去。</p>
<p>  还有更多的事实，都证明了马克思所取得的所有科学成就均属无用。但即使人们都这么说，依然有一个事实不可否认，那就是这个一贫如洗的作家，尽管其名字不为其同时代的大多数国务活动家和政治理论家们所知，但其思想却要比任何一种哲学更为深远地影响了历史进程或者世界事务长达七八十年之久。</p>
</blockquote>
</li>
<li><blockquote>
<p>  ﻿我们人类由于自身存在着各种弱点和谬误，所以不可能知道，通过某个超人类智慧生物的角度来看，我们俗世的生活到底是怎样的。但我们能够观察到这样的事实，所有非资本主义社会的民众都心照不宣地承认了资本主义方式在推销其产品方面的优越性。</p>
</blockquote>
</li>
<li><blockquote>
<p>  有关资本主义体系的成就，以及所有社会主义和半社会主义实验的失败，还有很多东西可说。然而首先需要弄清楚的是经济学家对社会主义所作的根本性的批评，那就是，社会主义不可能创立任何一种经济学的核算体系，因而在满足人类的需要方面也就缺少衡量这种满意度多寡的任何一种有效的方法。因此，从经济学的角度来看，受到多数人拥护的社会主义体系并没有什么长处。社会主义尚在黑暗中摸索前行，从他们自己的观点来看，也就是从社会主义生产管理者的观点以及其人民的观点来看，社会主义尚无法对社会需求的数量关系进行核算。到目前为止，这种计算能力的缺失还没有给共产主义国家的统治者带来麻烦，因为他们依然可以利用建立在资本主义国家市场机制之上的价格理论。</p>
<p>  ﻿然而，我们指出的社会主义生产方式的那个无可补救的痼疾却依然确凿地存在，也就是说，在一个实行社会主义制度的社会中，任何形式的经济计算都是绝对不可能的。对任何企业和商号的集体管理都会不可避免地导致财务上的失效和服务提供上的贫乏。对经济事务的官僚化管理，其效率低下早已有目共睹。而将工业上的集体管理原则加以无限制扩张的思想甚至让那些心胸最为偏狭的社会主义政治家们也会感到不寒而栗。</p>
</blockquote>
</li>
<li><blockquote>
<p>  ﻿自由主义主张消除一切等级特权，等级社会必须让位于一个全新的社会秩序。在这个新的社会里，只能有平等的国家公民。不但要取消某一个等级的特权地位，而且要消除一切特权等级的存在。自由主义要废除一切等级的樊篱，把人们从他们所属的狭隘的等级制度中解放出来。只有在资本主义社会里，只有在按照自由的基本原则而建立的国家制度中，每个人才有希望成为国家政治建筑的直接参与者，只有在这种社会制度下，个人才能选择和决定他的政治目标和理想。</p>
</blockquote>
</li>
<li><blockquote>
<p>  ﻿阶级斗争的学说是针对自由主义关于在生产资料私有制基础上，所有社会阶层的利益联合起来的学说而提出的，这两种学说尖锐对立。自由主义主张消除等级差别，取消特权，建立一个在法律面前人人平等的法制社会，实现了这些目标之后，就没有任何东西能够阻止所有社会阶层之间的和平与合作了，这是因为，人们在这一过程中同时也正确地认清了他们的利益之所在。</p>
</blockquote>
</li>
<li><blockquote>
<p>  ﻿因此，它们建立了政党机构，力图把每个人都牢牢地束缚在党内，不允许他们有任何脱离该党的想法。这种刻板的制度已在德国和奥地利建立起来，在东欧的一些国家里，这种制度正在形成之中。在上述所有的国家里，个人再也不是国家的公民了，而首先是党员。甚至连少年儿童都被置于党的监护之下。体育运动和社会交际活动也由政党来主办，并且直接为党的政治服务。</p>
<p>  ﻿建立政党自己的军队，是政党组织形式的极端。党的军事组织是按照国家正规军的模式组建的，它们拥有作战动员计划和作战计划，手中掌握着武器并随时准备开战。它们高奏军乐，高举战旗带着队伍招摇过市，向世人宣告着一个没完没了的混乱和战争时代的到来。</p>
</blockquote>
</li>
<li><blockquote>
<p>  启蒙运动哲学认为其最值得珍视的成就就是宽容原则，自由主义主张，一个人持什么样的宗教和哲学观点，政府无权干涉。他们同样急切地要求赋予每个人选择的权利，可以自由地选择如何将自己融入社会协作体系的方式。古典自由主义时代伟大的理想就是自由权，就是每个人为自己的生活制定计划的自由权。而今天社会主义社会中的人们所渴望和争取的则是市场经济“计划”的代用品。按照他们使用这个词的方式，“计划”的意思是指：由他人所制定的计划将规定我应该做什么以及如何做。我要过的生活就如同寄宿学校的学生，军队中的士兵，牢房中的囚犯一样。我观看、听闻、阅读和学习的，都是我的上级认为适合于我的。我将成为一架庞大机器中的一个齿轮，其转动的方向得由当权者来定。只有一种哲学，一种思想体系，一种准宗教可供人们自由地信仰和传播。任何背离这种教条主义信条的行为都会带来灭顶之灾。</p>
</blockquote>
</li>
</ul>
<h3 id="32-苏联的最后一天"><a href="#32-苏联的最后一天" class="headerlink" title="32. 苏联的最后一天"></a>32. 苏联的最后一天</h3><p>12 月 25 日，对于西方世界是一个重要的日子，这一天是圣诞节，同时也是苏联解体值得共同欢庆得日子。从波罗的海民独立、柏林墙倒塌、东欧剧变、匈牙利十月革命、切尔诺贝利事故等等。都是一步一步昭示着社会主义本悲惨的结局。</p>
<p>提到苏联不得不想起了几位从苏联时期逃亡移民到美国的比较牛逼的人物：</p>
<ul>
<li><p>现代计算机体系架构奠基人 <code>约翰·冯·诺伊曼</code>，出生于从匈牙利的布达佩斯，后来移民到美国。</p>
</li>
<li><p>查尔斯·西蒙尼：微软 Office 中 word 的创始人，领导着微软 office 部门一路突飞猛进、匈牙利命名法提出者，也是从匈牙利逃亡移民到美国。他的父母为了帮助他逃离苏联时期统治下的匈牙利被送进了监狱。</p>
</li>
<li><p>Google 创始人，谢尔盖·布林，出生于苏联，在他老爸的带领下逃亡移民到美国。</p>
</li>
<li><p>Intel 的 CEO 安迪·葛洛夫：曾经也是个勇武派，参加过匈牙利的十月事件，和平示威的时候被打断了胳膊。</p>
</li>
<li><blockquote>
<p>  安迪·格鲁夫于1936年出生于匈牙利，和大多数牛人一样，他也是犹太人。在他20岁的时候，也就是1956年，正值热血青年的他，他参于了一场学生请愿，这个事件很著名，在历史上称之为匈牙利十月事件。简单来说就是这些学生以及数十万匈牙利人发起了对政府的抗议，主要是抗议苏联为首的派别，和大部分列宁党的反应一样，政府用子弹回应了这十万匈牙利人，数千人死在了苏联军队的枪口下。匈牙利当局把这次事件定义为严重的反革命事件，随后的日子里，又抓了数千人蹲监狱。当天参加流行的人又是害怕又是绝望，在接下来超过20万匈牙利人偷偷超过边境，到达了周围的非社会主义国家，主要是奥地利，这其中就有20岁的青年安迪·格鲁夫，他在游行时被苏联和匈牙利当局士兵殴打，在逃亡奥地利的时候，胳膊还处于骨折未愈的状态。毕竟伤筋动骨100天，他这个才几天，跑得慢了就进监狱了。<br>  在奥地利当了快一年难民之后，他辗转来到了美国纽约，因为他是难民，还不会说英语，美国政府就给他免费学语言，还提供免费的食物给他吃，他学习很快就成了当时最好的之一，考到了纽约市学院（City College of New York），专业是化学。后来又考到了加州大学伯克利学院（University of California, Berkeley）的博士，专业还是化学。我之所以强调他的化学专业，是因为他NB的起点就是他的化学专业。<br>  此处引用<a href="https://liuyandong.com/2019/12/18/223/#more" target="_blank" rel="noopener">223. Intel公司的诞生(1)</a></p>
</blockquote>
</li>
<li><p>PayPal 创始人质疑的马克斯·列夫琴：乌克兰人，全家到美国去旅游，刚到美国之后苏联就解体了，在美国沦为了难民</p>
</li>
<li>尤金·维格纳：诺奖得主、量子力学的重要奠基人，也是匈牙利人</li>
<li>西奥多·冯·卡门：流体力学、空气动力学理论专家、钱学森的老师，也是从匈牙利逃亡移民到美国的。</li>
<li>乔治·伽莫夫：顶级的物理学家，热大爆炸宇宙学模型的创立者</li>
</ul>
<h4 id="作者-25"><a href="#作者-25" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[爱]康纳·奥克勒里</li>
</ul>
<h4 id="简介-24"><a href="#简介-24" class="headerlink" title="简介"></a>简介</h4><blockquote>
<p>爱尔兰记者奥克莱里是苏联解体的见证者，在本书中，他以1991年12月25日这一天为框架，围绕着戈尔巴乔夫和叶利钦的斗争，将苏联最后六年的政治混乱、经济衰败、人心向背，用细致可靠的描写，表现得清晰而传神。</p>
</blockquote>
<blockquote>
<p>苏联陷入泥潭难以自拔，整个国家的命运和走向，最集中地体现在戈尔巴乔夫和叶利钦两个人身上。每个人都看着他们，“就像狼群等着最强壮的两头狼对峙”，看谁会成为领导者。卑微不是戈尔巴乔夫的脾性，宽宏大量也不是叶利钦的风格。两人从最初的联手合作，到后来的冲突不断，终于变得势同水火，各不相让。最终，戈尔巴乔夫不能很好地判断他的人民，在自我认识上更加糟糕，而叶利钦则在动物般的直觉下，听到了远处历史车轮的轰隆声。</p>
</blockquote>
<h4 id="摘抄-22"><a href="#摘抄-22" class="headerlink" title="摘抄"></a>摘抄</h4><ul>
<li><blockquote>
<p>这是人类史上一个重要的时刻，是千年俄罗斯和苏维埃帝国的终结，也是俄罗斯民族和国家复兴的开端。这一天的到来让美国的保守派提前庆祝哲学家弗朗西斯·福山的预言：苏联的分裂标志着“历史的终结”，而西方自由民主制将作为人类政府的最终形式得到普及。</p>
</blockquote>
</li>
<li><blockquote>
<p>在1991年12月25日，能够与1918年奥匈帝国覆灭或1923年土耳其帝国垮台相提并论的一个历史事件的发生，却没有国外战争或流血革命作为催化剂。共产主义南斯拉夫在烈火中分崩离析，而苏联却在全世界难以置信的目光中几乎无波无澜地解体了。强大的苏维埃军队毫不抵抗就将一个由众多附属共和国组成的帝国拱手让出。这一切发生得太快了。直到1991年初，都没有政治家或学者推测出即将在此年年末发生的历史剧变的规模和波及范围。</p>
</blockquote>
</li>
<li><blockquote>
<p>这一天是一个警醒，提醒他们曾经强大的超级大国的失势被美国当做冷战的胜利来庆祝，而不是当做人们和平推翻一个政权体系从而采纳民主制和自由市场经济制度的胜利来庆祝。前苏联总统参谋长亚历山大·里昂提耶夫在不久后这样描述：“美国人在苏联的葬礼上喝得太多了，以致现在还醒不过来。”</p>
</blockquote>
</li>
<li><blockquote>
<p>但是，成千上万的政治犯在拘留营里日渐憔悴，这是斯大林时期的遗留问题。那时候，没有独立的媒体，没有集会的权利，不能自由移民，没有民主政治，宗教自由受限，并且完全不能容忍大众对高层官员的批判。腐败和酗酒成了一种生活方式。法院听命于党，警察和克勃格可以逮捕任何人而不需要承担法律赔偿。秘密警察杜绝一切未授权的活动，不论是艺术展还是学生讨论组。外国书籍、杂志和电影如带有未经批准的内容将会被取缔。</p>
</blockquote>
</li>
<li><blockquote>
<p>社会需要一些改变。人们越来越意识到这个国家在自由度和生活水平方面被资本主义世界抛在了后面。新一代俄罗斯人变得对审查制度和旅游限制不满。这也是他们转向高层官员中最年轻也最有精力的同志米哈伊尔·戈尔巴乔夫的原因。</p>
</blockquote>
</li>
<li><blockquote>
<p>叶利钦喜欢给达到他高标准的官员送手表以资鼓励。他从手腕上脱下自己的手表送给能够取悦他的人，几分钟后，又从口袋里拿出一块一模一样的手表送给另一个人。有一次，他让他的助手把他的日本精工手表脱下来送给一名建筑工人。他的保镖科尔扎科夫已经学会总是在口袋里揣上备用的手表了。😂 我去苏联版大表哥🤣</p>
</blockquote>
</li>
<li><blockquote>
<p>铁幕”的唯一目的就是防止苏联公民知道外面的世界是什么样子的，因为这可能是他们无法承受的。</p>
</blockquote>
</li>
<li><blockquote>
<p>萨哈罗夫在沃斯特里亚科夫公墓入殓前，超过十万群众参加了在一个泥泞的停车场举行的葬礼集会，集会上最主要的呼声是要求结束苏联共产党的一党专政。驶过的一辆火车上，乘客打开窗户，一边喊叫一边挥手以资鼓励。群众的态度变得更加蔑视权威。对一个依靠控制麻木群众来掌握政权的政党来说，这样的表现是不利的。</p>
</blockquote>
</li>
<li><blockquote>
<p>戈尔巴乔夫坚持改革进程，他鼓励苏联十五个共和国进行各自的民主选举，选取对民众更加负责任的领导人。每个共和国都已经有了自己的议会，但是，投票的结果往往是由共产党领导人安排好的，立法机关也没有多少立法权。</p>
</blockquote>
</li>
</ul>
<h2 id="漫画"><a href="#漫画" class="headerlink" title="漫画"></a>漫画</h2><h3 id="1-《流浪神差》"><a href="#1-《流浪神差》" class="headerlink" title="1.《流浪神差》"></a>1.《流浪神差》</h3><h4 id="作者-26"><a href="#作者-26" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[日]安达渡嘉</li>
</ul>
<h4 id="简介-25"><a href="#简介-25" class="headerlink" title="简介"></a>简介</h4><p>流浪神差又名野良神，是我真正意义上的入宅作。虽然我高中的时候也追过火影，但那时候并不是对二次元有多大的兴趣。那时候还是为火影的热血所吸引吧。高中的时候只知道死读书，没有时间和经历看喜欢的的动画和漫画。而大一的时候，有的是充裕的时间，包括整个大学期间也看了将近 300 部动漫作品。想要知道我看过那些的可以去看看我的番组计划  <a href="https://bgm.tv/anime/list/512178" target="_blank" rel="noopener">木子的番组计划</a> 。大一的时候看完的动画第一季和第二季，眼看着四年过去了，真希望这部作品能接着出第三季和第四季。今年十一月份的时候看的漫画，作者是两位妹子，前两年的时候因为身体原因停更了，去年的时候又开始连载了。</p>
<h3 id="2-《终将成为你》"><a href="#2-《终将成为你》" class="headerlink" title="2.《终将成为你》"></a>2.《终将成为你》</h3><h4 id="作者-27"><a href="#作者-27" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[日]仲谷鳩</li>
</ul>
<h4 id="简介-26"><a href="#简介-26" class="headerlink" title="简介"></a>简介</h4><p>去年的时候看完的动画，今年每个月都等着更新看完了漫画，直到十月份才完结。是一部不错滴百合漫画，嘻嘻，我比较喜欢百合😂，单纯的女生之间超越友情的那份爱。我尊重理解并支持同性恋群体们❤。</p>
<h3 id="3-《-Happy-Sugar-Life-～幸福甜蜜生活～》"><a href="#3-《-Happy-Sugar-Life-～幸福甜蜜生活～》" class="headerlink" title="3.《 Happy Sugar Life ～幸福甜蜜生活～》"></a>3.《 Happy Sugar Life ～幸福甜蜜生活～》</h3><h4 id="作者-28"><a href="#作者-28" class="headerlink" title="作者"></a>作者</h4><ul>
<li>[日]鍵空とみやき</li>
</ul>
<h4 id="简介-27"><a href="#简介-27" class="headerlink" title="简介"></a>简介</h4><p>下班后回来躺床上花了三个小时一口气看完的动画，之后又在 Kindle Oasis 上看完了漫画。十一月三十号下午买的二手 Kindle Oasis 2，最大的动因就是在 Kindle Paperwhite 3 上已经无法满足我看漫画的需求了😂</p>
<h3 id="4-《-citrus-柑橘味香氣-》"><a href="#4-《-citrus-柑橘味香氣-》" class="headerlink" title="4.《 citrus 柑橘味香氣 》"></a>4.《 citrus 柑橘味香氣 》</h3><h4 id="作者-29"><a href="#作者-29" class="headerlink" title="作者"></a>作者</h4><ul>
<li>サブロウタ</li>
</ul>
<h4 id="简介-28"><a href="#简介-28" class="headerlink" title="简介"></a>简介</h4><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h2 id="2020-年阅读计划"><a href="#2020-年阅读计划" class="headerlink" title="2020 年阅读计划"></a>2020 年阅读计划</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><ul>
<li>读懂<code>弗里德利希·奥古斯特·哈耶克</code> 和 <code>汉娜·阿伦特</code></li>
</ul>
<h3 id="阅读计划"><a href="#阅读计划" class="headerlink" title="阅读计划"></a>阅读计划</h3><ul>
<li>《开放社会与敌人》 第二遍</li>
<li>《通往奴役之路》第三遍</li>
<li>《极权主义的起源》第二遍</li>
<li>《 <em>Amusing Ourselves to Death</em> 》</li>
<li>《法律、立法与自由》</li>
<li>《自由宪章》</li>
<li>《致命的自负》</li>
<li>《自由秩序原理》</li>
<li>《科学的反革命》</li>
<li>《个人主义与经济秩序》</li>
<li>《资本主义与自由》</li>
<li>《轴心时代》</li>
<li>《自由与繁荣的过度》</li>
<li>《重申自由主义》</li>
<li>《秩序自由主义》</li>
<li>《宪政经济学》</li>
<li>《知识、自由与秩序》</li>
<li>《大国的崩溃：苏联解体的台前幕后》</li>
<li>《公正：该如何做是好》</li>
</ul>
<p>其中读第二遍或者第三遍的图书准备写几篇博客</p>
<h2 id="关于书籍"><a href="#关于书籍" class="headerlink" title="关于书籍"></a>关于书籍</h2><p>上面的书大部分 kindle 上有，因为我是  <em>Kindle Unlimited</em>  的会员，所以能免费借阅上面的书。有 kindle 的小伙伴推荐去订阅亚马逊的这个  <em>Kindle Unlimited</em>   会员，一年价格才 98块人民币，超值啊😂 支持一下正版嘛。</p>
<p>但有些书不得不看盗版，没办法，因为还在摸着石头过河的国家并没有出版自由和新闻自由，我也很无奈。</p>
<p>另外你会发现，我读过的书绝大多数都是外国作者写的，而且他们绝大多数也都是学术界很有名的经济学家，甚至有些都是诺贝尔经济学奖得主。我觉着这些获得诺奖的经济学家，他们或许都亲身目睹了共产主义运动在欧洲所带来的杀戮，见证了苏联的崛起和陨落，这些经历也让他们清楚地认识到共产主义的邪恶。启迪当下，他们的思想值得我们深读和研究。不像某些只会唱赞歌的人，比如胡某进的《 X领导的强大体制对XX意味着什么 》，写的书里面装的都是一堆屎，一看到书名就想吐的那种。读书最主要的目的是为了思辨，是为了思考，而不是教会我们如何唱赞歌。</p>
<h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><h4 id="读书是为了什么？"><a href="#读书是为了什么？" class="headerlink" title="读书是为了什么？"></a>读书是为了什么？</h4><p>我不会告诉你读书是快乐的，读书能带给你勇气之类的鸡汤话。而且我也讨厌这种觉着多读几本书就高人一等、读书是多么美好的事情这类的自豪感。我并不觉着读书多么快乐，因为我很少抱有这种非理性的期望。读书的过程需要你集中注意力和思考，而思考是费力的，读书的过程远不如你看场电影那么舒服。</p>
<blockquote>
<p><strong>独立之精神，自由之思想</strong>                                     ——陈寅恪</p>
</blockquote>
]]></content>
      <tags>
        <tag>阅读</tag>
        <tag>读书笔记</tag>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title>2019 review</title>
    <url>/archives/2019-review.html</url>
    <content><![CDATA[<h2 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h2><p>之前是么有打算写个总结啥的，但作为博客正式开通的第一年，还是要认真总结一下想法。不过这篇博客也就花了半个多小时才仓促写完，心中的想法如果要写完的话估计要花二三十个小时，今天就简简单单地写一点吧。明天就 2020 年了，作为 90 后的我们这一代也开始奔四了。</p>
<p>离开学校，直到 2019 届大一学生开学时，带着小学弟去杜甫草堂玩儿。买门票的时候才意识到自己已经不再是学生了，无法享受到学生优惠了。离开学校这个牢笼，没有了限制，眼界也比以往大了很多。思考了很多事情，国庆前后写了一篇三万字左右的《毕业后的一点思考》。虽然已经不再是学生，但现在的生活节奏就像学生时代一样。早上八点起床，九点上班，下午五点半下班，回到住的地方看书学习，这种生活节凑几乎和学校一模一样。</p>
<h2 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h2>

<blockquote class="twitter-tweet"><p lang="zh" dir="ltr">2019 年 review：<a href="https://t.co/epBFjZevbQ" target="_blank" rel="noopener">https://t.co/epBFjZevbQ</a><br>- 读了四十一本书<br>- 水了五十篇博客<br>- 写了五十八万字<br>- 看了六百集影视<br><br>感谢辅导员帮给找到第一份工作的机会；<br>感谢我司 955 工作制让我有这么多属于自己的时间；<br>感谢自己尽早退群删号走人，远离毫无意义的群聊扯淡撕逼，把更多的时间和精力留给自己；</p>&mdash; 502.li (@muzi_ii) <a href="https://twitter.com/muzi_ii/status/1211992923216080897?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">December 31, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<h3 id="读完四十一本书"><a href="#读完四十一本书" class="headerlink" title="读完四十一本书"></a>读完四十一本书</h3><h4 id="2019年读书笔记和思考"><a href="#2019年读书笔记和思考" class="headerlink" title="2019年读书笔记和思考"></a><a href="https://blog.502.li/archives/2019-reading-notes.html">2019年读书笔记和思考</a></h4><p>1.《1984》</p>
<p>2.《如果沒有今天，明天会不会有昨天？》</p>
<p>3.《开放社会与敌人》</p>
<p>4.《历史决定论的贫困》</p>
<p>5.《通往奴役之路》</p>
<p>6.《末日时在做什么？有没有空？可以来拯救吗？》</p>
<p>7.《切尔诺贝利的悲鸣》</p>
<p>8.《一百个人的十年》</p>
<p>9.《娱乐至死》</p>
<p>10.《浅薄：互联网如何毒化了我们的大脑》</p>
<p>11.《学会提问：批判性思维指南》</p>
<p>12.《少有人走的路》</p>
<p>13.《上帝笑了99次：哲学悖论里的大思考》</p>
<p>14.《疯狂的投资：跨越大西洋电缆的商业传奇》</p>
<p>15.《乌合之众》</p>
<p>16.《独裁者手册》</p>
<p>17.《肠子的小心思》</p>
<p>18.《民主的奇迹：美国宪法制定的127天》</p>
<p>19.《Kubernetes指南第四版》</p>
<p>20.《程序员的自我修养：链接、装载与库》</p>
<p>21.《程序员的英语》</p>
<p>22.《第二性》</p>
<p>23.《过去与未来之间》</p>
<p>24.《论革命》</p>
<p>25.《极权主义的起源》</p>
<p>26.《童年的消逝》</p>
<p>27.《永久记录》</p>
<p>28.《沃兹传：与苹果一起疯狂》</p>
<p>29.《公正：该如何做是好?》</p>
<p>30.《技术垄断:文化向技术投降》</p>
<p>31.《自由与繁荣的国度》</p>
<p>32.《苏联的最后一天》</p>
<p>33.《流浪神差》</p>
<p>34.《终将成为你》</p>
<p>35.《HappySugarLife～幸福甜蜜生活～》</p>
<p>36.《citrus 柑橘味香氣》</p>
<ul>
<li>以及五本真理部审查的书，在这里就不列出了</li>
</ul>
<h3 id="水了五十篇博客"><a href="#水了五十篇博客" class="headerlink" title="水了五十篇博客"></a>水了五十篇博客</h3><ul>
<li>所有的文章一共 84 篇，其中 34 篇是草(wa)稿(keng)</li>
<li>我的博客 markdown 源码文件在 <a href="https://github.com/muzi502/blog" target="_blank" rel="noopener">muzi502/blog</a></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@Oracle /var/www/hexo/<span class="built_in">source</span> ‹master›</span><br><span class="line">╰─<span class="comment"># find . -name "*.md" | wc</span></span><br><span class="line">     84      84    3217</span><br><span class="line">╭─root@Oracle /var/www/hexo/<span class="built_in">source</span> ‹master›</span><br><span class="line">╰─<span class="comment"># tree</span></span><br><span class="line">.</span><br><span class="line">├── _posts</span><br><span class="line">│   ├── 2018-07-04-python-cnni.md</span><br><span class="line">│   ├── 2018-09-12-justic.md</span><br><span class="line">│   ├── 2018-10-20-kernel-note-book.md</span><br><span class="line">│   ├── 2018-11-20-domain-email.md</span><br><span class="line">│   ├── 2018-12-20-buffon.md</span><br><span class="line">│   ├── 2019-02-14-software-museum.md</span><br><span class="line">│   ├── 2019-03-03-Code-It<span class="_">-s</span>-Trivial.md</span><br><span class="line">│   ├── 2019-03-15-RMS.md</span><br><span class="line">│   ├── 2019-03-20-android-taibackup.md</span><br><span class="line">│   ├── 2019-04-02-play-with-docker.md</span><br><span class="line">│   ├── 2019-04-05-networktools.md</span><br><span class="line">│   ├── 2019-04-12-moto-z-play-AOSIP.md</span><br><span class="line">│   ├── 2019-04-14-privacy-protections.md</span><br><span class="line">│   ├── 2019-04-15-used-devices.md</span><br><span class="line">│   ├── 2019-04-24-android-tasker.md</span><br><span class="line">│   ├── 2019-04-27-android-tools.md</span><br><span class="line">│   ├── 2019-04-29-animal.md</span><br><span class="line">│   ├── 2019-05-02-ops36.md</span><br><span class="line">│   ├── 2019-05-03-oracle-rips-redhat.md</span><br><span class="line">│   ├── 2019-05-13-zabbix-compose.md</span><br><span class="line">│   ├── 2019-05-16-install-k8s-ubuntu18-04.md</span><br><span class="line">│   ├── 2019-05-18-CentOS7-install-k8s.md</span><br><span class="line">│   ├── 2019-05-22-gitlab-install.md</span><br><span class="line">│   ├── 2019-05-25-fuch-rush-app-dir.md</span><br><span class="line">│   ├── 2019-06-18-dashboard.md</span><br><span class="line">│   ├── 2019-06-24-get-someone-info.md</span><br><span class="line">│   ├── 2019-06-30-oh-my-pink.md</span><br><span class="line">│   ├── 2019-07-01-Asking-the-right-questions.md</span><br><span class="line">│   ├── 2019-07-12-amd-yes.md</span><br><span class="line">│   ├── 2019-08-08-centos7-offline-install-docker.md</span><br><span class="line">│   ├── 2019-08-15-How-to-choose-the-right-version-of-kubernetes.md</span><br><span class="line">│   ├── 2019-08-18-mirrors-test.md</span><br><span class="line">│   ├── 2019-08-23-debian-gateway.md</span><br><span class="line">│   ├── 2019-08-28-esxi-vmbase.md</span><br><span class="line">│   ├── 2019-09-20-The-Dictator’s-Handbook.md</span><br><span class="line">│   ├── 2019-09-21-esxi-openwrt.md</span><br><span class="line">│   ├── 2019-09-22-ovf-to-ova.md</span><br><span class="line">│   ├── 2019-09-23-esp8266-pc-switch.md</span><br><span class="line">│   ├── 2019-09-24-reading.md</span><br><span class="line">│   ├── 2019-09-25-docker-deploy-fastdfs.md</span><br><span class="line">│   ├── 2019-09-28-fastdfs-lua-redis.md</span><br><span class="line">│   ├── 2019-09-29-frps-prot-monitor.md</span><br><span class="line">│   ├── 2019-10-08-wndr3700v4-openwrt.md</span><br><span class="line">│   ├── 2019-10-10-ffmepg-rtsp.md</span><br><span class="line">│   ├── 2019-10-13-life-sciences.md</span><br><span class="line">│   ├── 2019-10-14-A-History-of-Protecting-Freedom-Where-Law-and-Technology-Collide.md</span><br><span class="line">│   ├── 2019-10-29-checklist.md</span><br><span class="line">│   ├── 2019-10-30-Internet-related-foundations-and-organizations.md</span><br><span class="line">│   ├── 2019-11-21-blog-typecho-to-hexo.md</span><br><span class="line">│   ├── 2019-11-30-amusing-ourselves-to-death-reading-notes.md</span><br><span class="line">│   ├── 2019-12-01-Kindle-Oasis2-vs-Paperwhite3.md</span><br><span class="line">│   ├── 2019-12-04-kubernetes-QA.md</span><br><span class="line">│   ├── 2019-12-10-Kubernetes-Introduction-for-VMware-Users-zh.md</span><br><span class="line">│   ├── 2019-12-19-dockone-post-index-archives.md</span><br><span class="line">│   ├── 2019-12-27-pc-e5v3-e3v3-amd2600.md</span><br><span class="line">│   ├── 2019-12-30-2019-reading-notes.md</span><br><span class="line">│   └── 2019-12-31-container-linux-os.md</span><br><span class="line">├── about.md</span><br><span class="line">├── avatar.png</span><br><span class="line">├── booklist.md</span><br><span class="line">├── draft</span><br><span class="line">│   ├── 11-frp.md</span><br><span class="line">│   ├── 2019-06-07-k8s.md</span><br><span class="line">│   ├── 2019-06-09-Chernobyl.md</span><br><span class="line">│   ├── 2019-09-30-thinking-in-2019.md</span><br><span class="line">│   ├── 2019-10-50x.md</span><br><span class="line">│   ├── 2019-11-15-govc-cli.md</span><br><span class="line">│   ├── 2019-11-20-the-histort-of-eff.md</span><br><span class="line">│   ├── 2019-12-18-linux-login-alarm-telegram.md</span><br><span class="line">│   ├── 2019-12-20-happy-with-shell.md</span><br><span class="line">│   ├── 2019-12-30-eff-2019-review.md</span><br><span class="line">│   ├── 2020-01-01.md</span><br><span class="line">│   ├── 7-bin.md</span><br><span class="line">│   ├── eff.org</span><br><span class="line">│   │   ├── 1-exhibit.a.md</span><br><span class="line">│   │   ├── 2-exhibit.b.complaint.md</span><br><span class="line">│   │   ├── 2019-11-13-federal-court-rules-suspicionless-searches-travelers-phones-and-laptops.md</span><br><span class="line">│   │   ├── 3-exhibit.d.complaint.md</span><br><span class="line">│   │   ├── eff-final-2018.md</span><br><span class="line">│   │   ├── eff-take-on-cases.md</span><br><span class="line">│   │   ├── eff.moto.md</span><br><span class="line">│   │   └── img</span><br><span class="line">│   │       └── border-act-3.jpg</span><br><span class="line">│   ├── en</span><br><span class="line">│   │   ├── 03-english.md</span><br><span class="line">│   │   ├── 12-en.md</span><br><span class="line">│   │   ├── 1997-1.md</span><br><span class="line">│   │   └── 1997-2.md</span><br><span class="line">│   └── index.html</span><br><span class="line">├── favicon.ico</span><br><span class="line">├── img/</span><br><span class="line">├── link</span><br><span class="line">│   └── index.md</span><br><span class="line">├── robot.txt</span><br><span class="line">└── tags</span><br><span class="line">    └── index.md</span><br><span class="line"></span><br><span class="line">8 directories, 287 files</span><br></pre></td></tr></table></figure>
<ul>
<li>发表的文章五十二篇，其中有两篇是去年的</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">╭─root@Oracle /var/www/hexo/source/_posts ‹master›</span><br><span class="line">╰─# ls | grep 2019 | wc</span><br><span class="line">     52      52    1745</span><br></pre></td></tr></table></figure>
<h3 id="写了五十八万字"><a href="#写了五十八万字" class="headerlink" title="写了五十八万字"></a>写了五十八万字</h3><p>把博客所有的文章全部合并为一个文件，在 VS Code 编辑器里显示的是 130 多万个字符。不过这样统计十分不准确，我只能大致估计为五十多万字，加上自己写的私密日记的话还要多一些。因为从 2019 年元旦开始养成了每周写日记的习惯，刚开始在博客上是对外开放的，后来担心怕被喝茶就搬到了 OneNote 上写，每周都写，就像流水账一样，都写下来。把胡思乱想、碎碎念等全都记录了下来。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─debian@debian /mnt/d/Desktop/hexo/<span class="built_in">source</span>  ‹master*›</span><br><span class="line">╰─$ find . -name <span class="string">"*.md"</span> -<span class="built_in">exec</span> cat &#123;&#125; &gt;&gt; ~/wordcount.md \;</span><br><span class="line">╭─debian@debian /mnt/d/Desktop/hexo/<span class="built_in">source</span>  ‹master*›</span><br><span class="line">╰─$ wc ~/wordcount.md</span><br><span class="line">  41353  198713 2846233 /home/debian/wordcount.md</span><br></pre></td></tr></table></figure>
<h3 id="看了六百集影视"><a href="#看了六百集影视" class="headerlink" title="看了六百集影视"></a>看了六百集影视</h3><p>六百集只是个大致估计，再次感谢我司 955 工作制😂，让我下班后有那么长的时间来看自己喜欢的记录片、电影、科普视频、动漫等。</p>
<h4 id="科普视频"><a href="#科普视频" class="headerlink" title="科普视频"></a>科普视频</h4><h4 id="1-李永乐老师"><a href="#1-李永乐老师" class="headerlink" title="1.李永乐老师"></a>1.李永乐老师</h4><p>李永乐的科普视频几乎每一期我都会追着看完，YouTube 上更新的比较快，我一般都是看 YouTube 上的😂</p>
<p>虽然已经不再是个学生啦，但还是很想学习，很想知道万事万物背后的科学原理，十分推荐李永乐老师的科普视频，不管男女老少都值得看滴。</p>
<h4 id="2-回到-2049"><a href="#2-回到-2049" class="headerlink" title="2.回到 2049"></a>2.回到 2049</h4><p>在 B 站上追的，不过我一般看的都是长篇大于三十分钟的那种。今年看的并不多，大概三十多集吧。</p>
<h4 id="3-妈咪说-Mommy-Talk"><a href="#3-妈咪说-Mommy-Talk" class="headerlink" title="3. 妈咪说 Mommy Talk"></a>3. 妈咪说 Mommy Talk</h4><p>在 YouTube 上追着看的，最近这几期在讲混沌体系，之前看过记录片😂</p>
<h4 id="电影"><a href="#电影" class="headerlink" title="电影"></a>电影</h4><ul>
<li>出租车司机</li>
<li>1987：黎明到来的那一天</li>
<li>华丽的假期</li>
<li>刺杀金正恩</li>
<li>斯大林之死</li>
<li>决战中途岛</li>
<li>绝命毒师</li>
</ul>
<h4 id="记录片"><a href="#记录片" class="headerlink" title="记录片"></a>记录片</h4><ul>
<li>我们的星球</li>
<li>蓝色海洋</li>
<li>混沌：数学探秘</li>
<li>维度：数学漫步</li>
<li>大国崛起</li>
<li>生命起源的奇幻旅程</li>
<li>地球的起源</li>
<li>食物的历史</li>
<li>超级运输</li>
<li>走进工厂：圣诞什锦巧克力</li>
<li>走进工厂：奶酪酱探秘</li>
<li>走进工厂：啤酒的奥秘</li>
<li>走进工厂：鞋厂探秘</li>
<li>走进工厂：土豆华夫饼</li>
<li>走进工厂：披萨工厂</li>
<li>走进工厂：黑加仑的味觉之旅</li>
<li>走进工厂：探秘咖喱酱</li>
<li>走进工厂：卫生卷纸工厂揭秘</li>
<li>走进工厂：鳕鱼条工厂揭秘</li>
<li>走进工厂：饼干工厂揭秘</li>
<li>走进工厂：咖啡工厂揭秘</li>
<li>走进工厂：探秘圣诞工厂</li>
<li>走进工厂：铅笔的前世今生</li>
<li>原油之旅</li>
<li>蓝色星球</li>
<li>海洋</li>
<li>战舰 之 水面下的战争</li>
<li>非洲伟大的文明</li>
<li>圣地 查科峡谷</li>
<li>新视野号冥王星之旅</li>
<li>工程步步高 摩天大楼</li>
<li>惊天工程 之 关西国际机场</li>
<li>伟大工程巡礼</li>
<li>史前公园</li>
<li>海豚湾</li>
<li>凛冬烈火：乌克兰为自由之战</li>
<li>切尔诺贝利</li>
<li>美国工厂</li>
<li>第四公民</li>
<li>汉娜·阿伦特</li>
<li>汉娜•阿伦特与高斯的访谈</li>
</ul>
<h4 id="动漫"><a href="#动漫" class="headerlink" title="动漫"></a>动漫</h4><p>我的<a href="https://bgm.tv/anime/list/512178" target="_blank" rel="noopener">番组计划</a>.三百集只是也约数，实际上会超过这些。作为一个死肥宅来讲，这些并不多。</p>
<ul>
<li>银魂</li>
<li>心理测量者</li>
<li>女子高生的虚度日常</li>
<li>你遭难了吗</li>
<li>青春笨蛋少年不做怀梦美少女的梦</li>
<li>进击的巨人第三季</li>
<li>天行九歌</li>
<li>复活的鲁鲁修</li>
<li>Fate/stay night [Heaven’s Feel] II.lost butterfly</li>
<li>辉夜大小姐想让我告白～天才们的恋爱头脑战～ </li>
<li>家有女友 </li>
<li>五等分的新娘</li>
<li>天使降临到了我身边</li>
<li>我是江小白 第二季 </li>
<li>刀剑神域 Alicization篇 </li>
<li>企鹅公路 </li>
<li>Happy Sugar Life </li>
<li>牵牛花与加濑同学</li>
<li>ReLIFE</li>
<li>龙王的工作！ </li>
<li>紫罗兰永恒花园 </li>
<li>樱Trick </li>
<li>citrus～柑橘味香气～ </li>
<li>3月的狮子</li>
<li>境界的彼方 -I’LL BE HERE- 未来篇</li>
</ul>
]]></content>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>Container Linux OS 从入坑到爬出来😂</title>
    <url>/archives/container-linux-os.html</url>
    <content><![CDATA[<h2 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h2><ul>
<li>2019-12-31 初稿，可能完成不了，等到来年了😂</li>
<li>2020-01-01</li>
</ul>
<h2 id="容器优化型操作系统？"><a href="#容器优化型操作系统？" class="headerlink" title="容器优化型操作系统？"></a>容器优化型操作系统？</h2><h3 id="GKE-的-Container-Optimized-OS"><a href="#GKE-的-Container-Optimized-OS" class="headerlink" title="GKE 的  Container-Optimized OS"></a>GKE 的  <a href="https://cloud.google.com/container-optimized-os/docs/" target="_blank" rel="noopener">Container-Optimized OS</a></h3><p>Google 家的  GKE  中的每个节点都是使用 <a href="https://cloud.google.com/container-optimized-os/docs/" target="_blank" rel="noopener">Container-Optimized OS</a> 来运行工作负载，不过仅仅是针对 GCE 来进行优化的，可能在 OpenStack 或者 vSphere 上运行不起来，(瞎猜😂</p>
<blockquote>
<p>Container-Optimized OS 是适用于 <a href="https://cloud.google.com/compute" target="_blank" rel="noopener">Compute Engine</a> 虚拟机的操作系统映像，专为运行 Docker 容器而优化。借助 Container-Optimized OS，您可以快速、高效、安全地在  Google Cloud Platform 上启动 Docker 容器。Container-Optimized OS 由 Google  维护，基于 <a href="https://www.chromium.org/chromium-os" target="_blank" rel="noopener">Chromium OS</a> 开放源代码项目。</p>
</blockquote>
<h3 id="CoreOS-Container-Linux"><a href="#CoreOS-Container-Linux" class="headerlink" title="CoreOS Container Linux"></a>CoreOS Container Linux</h3><p>个人认为 CoreOS 的 CoreOS Container Linux 要比 Container-Optimized OS 和 Photon OS 要更加专业，尤其是针对容器来讲， CoreOS 就是专门用来运行容器的，它没有像 yum 或 apt 这样的包管理器来安装软件，在 CoreOS 中你不需要安装软件，因为所有的应用程序都要使用 docker 来打包。</p>
<blockquote>
<p>额外提一句，CoreOS 是一个团队，现如今已经被 Red Hat® 收购了，而 Red Hat® 已经被 IBM 收购了，按照关系来讲而 CoreOS 应该是 IBM 的孙子吧🙃。而 CoreOS Container Linux 仅仅是他们维护项目的其中一个，CoreOS 开源的项目还有：</p>
<ul>
<li>etcd：</li>
<li>Clair:</li>
<li>dex：</li>
<li>Prometheus：</li>
<li>flannel：</li>
</ul>
</blockquote>
<p>在 Linux 世界里有大量的发行版可以做为服务器系统使用, 但是这些系统大多部署复杂, 更新系统更是困难重重. 这些都是 CoreOS 试图解决的问题。</p>
<h4 id="特点如下"><a href="#特点如下" class="headerlink" title="特点如下"></a>特点如下</h4><ul>
<li>最小化的操作系统： 占用内存很少，比典型的服务器版本 Linux 少占 40%的内存。</li>
<li>易于升级： CoreOS 采用双系统分区（主动分区/被动分区）设计而不是采用传统的通过升级包来升级系统，这使得每次升级更加快速，可靠和易于回滚。</li>
<li>集成 Docker： CoreOS 默认集成 Docker 并作了很好的支持和优化，省去用户安装，配置，优化 Docker 的时间，极大地方便了用户。</li>
<li>易于集群化： CoreOS 本身提供了大型 Docker 容器集群的整体解决方案，通过内置的 fleet 工具在多台系统中部署容器并进行集群化管理。同时通过提供 Discovery Service，便于动态部署和管理集群，解决方案比较成熟。</li>
<li>自动化的大规模部署： CoreOS 自身提供的解决方案能够自动地大规模批量部署并操作系统，极大地减少用户工作量。</li>
<li>使用 systemd 做为系统服务管理工具，性能比较好，systemd 有现代化的日志功能，同时采用 socket 式与 D-Bus 总线式激活服务.</li>
</ul>
<h3 id="Photon-OS"><a href="#Photon-OS" class="headerlink" title="Photon OS"></a>Photon OS</h3><h4 id="官方宣传册"><a href="#官方宣传册" class="headerlink" title="官方宣传册"></a>官方宣传册</h4><p>PPT 做的不错呦😂</p>
<p><img src="../img/image-20191231163325900.png" alt="image-20191231163325900"></p>
<p><img src="../img/image-20191231163400135.png" alt="image-20191231163400135"></p>
<p>剽窃一段 VMware 官方的<a href="https://vmware.github.io/photon/" target="_blank" rel="noopener">文档</a>介绍：</p>
<blockquote>
<p>Project Photon OS™ is an open source, minimal Linux container host  that is optimized for cloud-native applications, cloud platforms, and  VMware infrastructure. Photon OS 3.0 introduces ARM64 support, installer improvements and updated packages. We invite partners, customers, and  community members to collaborate on using Photon OS to run  high-performance virtual machines and containerized applications.</p>
<ul>
<li><strong>Optimized for VMware vSphere®</strong>: The Linux kernel is tuned for performance when Photon OS runs on vSphere.</li>
<li><strong>Support for containers</strong>: Photon OS includes the Docker daemon and works with container orchestration frameworks, such as Mesos and Kubernetes.</li>
<li><strong>Efficient lifecycle management</strong>: Photon OS is easy to manage, patch, and update.</li>
<li><strong>Security hardened</strong>: The kernel and other aspects of the operating system are built with an emphasis on security.</li>
</ul>
<p>For more information, see the <a href="https://vmware.github.io/photon/assets/files/photon-os-datasheet.pdf" target="_blank" rel="noopener">datasheet</a>.</p>
<p>Track our progress in earning the Linux Foundation’s Core Infrastructure Initiative’s Best Practices Badge. </p>
</blockquote>
<p>可以看出 Photon OS™ 是针对 VMware vSphere® 虚拟化平台进行内核优化的容器专用操作系统，就和 CoreOS 一样。十分适合专门用来运行容器，当作 Kubernetes 集群中的工作负载来使用。</p>
<h3 id="RancherOS"><a href="#RancherOS" class="headerlink" title="RancherOS"></a>RancherOS</h3><p>剽窃一段官方的<a href="https://rancher.com/docs/os/v1.x/en/" target="_blank" rel="noopener">介绍</a>：</p>
<blockquote>
<p>RancherOS is the smallest, easiest way to run Docker in production. Every process in RancherOS is a container managed by Docker. This includes system services such as <code>udev</code> and <code>syslog</code>. Because it only includes the services necessary to run Docker, RancherOS is significantly smaller than most traditional operating systems. By removing unnecessary libraries and services, requirements for security patches and other maintenance are also reduced. This is possible because, with Docker, users typically package all necessary libraries into their containers.</p>
<p>Another way in which RancherOS is designed specifically for running Docker is that it always runs the latest version of Docker. This allows users to take advantage of the latest Docker capabilities and bug fixes.</p>
<p>Like other minimalist Linux distributions, RancherOS boots incredibly quickly. Starting Docker containers is nearly instant, similar to starting any other process. This speed is ideal for organizations adopting microservices and autoscaling.</p>
<p>Docker is an open-source platform designed for developers, system admins, and DevOps. It is used to build, ship, and run containers, using a simple and powerful command line interface (CLI). To get started with Docker, please visit the <a href="https://docs.docker.com/engine/userguide/" target="_blank" rel="noopener">Docker user guide</a>.</p>
</blockquote>
<p>RancherOS 是 Rancher 团队所维护的开源项目，也是对标 CoreOS 一样，专门用来运行容器，并且可以运行在生产环境（至少官方做了这么样的承诺，咱也没在生产用过，不好说。在 RancherOS 中所有的进程（包括系统所有的服务，比如 udev 和 syslog）都是用 docker 来管理，这一点要比 CoreOS 更加激进一些，而 CoreOS 还是使用传统 Linux 发行版中的 systemd 来管理系统中的服务。通过移除传统 Linux 发行版中不必要的服务和库来最小化系统，使他专注单一的功能，即运行 docker 容器。</p>
<blockquote>
<p>Everything in RancherOS is a Docker container. We accomplish this by launching two instances of Docker. One is what we call <strong>System Docker</strong> and is the first process on the system. All other system services, like <code>ntpd</code>, <code>syslog</code>, and <code>console</code>, are running in Docker containers. System Docker replaces traditional init systems like <code>systemd</code> and is used to launch <a href="https://rancher.com/docs/os/v1.x/en/installation/system-services/adding-system-services/" target="_blank" rel="noopener">additional system services</a>.</p>
<p>System Docker runs a special container called <strong>Docker</strong>, which is another Docker daemon responsible for managing all of the user’s containers. Any containers that you launch as a user from the console will run inside this Docker. This creates isolation from the System Docker containers and ensures that normal user commands don’t impact system services.</p>
<p>We created this separation not only for the security benefits, but also to make sure that commands like <code>docker rm -f $(docker ps -qa)</code> don’t delete the entire OS.</p>
</blockquote>
<p><code>Everything in RancherOS is a Docker container.</code> 感觉这个要比 CoreOS 更加容器化，甚至使用 docker 取代了 systemd 来管理系统的各种服务。系统启动后运行两个 docker 服务进程，一个是系统 docker ，在此之上在运行系统服务容器，和用户层面的 docker 。不过看一下下面的这张图你就会明白。总的来讲 RancherOS 是使用 docker 来管理整个系统的服务的，包括用户层面的 docker 。</p>
<p><img src="../img/rancheroshowitworks.png" alt="How it works"></p>
<h2 id="安装体验"><a href="#安装体验" class="headerlink" title="安装体验"></a>安装体验</h2><p>咱的虚拟化平台是 VMware vSphere ，因为硬件服务器大多数都是 Dell 的，而  Dell  是 VMware 母公司，对于我司这种传统企业来讲使用 VMware vSphere 这种用户 UI 友好的虚拟化无疑是最好的选择，哈哈😂。其他虚拟化平台比如 OpenStack 安装步骤会有所不同。</p>
<h3 id="Container-Optimized-OS"><a href="#Container-Optimized-OS" class="headerlink" title="Container-Optimized OS"></a>Container-Optimized OS</h3><p>因为仅仅是针对 GCE 进行优化的系统，传统的虚拟化比如 KVM 、 ESXi 可能用不了。另外还需要拿 <a href="https://www.chromium.org/chromium-os" target="_blank" rel="noopener">Chromium OS</a>  的源码来编译镜像，没有现成的  ISO 或者 OVA 虚拟机模板可用，咱就不折腾了。毕竟硬件资源有限，现场编译一个 <a href="https://www.chromium.org/chromium-os" target="_blank" rel="noopener">Chromium OS</a>  也需要十几个小时😥</p>
<h2 id="Photon-OS-1"><a href="#Photon-OS-1" class="headerlink" title="Photon OS"></a>Photon OS</h2><p>可以现成编译一个 ISO 镜像，也可以使用官方已经编译好的 ISO 镜像或者 OVA 虚拟机模板。不过也支持常见的公有云，比如 Amazon AMI 、Google GCE Image、Azure VHD。甚至还有 Raspberry Pi3 Image 树莓派3😂</p>
<h3 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a><a href="https://vmware.github.io/photon/assets/files/html/3.0/photon_installation/" target="_blank" rel="noopener">官方文档</a></h3><p>官方的安装文档中都给出了各种环境的安装方式，选择自己的环境按照文档一步一步来就行，不过在此注意以下几点。</p>
<h3 id="安装镜像"><a href="#安装镜像" class="headerlink" title="安装镜像"></a>安装镜像</h3><ul>
<li><h4 id="ISO"><a href="#ISO" class="headerlink" title="ISO"></a><a href="https://github.com/vmware/photon/wiki/Downloading-Photon-OS" target="_blank" rel="noopener">ISO</a></h4></li>
</ul>
<p>通用的方案，适用于各种环境，无论是虚拟机还是物理机，由于咱使用的是 VMware vSphere 虚拟化，咱就使用 OVA 格式，因为后者对 vSphere 进行了优化。对于 VMware 用户来讲最好使用 OVA 格式来进行安装。</p>
<ul>
<li><h4 id="OVA"><a href="#OVA" class="headerlink" title="OVA"></a><a href="https://github.com/vmware/photon/wiki/Downloading-Photon-OS" target="_blank" rel="noopener">OVA</a></h4><blockquote>
<p>Pre-installed minimal environment, customized for VMware hypervisor  environments. These customizations include a highly sanitized and  optimized kernel to give improved boot and runtime performance for  containers and Linux applications. Since an OVA is a complete virtual  machine definition, we’ve made available a Photon OS OVA that has  virtual hardware version 11; this will allow for compatibility with  several versions of VMware platforms or allow for the latest and  greatest virtual hardware enhancements.</p>
</blockquote>
</li>
</ul>
<p>根据官方文档所描述的 OVA 虚拟机模板是针对  VMware hypervisor  虚拟化环境进行优化定制的。</p>
<ul>
<li><h5 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h5></li>
<li><p><a href="https://github.com/vmware/photon/wiki/Downloading-Photon-OS" target="_blank" rel="noopener">Amazon Machine Image</a></p>
</li>
<li><a href="https://github.com/vmware/photon/wiki/Downloading-Photon-OS" target="_blank" rel="noopener">Google Compute Engine image</a></li>
<li><a href="https://github.com/vmware/photon/wiki/Downloading-Photon-OS" target="_blank" rel="noopener">Azure VHD</a></li>
<li><a href="https://github.com/vmware/photon/wiki/Downloading-Photon-OS" target="_blank" rel="noopener">Raspberry Pi3</a></li>
</ul>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>下载好 OVA 虚拟机模板后，登录到 ESXi 或者 vCenter 中直接使用 OVA 创建虚拟机模板即可，对于 <code>VMware® Workstation 1x Pro</code>  可以直接将 OVA 导入成为虚拟机来运行。</p>
<h4 id="1-导入-OVA-虚拟机模板"><a href="#1-导入-OVA-虚拟机模板" class="headerlink" title="1. 导入 OVA 虚拟机模板"></a>1. 导入 OVA 虚拟机模板</h4><p><img src="../img/image-20191231105906355.png" alt="image-20191231105906355"></p>
<h4 id="2-添加-OVA-虚拟机模板"><a href="#2-添加-OVA-虚拟机模板" class="headerlink" title="2.添加 OVA 虚拟机模板"></a>2.添加 OVA 虚拟机模板</h4><p><img src="../img/image-20191231110111943.png" alt="image-20191231110111943"></p>
<h4 id="3-选择存储"><a href="#3-选择存储" class="headerlink" title="3. 选择存储"></a>3. 选择存储</h4><p><img src="../img/image-20191231110153113.png" alt="image-20191231110153113"></p>
<h4 id="4-同意许可协议"><a href="#4-同意许可协议" class="headerlink" title="4. 同意许可协议"></a>4. 同意许可协议</h4><p><img src="../img/image-20191231110231422.png" alt="image-20191231110231422"></p>
<h4 id="5-部署选项"><a href="#5-部署选项" class="headerlink" title="5.部署选项"></a>5.部署选项</h4><ul>
<li>选择好网络</li>
<li>磁盘置备的方式：精简就是使用到的时候再对磁盘进行制令。厚置备就是创建虚拟机的时候对磁盘进行置零，性能会好一些。</li>
</ul>
<p><img src="../img/image-20191231110339494.png" alt="image-20191231110339494"></p>
<h4 id="6-即将完成"><a href="#6-即将完成" class="headerlink" title="6. 即将完成"></a>6. 即将完成</h4><p><img src="../img/image-20191231110531238.png" alt="image-20191231110531238"></p>
<h3 id="系统启动"><a href="#系统启动" class="headerlink" title="系统启动"></a>系统启动</h3><p><img src="../img/image-20191231111131193.png" alt="image-20191231111131193"></p>
<p>初始用户名是 <code>root</code> ，密码是 <code>changeme</code> ，输入完密码之后会强制要求你更改密码，在输入一次 <code>changeme</code> 之后输入两次修改的密码即可。</p>
<p>登录到系统之后使用 <code>ip addr</code> 命令查看由默认的 DHCP 获取到的方式来查看 IP，然后编辑 sshd_config 配置文件允许 root 登录。不得不说 ESXi 的 Web 控制台实在是太难用了，还是 ssh 上去使用吧。</p>
<ul>
<li><code>vi /etc/ssh/sshd_config</code> 把 <code>PermitRootLogin</code> 配置项修改为 <code>yes</code> 即可</li>
<li>重启 sshd 服务 <code>systemctl restart sshd</code></li>
</ul>
<h3 id="内核"><a href="#内核" class="headerlink" title="内核"></a>内核</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Linux  4.19.79-1.ph3-esx <span class="comment">#1-photon SMP Tue Oct 22 23:53:27 UTC 2019 x86_64 GNU/Linux</span></span><br><span class="line"></span><br><span class="line">root@photon-machine [ ~ ]<span class="comment"># cat /etc/os-release</span></span><br><span class="line">NAME=<span class="string">"VMware Photon OS"</span></span><br><span class="line">VERSION=<span class="string">"3.0"</span></span><br><span class="line">ID=photon</span><br><span class="line">VERSION_ID=3.0</span><br><span class="line">PRETTY_NAME=<span class="string">"VMware Photon OS/Linux"</span></span><br><span class="line">ANSI_COLOR=<span class="string">"1;34"</span></span><br><span class="line">HOME_URL=<span class="string">"https://vmware.github.io/photon/"</span></span><br><span class="line">BUG_REPORT_URL=<span class="string">"https://github.com/vmware/photon/issues"</span></span><br></pre></td></tr></table></figure>
<p>目前的内核版本是 4.19.79 ，比 CentOS 7 系那种五年前的 3.18 内核高到不知道哪里去了。不过个人认为，对于容器虚拟化这种依赖于内核特性的技术来讲还是要选择高一点的版本比较好。像 CentOS 那种五年前的 3.18 版本，那时候容器所依赖的很多内核特性在这些版本上还不够成熟。从使用来讲，或外的公有云像 GKE 、AKS、AKE 等都是使用的 4.14 内核版本以上。</p>
<p>4.19 版本有个小问题，就是如果 kube-proxy 使用 IPVS 的话，需要开启相应的内核模块，主要依赖的内核模块有以下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br></pre></td></tr></table></figure>
<p>在 4.19 版本之后 nf_conntrack_ipv4 内核模块替换成了 nf_conntrack ，参看 <a href="https://github.com/coreos/bugs/issues/2518" target="_blank" rel="noopener">coreos/bugs#2518</a></p>
<h3 id="资源占用情况"><a href="#资源占用情况" class="headerlink" title="资源占用情况"></a>资源占用情况</h3><h4 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h4><ul>
<li>系统初始化启动之后内存仅仅使用了 45Mi</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@photon-machine [ ~ ]<span class="comment"># free -h</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          2.0Gi        45Mi       1.8Gi       0.0Ki        93Mi       1.8Gi</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>
<ul>
<li>启动 docker 进程之后的占用情况，也仅仅 109Mi</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          2.0Gi       109Mi       1.6Gi       0.0Ki       238Mi       1.8Gi</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>
<h4 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h4><p>使用 OVA 虚拟机模板启动后的虚拟机，磁盘仅仅占用了 515MB ，确实是相当轻量化，这还是包含了 docker。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@photon-machine [ ~ ]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/root        16G  515M   15G   4% /</span><br><span class="line">devtmpfs        998M     0  998M   0% /dev</span><br><span class="line">tmpfs          1000M     0 1000M   0% /dev/shm</span><br><span class="line">tmpfs          1000M  532K  999M   1% /run</span><br><span class="line">tmpfs          1000M     0 1000M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs          1000M     0 1000M   0% /tmp</span><br><span class="line">/dev/sda2        10M  2.2M  7.9M  22% /boot/efi</span><br><span class="line">tmpfs           200M     0  200M   0% /run/user/0</span><br></pre></td></tr></table></figure>
<h4 id="负载"><a href="#负载" class="headerlink" title="负载"></a>负载</h4><p><img src="../img/image-20191231113306435.png" alt="image-20191231113306435"></p>
<h3 id="进程和服务"><a href="#进程和服务" class="headerlink" title="进程和服务"></a>进程和服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">● photon-machine</span><br><span class="line">    State: running</span><br><span class="line">     Jobs: 0 queued</span><br><span class="line">   Failed: 0 units</span><br><span class="line">    Since: Tue 2019-12-31 13:53:18 UTC; 11min ago</span><br><span class="line">   CGroup: /</span><br><span class="line">           ├─user.slice</span><br><span class="line">           │ └─user-0.slice</span><br><span class="line">           │   ├─session-c1.scope</span><br><span class="line">           │   │ ├─363 /bin/login -p --</span><br><span class="line">           │   │ └─396 -bash</span><br><span class="line">           │   ├─session-c2.scope</span><br><span class="line">           │   │ ├─408 sshd: root@pts/0</span><br><span class="line">           │   │ ├─415 -bash</span><br><span class="line">           │   │ └─560 systemctl status</span><br><span class="line">           │   └─user@0.service</span><br><span class="line">           │     └─init.scope</span><br><span class="line">           │       ├─388 /lib/systemd/systemd --user</span><br><span class="line">           │       └─389 (sd-pam)</span><br><span class="line">           ├─init.scope</span><br><span class="line">           │ └─1 /lib/systemd/systemd</span><br><span class="line">           └─system.slice</span><br><span class="line">             ├─systemd-networkd.service</span><br><span class="line">             │ └─255 /lib/systemd/systemd-networkd</span><br><span class="line">             ├─systemd-udevd.service</span><br><span class="line">             │ └─125 /lib/systemd/systemd-udevd</span><br><span class="line">             ├─vgauthd.service</span><br><span class="line">             │ └─197 /usr/bin/VGAuthService -s</span><br><span class="line">             ├─docker.service</span><br><span class="line">             │ ├─430 /usr/bin/dockerd</span><br><span class="line">             │ └─437 docker-containerd --config /var/run/docker/containerd/containerd.toml</span><br><span class="line">             ├─systemd-journald.service</span><br><span class="line">             │ └─100 /lib/systemd/systemd-journald</span><br><span class="line">             ├─sshd.service</span><br><span class="line">             │ └─361 /usr/sbin/sshd -D</span><br><span class="line">             ├─vmtoolsd.service</span><br><span class="line">             │ └─94 /usr/bin/vmtoolsd</span><br><span class="line">             ├─systemd-resolved.service</span><br><span class="line">             │ └─257 /lib/systemd/systemd-resolved</span><br><span class="line">             ├─dbus.service</span><br><span class="line">             │ └─198 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only</span><br><span class="line">             ├─systemd-timesyncd.service</span><br><span class="line">             │ └─167 /lib/systemd/systemd-timesyncd</span><br><span class="line">             └─systemd-logind.service</span><br><span class="line">               └─195 /lib/systemd/systemd-logind</span><br></pre></td></tr></table></figure>
<h3 id="包管理工具"><a href="#包管理工具" class="headerlink" title="包管理工具"></a>包管理工具</h3><p>Photon OS 默认的包管理工具是 tdnf ，不过也支持 yum ，两者使用方式有细微的差别，使用的也是相同的软件包源，而且对于国内用户来讲，软件包源在国外服务器上（<a href="https://dl.bintray.com/vmware/），速度感人，肉眼可见" target="_blank" rel="noopener">https://dl.bintray.com/vmware/），速度感人，肉眼可见</a> KB/s 级别的速度。你懂的，操他奶奶的 GFW，尼玛死了😡，搞网络封锁耽误这人搬砖。安装速度慢得一批，单单下载 50 MB 的软件包就下不下来，不得不用上我那台透明代理的旁路网关。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@photon-OS [ ~ ]<span class="comment"># tdnf upgrade</span></span><br><span class="line"></span><br><span class="line">Installing:</span><br><span class="line">runc                x86_64  1.0.0.rc9-1.ph3   photon-updates     10.24M 10736757</span><br><span class="line">containerd          x86_64  1.2.10-1.ph3      photon-updates     76.25M 79950751</span><br><span class="line">docker-engine       x86_64  18.09.9-1.ph3     photon-updates     91.29M 95721322</span><br><span class="line">docker-cli          x86_64  18.09.9-1.ph3     photon-updates     72.76M 76299393</span><br><span class="line"></span><br><span class="line">Total installed size: 250.54M 262708223</span><br><span class="line"></span><br><span class="line">Upgrading:</span><br><span class="line">sqlite-libs         x86_64  3.27.2-6.ph3      photon-updates      1.08M 1129424</span><br><span class="line">python3-setuptools  noarch  3.7.5-1.ph3       photon-updates      1.61M 1692186</span><br><span class="line">python3-xml         x86_64  3.7.5-1.ph3       photon-updates    333.69k 341698</span><br><span class="line">python3-libs        x86_64  3.7.5-1.ph3       photon-updates     22.88M 23990697</span><br><span class="line">python3             x86_64  3.7.5-1.ph3       photon-updates      2.90M 3044206</span><br><span class="line">openssl             x86_64  1.0.2t-2.ph3      photon-updates      4.53M 4750710</span><br><span class="line">openssh-server      x86_64  7.8p1-6.ph3       photon-updates    904.54k 926254</span><br><span class="line">openssh-clients     x86_64  7.8p1-6.ph3       photon-updates      3.65M 3831266</span><br><span class="line">openssh             x86_64  7.8p1-6.ph3       photon-updates        0.00b 0</span><br><span class="line">linux-esx           x86_64  4.19.87-1.ph3     photon-updates     12.67M 13284780</span><br><span class="line">libarchive          x86_64  3.3.3-4.ph3       photon-updates    804.34k 823648</span><br><span class="line">e2fsprogs-libs      x86_64  1.44.3-4.ph3      photon-updates     74.62k 76416</span><br><span class="line">e2fsprogs           x86_64  1.44.3-4.ph3      photon-updates      1.88M 1972142</span><br><span class="line">docker              x86_64  18.09.9-1.ph3     photon-updates        0.00b 0</span><br><span class="line">dhcp-libs           x86_64  4.3.5-7.ph3       photon-updates    264.25k 270588</span><br><span class="line">dhcp-client         x86_64  4.3.5-7.ph3       photon-updates      2.52M 2642853</span><br><span class="line"></span><br><span class="line">Total installed size:  56.05M 58776868</span><br><span class="line">Is this ok [y/N]:y</span><br><span class="line"></span><br><span class="line">Downloading:</span><br><span class="line">docker-engine                           302192      1%</span><br><span class="line"></span><br><span class="line">docker-engine                           515184      2%</span><br><span class="line">docker-engine                           523376      2%</span><br><span class="line">docker-engine                          4234352     15%</span><br><span class="line">docker-engine                         23477360     84%</span><br><span class="line"></span><br><span class="line">docker-engine                         23477360     84%</span><br></pre></td></tr></table></figure>
<ul>
<li>56.05M / 58776868B 大小的文件，下载了一上午都没搞完……气的我想掀桌子、砸键盘、摔鼠标😑</li>
</ul>
<p>不过可以根据官方的编译文档，把整个软件包源编译出来 ，放在本地使用，然后添加本的 yum 源码即可。</p>
<h3 id="docker-容器引擎"><a href="#docker-容器引擎" class="headerlink" title="docker 容器引擎"></a>docker 容器引擎</h3><figure class="highlight"><table><tr><td class="code"><pre><span class="line">root@photon-machine [ ~ ]# docker info</span><br><span class="line">Containers: 0</span><br><span class="line"> Running: 0</span><br><span class="line"> Paused: 0</span><br><span class="line"> Stopped: 0</span><br><span class="line">Images: 0</span><br><span class="line">Server Version: 18.06.2-ce</span><br><span class="line">Storage Driver: overlay2</span><br><span class="line"> Backing Filesystem: extfs</span><br><span class="line"> Supports d_type: true</span><br><span class="line"> Native Overlay Diff: true</span><br><span class="line">Logging Driver: json-file</span><br><span class="line">Cgroup Driver: cgroupfs</span><br><span class="line">Plugins:</span><br><span class="line"> Volume: local</span><br><span class="line"> Network: bridge host macvlan null overlay</span><br><span class="line"> Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog</span><br><span class="line">Swarm: inactive</span><br><span class="line">Runtimes: runc</span><br><span class="line">Default Runtime: runc</span><br><span class="line">Init Binary: docker-init</span><br><span class="line">containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e</span><br><span class="line">runc version: a592beb5bc4c4092b1b1bac971afed27687340c5 (expected: 69663f0bd4b60df09991c08812a60108003fa340)</span><br><span class="line">init version: fec3683</span><br><span class="line">Security Options:</span><br><span class="line"> apparmor</span><br><span class="line"> seccomp</span><br><span class="line">  Profile: default</span><br><span class="line">Kernel Version: 4.19.79-1.ph3-esx</span><br><span class="line">Operating System: VMware Photon OS/Linux</span><br><span class="line">OSType: linux</span><br><span class="line">Architecture: x86_64</span><br><span class="line">CPUs: 1</span><br><span class="line">Total Memory: 1.951GiB</span><br><span class="line">Name: photon-machine</span><br><span class="line">ID: N53E:2APV:XYZX:QFPE:GGZU:7567:XBFB:M4VQ:F5HZ:XPRK:W33H:QYMI</span><br><span class="line">Docker Root Dir: /var/lib/docker</span><br><span class="line">Debug Mode (client): false</span><br><span class="line">Debug Mode (server): false</span><br><span class="line">Registry: https://index.docker.io/v1/</span><br><span class="line">Labels:</span><br><span class="line">Experimental: false</span><br><span class="line">Insecure Registries:</span><br><span class="line"> 127.0.0.0/8</span><br><span class="line">Live Restore Enabled: false</span><br></pre></td></tr></table></figure>
<h3 id="使用体验"><a href="#使用体验" class="headerlink" title="使用体验"></a>使用体验</h3><p>总体来讲，除了安装软件速度极慢之外，使用起来和普通的 Linux 发行版无多大差别，系统资源占用比传统的 Linux 发行版要低的多。即便是运行了 docker 进程后系统内存也仅仅占用 100 Mb 左右，而磁盘占用才 500MB 算是比较轻量化的。至于性能方面，目前我还是找不到可以测试对比的方案。</p>
<p>较传统的 Linux 发行版，精简了大量不必要的服务和软件，甚至连 tar 命令都没有……。如果把它当作 kubenetes 工作负载 Node 节点来使用，需要注意的是，kube-proxy 依赖的一些工具并没有安装上。我使用 kubeadm 将该节点加入到集群当中的时候就提示缺少以下几个工具： <code>ipset socat ethtool ebtables</code> ，这些对于 IPVS 都是需要的。最好使用 tdnf 一并安装上，并且开启相应的 IPVS 内核模块。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tdnf install ipset socat ethtool ebtables tar -y </span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack</span><br></pre></td></tr></table></figure>
<p>虽然经过了 3 个版本的更新迭代，但 Photon OS 用于生产环境还需要进行稳定性测试，它不如 CoreOS 那样已经在大规模集群中得到的实践，目前用 Photon OS 的企业我目前还未见到过。而 CoreOS </p>
<blockquote>
<p>“作为 Linux 以及开源软件的支持者，我们相信与 CoreOS  这样的开源社区创新先锋合作是非常重要的。我们希望通过这样的合作来为云平台用户带来更多、更灵活的选择。” 微软 Azure 的首席技术官 Mark Russinovich 提到， “CoreOS Linux  与高性能、大规模的微软云相结合，无疑将会促进各种应用服务的创新、以及全球团队的协作。”</p>
</blockquote>
<blockquote>
<p>“我们已经在上千台物理机上成功部署并运行了 CoreOS  Linux。无论从操作系统的安装、升级，还是从容器的管理和应用部署上，她给我们带来了前所未有的体验！对于光音网络这种飞速发展的互联网公司来说，CoreOS 为我们平台的建设提供了有力的技术保障！在使用 CoreOS 的这两年中，我们不再去担心操作系统、Docker 以及 Kubernetes  的兼容性、版本升级以及稳定性，这使得我们可以更专注于应用、业务层上的管理和研发。”  光音网络技术负责人王鹏说，“我们的平台不仅可以跑在自己的物理机上，而且还可以轻松地部署到 AWS 及阿里云上，CoreOS  在这方面功不可没。我们现在很高兴地得知 CoreOS 将强势登陆中国市场，我们对于更好的技术支持和服务无比期待！”</p>
<p>此处引用 CoreOS <a href="https://coreos.com/blog/coreos-linux-available-in-china.html" target="_blank" rel="noopener">官网博客</a></p>
</blockquote>
<p>CoreOS 的稳定性以及生产实践已经相当成熟了，那么接下来就介绍 CoreOS 的使用体验。</p>
<h2 id="CoreOS-Container-Linux-1"><a href="#CoreOS-Container-Linux-1" class="headerlink" title="CoreOS Container Linux"></a>CoreOS Container Linux</h2><p>CoreOS 使用用来创建一套大规模的集群环境，单独使用的意义并不大。而且对于我司的 VMware vSphere 并没有进行优化。所以就按照裸金属部署的方式来安装体验。</p>
<h3 id="官方文档-1"><a href="#官方文档-1" class="headerlink" title="官方文档"></a><a href="http://coreos.com/os/docs/latest/" target="_blank" rel="noopener">官方文档</a></h3><h4 id="Cloud-Providers"><a href="#Cloud-Providers" class="headerlink" title="Cloud Providers"></a>Cloud Providers</h4><p>适用于公有云</p>
<ul>
<li><a href="http://coreos.com/os/docs/latest/booting-on-ec2.html" target="_blank" rel="noopener">Amazon EC2</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-on-digitalocean.html" target="_blank" rel="noopener">DigitalOcean</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-on-google-compute-engine.html" target="_blank" rel="noopener">Google Compute Engine</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-on-azure.html" target="_blank" rel="noopener">Microsoft Azure</a><a href="http://coreos.com/os/docs/latest/booting-with-qemu.html" target="_blank" rel="noopener">QEMU</a></li>
</ul>
<h4 id="Bare-Metal"><a href="#Bare-Metal" class="headerlink" title="Bare Metal"></a>Bare Metal</h4><p>适用于物理机</p>
<ul>
<li><a href="http://coreos.com/matchbox/" target="_blank" rel="noopener">Using Matchbox</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-with-ipxe.html" target="_blank" rel="noopener">Booting with iPXE</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-with-pxe.html" target="_blank" rel="noopener">Booting with PXE</a></li>
<li><a href="http://coreos.com/os/docs/latest/installing-to-disk.html" target="_blank" rel="noopener">Installing to Disk</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-with-iso.html" target="_blank" rel="noopener">Booting from ISO</a></li>
<li><a href="http://coreos.com/os/docs/latest/root-filesystem-placement.html" target="_blank" rel="noopener">Root filesystem placement</a></li>
</ul>
<h4 id="Community-Platforms"><a href="#Community-Platforms" class="headerlink" title="Community Platforms"></a>Community Platforms</h4><p>社区提供支持的</p>
<p>These <a href="http://coreos.com/os/docs/latest/community-platforms.html" target="_blank" rel="noopener">platforms and providers</a> offer support and documentation for running Container Linux.</p>
<ul>
<li><a href="http://coreos.com/os/docs/latest/booting-on-cloudstack.html" target="_blank" rel="noopener">CloudStack</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-on-eucalyptus.html" target="_blank" rel="noopener">Eucalyptus</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-with-libvirt.html" target="_blank" rel="noopener">libvirt</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-on-openstack.html" target="_blank" rel="noopener">OpenStack</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-on-vagrant.html" target="_blank" rel="noopener">Vagrant</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-on-virtualbox.html" target="_blank" rel="noopener">VirtualBox</a></li>
<li><a href="http://coreos.com/os/docs/latest/booting-on-vmware.html" target="_blank" rel="noopener">VMware</a></li>
</ul>
<h3 id="安装镜像-OVA"><a href="#安装镜像-OVA" class="headerlink" title="安装镜像 OVA"></a>安装镜像 <a href="https://stable.release.core-os.net/amd64-usr/current/coreos_production_vmware_ova.ova" target="_blank" rel="noopener">OVA</a></h3><p>下载下来 OVA 虚拟机模板 <a href="https://stable.release.core-os.net/amd64-usr/current/coreos_production_vmware_ova.ova" target="_blank" rel="noopener">OVA</a></p>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p>和 Photon OS 安装步骤一样，在 ESXi 上导入 OVA 虚拟机模板即可，不过需要在最后一步配置好 OS ，包括主机名、配置文件数配置文件 url、加密的配置文件等等，根据自身需求配好即可。可以参照官方<a href="https://coreos.com/os/docs/latest/clc-examples.html" target="_blank" rel="noopener">配置文件的文档</a> 。这一步是必须要做的，不然没有 ssh 公钥和密码你是无法登录到系统中的。</p>
<p>注意，官方给了两种配置文件合适，一个是 yaml 一个是 json ，不过在这里要使用</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"ignition"</span>: &#123;</span><br><span class="line">    <span class="attr">"config"</span>: &#123;&#125;,</span><br><span class="line">    <span class="attr">"timeouts"</span>: &#123;&#125;,</span><br><span class="line">    <span class="attr">"version"</span>: <span class="string">"2.1.0"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"networkd"</span>: &#123;&#125;,</span><br><span class="line">  <span class="attr">"passwd"</span>: &#123;</span><br><span class="line">    <span class="attr">"users"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"core"</span>,</span><br><span class="line">        <span class="attr">"passwordHash"</span>: <span class="string">"$6$43y3tkl..."</span>,</span><br><span class="line">        <span class="attr">"sshAuthorizedKeys"</span>: [</span><br><span class="line">          <span class="string">"key1"</span></span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"storage"</span>: &#123;&#125;,</span><br><span class="line">  <span class="attr">"systemd"</span>: &#123;&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>password_hash</code> 可以通过 openssl 命令来生成，把生成的一整串内容填写到上面，包括后面那个点<code>.</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─@debian ~</span><br><span class="line">╰─$ openssl passwd -1                                                                         </span><br><span class="line">Password:</span><br><span class="line">Verifying - Password:</span><br><span class="line"><span class="variable">$1</span><span class="variable">$nCzW8953</span><span class="variable">$un</span>/JUMJDE2588l7Y6KkP.</span><br></pre></td></tr></table></figure>
<ul>
<li><code>ssh_authorized_keys</code> 通过 ssh-keygen 生成，生成的公钥填写在上面。</li>
</ul>
<p>配置完成之后就把整个内容复制粘贴到第二个框框 <code>CoreOS config data</code> 里</p>
<h4 id="其他设置"><a href="#其他设置" class="headerlink" title="其他设置"></a>其他设置</h4><p><img src="../img/image-20191231125441199.png" alt="image-20191231125441199"></p>
<h3 id="系统启动-1"><a href="#系统启动-1" class="headerlink" title="系统启动"></a>系统启动</h3><p>可能是 coreos config 配置文件没有配好，而导致启动后输入设置的密码提示错误😥，僵硬，只能通过修改 grub 启动参数来跳过了。</p>
<ul>
<li>1.打开 CoreOS 虚拟机电源，并打开控制台。</li>
<li>2.当 Boot Loader 提示出现的时候，按下 e 键来编辑 GRUB 菜单。选择第一个 coreos default 编辑。</li>
<li>3.添加 <code>coreos.autologin</code> 作为启动参数，并 Ctrl-x 或 F10 重启。这将使控制台跳过登录提示并直接进入用户 core 的 shell。</li>
<li><img src="../img/image-20191231133509428.png" alt="image-20191231133509428"></li>
<li>启动进入系统之后输入 <code>sudo passwd</code> 来修改 root 密码。然后切换到 root 用户下 <code>passwd core</code> 修改 core 这个用户的密码。修改之后就可以通过 ssh 登录啦😂，比 Photon OS 要折腾一番呀。不过啊，使用 OVA 部署最好结合 could-init 来设置虚拟机的 ssh 密钥，网络，主机名等参数。</li>
</ul>
<h3 id="资源占用情况-1"><a href="#资源占用情况-1" class="headerlink" title="资源占用情况"></a>资源占用情况</h3><h5 id="内存-1"><a href="#内存-1" class="headerlink" title="内存"></a>内存</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">core@localhost ~ $ free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          961Mi       177Mi       398Mi       199Mi       385Mi       445Mi</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>
<h4 id="磁盘-1"><a href="#磁盘-1" class="headerlink" title="磁盘"></a>磁盘</h4><p>CoreOS 的磁盘分区和 Photon OS 略有不同</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">core@localhost ~ $ df -h</span><br><span class="line">Filesystem       Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs         460M     0  460M   0% /dev</span><br><span class="line">tmpfs            481M     0  481M   0% /dev/shm</span><br><span class="line">tmpfs            481M  484K  481M   1% /run</span><br><span class="line">tmpfs            481M     0  481M   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda9        6.0G   60M  5.6G   2% /</span><br><span class="line">/dev/mapper/usr  985M  854M   80M  92% /usr</span><br><span class="line">none             481M  200M  282M  42% /run/torcx/unpack</span><br><span class="line">tmpfs            481M     0  481M   0% /media</span><br><span class="line">tmpfs            481M     0  481M   0% /tmp</span><br><span class="line">/dev/sda6        108M  7.9M   92M   8% /usr/share/oem</span><br><span class="line">/dev/sda1        127M   54M   73M  43% /boot</span><br><span class="line">tmpfs             97M     0   97M   0% /run/user/500</span><br></pre></td></tr></table></figure>
<h3 id="内核以及发行版信息"><a href="#内核以及发行版信息" class="headerlink" title="内核以及发行版信息"></a>内核以及发行版信息</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Linux localhost 4.19.86-coreos <span class="comment">#1 SMP Mon Dec 2 20:13:38 -00 2019 x86_64 Intel(R) Core(TM) i5-4590 CPU @ 3.30GHz GenuineIntel GNU/Linux</span></span><br><span class="line"></span><br><span class="line">core@localhost ~ $ cat /etc/os-release</span><br><span class="line">NAME=<span class="string">"Container Linux by CoreOS"</span></span><br><span class="line">ID=coreos</span><br><span class="line">VERSION=2303.3.0</span><br><span class="line">VERSION_ID=2303.3.0</span><br><span class="line">BUILD_ID=2019-12-02-2049</span><br><span class="line">PRETTY_NAME=<span class="string">"Container Linux by CoreOS 2303.3.0 (Rhyolite)"</span></span><br><span class="line">ANSI_COLOR=<span class="string">"38;5;75"</span></span><br><span class="line">HOME_URL=<span class="string">"https://coreos.com/"</span></span><br><span class="line">BUG_REPORT_URL=<span class="string">"https://issues.coreos.com"</span></span><br><span class="line">COREOS_BOARD=<span class="string">"amd64-usr"</span></span><br></pre></td></tr></table></figure>
<h3 id="docker-容器引擎-1"><a href="#docker-容器引擎-1" class="headerlink" title="docker 容器引擎"></a>docker 容器引擎</h3><figure class="highlight"><table><tr><td class="code"><pre><span class="line">core@localhost ~ $ docker info</span><br><span class="line">Containers: 0</span><br><span class="line"> Running: 0</span><br><span class="line"> Paused: 0</span><br><span class="line"> Stopped: 0</span><br><span class="line">Images: 0</span><br><span class="line">Server Version: 18.06.3-ce</span><br><span class="line">Storage Driver: overlay2</span><br><span class="line"> Backing Filesystem: extfs</span><br><span class="line"> Supports d_type: true</span><br><span class="line"> Native Overlay Diff: true</span><br><span class="line">Logging Driver: json-file</span><br><span class="line">Cgroup Driver: cgroupfs</span><br><span class="line">Plugins:</span><br><span class="line"> Volume: local</span><br><span class="line"> Network: bridge host macvlan null overlay</span><br><span class="line"> Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog</span><br><span class="line">Swarm: inactive</span><br><span class="line">Runtimes: runc</span><br><span class="line">Default Runtime: runc</span><br><span class="line">Init Binary: docker-init</span><br><span class="line">containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e</span><br><span class="line">runc version: a592beb5bc4c4092b1b1bac971afed27687340c5</span><br><span class="line">init version: fec3683b971d9c3ef73f284f176672c44b448662</span><br><span class="line">Security Options:</span><br><span class="line"> seccomp</span><br><span class="line">  Profile: default</span><br><span class="line"> selinux</span><br><span class="line">Kernel Version: 4.19.86-coreos</span><br><span class="line">Operating System: Container Linux by CoreOS 2303.3.0 (Rhyolite)</span><br><span class="line">OSType: linux</span><br><span class="line">Architecture: x86_64</span><br><span class="line">CPUs: 2</span><br><span class="line">Total Memory: 961.7MiB</span><br><span class="line">Name: localhost</span><br><span class="line">ID: VUKA:LDLW:WECP:IZKO:A6ED:IKIN:6C3V:VRIL:S4ND:SCII:66EH:GDYP</span><br><span class="line">Docker Root Dir: /var/lib/docker</span><br><span class="line">Debug Mode (client): false</span><br><span class="line">Debug Mode (server): false</span><br><span class="line">Registry: https://index.docker.io/v1/</span><br><span class="line">Labels:</span><br><span class="line">Experimental: false</span><br><span class="line">Insecure Registries:</span><br><span class="line"> 127.0.0.0/8</span><br><span class="line">Live Restore Enabled: false</span><br></pre></td></tr></table></figure>
<h3 id="负载-1"><a href="#负载-1" class="headerlink" title="负载"></a>负载</h3><p><img src="../img/image-20191231135348120.png" alt="image-20191231135348120"></p>
<h3 id="进程和服务-1"><a href="#进程和服务-1" class="headerlink" title="进程和服务"></a>进程和服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">● localhost</span><br><span class="line">    State: running</span><br><span class="line">     Jobs: 0 queued</span><br><span class="line">   Failed: 0 units</span><br><span class="line">    Since: Tue 2019-12-31 13:38:05 UTC; 7h left</span><br><span class="line">   CGroup: /</span><br><span class="line">           ├─user.slice</span><br><span class="line">           │ └─user-500.slice</span><br><span class="line">           │   ├─user@500.service</span><br><span class="line">           │   │ └─init.scope</span><br><span class="line">           │   │   ├─725 /usr/lib/systemd/systemd --user</span><br><span class="line">           │   │   └─726 (sd-pam)</span><br><span class="line">           │   ├─session-2.scope</span><br><span class="line">           │   │ ├─768 sshd: core [priv]</span><br><span class="line">           │   │ ├─781 sshd: core@pts/0</span><br><span class="line">           │   │ ├─782 -bash</span><br><span class="line">           │   │ └─978 systemctl status</span><br><span class="line">           │   └─session-1.scope</span><br><span class="line">           │     ├─713 /bin/login -f</span><br><span class="line">           │     ├─731 -bash</span><br><span class="line">           │     ├─762 su</span><br><span class="line">           │     ├─763 bash</span><br><span class="line">           │     ├─770 su core</span><br><span class="line">           │     ├─771 bash</span><br><span class="line">           │     ├─775 su</span><br><span class="line">           │     └─776 bash</span><br><span class="line">           ├─init.scope</span><br><span class="line">           │ └─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 16</span><br><span class="line">           └─system.slice</span><br><span class="line">             ├─locksmithd.service</span><br><span class="line">             │ └─718 /usr/lib/locksmith/locksmithd</span><br><span class="line">             ├─containerd.service</span><br><span class="line">             │ └─800 /run/torcx/bin/containerd --config /run/torcx/unpack/docker/usr/share/containerd/config.toml</span><br><span class="line">             ├─systemd-networkd.service</span><br><span class="line">             │ └─584 /usr/lib/systemd/systemd-networkd</span><br><span class="line">             ├─systemd-udevd.service</span><br><span class="line">             │ └─583 /usr/lib/systemd/systemd-udevd</span><br><span class="line">             ├─docker.service</span><br><span class="line">             │ └─802 /run/torcx/bin/dockerd --host=fd:// --containerd=/var/run/docker/libcontainerd/docker-containerd.sock --selinux-enabled=<span class="literal">true</span></span><br><span class="line">             ├─update-engine.service</span><br><span class="line">             │ └─663 /usr/sbin/update_engine -foreground -logtostderr</span><br><span class="line">             ├─systemd-journald.service</span><br><span class="line">             │ └─553 /usr/lib/systemd/systemd-journald</span><br><span class="line">             ├─systemd-resolved.service</span><br><span class="line">             │ └─635 /usr/lib/systemd/systemd-resolved</span><br><span class="line">             ├─dbus.service</span><br><span class="line">             │ └─674 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation</span><br><span class="line">             ├─systemd-timesyncd.service</span><br><span class="line">             │ └─634 /usr/lib/systemd/systemd-timesyncd</span><br><span class="line">             └─systemd-logind.service</span><br><span class="line">               └─672 /usr/lib/systemd/systemd-logind</span><br></pre></td></tr></table></figure>
<h3 id="包管理工具-1"><a href="#包管理工具-1" class="headerlink" title="包管理工具"></a>包管理工具</h3><p><strong>没得😂</strong>，你没看错，确实如此，在 CoreOS 上没有你可以用的包管理器，不像 PhotonOS 那样有个 tdnf/yum 让你爽一把😂。在 CoreOS 一切皆容器。可以看一下 <code>stackexchange.com</code> 这个答案😂：</p>
<blockquote>
<p>To do this on a CoreOS box, following the hints from the <a href="https://coreos.com/os/docs/latest/install-debugging-tools.html" target="_blank" rel="noopener">guide here</a>:</p>
<ol>
<li>Boot up the CoreOS box and connect as the <code>core</code> user</li>
<li>Run the <code>/bin/toolbox</code> command to enter the stock Fedora container.</li>
<li>Install any software you need. To install nano in this case, it would be as simple as doing a <code>dnf -y install nano</code> (dnf has replaced yum)</li>
<li>Use nano to edit files. “But wait – I’m in a container!” Don’t worry – the host’s file system is mounted at <code>/media/root</code> when inside the container. So just save a sample text file at <code>/media/root/home/core/test.txt</code>, then <code>exit</code> the container, and finally go list the files in <code>/home/core</code>. Notice your test.txt file?</li>
</ol>
<p>If any part of this is too cryptic or confusing, please ask follow up questions. :-)</p>
</blockquote>
<p>官方推荐使用 <a href="https://github.com/coreos" target="_blank" rel="noopener">coreos</a>/<strong><a href="https://github.com/coreos/toolbox" target="_blank" rel="noopener">toolbox</a></strong> 来安装所需要的软件，这个工具以后再详细讲解一下吧。</p>
<h3 id="使用体验-1"><a href="#使用体验-1" class="headerlink" title="使用体验"></a>使用体验</h3><p>安装过程要出于安全考虑比 Photon OS 多于个步骤来登录到系统，目前我还没有找到启动的时候添加 ssh 密钥的办法。总的来讲，再 CoreOS 里一切皆容器运行所需要的服务，这种里面要先进的多。下面的 RancherOS 更是将一切皆容器贯彻到底，甚至将 systemd 取代掉，使用 docker 来管理系统服务。</p>
<h2 id="RancherOS-1"><a href="#RancherOS-1" class="headerlink" title="RancherOS"></a>RancherOS</h2><p>目前 RancherOS 的版本是 v1.5.5</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Linux 4.14.138</span><br><span class="line">Buildroot: 2018.02.11</span><br><span class="line">Docker docker-19.03.5 by default</span><br><span class="line">RPi64: Linux 4.14.114</span><br><span class="line">Console:</span><br><span class="line">Alpine: 3.10</span><br><span class="line">CentOS: 7.7.1908</span><br><span class="line">Debian: stretch</span><br><span class="line">Fedora: 31</span><br><span class="line">Ubuntu: bionic</span><br></pre></td></tr></table></figure>
<h3 id="官方文档-2"><a href="#官方文档-2" class="headerlink" title="官方文档"></a><a href="https://rancher.com/docs/os/v1.x/en/" target="_blank" rel="noopener">官方文档</a></h3><p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/" target="_blank" rel="noopener">安装文档</a></p>
<h4 id="Cloud-云平台"><a href="#Cloud-云平台" class="headerlink" title="Cloud 云平台"></a>Cloud 云平台</h4><p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/cloud/aws" target="_blank" rel="noopener">Amazon EC2</a></p>
<p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/cloud/gce" target="_blank" rel="noopener">Google Compute Engine</a></p>
<p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/cloud/do" target="_blank" rel="noopener">DigitalOcean</a></p>
<p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/cloud/azure" target="_blank" rel="noopener">Azure</a></p>
<p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/cloud/openstack" target="_blank" rel="noopener">OpenStack</a></p>
<p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/cloud/vmware-esxi" target="_blank" rel="noopener">VMware ESXi</a></p>
<p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/cloud/aliyun" target="_blank" rel="noopener">Aliyun</a></p>
<h4 id="Bare-Metal-amp-Virtual-Servers-裸金属"><a href="#Bare-Metal-amp-Virtual-Servers-裸金属" class="headerlink" title="Bare Metal &amp; Virtual Servers 裸金属"></a>Bare Metal &amp; Virtual Servers 裸金属</h4><p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/server/pxe" target="_blank" rel="noopener">PXE</a></p>
<p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/server/install-to-disk" target="_blank" rel="noopener">Install to Hard Disk</a></p>
<p><a href="https://rancher.com/docs/os/v1.x/en/installation/running-rancheros/server/raspberry-pi" target="_blank" rel="noopener">Raspberry Pi</a></p>
<h3 id="安装镜像-1"><a href="#安装镜像-1" class="headerlink" title="安装镜像"></a><a href="https://github.com/rancher/os/releases/" target="_blank" rel="noopener">安装镜像</a></h3><p>RancherOS 将各个平台的安装镜像都放在了 GitHub <a href="https://github.com/rancher/os/releases/" target="_blank" rel="noopener">release</a> 页面上。对于 VMware 用户就使用 <a href="https://github.com/rancher/os/releases/download/v1.5.5/rancheros-vmware.iso" target="_blank" rel="noopener">rancheros-vmware.iso</a> 这个镜像即可。没得 OVA 虚拟机模板只能手动搓一个啦。下载完成之后将这个镜像上传到 vSphere 的数据存储中，按照创建常规虚拟机的方式来创建虚拟机。</p>
<h3 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h3><p><img src="../img/image-20191231142454934.png" alt="image-20191231142454934"></p>
<p>使用 ISO 启动之后进入得是一个 liveCD 型得系统，并没有安装虚拟机得磁盘当中，我们需要将 RancherOS 安装到磁盘上。提前准备好 cloud-init 的配置文件，只需要执行 <code>ros install -c cloud-config.yml -d /dev/sda</code> 命令就行啦。-d 参数后面跟着安装到的磁盘。</p>
<p>不过需要像 CoreOS 那样准备给一个 <code>cloud-config.yml</code> 配置文件，将我们得 ssh 公钥和用户密码填写到里面，不过 <code>cloud-config</code> 能配置得选项非常多，在此就不赘述了，等抽空专门写一篇博客来讲讲 cloud-init 的使用。（又挖坑😂，不知何时能填上🙃</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rancher rancher]<span class="comment"># ros install -c cloud-config.yml -d /dev/sda</span></span><br><span class="line">INFO[0000] No install <span class="built_in">type</span> specified...defaulting to generic</span><br><span class="line">Installing from rancher/os:v1.5.5</span><br><span class="line">Continue [y/N]: y</span><br><span class="line">INFO[0002] start !isoinstallerloaded</span><br><span class="line">INFO[0002] trying to load /bootiso/rancheros/installer.tar.gz</span><br><span class="line">69b8396f5d61: Loading layer [==================================================&gt;]  11.89MB/11.89MB</span><br><span class="line">cae31a9aae74: Loading layer [==================================================&gt;]  1.645MB/1.645MB</span><br><span class="line">78885fd6d98c: Loading layer [==================================================&gt;]  1.536kB/1.536kB</span><br><span class="line">51228f31b9ce: Loading layer [==================================================&gt;]   2.56kB/2.56kB</span><br><span class="line">d8162179e708: Loading layer [==================================================&gt;]   2.56kB/2.56kB</span><br><span class="line">3ee208751cd2: Loading layer [==================================================&gt;]  3.072kB/3.072kB</span><br><span class="line">Loaded image: rancher/os-installer:latest</span><br><span class="line">INFO[0002] Loaded images from /bootiso/rancheros/installer.tar.gz</span><br><span class="line">INFO[0002] starting installer container <span class="keyword">for</span> rancher/os-installer:latest (new)</span><br><span class="line">Installing from rancher/os-installer:latest</span><br><span class="line">mke2fs 1.45.2 (27-May-2019)</span><br><span class="line">64-bit filesystem support is not enabled.  The larger fields afforded by this feature <span class="built_in">enable</span> full-strength checksumming.  Pass -O 64bit to rectify.</span><br><span class="line">Creating filesystem with 7863808 4k blocks and 7864320 inodes</span><br><span class="line">Filesystem UUID: fe29cb27-b4ac-4c75-a12d-895ea7e52af9</span><br><span class="line">Superblock backups stored on blocks:</span><br><span class="line">        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,</span><br><span class="line">        4096000</span><br><span class="line"></span><br><span class="line">Allocating group tables: <span class="keyword">done</span></span><br><span class="line">Writing inode tables: <span class="keyword">done</span></span><br><span class="line">Creating journal (32768 blocks): <span class="keyword">done</span></span><br><span class="line">Writing superblocks and filesystem accounting information: <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">Continue with reboot [y/N]:y</span><br><span class="line">INFO[0288] Rebooting</span><br><span class="line">INFO[0288] Setting reboot timeout to 60 (rancher.shutdown_timeout <span class="built_in">set</span> to 60)</span><br><span class="line">....^[            ] reboot:info: Setting reboot timeout to 60 (rancher.shutdown_timeout <span class="built_in">set</span> to 60)</span><br><span class="line">.=.[            ] reboot:info: Stopping /docker : 3d39a73e4089</span><br><span class="line">...........M..........[            ] reboot:info: Stopping /open-vm-tools : ccd97f8a7775</span><br><span class="line">:.[            ] reboot:info: Stopping /ntp : acf47c78a711</span><br><span class="line">.&gt;.[            ] reboot:info: Stopping /network : 08be8ef68e27</span><br><span class="line">..&lt;..[            ] reboot:info: Stopping /udev : 4986cd58a227</span><br><span class="line">.=.[            ] reboot:info: Stopping /syslog : 254137c5e66a</span><br><span class="line">.&lt;.[            ] reboot:info: Stopping /acpid : a2ededff859c</span><br><span class="line">..C..[            ] reboot:info: Stopping /system-cron : 899028a78e3a</span><br><span class="line">..H.[            ] reboot:info: Console Stopping [/console] : 6fc9ef66b43c</span><br><span class="line">Connection to 10.20.172.119 closed by remote host.</span><br><span class="line">Connection to 10.20.172.119 closed.</span><br></pre></td></tr></table></figure>
<h3 id="内核以及发行版信息-1"><a href="#内核以及发行版信息-1" class="headerlink" title="内核以及发行版信息"></a>内核以及发行版信息</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rancher rancher]<span class="comment"># uname -a</span></span><br><span class="line">Linux rancher 4.14.138-rancher <span class="comment">#1 SMP Sat Aug 10 11:25:46 UTC 2019 x86_64 GNU/Linux</span></span><br><span class="line">[root@rancher rancher]<span class="comment"># cat /etc/os-release</span></span><br><span class="line">NAME=<span class="string">"RancherOS"</span></span><br><span class="line">VERSION=v1.5.5</span><br><span class="line">ID=rancheros</span><br><span class="line">ID_LIKE=</span><br><span class="line">VERSION_ID=v1.5.5</span><br><span class="line">PRETTY_NAME=<span class="string">"RancherOS v1.5.5"</span></span><br><span class="line">HOME_URL=<span class="string">"http://rancher.com/rancher-os/"</span></span><br><span class="line">SUPPORT_URL=<span class="string">"https://forums.rancher.com/c/rancher-os"</span></span><br><span class="line">BUG_REPORT_URL=<span class="string">"https://github.com/rancher/os/issues"</span></span><br><span class="line">BUILD_ID=</span><br></pre></td></tr></table></figure>
<h3 id="docker-容器引擎-2"><a href="#docker-容器引擎-2" class="headerlink" title="docker 容器引擎"></a>docker 容器引擎</h3><p>在 RancherOS 中有两套 docker ，一套是用来容器化运行系统服务的，包括用户空间的 docker ，而另一套 docker 就是用户空间的 docker</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="section">[root@rancher rancher]</span><span class="comment"># docker info</span></span><br><span class="line">Client:</span><br><span class="line"> Debug Mode: false</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Containers: 0</span><br><span class="line">  Running: 0</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 0</span><br><span class="line"> Images: 0</span><br><span class="line"> Server Version: 19.03.5</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: tmpfs</span><br><span class="line">  Supports d_type: true</span><br><span class="line">  Native Overlay Diff: true</span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: cgroupfs</span><br><span class="line"> Plugins:</span><br><span class="line">  Volume: local</span><br><span class="line">  Network: bridge host ipvlan macvlan null overlay</span><br><span class="line">  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog</span><br><span class="line"> Swarm: inactive</span><br><span class="line"> Runtimes: runc</span><br><span class="line"> Default Runtime: runc</span><br><span class="line"> Init Binary: docker-init</span><br><span class="line"> containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339</span><br><span class="line"> runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657</span><br><span class="line"> init version: fec3683</span><br><span class="line"> Security Options:</span><br><span class="line">  seccomp</span><br><span class="line">   Profile: default</span><br><span class="line"> Kernel Version: 4.14.138-rancher</span><br><span class="line"> Operating System: RancherOS v1.5.5</span><br><span class="line"> OSType: linux</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> CPUs: 4</span><br><span class="line"> Total Memory: 3.855GiB</span><br><span class="line"> Name: rancher</span><br><span class="line"> ID: 2256:3I2G:WFHC:ZRTL:CKG6:GXD6:3RDL:645J:CD4J:GKJ7:55SG:U32I</span><br><span class="line"> Docker Root Dir: /var/lib/docker</span><br><span class="line"> Debug Mode: false</span><br><span class="line"> Registry: https://index.docker.io/v1/</span><br><span class="line"> Labels:</span><br><span class="line"> Experimental: false</span><br><span class="line"> Insecure Registries:</span><br><span class="line">  127.0.0.0/8</span><br><span class="line"> Live Restore Enabled: false</span><br><span class="line"> Product License: Community Engine</span><br></pre></td></tr></table></figure>
<h3 id="rancher-引擎"><a href="#rancher-引擎" class="headerlink" title="rancher 引擎"></a>rancher 引擎</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rancher rancher]<span class="comment"># du -sh /var/lib/rancher/engine/*</span></span><br><span class="line">116.0K  /var/lib/rancher/engine/completion</span><br><span class="line">33.0M   /var/lib/rancher/engine/containerd</span><br><span class="line">5.8M    /var/lib/rancher/engine/containerd-shim</span><br><span class="line">18.0M   /var/lib/rancher/engine/ctr</span><br><span class="line">62.6M   /var/lib/rancher/engine/docker</span><br><span class="line">748.0K  /var/lib/rancher/engine/docker-init</span><br><span class="line">2.7M    /var/lib/rancher/engine/docker-proxy</span><br><span class="line">68.8M   /var/lib/rancher/engine/dockerd</span><br><span class="line">8.3M    /var/lib/rancher/engine/runc</span><br></pre></td></tr></table></figure>
<h3 id="资源占用"><a href="#资源占用" class="headerlink" title="资源占用"></a>资源占用</h3><h4 id="负载-2"><a href="#负载-2" class="headerlink" title="负载"></a>负载</h4><ul>
<li>可以看出 RancherOS 运行着大量的 <code>system-docker-containerd-shim</code> 这是因为它将系服务也都容器化来运行，但奇怪的是无法使用 docker 命令来管理这些服务。</li>
</ul>
<p><img src="../img/image-20191231143958024.png" alt="image-20191231143958024"></p>
<h4 id="内存-2"><a href="#内存-2" class="headerlink" title="内存"></a>内存</h4><ul>
<li>初始化启动后内存使用了 1224MB😂，要比 CoreOS 和 Photon OS 加起来还多😂</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rancher@rancher ~]$ free -m</span><br><span class="line">             total       used       free     shared    buffers     cached</span><br><span class="line">Mem:          3947       1224       2722        993          0        993</span><br><span class="line">-/+ buffers/cache:        231       3715</span><br><span class="line">Swap:            0          0          0</span><br></pre></td></tr></table></figure>
<h4 id="磁盘-2"><a href="#磁盘-2" class="headerlink" title="磁盘"></a>磁盘</h4><p>由于系统服务是以容器的方式来运行的，而容器内的进程要访问系统文件系统的话就要将这些文件挂载到容器里去，所以会出现这么多的分区情况，不过绝大多数都是容器挂载的数据卷。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rancher rancher]<span class="comment"># df -h</span></span><br><span class="line">Filesystem                Size      Used Available Use% Mounted on</span><br><span class="line">overlay                  28.0G      1.0G     25.5G   4% /</span><br><span class="line">tmpfs                     1.9G         0      1.9G   0% /dev</span><br><span class="line">tmpfs                     1.9G         0      1.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /media</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /opt</span><br><span class="line">none                      1.9G    944.0K      1.9G   0% /run</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /mnt</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /home</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /etc/resolv.conf</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /etc/logrotate.d</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /usr/lib/firmware</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /usr/sbin/iptables</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /etc/docker</span><br><span class="line">none                      1.9G    944.0K      1.9G   0% /var/run</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/<span class="built_in">log</span></span><br><span class="line">devtmpfs                  1.9G         0      1.9G   0% /host/dev</span><br><span class="line">shm                      64.0M         0     64.0M   0% /host/dev/shm</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /etc/selinux</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /etc/hosts</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /usr/lib/modules</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /etc/hostname</span><br><span class="line">shm                      64.0M         0     64.0M   0% /dev/shm</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /usr/bin/system-docker</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/lib/boot2docker</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /usr/share/ros</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/lib/m-user-docker</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/lib/waagent</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/lib/docker</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/lib/kubelet</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/lib/rancher</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /usr/bin/ros</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /usr/bin/system-docker-runc</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /etc/ssl/certs/ca-certificates.crt.rancher</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/lib/rancher/cache</span><br><span class="line">/dev/sda1                28.0G      1.0G     25.5G   4% /var/lib/rancher/conf</span><br><span class="line">devtmpfs                  1.9G         0      1.9G   0% /dev</span><br><span class="line">shm                      64.0M         0     64.0M   0% /dev/shm</span><br></pre></td></tr></table></figure>
<h4 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rancher rancher]<span class="comment"># mount</span></span><br><span class="line">overlay on / <span class="built_in">type</span> overlay (rw,relatime,lowerdir=/var/lib/system-docker/overlay2/l/TBWLXSEPWSCBGMNSU37HJXNRO3:/var/lib/system-docker/overlay2/l/DWK2WF5FKFYZTH74WUBGHTRF4V:/var/lib/system-docker/overlay2/l/HDUW6LV2DFEIJPW3IA33YTCNWX:/var/lib/system-docker/overlay2/l/ZDK3KMGDSN5O33AR6XJJF27NFO:/var/lib/system-docker/overlay2/l/TSWFV744M2LUOSPV2N6QHON4NP:/var/lib/system-docker/overlay2/l/QZ3U27554L5LKMJDYP3DC356L7:/var/lib/system-docker/overlay2/l/D6LSXZS2UGAZ7NMKQJKMQVT24P:/var/lib/system-docker/overlay2/l/KHB3OKMEQIL2P34QMHYF3HWTLT,upperdir=/var/lib/system-docker/overlay2/fc79b6b6cf5c6d0b34b5abb95a1a19d765c1a00d66d0cff1ef3778d109471522/diff,workdir=/var/lib/system-docker/overlay2/fc79b6b6cf5c6d0b34b5abb95a1a19d765c1a00d66d0cff1ef3778d109471522/work)</span><br><span class="line">proc on /proc <span class="built_in">type</span> proc (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">tmpfs on /dev <span class="built_in">type</span> tmpfs (rw,nosuid,mode=755)</span><br><span class="line">devpts on /dev/pts <span class="built_in">type</span> devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666)</span><br><span class="line">sysfs on /sys <span class="built_in">type</span> sysfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">tmpfs on /sys/fs/cgroup <span class="built_in">type</span> tmpfs (rw,nosuid,nodev,noexec,relatime,mode=755)</span><br><span class="line">none on /sys/fs/cgroup/freezer <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,freezer)</span><br><span class="line">none on /sys/fs/cgroup/devices <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">none on /sys/fs/cgroup/net_cls,net_prio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)</span><br><span class="line">none on /sys/fs/cgroup/perf_event <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)</span><br><span class="line">none on /sys/fs/cgroup/hugetlb <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)</span><br><span class="line">none on /sys/fs/cgroup/cpuset <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</span><br><span class="line">none on /sys/fs/cgroup/cpu,cpuacct <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)</span><br><span class="line">none on /sys/fs/cgroup/blkio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,blkio)</span><br><span class="line">none on /sys/fs/cgroup/memory <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,memory)</span><br><span class="line">none on /sys/fs/cgroup/pids <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,pids)</span><br><span class="line">mqueue on /dev/mqueue <span class="built_in">type</span> mqueue (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">/dev/sda1 on /media <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /opt <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">none on /run <span class="built_in">type</span> tmpfs (rw,relatime)</span><br><span class="line">nsfs on /run/docker/netns/default <span class="built_in">type</span> nsfs (rw)</span><br><span class="line">nsfs on /run/system-docker/netns/default <span class="built_in">type</span> nsfs (rw)</span><br><span class="line">nsfs on /run/system-docker/netns/d15f3e062bb6 <span class="built_in">type</span> nsfs (rw)</span><br><span class="line">/dev/sda1 on /mnt <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /home <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /etc/resolv.conf <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /etc/logrotate.d <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /usr/lib/firmware <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /usr/sbin/iptables <span class="built_in">type</span> ext4 (ro,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /etc/docker <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">none on /var/run <span class="built_in">type</span> tmpfs (rw,relatime)</span><br><span class="line">nsfs on /var/run/docker/netns/default <span class="built_in">type</span> nsfs (rw)</span><br><span class="line">nsfs on /var/run/system-docker/netns/default <span class="built_in">type</span> nsfs (rw)</span><br><span class="line">nsfs on /var/run/system-docker/netns/d15f3e062bb6 <span class="built_in">type</span> nsfs (rw)</span><br><span class="line">/dev/sda1 on /var/<span class="built_in">log</span> <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">devtmpfs on /host/dev <span class="built_in">type</span> devtmpfs (rw,relatime,size=1949420k,nr_inodes=487355,mode=755)</span><br><span class="line">none on /host/dev/pts <span class="built_in">type</span> devpts (rw,relatime,mode=600,ptmxmode=000)</span><br><span class="line">shm on /host/dev/shm <span class="built_in">type</span> tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)</span><br><span class="line">mqueue on /host/dev/mqueue <span class="built_in">type</span> mqueue (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">/dev/sda1 on /etc/selinux <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /etc/hosts <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /usr/lib/modules <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /etc/hostname <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">shm on /dev/shm <span class="built_in">type</span> tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)</span><br><span class="line">/dev/sda1 on /usr/bin/system-docker <span class="built_in">type</span> ext4 (ro,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /var/lib/boot2docker <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /usr/share/ros <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /var/lib/m-user-docker <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /var/lib/waagent <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /var/lib/docker <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /var/lib/kubelet <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /var/lib/rancher <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /usr/bin/ros <span class="built_in">type</span> ext4 (ro,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /usr/bin/system-docker-runc <span class="built_in">type</span> ext4 (ro,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /etc/ssl/certs/ca-certificates.crt.rancher <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /var/lib/rancher/cache <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">/dev/sda1 on /var/lib/rancher/conf <span class="built_in">type</span> ext4 (rw,relatime,data=ordered)</span><br><span class="line">devtmpfs on /dev <span class="built_in">type</span> devtmpfs (rw,relatime,size=1949420k,nr_inodes=487355,mode=755)</span><br><span class="line">none on /dev/pts <span class="built_in">type</span> devpts (rw,relatime,mode=600,ptmxmode=000)</span><br><span class="line">shm on /dev/shm <span class="built_in">type</span> tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)</span><br><span class="line">mqueue on /dev/mqueue <span class="built_in">type</span> mqueue (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">cgroup on /sys/fs/cgroup/systemd <span class="built_in">type</span> cgroup (rw,relatime,name=systemd)</span><br><span class="line">none on /sys/fs/selinux <span class="built_in">type</span> selinuxfs (ro,relatime)</span><br></pre></td></tr></table></figure>
<h3 id="系统服务容器化"><a href="#系统服务容器化" class="headerlink" title="系统服务容器化"></a>系统服务容器化</h3><p>通过 top 命令和 ps 命令查看系统运行的进程可以发现以下几个重要的进程</p>
<h4 id="top"><a href="#top" class="headerlink" title="top"></a>top</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PID  PPID USER     STAT   VSZ %VSZ %CPU COMMAND</span><br><span class="line">1695  1620 root     S     558m  14%   0% containerd --config /var/run/docker/containerd/containerd.toml --<span class="built_in">log</span>-level info</span><br><span class="line">1988  1922 root     S    11420   0%   0% top</span><br><span class="line">   1     0 root     S    1287m  32%   0% system-dockerd --storage-driver overlay2 --graph /var/lib/system-docker --config-file /etc/docker/system-docker.json --restart=<span class="literal">false</span> --group root --userland-proxy=<span class="literal">false</span> --bip 172.18.42.1/16 --<span class="built_in">log</span>-opt max-file=2 --<span class="built_in">log</span>-opt max-size</span><br><span class="line"> 489     1 root     S     833m  21%   0% system-docker-containerd -l unix:///var/run/system-docker/libcontainerd/system-docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/system-docker/libcontainerd/containerd --shim system-docker-contai</span><br><span class="line">1370  1353 root     S     808m  20%   0% respawn -f /etc/respawn.conf</span><br><span class="line">1620  1415 root     S     658m  16%   0% dockerd --group docker --host unix:///var/run/docker.sock --<span class="built_in">log</span>-opt max-file=2 --<span class="built_in">log</span>-opt max-size=25m</span><br><span class="line">1398   489 root     S     472m  12%   0% system-docker-containerd-shim 3d39a73e4089dcbdd144277adb398d3e0d8ba62812a699be7cfeac9598539f6e /var/run/system-docker/libcontainerd/3d39a73e4089dcbdd144277adb398d3e0d8ba62812a699be7cfeac9598539f6e system-docker-runc</span><br><span class="line">1285   489 root     S     470m  12%   0% system-docker-containerd-shim 254137c5e66a7075c2104cca82fa2e6584509170688064fac1147fbfcda2f5c0 /var/run/system-docker/libcontainerd/254137c5e66a7075c2104cca82fa2e6584509170688064fac1147fbfcda2f5c0 system-docker-runc</span><br><span class="line">1588  1370 root     S     452m  11%   0% /usr/bin/autologin rancher:tty1</span><br><span class="line">1013   995 root     S     452m  11%   0% netconf</span><br><span class="line">1151   489 root     S     406m  10%   0% system-docker-containerd-shim ccd97f8a77756dcc4ae21c935dcaf35aa8f02399e9ca87811a5f4ec1d5d6d1a3 /var/run/system-docker/libcontainerd/ccd97f8a77756dcc4ae21c935dcaf35aa8f02399e9ca87811a5f4ec1d5d6d1a3 system-docker-runc</span><br><span class="line"> 995   489 root     S     398m  10%   0% system-docker-containerd-shim 08be8ef68e27d7e3b8f9d2a62914f9b581545ed96d65a751b487e7814f2bc795 /var/run/system-docker/libcontainerd/08be8ef68e27d7e3b8f9d2a62914f9b581545ed96d65a751b487e7814f2bc795 system-docker-runc</span><br><span class="line"> 784   489 root     S     335m   8%   0% system-docker-containerd-shim 899028a78e3a3baa42ad1e3042d49f23e9fe2d6cce8b824850aaca4270d681fd /var/run/system-docker/libcontainerd/899028a78e3a3baa42ad1e3042d49f23e9fe2d6cce8b824850aaca4270d681fd system-docker-runc</span><br><span class="line"> 803   489 root     S     335m   8%   0% system-docker-containerd-shim a2ededff859cc3d7c1a6342eb5d92606d4da605433d03abc92cc5f6503d53c6f /var/run/system-docker/libcontainerd/a2ededff859cc3d7c1a6342eb5d92606d4da605433d03abc92cc5f6503d53c6f system-docker-runc</span><br><span class="line">1076   489 root     S     334m   8%   0% system-docker-containerd-shim acf47c78a71194f1ef094302846855c777ef84fe613eb1ac1cc5f7ac868d618c /var/run/system-docker/libcontainerd/acf47c78a71194f1ef094302846855c777ef84fe613eb1ac1cc5f7ac868d618c system-docker-runc</span><br><span class="line"> 956   489 root     S     280m   7%   0% system-docker-containerd-shim 4986cd58a227547af8e4867da067cf9f066062536268bf025466f88b4b38d9c3 /var/run/system-docker/libcontainerd/4986cd58a227547af8e4867da067cf9f066062536268bf025466f88b4b38d9c3 system-docker-runc</span><br><span class="line">1353   489 root     S     270m   7%   0% system-docker-containerd-shim 6fc9ef66b43c9902e23cea7cfdd78b8b5842df2b981d8d7899eacb3b063294fd /var/run/system-docker/libcontainerd/6fc9ef66b43c9902e23cea7cfdd78b8b5842df2b981d8d7899eacb3b063294fd system-docker-runc</span><br><span class="line">1311  1285 root     S     238m   6%   0% rsyslogd -n</span><br><span class="line">1168  1151 root     S     146m   4%   0% /usr/bin/vmtoolsd</span><br><span class="line">1415  1398 root     S     122m   3%   0% system-docker-runc <span class="built_in">exec</span> -- 6fc9ef66b43c9902e23cea7cfdd78b8b5842df2b981d8d7899eacb3b063294fd env PATH=/usr/<span class="built_in">local</span>/sbin:/usr/<span class="built_in">local</span>/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME=rancher HOME=/ ros docker-init --group docker --host unix:</span><br><span class="line"> 907   784 root     S     109m   3%   0% container-crontab</span><br><span class="line">1105  1076 root     S    94084   2%   0% ntpd --nofork -g</span><br><span class="line"> 973   956 root     S    22544   1%   0% udevd</span><br><span class="line">1890  1888 rancher  S    22448   1%   0% sshd: rancher@pts/0</span><br><span class="line">1586  1370 root     S    22096   1%   0% /usr/sbin/sshd -D</span><br><span class="line">1888  1586 root     S    22096   1%   0% sshd: rancher [priv]</span><br><span class="line">1989  1586 root     S    22096   1%   0% sshd: rancher [priv]</span><br><span class="line">1991  1989 rancher  S    22096   1%   0% sshd: rancher@pts/1</span><br><span class="line">1922  1891 root     S    16244   0%   0% bash</span><br><span class="line">1641  1588 rancher  S    16116   0%   0% -bash</span><br><span class="line">1885  1641 root     S    16116   0%   0% bash</span><br><span class="line">1891  1890 rancher  S    16116   0%   0% -bash</span><br><span class="line">1992  1991 rancher  S    16116   0%   0% -bash</span><br><span class="line">1997  1992 rancher  R    11420   0%   0% top</span><br><span class="line">1589  1370 root     S     6404   0%   0% /sbin/agetty --noclear tty2 linux</span><br><span class="line">1591  1370 root     S     6404   0%   0% /sbin/agetty --noclear tty3 linux</span><br><span class="line">1592  1370 root     S     6404   0%   0% /sbin/agetty --noclear tty4 linux</span><br><span class="line">1594  1370 root     S     6404   0%   0% /sbin/agetty --noclear tty5 linux</span><br><span class="line">1595  1370 root     S     6404   0%   0% /sbin/agetty --noclear tty6 linux</span><br><span class="line">1112   995 root     S     4660   0%   0% dhcpcd -MA4 -e force_hostname=<span class="literal">true</span> --timeout 10 -w --debug eth0</span><br><span class="line"> 850   803 root     S     4276   0%   0% /usr/sbin/acpid -f</span><br><span class="line"> 477     1 root     Z        0   0%   0% [ros]</span><br><span class="line">  49     2 root     IW       0   0%   0% [kworker/1:1]</span><br><span class="line">   8     2 root     IW       0   0%   0% [rcu_sched]</span><br><span class="line">  33     2 root     IW       0   0%   0% [kworker/0:1]</span><br><span class="line">   7     2 root     SW       0   0%   0% [ksoftirqd/0]</span><br><span class="line">  39     2 root     SWN      0   0%   0% [khugepaged]</span><br><span class="line">1317     2 root     IW       0   0%   0% [kworker/3:2]</span><br><span class="line">  48     2 root     IW       0   0%   0% [kworker/u8:1]</span><br><span class="line">  76     2 root     SW       0   0%   0% [scsi_eh_1]</span><br><span class="line">1244     2 root     IW       0   0%   0% [kworker/2:2]</span><br><span class="line">   2     0 root     SW       0   0%   0% [kthreadd]</span><br><span class="line">   4     2 root     IW&lt;      0   0%   0% [kworker/0:0H]</span><br><span class="line">   6     2 root     IW&lt;      0   0%   0% [mm_percpu_wq]</span><br><span class="line">   9     2 root     IW       0   0%   0% [rcu_bh]</span><br><span class="line">  10     2 root     SW       0   0%   0% [migration/0]</span><br><span class="line">  11     2 root     SW       0   0%   0% [watchdog/0]</span><br><span class="line">  12     2 root     SW       0   0%   0% [cpuhp/0]</span><br><span class="line">  13     2 root     SW       0   0%   0% [cpuhp/1]</span><br><span class="line">  14     2 root     SW       0   0%   0% [watchdog/1]</span><br><span class="line">  15     2 root     SW       0   0%   0% [migration/1]</span><br><span class="line">  16     2 root     SW       0   0%   0% [ksoftirqd/1]</span><br><span class="line">  18     2 root     IW&lt;      0   0%   0% [kworker/1:0H]</span><br></pre></td></tr></table></figure>
<h3 id="ros"><a href="#ros" class="headerlink" title="ros"></a>ros</h3><blockquote>
<p>A system service is a container that can be run in either System Docker or Docker. Rancher provides services that are already available in RancherOS by adding them to the <a href="https://github.com/rancher/os-services" target="_blank" rel="noopener">os-services repo</a>. Anything in the <code>index.yml</code> file from the repository for the tagged release will be an available system service when using the <code>ros service list</code> command.</p>
</blockquote>
<p>RancherOS 移除了 systemd ，取而代之的是使用 ros 来管理系统服务。而相应的系统服务也是采用 docker 的方式来运行，包括用户空间的 docker 也是采用 docker 的方式来运行。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rancher rancher]<span class="comment"># ros</span></span><br><span class="line">NAME:</span><br><span class="line">   ros - Control and configure RancherOS</span><br><span class="line">built: <span class="string">'2019-12-30T09:16:00Z'</span></span><br><span class="line"></span><br><span class="line">USAGE:</span><br><span class="line">   ros [global options] <span class="built_in">command</span> [<span class="built_in">command</span> options] [arguments...]</span><br><span class="line"></span><br><span class="line">VERSION:</span><br><span class="line">   v1.5.5</span><br><span class="line"></span><br><span class="line">AUTHOR(S):</span><br><span class="line">   Rancher Labs, Inc.</span><br><span class="line"></span><br><span class="line">COMMANDS:</span><br><span class="line">     config, c   configure settings</span><br><span class="line">     console     manage <span class="built_in">which</span> console container is used</span><br><span class="line">     engine      manage <span class="built_in">which</span> Docker engine is used</span><br><span class="line">     service, s</span><br><span class="line">     os          operating system upgrade/downgrade</span><br><span class="line">     tls         setup tls configuration</span><br><span class="line">     install     install RancherOS to disk</span><br><span class="line">     <span class="built_in">help</span>, h     Shows a list of commands or <span class="built_in">help</span> <span class="keyword">for</span> one <span class="built_in">command</span></span><br><span class="line"></span><br><span class="line">GLOBAL OPTIONS:</span><br><span class="line">   --<span class="built_in">help</span>, -h     show <span class="built_in">help</span></span><br><span class="line">   --version, -v  <span class="built_in">print</span> the version</span><br></pre></td></tr></table></figure>
<h3 id="系统进程"><a href="#系统进程" class="headerlink" title="系统进程"></a>系统进程</h3><ul>
<li>可以看到，使用 <code>ros service ps</code> 命令来查看正在运行的系统服务，这些服务都是以容器的方式来运行的。比如用户空间里的 <code>user-docker</code> 、<code>syslog</code> 、<code>udevd</code>   等等都是以容器的方式来运行的，而不是以传统进程服务来运行的。包括我们安装 RancherOS 到磁盘的时候  <code>starting installer container for rancher/os-installer:latest (new)</code> 这个安装程序也是由容器的方式来运行的，把磁盘设备和 <code>cloud-init</code> 配置文件一并挂载到容器中。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rancher rancher]<span class="comment"># ros service ps</span></span><br><span class="line">Name                    Command                                                            State                     Ports</span><br><span class="line">docker                  ros user-docker                                                    Up 9 minutes             </span><br><span class="line">logrotate               /usr/bin/entrypoint.sh /usr/sbin/logrotate -v /etc/logrotate.conf  Created                  </span><br><span class="line">system-cron             container-crontab                                                  Up 9 minutes             </span><br><span class="line">container-data-volumes  /usr/bin/ros entrypoint <span class="built_in">echo</span>                                       Created                  </span><br><span class="line">console                 /usr/bin/ros entrypoint ros console-init                           Up 9 minutes             </span><br><span class="line">system-volumes          /usr/bin/ros entrypoint <span class="built_in">echo</span>                                       Created                  </span><br><span class="line">ntp                     /usr/bin/ros entrypoint /bin/start_ntp.sh                          Up 9 minutes             </span><br><span class="line">subscriber              /usr/bin/ros entrypoint os-subscriber                              Exited (0) 2 minutes ago </span><br><span class="line">syslog                  /usr/bin/entrypoint.sh rsyslogd -n                                 Up 9 minutes             </span><br><span class="line">media-volumes           /usr/bin/ros entrypoint <span class="built_in">echo</span>                                       Created                  </span><br><span class="line">preload-user-images     /usr/bin/ros entrypoint ros preload-images                         Exited (0) 9 minutes ago </span><br><span class="line">udev                    /usr/bin/ros entrypoint udevd                                      Up 9 minutes             </span><br><span class="line">udev-cold               /usr/bin/ros entrypoint ros udev-settle                            Exited (0) 9 minutes ago </span><br><span class="line">network                 /usr/bin/ros entrypoint netconf                                    Up 9 minutes             </span><br><span class="line">open-vm-tools           /usr/bin/ros entrypoint /usr/bin/vmtoolsd                          Up 9 minutes             </span><br><span class="line">acpid                   /usr/bin/ros entrypoint /usr/sbin/acpid -f                         Up 9 minutes             </span><br><span class="line"><span class="built_in">command</span>-volumes         /usr/bin/ros entrypoint <span class="built_in">echo</span>                                       Created                  </span><br><span class="line">cloud-init-execute      /usr/bin/ros entrypoint cloud-init-execute -pre-console            Exited (0) 9 minutes ago </span><br><span class="line">user-volumes            /usr/bin/ros entrypoint <span class="built_in">echo</span>                                       Created                  </span><br><span class="line">all-volumes             /usr/bin/ros entrypoint <span class="built_in">echo</span></span><br></pre></td></tr></table></figure>
<h3 id="包管理器"><a href="#包管理器" class="headerlink" title="包管理器"></a>包管理器</h3><p>和 CoreOS 一样，RancherOS 也没得相应的包管理器😂，都是采用容器来运行所需的服务，使用 <code>ros</code> 命令来管理相应的服务。如果想要运行一个服务的话，需要使用 ros 来创建相应的容器来运行才可以。而使用 ros 来创建服务</p>
<h3 id="使用体验-2"><a href="#使用体验-2" class="headerlink" title="使用体验"></a>使用体验</h3><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2><p>文章写的太仓促了，感觉这些容器优化行操作系统都值得玩一玩得，尤其是 RancherOS 这种将 systemc 取代掉使用 docker 来管理系统服务得牛皮技术，值得研究一哈。因为时间有限，所以就没有详细地展开来将，就等到 2020 年吧😂。祝大家 2020 年元旦快乐，新的一年里……省略千字祝福😝</p>
]]></content>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
        <tag>Linux</tag>
        <tag>kubernees</tag>
      </tags>
  </entry>
  <entry>
    <title>台式机装机方案</title>
    <url>/archives/pc-e5v3-e3v3-amd2600.html</url>
    <content><![CDATA[<h2 id="TL"><a href="#TL" class="headerlink" title="TL"></a>TL</h2>
<blockquote class="twitter-tweet"><p lang="zh" dir="ltr">分享一个装机方案：<br>CPU: E5 2670V3 ×2<br>主板: Dell T7810 准系统<br>内存: 三星 DDR4 2133 16G×4<br>显卡: Quador K2000 2GB<br>硬盘: 西数 HC310 7K 4TB<br>固态: 三星 PM 981 256GB<br><br>价格: 550×2+1700+260×4+400+760+290=5290￥<br><br>你就能拥有一台 24C/48T CPU、64GB RAM 、256GB SDD/4TB HDD 配置的高性能工作站 <a href="https://t.co/NIkegB1Vck" target="_blank" rel="noopener">pic.twitter.com/NIkegB1Vck</a></p>&mdash; 502 (@muzi_ii) <a href="https://twitter.com/muzi_ii/status/1209832133092528129?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">December 25, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<h2 id="E3-V3"><a href="#E3-V3" class="headerlink" title="E3 V3"></a>E3 V3</h2><table>
<thead>
<tr>
<th style="text-align:center">硬件</th>
<th>配置</th>
<th style="text-align:center">价格</th>
<th style="text-align:center">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CPU</td>
<td>E3-1270 V3 4C/8T 3.50 GHz~3.90 GHz</td>
<td style="text-align:center">520</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">主板</td>
<td>T1700 准系统：Intel ®C2261</td>
<td style="text-align:center">400</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">内存</td>
<td>三星 DDR3 ECC 16GB 1600 Mhz ×2</td>
<td style="text-align:center">260×2</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">显卡</td>
<td>GTX 950 2GB</td>
<td style="text-align:center">300</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">固态</td>
<td>三星 850 PRO SATA III 256GB</td>
<td style="text-align:center">210</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">机箱</td>
<td>T1700 准系统：</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">电源</td>
<td>T1700 准系统：290W 开关电源</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">总价</td>
<td></td>
<td style="text-align:center">1950</td>
</tr>
</tbody>
</table>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li>如今的 E3 V3 价格已经跌破 500 左右了，但 AMD Ryzen R5 的价格散片也就 650 左右，加上 150 块钱就能提升 30% 的单核性能，外加 2 个核心和 4 个框框😂，总之 E3 V3 目前来讲性价比不如 AMD Ryzen R5。</li>
<li>E3 V3 是 Intel 第四代  CPU 1150 芯片组无法从 M.2 启动，速度只能达到 SATA III 也就是顶多 600 MB/s 的读写速度，而目前随便一块支持  PCI-e M.2 的主板普遍都能达到 3000MB/s 了。所以这一点来讲 E3 V3 已经不值得捡了。</li>
</ul>
<h2 id="AMD-Ryzen"><a href="#AMD-Ryzen" class="headerlink" title="AMD Ryzen"></a>AMD Ryzen</h2><table>
<thead>
<tr>
<th style="text-align:center">硬件</th>
<th>配置</th>
<th style="text-align:center">价格</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CPU</td>
<td>AMD Ryzen R5 2400G</td>
<td style="text-align:center">720</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">主板</td>
<td>MSI B350M</td>
<td style="text-align:center">320</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">内存</td>
<td>镁光 DDR4 16GB 2400 Mhz ×2</td>
<td style="text-align:center">300 ×2</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">显卡</td>
<td>GTX 950 2GB</td>
<td style="text-align:center">300</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">固态</td>
<td>三星 PM 981 256GB</td>
<td style="text-align:center">290</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">机箱</td>
<td>Dell 3010 机箱</td>
<td style="text-align:center">170</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">电源</td>
<td>Dell 3010 电源： 230W 光宝开关电源</td>
<td style="text-align:center">0</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">总价</td>
<td></td>
<td style="text-align:center">2400</td>
</tr>
</tbody>
</table>
<h3 id="天梯图"><a href="#天梯图" class="headerlink" title="天梯图"></a><a href="http://itianti.sinaapp.com/index.php/cpu" target="_blank" rel="noopener">天梯图</a></h3><ul>
<li>仅供娱乐，实际性能还要做对比测试，只是让您心里有点 B 数</li>
<li>AMD Ryzen 5 2400G 的性能和 E3-1270 V3 性能相近，AMD Ryzen 5 2600 性能要比两者高大概 30% 的性能（个人瞎猜）。</li>
<li>AMD Ryzen 5 2400G 的散片价格，目前（2019-12-26）淘宝 720￥，而 AMD Ryzen 5 2600 的价格在 640￥ 左右。</li>
<li>AMD Ryzen 5 2400G 核显性能相当于 GTX 1030 2GB ，而 GTX 1030 价格在 300￥ 左右，所以说牺牲两个核心和四个框框外加 80 块钱买个 300 块的 GTX 1030 。性价比是相当高滴。如果是日常用不打游戏，买 AMD Ryzen 5 2400G 是最佳选择。</li>
<li>AMD Ryzen 5 3400G 的价格在 820￥ 左右</li>
</ul>
<table>
<thead>
<tr>
<th>165</th>
<th>AMD Ryzen 5 2600X</th>
<th>14377</th>
</tr>
</thead>
<tbody>
<tr>
<td>101</td>
<td>AMD Ryzen 7 2700X</td>
<td>16971</td>
</tr>
<tr>
<td>165</td>
<td>AMD Ryzen 5 2600X</td>
<td>14377</td>
</tr>
<tr>
<td>166</td>
<td>Intel Core i7-6850K @ 3.60GHz</td>
<td>14372</td>
</tr>
<tr>
<td>169</td>
<td>Intel Core i9-8950HK @ 2.90GHz</td>
<td>14259</td>
</tr>
<tr>
<td>170</td>
<td>AMD Ryzen 5 PRO 2600</td>
<td>14221</td>
</tr>
<tr>
<td>195</td>
<td>Intel Core i7-6800K @ 3.40GHz</td>
<td>13570</td>
</tr>
<tr>
<td>197</td>
<td>Intel Core i5-9600K @ 3.70GHz</td>
<td>13527</td>
</tr>
<tr>
<td>199</td>
<td><strong>AMD Ryzen 5 2600</strong></td>
<td>13507</td>
</tr>
<tr>
<td>202</td>
<td>AMD Ryzen 5 1600X</td>
<td>13203</td>
</tr>
<tr>
<td>203</td>
<td>Intel Xeon E5-2660 v2 @ 2.20GHz</td>
<td>13186</td>
</tr>
<tr>
<td>207</td>
<td>Intel Core i7-4930K @ 3.40GHz</td>
<td>13007</td>
</tr>
<tr>
<td>326</td>
<td>Intel Core i7-7920HQ @ 3.10GHz</td>
<td>9986</td>
</tr>
<tr>
<td>327</td>
<td>Intel Xeon E3-1285L v3 @ 3.10GHz</td>
<td>9981</td>
</tr>
<tr>
<td>328</td>
<td>AMD Ryzen 5 PRO 2400G</td>
<td>9963</td>
</tr>
<tr>
<td>329</td>
<td>Intel Core i7-7820HK @ 2.90GHz</td>
<td>9963</td>
</tr>
<tr>
<td>330</td>
<td><strong>AMD Ryzen 5 3400G</strong></td>
<td>9957</td>
</tr>
<tr>
<td>333</td>
<td><strong>Intel Xeon E3-1270 v3 @ 3.50GHz</strong></td>
<td>9919</td>
</tr>
<tr>
<td>387</td>
<td>Intel Xeon E3-1230 v3 @ 3.30GHz</td>
<td>9327</td>
</tr>
<tr>
<td>388</td>
<td><strong>AMD Ryzen 5 2400G</strong></td>
<td>9234</td>
</tr>
<tr>
<td>395</td>
<td>Intel Core i3-8350K @ 4.00GHz</td>
<td>9221</td>
</tr>
</tbody>
</table>
<h3 id="注意事项-1"><a href="#注意事项-1" class="headerlink" title="注意事项"></a>注意事项</h3><p>这也是我目前的装机方案。我是在 7 月分的时组装的，那时候第三代 Ryzen 刚刚发布，而那时候的价格要比第二代 Ryzen 高出 500 多块钱，所以就没有使用第三代  Ryzen 。不过我当时买的是 U 板套装，加起来价格才 1180￥ ，那时候价格是相当便宜了，主板是华硕 B350M-K 丐板 的，理论上是支持第三代 Ryzen 的。虽然现在很后悔，但当时心切想买😂</p>
<h2 id="双路-E5-V3"><a href="#双路-E5-V3" class="headerlink" title="双路 E5 V3"></a>双路 E5 V3</h2><table>
<thead>
<tr>
<th style="text-align:center">硬件</th>
<th>配置</th>
<th style="text-align:center">价格</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CPU</td>
<td>Intel Xeon E5-2660 v3 @ 2.60GHz ×2</td>
<td style="text-align:center">600 ×2</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">主板</td>
<td>Dell T7810 准系统 或者 Dell R630 准系统</td>
<td style="text-align:center">1700</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">内存</td>
<td>三星 DDR4 2133 Mhz 16GB ×4</td>
<td style="text-align:center">260×4</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">显卡</td>
<td>GTX 950 2GB</td>
<td style="text-align:center">300</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">固态</td>
<td>三星 PM 981 256GB</td>
<td style="text-align:center">290</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">机箱</td>
<td>Dell T7810 准系统</td>
<td style="text-align:center">0</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">电源</td>
<td>Dell T7810 准系统</td>
<td style="text-align:center">0</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">总价</td>
<td></td>
<td style="text-align:center">4530</td>
</tr>
</tbody>
</table>
<h3 id="注意事项-2"><a href="#注意事项-2" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li><p>目前来讲 E5 V3 平台装机最令人头疼的就是主板死贵，主板价格都比两个 U 加起来的价格还要高。之所以选择 Dell T7810 准系统 准系统是因为相比来讲 Dell 塔式服务器的稳定性要比捡垃圾搞来的工包主板稳定性强很多，翻车概率要小一些。如果单独买主板的话还要和机箱象匹配，电源功率也要够。而 Dell T7810 准系统完美地解决了这些困扰，不用再考虑买合适的机箱和电源。一整套配合起来完美运行。</p>
</li>
<li><p>开箱博客 <a href="https://blog.silversky.moe/works/evaluation-of-out-of-the-box-dell-precision-t7910" target="_blank" rel="noopener">开箱测评——DELL PRECISION T7910</a></p>
</li>
<li><p>Dell T7810 有一些毛病，可以参考如下：</p>
</li>
<li><blockquote>
<ul>
<li>并不建议使用DELL T7910，非常伤 因为阵列卡的原因，系统速度会非常慢（肉眼可见的，比如说打开Windows Image Viewer，会等1-2秒才会显示（不管大小） 目测应该是什么硬件冲突，禁用板载阵列卡就好了（已经在国外论坛上看到很多案例了，很多公司/个人因为这个不去买DELL这个账</li>
<li>那是不是禁用阵列卡不用他不就好了呢 然而T7910的阵列卡和“背板”是12G的，接口使用的MiniSAS HD（SFF-8643）不管是再买阵列卡还是通道卡，都要有一笔不小的花费 还有K2000太烂了。</li>
<li>当然，我指的是这一代DELL Precision，不光是T7910</li>
<li>继续吐槽，T7910正面是三个风扇的，通过橡胶的减震钉固定在风扇架上。这些橡胶的减震钉，时间长了会老化，然后就会变得很恶心（最后被我拆掉用螺丝+螺帽代替）（我印象中我摸过其他的Lenovo的机器，甚至时间更长的都没有DELL这个老化之后的恶心 而且风扇的异响会变得比较讨厌（购入后1年内</li>
<li>顺便，应该是批次问题，如果你不幸买到了我这批的 你的电源会出现电弧的声音（没错，就是那个电弧 但是看不到任何东西，客服跟我讲可能我这边潮湿（你逗我，北方潮湿？？</li>
<li>电源，不管是T7910这样的模块化电源还是普通的电源，OEM机型你都会遇到一个问题，扩展电源接口不够 T7910只有一个SATA供电接口，本身设计是给光驱使用的 其他的电源接口是直接给硬盘笼供电的 如果你比较扭曲，像我这样可以直接剪掉重新焊接，或者你愿意多花钱买扩展线，那无所谓</li>
<li>以及前面提到的硬盘问题，别想着直接不用板载的SAS3008用板子上的SATA就完了 板子上就两个SATA。</li>
<li>这一代的Precision有巨多的问题（设计和硬件上的） 我是不可能推荐Precision的（至少是这代，因为我用了，用的还是旗舰） 相比之下，如果是OEM准系统组装的话，我更愿意推荐PowerEdge T630或者HPE的Z系列 T630有更好的电源配置，散热系统，扩展性，以及易于维护 HPE Z系列的模块化设计也是甩DELL10条街</li>
<li><p>btw, 我在6月把这台机器扔给我妈办公用之前，DELL的新固件我都会刷，然而并没有任何卵用</p>
<p>引用自 <a href="https://twitter.com/AkatsukiRyuu/status/1210157947906490368" target="_blank" rel="noopener">暁龍之介的推文</a></p>
</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="天梯图-1"><a href="#天梯图-1" class="headerlink" title="天梯图"></a><a href="http://itianti.sinaapp.com/index.php/cpu" target="_blank" rel="noopener">天梯图</a></h3><ul>
<li><p>仅供娱乐，具体实际性能还要看是实际的测试</p>
</li>
<li><p>可见  E5-2660 v3 的单核性能和 i7-8700K、Ryzen 7 2700x 相近</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>排名</th>
<th>型号</th>
<th>得分</th>
</tr>
</thead>
<tbody>
<tr>
<td>101</td>
<td>AMD Ryzen 7 2700X</td>
<td>16971</td>
</tr>
<tr>
<td>104</td>
<td>Intel Core i7-8086K @ 4.00GHz</td>
<td>16688</td>
</tr>
<tr>
<td>115</td>
<td>Intel Xeon Gold 5120 @ 2.20GHz</td>
<td>16308</td>
</tr>
<tr>
<td>120</td>
<td><strong>Intel Xeon E5-2660 v3 @ 2.60GHz</strong></td>
<td>16184</td>
</tr>
<tr>
<td>123</td>
<td>AMD Ryzen Threadripper 1900X</td>
<td>16089</td>
</tr>
<tr>
<td>124</td>
<td>Intel Xeon E-2186G @ 3.80GHz</td>
<td>16057</td>
</tr>
<tr>
<td>127</td>
<td>Intel Core i7-8700K @ 3.70GHz</td>
<td>15960</td>
</tr>
<tr>
<td>128</td>
<td>Intel Core i7-5960X @ 3.00GHz</td>
<td>15944</td>
</tr>
<tr>
<td>129</td>
<td>Intel Core i7-9700 @ 3.00GHz</td>
<td>15923</td>
</tr>
<tr>
<td>136</td>
<td>AMD Ryzen 7 PRO 2700</td>
<td>15714</td>
</tr>
<tr>
<td>138</td>
<td>Intel Core i7-9700F @ 3.00GHz</td>
<td>15566</td>
</tr>
<tr>
<td>141</td>
<td>AMD Ryzen 7 1800X</td>
<td>15420</td>
</tr>
<tr>
<td>143</td>
<td>Intel Xeon E5-2640 v4 @ 2.40GHz</td>
<td>15380</td>
</tr>
<tr>
<td>144</td>
<td>AMD Ryzen 7 PRO 1700X</td>
<td>15367</td>
</tr>
</tbody>
</table>
<h4 id="双路"><a href="#双路" class="headerlink" title="双路"></a>双路</h4><table>
<thead>
<tr>
<th>43</th>
<th>[双路] AMD EPYC 7501</th>
<th>23727</th>
</tr>
</thead>
<tbody>
<tr>
<td>44</td>
<td>[双路] Intel Xeon E5-2687W v2 @ 3.40GHz</td>
<td>23727</td>
</tr>
<tr>
<td>45</td>
<td>[双路] Intel Xeon E5-2697 v2 @ 2.70GHz</td>
<td>23574</td>
</tr>
<tr>
<td>46</td>
<td>[双路] AMD EPYC 7401</td>
<td>23518</td>
</tr>
<tr>
<td>47</td>
<td>[双路] Intel Xeon Gold 6128 @ 3.40GHz</td>
<td>23396</td>
</tr>
<tr>
<td>51</td>
<td>[双路] Intel Xeon E5-2660 v4 @ 2.00GHz</td>
<td>23117</td>
</tr>
<tr>
<td>54</td>
<td>[双路] Intel Xeon E5-2673 v3 @ 2.40GHz</td>
<td>22959</td>
</tr>
<tr>
<td>55</td>
<td><strong>[双路] Intel Xeon E5-2660 v3 @ 2.60GHz</strong></td>
<td>22733</td>
</tr>
<tr>
<td>56</td>
<td>[双路] Intel Xeon E5-4660 v3 @ 2.10GHz</td>
<td>22461</td>
</tr>
<tr>
<td>57</td>
<td>[双路] Intel Xeon E7-4890 v2 @ 2.80GHz</td>
<td>22412</td>
</tr>
<tr>
<td>58</td>
<td>[双路] Intel Xeon E5-2670 v3 @ 2.30GHz</td>
<td>22383</td>
</tr>
</tbody>
</table>
<h2 id="单路-E5-V3"><a href="#单路-E5-V3" class="headerlink" title="单路 E5 V3"></a>单路 E5 V3</h2><table>
<thead>
<tr>
<th style="text-align:center">硬件</th>
<th>配置</th>
<th style="text-align:center">价格</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CPU</td>
<td>Intel Xeon E5-2660 v3 @ 2.60GHz</td>
<td style="text-align:center">600</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">主板</td>
<td>Dell T5810 准系统</td>
<td style="text-align:center">1200</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">内存</td>
<td>三星 DDR4 2133 Mhz 16GB ×4</td>
<td style="text-align:center">260×4</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">显卡</td>
<td>GTX 950 2GB</td>
<td style="text-align:center">300</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">固态</td>
<td>三星 PM 981 256GB M.2</td>
<td style="text-align:center">290</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">机箱</td>
<td>Dell T7810 准系统</td>
<td style="text-align:center">0</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">电源</td>
<td>Dell T7810 准系统</td>
<td style="text-align:center">0</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">总价</td>
<td></td>
<td style="text-align:center">3430</td>
</tr>
</tbody>
</table>
<p>不过我倒是 jio 着，既然垃圾佬都上 E5 了，不玩玩双路对得起自己嘛，所以多花 1000 块相当于多一个 U ，多 12C/24T ，双路要比单路多 24 个框框啊，数起可好玩喽😂</p>
]]></content>
      <tags>
        <tag>捡垃圾</tag>
        <tag>PC</tag>
      </tags>
  </entry>
  <entry>
    <title>DockOne 社群分享汇总</title>
    <url>/archives/dockone-post-index-archives.html</url>
    <content><![CDATA[<h2 id="README"><a href="#README" class="headerlink" title="README"></a>README</h2><p>目前国内有关容器和 kubernetes 的社区，<a href="http://dockone.io/" target="_blank" rel="noopener">DockOne</a> 无疑是最优秀的社群分享平台。每周都会在微信群中直播分享 kubernetes 相关的技术。在此整理和汇总一下每次分享的主题，方便读者们找到感兴趣的内容。</p>
<h2 id="社群分享汇总列表"><a href="#社群分享汇总列表" class="headerlink" title="社群分享汇总列表"></a>社群分享汇总列表</h2><table>
<thead>
<tr>
<th></th>
<th>分享内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>二四二</td>
<td><a href="http://dockone.io/article/9560" target="_blank" rel="noopener">Open Policy Agent在Kubernetes中的应用</a></td>
</tr>
<tr>
<td>二四一</td>
<td><a href="http://dockone.io/article/9538" target="_blank" rel="noopener">Volcano介绍及其在深度学习场景下的应用</a></td>
</tr>
<tr>
<td>二四〇</td>
<td><a href="http://dockone.io/article/9526" target="_blank" rel="noopener">Knative Serverless 之道：如何 0运维、低成本实现应用托管？</a></td>
</tr>
<tr>
<td>二三九</td>
<td><a href="http://dockone.io/article/9517" target="_blank" rel="noopener">Kubernetes在信也科技的落地实战</a></td>
</tr>
<tr>
<td>二三八</td>
<td><a href="http://dockone.io/article/9432" target="_blank" rel="noopener">基于CDN的边缘计算平台设计和思考</a></td>
</tr>
<tr>
<td>二三七</td>
<td><a href="http://dockone.io/article/9412" target="_blank" rel="noopener">基于云原生日志分类处理方案与落地实践</a></td>
</tr>
<tr>
<td>二三六</td>
<td><a href="http://dockone.io/article/9386" target="_blank" rel="noopener">扇贝 Service Mesh发展历程</a></td>
</tr>
<tr>
<td>二三五</td>
<td><a href="http://dockone.io/article/9384" target="_blank" rel="noopener">k3s在边缘计算中的应用实践</a></td>
</tr>
<tr>
<td>二三四</td>
<td><a href="http://dockone.io/article/9369" target="_blank" rel="noopener">Kubernetes在宜信的落地实践</a></td>
</tr>
<tr>
<td>二三三</td>
<td><a href="http://dockone.io/article/9361" target="_blank" rel="noopener">Jenkins X：基于 Kubernetes 的 Serverless Jenkins</a></td>
</tr>
<tr>
<td>二三二</td>
<td><a href="http://dockone.io/article/9357" target="_blank" rel="noopener">基于 Ceph 的 Kubernetes 数据持久化</a></td>
</tr>
<tr>
<td>二三一</td>
<td><a href="http://dockone.io/article/9348" target="_blank" rel="noopener">玩转Kubernetes开发测试环境</a></td>
</tr>
<tr>
<td>二三〇</td>
<td><a href="http://dockone.io/article/9333" target="_blank" rel="noopener">Kubernetes在SHAREit的落地实战</a></td>
</tr>
<tr>
<td>二二九</td>
<td><a href="http://dockone.io/article/9313" target="_blank" rel="noopener">蔚来汽车的Kubernetes实践</a></td>
</tr>
<tr>
<td>二二八</td>
<td><a href="http://dockone.io/article/9286" target="_blank" rel="noopener">HC Bridge容器网络模式分享</a></td>
</tr>
<tr>
<td>二二七</td>
<td><a href="http://dockone.io/article/9270" target="_blank" rel="noopener">云原生可观察性之日志管理</a></td>
</tr>
<tr>
<td>二二六</td>
<td><a href="http://dockone.io/article/9269" target="_blank" rel="noopener">Prometheus架构与实践分享</a></td>
</tr>
<tr>
<td>二二五</td>
<td><a href="http://dockone.io/article/9254" target="_blank" rel="noopener">eBay Kubernetes集群的存储实践</a></td>
</tr>
<tr>
<td>二二四</td>
<td><a href="http://dockone.io/article/9234" target="_blank" rel="noopener">基于Kubernetes的DevOps平台实战</a></td>
</tr>
<tr>
<td>二二三</td>
<td><a href="http://dockone.io/article/9226" target="_blank" rel="noopener">Porter：面向裸金属环境的 Kubernetes 开源负载均衡器</a></td>
</tr>
<tr>
<td>二二二</td>
<td><a href="http://dockone.io/article/9207" target="_blank" rel="noopener">小公司如何优雅地推进应用上Kubernetes容器云</a></td>
</tr>
<tr>
<td>二二一</td>
<td><a href="http://dockone.io/article/9191" target="_blank" rel="noopener">初探云原生应用管理之：聊聊 Tekton 项目</a></td>
</tr>
<tr>
<td>二二〇</td>
<td><a href="http://dockone.io/article/9189" target="_blank" rel="noopener">PPmoney基于Kubernetes的DevOps实践</a></td>
</tr>
<tr>
<td>二一九</td>
<td><a href="http://dockone.io/article/9165" target="_blank" rel="noopener">跨境时尚电商SHEIN基于Kubernetes的DevOps实践</a></td>
</tr>
<tr>
<td>二一八</td>
<td><a href="http://dockone.io/article/9157" target="_blank" rel="noopener">基于OVS自研容器网络插件在金融类企业的落地实践</a></td>
</tr>
<tr>
<td>二一七</td>
<td><a href="http://dockone.io/article/9123" target="_blank" rel="noopener">TiDB Operator 的设计与实现</a></td>
</tr>
<tr>
<td>二一六</td>
<td><a href="http://dockone.io/article/9107" target="_blank" rel="noopener">基于Istio的灰度平台实践</a></td>
</tr>
<tr>
<td>二一五</td>
<td><a href="http://dockone.io/article/9076" target="_blank" rel="noopener">Kube-OVN的设计思路和实现原理</a></td>
</tr>
<tr>
<td>二一四</td>
<td><a href="http://dockone.io/article/9045" target="_blank" rel="noopener">震坤行的容器云实践</a></td>
</tr>
<tr>
<td>二一三</td>
<td><a href="http://dockone.io/article/9014" target="_blank" rel="noopener">智能工厂的容器云实践</a></td>
</tr>
<tr>
<td>二一二</td>
<td><a href="http://dockone.io/article/8994" target="_blank" rel="noopener">基于kubeadm搭建Kubernetes HA集群</a></td>
</tr>
<tr>
<td>二一一</td>
<td><a href="http://dockone.io/article/8977" target="_blank" rel="noopener">基于Actor模型的CQRS/ES解决方案分享</a></td>
</tr>
<tr>
<td>二一零</td>
<td><a href="http://dockone.io/article/8929" target="_blank" rel="noopener">平安证券Kubernetes容器集群的DevOps实践</a></td>
</tr>
<tr>
<td>二零九</td>
<td><a href="http://dockone.io/article/8825" target="_blank" rel="noopener">荔枝运维平台容器化实践</a></td>
</tr>
<tr>
<td>二零八</td>
<td><a href="http://dockone.io/article/8801" target="_blank" rel="noopener">华尔街见闻Istio生产实践</a></td>
</tr>
<tr>
<td>二零七</td>
<td><a href="http://dockone.io/article/8780" target="_blank" rel="noopener">瓜子云平台的实践经验</a></td>
</tr>
<tr>
<td>二零六</td>
<td><a href="http://dockone.io/article/8738" target="_blank" rel="noopener">容器环境下的持续集成最佳实践</a></td>
</tr>
<tr>
<td>二零五</td>
<td><a href="http://dockone.io/article/8718" target="_blank" rel="noopener">基于OVN的Kubernetes网络架构解析</a></td>
</tr>
<tr>
<td>二零四</td>
<td><a href="http://dockone.io/article/8695" target="_blank" rel="noopener">小团队微服务落地实践</a></td>
</tr>
<tr>
<td>二零三</td>
<td><a href="http://dockone.io/article/8622" target="_blank" rel="noopener">骞云科技DevOps实践</a></td>
</tr>
<tr>
<td>二零二</td>
<td><a href="http://dockone.io/article/8600" target="_blank" rel="noopener">房多多Service Mesh实践</a></td>
</tr>
<tr>
<td>二零一</td>
<td><a href="http://dockone.io/article/8538" target="_blank" rel="noopener">得到App的容器及Kubernetes实践</a></td>
</tr>
<tr>
<td>二零零</td>
<td><a href="http://dockone.io/article/8485" target="_blank" rel="noopener">龙腾出行基于Kubernetes的DevOps流水线实战</a></td>
</tr>
<tr>
<td>一九九</td>
<td><a href="http://dockone.io/article/8472" target="_blank" rel="noopener">如何评估Kubernetes持久化存储方案</a></td>
</tr>
<tr>
<td>一九八</td>
<td><a href="http://dockone.io/article/8469" target="_blank" rel="noopener">容器网络限流实践</a></td>
</tr>
<tr>
<td>一九七</td>
<td><a href="http://dockone.io/article/8464" target="_blank" rel="noopener">etcd 集群运维实践</a></td>
</tr>
<tr>
<td>一九六</td>
<td><a href="http://dockone.io/article/8442" target="_blank" rel="noopener">聚美优品云平台实践</a></td>
</tr>
<tr>
<td>一九五</td>
<td><a href="http://dockone.io/article/8403" target="_blank" rel="noopener">智融集团基于OpenShift的容器化PaaS平台实践</a></td>
</tr>
<tr>
<td>一九四</td>
<td><a href="http://dockone.io/article/8384" target="_blank" rel="noopener">猪八戒网DevOps容器云与流水线</a></td>
</tr>
<tr>
<td>一九三</td>
<td><a href="http://dockone.io/article/8365" target="_blank" rel="noopener">容器化落地实践的一个案例</a></td>
</tr>
<tr>
<td>一九二</td>
<td><a href="http://dockone.io/article/8353" target="_blank" rel="noopener">360搜索容器云探索与实践</a></td>
</tr>
<tr>
<td>一九〇</td>
<td><a href="http://dockone.io/article/8329" target="_blank" rel="noopener">Spring Cloud Kubernetes容器化实践</a></td>
</tr>
<tr>
<td>一八九</td>
<td><a href="http://dockone.io/article/8271" target="_blank" rel="noopener">有赞容器化实践</a></td>
</tr>
<tr>
<td>一八八</td>
<td><a href="http://dockone.io/article/8257" target="_blank" rel="noopener">唯品会Noah云平台实现内幕披露</a></td>
</tr>
<tr>
<td>一八七</td>
<td><a href="http://dockone.io/article/8217" target="_blank" rel="noopener">gVisor是什么？可以解决什么问题？</a></td>
</tr>
<tr>
<td>一八六</td>
<td><a href="http://dockone.io/article/8171" target="_blank" rel="noopener">有货基于Kubernetes容器环境的持续交付实践</a></td>
</tr>
<tr>
<td>一八五</td>
<td><a href="http://dockone.io/article/8149" target="_blank" rel="noopener">Nepxion Discovery：Spring Cloud灰度发布神器</a></td>
</tr>
<tr>
<td>一八四</td>
<td><a href="http://dockone.io/article/8139" target="_blank" rel="noopener">基于Spring Cloud的微服务容器化实践</a></td>
</tr>
<tr>
<td>一八三</td>
<td><a href="http://dockone.io/article/8133" target="_blank" rel="noopener">滴滴弹性云Kubernetes实践</a></td>
</tr>
<tr>
<td>一八二</td>
<td><a href="http://dockone.io/article/8103" target="_blank" rel="noopener">基于 GitLab 的 CI 实践</a></td>
</tr>
<tr>
<td>一八一</td>
<td><a href="http://dockone.io/article/7735" target="_blank" rel="noopener">小米弹性调度平台Ocean</a></td>
</tr>
<tr>
<td>一八十</td>
<td><a href="http://dockone.io/article/7720" target="_blank" rel="noopener">Hulu大规模容器调度系统Capos</a></td>
</tr>
<tr>
<td>一七八</td>
<td><a href="http://dockone.io/article/6049" target="_blank" rel="noopener">基于Pipeline的CI/CD在趣头条的应用实践</a></td>
</tr>
<tr>
<td>一七七</td>
<td><a href="http://dockone.io/article/6021" target="_blank" rel="noopener">苏宁容器云基于Kubernetes和Contiv的网络架构技术实现</a></td>
</tr>
<tr>
<td>一七六</td>
<td><a href="http://dockone.io/article/6020" target="_blank" rel="noopener">海信商业云平台的微服务落地实践</a></td>
</tr>
<tr>
<td>一七五</td>
<td><a href="http://dockone.io/article/5992" target="_blank" rel="noopener">盘点Kubernetes网络问题的4种解决方案</a></td>
</tr>
<tr>
<td>一七四</td>
<td><a href="http://dockone.io/article/5803" target="_blank" rel="noopener">腾讯云TSF微服务平台及ServiceMesh技术实践</a></td>
</tr>
<tr>
<td>一七三</td>
<td><a href="http://dockone.io/article/5716" target="_blank" rel="noopener">全面学习Prometheus</a></td>
</tr>
<tr>
<td>一七二</td>
<td><a href="http://dockone.io/article/5501" target="_blank" rel="noopener">Kubernetes网络安全之访问控制技术实践</a></td>
</tr>
<tr>
<td>一七一</td>
<td><a href="http://dockone.io/article/5418" target="_blank" rel="noopener">TalkingData的Spark On Kubernetes实践</a></td>
</tr>
<tr>
<td>一七〇</td>
<td><a href="http://dockone.io/article/5293" target="_blank" rel="noopener">贝壳找房权限服务的探索和实践</a></td>
</tr>
<tr>
<td>一六九</td>
<td><a href="http://dockone.io/article/5269" target="_blank" rel="noopener">Helm：强大的Kubernetes包管理工具</a></td>
</tr>
<tr>
<td>一六八</td>
<td><a href="http://dockone.io/article/5268" target="_blank" rel="noopener">DBaaS在金融生产环境的落地实践</a></td>
</tr>
<tr>
<td>一六六</td>
<td><a href="http://dockone.io/article/4896" target="_blank" rel="noopener">Kubernetes on DC/OS最佳实践</a></td>
</tr>
<tr>
<td>一六五</td>
<td><a href="http://dockone.io/article/4892" target="_blank" rel="noopener">为什么Kubernetes天然适合微服务？</a></td>
</tr>
<tr>
<td>一六四</td>
<td><a href="http://dockone.io/article/4891" target="_blank" rel="noopener">扇贝网微服务编排和治理实践</a></td>
</tr>
<tr>
<td>一六三</td>
<td><a href="http://dockone.io/article/4645" target="_blank" rel="noopener">Kubernetes官方集群部署工具kubeadm原理解析</a></td>
</tr>
<tr>
<td>一六二</td>
<td><a href="http://dockone.io/article/4622" target="_blank" rel="noopener">新东方利用容器技术在用户自服务方面的探索</a></td>
</tr>
<tr>
<td>一六一</td>
<td><a href="http://dockone.io/article/4057" target="_blank" rel="noopener">聊聊Docker监控那点事儿</a></td>
</tr>
<tr>
<td>一六零</td>
<td><a href="http://dockone.io/article/3601" target="_blank" rel="noopener">基于Kubernetes的DevOps实践之路</a></td>
</tr>
<tr>
<td>一五九</td>
<td><a href="http://dockone.io/article/3300" target="_blank" rel="noopener">TensorFlow on Kubernetes的架构与实践</a></td>
</tr>
<tr>
<td>一五八</td>
<td><a href="http://dockone.io/article/3063" target="_blank" rel="noopener">Kubernetes存储系统介绍及机制实现</a></td>
</tr>
<tr>
<td>一五七</td>
<td><a href="http://dockone.io/article/3041" target="_blank" rel="noopener">一个可供参考的企业应用容器化实践案例</a></td>
</tr>
<tr>
<td>一五六</td>
<td><a href="http://dockone.io/article/3039" target="_blank" rel="noopener">由浅入深SCF无服务器云函数实践</a></td>
</tr>
<tr>
<td>一五五</td>
<td><a href="http://dockone.io/article/2992" target="_blank" rel="noopener">分布式配置中心架构与实战</a></td>
</tr>
<tr>
<td>一五四</td>
<td><a href="http://dockone.io/article/2990" target="_blank" rel="noopener">在项目实践中，如何进行容器化改造和DevOps建设？</a></td>
</tr>
<tr>
<td>一五三</td>
<td><a href="http://dockone.io/article/2988" target="_blank" rel="noopener">JDOS 2.0：Kubernetes的工业级实践</a></td>
</tr>
<tr>
<td>一五二</td>
<td><a href="http://dockone.io/article/2973" target="_blank" rel="noopener">东方国信基于Kubernetes构建容器云平台的实践和思考</a></td>
</tr>
<tr>
<td>一五一</td>
<td><a href="http://dockone.io/article/2965" target="_blank" rel="noopener">Docker在测试中的应用</a></td>
</tr>
<tr>
<td>一五〇</td>
<td><a href="http://dockone.io/article/2931" target="_blank" rel="noopener">小型公司DevOps落地实践案例</a></td>
</tr>
<tr>
<td>一四九</td>
<td><a href="http://dockone.io/article/2885" target="_blank" rel="noopener">Kubernetes调度详解</a></td>
</tr>
<tr>
<td>一四八</td>
<td><a href="http://dockone.io/article/2867" target="_blank" rel="noopener">Kubernetes的多集群管理实践</a></td>
</tr>
<tr>
<td>一四七</td>
<td><a href="http://dockone.io/article/2845" target="_blank" rel="noopener">瓜子云的任务调度系统</a></td>
</tr>
<tr>
<td>一四六</td>
<td><a href="http://dockone.io/article/2799" target="_blank" rel="noopener">中小型互联网公司微服务实践之经验和教训</a></td>
</tr>
<tr>
<td>一四五</td>
<td><a href="http://dockone.io/article/2771" target="_blank" rel="noopener">乐高式微服务化改造</a></td>
</tr>
<tr>
<td>一四四</td>
<td><a href="http://dockone.io/article/2760" target="_blank" rel="noopener">BizCloud：基于Kubernetes的私有云实践</a></td>
</tr>
<tr>
<td>一四三</td>
<td><a href="http://dockone.io/article/2733" target="_blank" rel="noopener">FreeWheel基于Kubernetes容器云构建与实践：应用编排与服务质量保证</a></td>
</tr>
<tr>
<td>一四二</td>
<td><a href="http://dockone.io/article/2730" target="_blank" rel="noopener">容器云在万达的落地经验</a></td>
</tr>
<tr>
<td>一四一</td>
<td><a href="http://dockone.io/article/2721" target="_blank" rel="noopener">如何开发部署Kubernetes Native应用</a></td>
</tr>
<tr>
<td>一四零</td>
<td><a href="http://dockone.io/article/2677" target="_blank" rel="noopener">Serverless云函数架构精解</a></td>
</tr>
<tr>
<td>一三九</td>
<td><a href="http://dockone.io/article/2634" target="_blank" rel="noopener">基于Kubernetes的应用编排实践</a></td>
</tr>
<tr>
<td>一三八</td>
<td><a href="http://dockone.io/article/2616" target="_blank" rel="noopener">白话Kubernetes网络</a></td>
</tr>
<tr>
<td>一三七</td>
<td><a href="http://dockone.io/article/2602" target="_blank" rel="noopener">Kubernetes主机和容器的监控方案</a></td>
</tr>
<tr>
<td>一三六</td>
<td><a href="http://dockone.io/article/2583" target="_blank" rel="noopener">Kubernetes健康检查策略</a></td>
</tr>
<tr>
<td>一三五</td>
<td><a href="http://dockone.io/article/2575" target="_blank" rel="noopener">求取一份极致的简单：海量应用容器化改造之路</a></td>
</tr>
<tr>
<td>一三四</td>
<td><a href="http://dockone.io/article/2563" target="_blank" rel="noopener">国内某大型酒店管理集团基于Kubernetes的实践</a></td>
</tr>
<tr>
<td>一三三</td>
<td><a href="http://dockone.io/article/2529" target="_blank" rel="noopener">深入理解Kubernetes网络策略</a></td>
</tr>
<tr>
<td>一三二</td>
<td><a href="http://dockone.io/article/2520" target="_blank" rel="noopener">58 赶集基于 Docker的自动化部署实践</a></td>
</tr>
<tr>
<td>一三一</td>
<td><a href="http://dockone.io/article/2513" target="_blank" rel="noopener">Juice——一种基于MesosFramework的任务云框架</a></td>
</tr>
<tr>
<td>一三零</td>
<td><a href="http://dockone.io/article/2504" target="_blank" rel="noopener">探究PaaS网络模型设计</a></td>
</tr>
<tr>
<td>一二九</td>
<td><a href="http://dockone.io/article/2485" target="_blank" rel="noopener">聊聊Service Mesh：linkerd</a></td>
</tr>
<tr>
<td>一二八</td>
<td><a href="http://dockone.io/article/2476" target="_blank" rel="noopener">容器化部署OpenStack的正确姿势</a></td>
</tr>
<tr>
<td>一二八</td>
<td><a href="http://dockone.io/article/2468" target="_blank" rel="noopener">容器如何监控？</a></td>
</tr>
<tr>
<td>一二七</td>
<td><a href="http://dockone.io/article/2447" target="_blank" rel="noopener">Docker的另类用法，就是这么简单粗暴</a></td>
</tr>
<tr>
<td>一二六</td>
<td><a href="http://dockone.io/article/2446" target="_blank" rel="noopener">Kubernetes在微服务化游戏中的探索实践</a></td>
</tr>
<tr>
<td>一二五</td>
<td><a href="http://dockone.io/article/2428" target="_blank" rel="noopener">深信服容器云的负载均衡实现</a></td>
</tr>
<tr>
<td>一二四</td>
<td><a href="http://dockone.io/article/2424" target="_blank" rel="noopener">轻松筹监控系统实现方案</a></td>
</tr>
<tr>
<td>一二三</td>
<td><a href="http://dockone.io/article/2405" target="_blank" rel="noopener">如何扩展Kubernetes管理的资源对象</a></td>
</tr>
<tr>
<td>一二二</td>
<td><a href="http://dockone.io/article/2392" target="_blank" rel="noopener">探索Kubernetes的网络原理及方案</a></td>
</tr>
<tr>
<td>一二一</td>
<td><a href="http://dockone.io/article/2371" target="_blank" rel="noopener">喜马拉雅FM测试环境的Docker化实践案例</a></td>
</tr>
<tr>
<td>一二〇</td>
<td><a href="http://dockone.io/article/2351" target="_blank" rel="noopener">基于Kubernetes的私有容器云建设实践</a></td>
</tr>
<tr>
<td>一一九</td>
<td><a href="http://dockone.io/article/2345" target="_blank" rel="noopener">Elastic-Job-Cloud作业云在当当的SRE实践</a></td>
</tr>
<tr>
<td>一一八</td>
<td><a href="http://dockone.io/article/2335" target="_blank" rel="noopener">容器技术在企业级服务里的实践</a></td>
</tr>
<tr>
<td>一一七</td>
<td><a href="http://dockone.io/article/2322" target="_blank" rel="noopener">沪江容器化运维实践</a></td>
</tr>
<tr>
<td>一一六</td>
<td><a href="http://dockone.io/article/2308" target="_blank" rel="noopener">某股份制商业银行定制化PaaS介绍</a></td>
</tr>
<tr>
<td>一一五</td>
<td><a href="http://dockone.io/article/2261" target="_blank" rel="noopener">基于Neutron的Kubernetes SDN实践经验之谈</a></td>
</tr>
<tr>
<td>一一四</td>
<td><a href="http://dockone.io/article/2248" target="_blank" rel="noopener">Jenkins在Google Cloud的自动化安装</a></td>
</tr>
<tr>
<td>一一三</td>
<td><a href="http://dockone.io/article/2227" target="_blank" rel="noopener">从一个实际案例来谈容器落地的问题</a></td>
</tr>
<tr>
<td>一一二</td>
<td><a href="http://dockone.io/article/2216" target="_blank" rel="noopener">Flannel中vxlan backend的原理和实现</a></td>
</tr>
<tr>
<td>一一一</td>
<td><a href="http://dockone.io/article/2191" target="_blank" rel="noopener">LAIN 平台远程进入容器功能设计与实现</a></td>
</tr>
<tr>
<td>一一零</td>
<td><a href="http://dockone.io/article/2180" target="_blank" rel="noopener">Docker在沪江落地的实践</a></td>
</tr>
<tr>
<td>一零九</td>
<td><a href="http://dockone.io/article/2145" target="_blank" rel="noopener">中小型团队的容器化之路</a></td>
</tr>
<tr>
<td>一零八</td>
<td><a href="http://dockone.io/article/2114" target="_blank" rel="noopener">基于Jenkins和Kubernetes的CI工作流</a></td>
</tr>
<tr>
<td>一零七</td>
<td><a href="http://dockone.io/article/2098" target="_blank" rel="noopener">SRE工程实践——基于时间序列存储数据的报警</a></td>
</tr>
<tr>
<td>一零六</td>
<td><a href="http://dockone.io/article/2077" target="_blank" rel="noopener">乐视云基于Kubernetes的PaaS平台建设</a></td>
</tr>
<tr>
<td>一零五</td>
<td><a href="http://dockone.io/article/2021" target="_blank" rel="noopener">度量驱动的DevOps转型</a></td>
</tr>
<tr>
<td>一零四</td>
<td><a href="http://dockone.io/article/2019" target="_blank" rel="noopener">艺龙部署体系的演进</a></td>
</tr>
<tr>
<td>一零三</td>
<td><a href="http://dockone.io/article/2016" target="_blank" rel="noopener">Kubernetes 有状态集群服务部署与管理</a></td>
</tr>
<tr>
<td>一零二</td>
<td><a href="http://dockone.io/article/1992" target="_blank" rel="noopener">基于容器的日志管理实践</a></td>
</tr>
<tr>
<td>一零一</td>
<td><a href="http://dockone.io/article/1976" target="_blank" rel="noopener">构建容器服务平台（CaaS</a></td>
</tr>
<tr>
<td>一零零</td>
<td><a href="http://dockone.io/article/1971" target="_blank" rel="noopener">构建支持多编排引擎的容器基础设施服务</a></td>
</tr>
<tr>
<td>九十九</td>
<td><a href="http://dockone.io/article/1925" target="_blank" rel="noopener">海航生态科技舆情大数据平台容器化改造</a></td>
</tr>
<tr>
<td>九十八</td>
<td><a href="http://dockone.io/article/1902" target="_blank" rel="noopener">Insta360容器化&amp;DevOps之路</a></td>
</tr>
<tr>
<td>九十七</td>
<td><a href="http://dockone.io/article/1863" target="_blank" rel="noopener">现有系统实施微服务架构改进经验分享</a></td>
</tr>
<tr>
<td>九十六</td>
<td><a href="http://dockone.io/article/1847" target="_blank" rel="noopener">爱油科技基于SpringCloud的微服务实践</a></td>
</tr>
<tr>
<td>九十五</td>
<td><a href="http://dockone.io/article/1833" target="_blank" rel="noopener">树莓派上的Docker集群管理</a></td>
</tr>
<tr>
<td>九十四</td>
<td><a href="http://dockone.io/article/1815" target="_blank" rel="noopener">唯品会基于Kubernetes的网络方案演进</a></td>
</tr>
<tr>
<td>九十三</td>
<td><a href="http://dockone.io/article/1806" target="_blank" rel="noopener">魅族云Docker实践</a></td>
</tr>
<tr>
<td>九十二</td>
<td><a href="http://dockone.io/article/1803" target="_blank" rel="noopener">如何使用 Node.js 和 Docker构建高质量的微服务</a></td>
</tr>
<tr>
<td>九十一</td>
<td><a href="http://dockone.io/article/1798" target="_blank" rel="noopener">打造百亿级数据处理量的弹性调度容器平台</a></td>
</tr>
<tr>
<td>九十</td>
<td><a href="http://dockone.io/article/1794" target="_blank" rel="noopener">猎豹移动基于CoreOS在AWS上的项目实践</a></td>
</tr>
<tr>
<td>八十九</td>
<td><a href="http://dockone.io/article/1779" target="_blank" rel="noopener">恒生金融交易系统的Docker化实践</a></td>
</tr>
<tr>
<td>八十八</td>
<td><a href="http://dockone.io/article/1775" target="_blank" rel="noopener">PPTV聚力传媒的Docker与DevOps</a></td>
</tr>
<tr>
<td>八十七</td>
<td><a href="http://dockone.io/article/1767" target="_blank" rel="noopener">基于Docker的开发云提高资源利用率的实践</a></td>
</tr>
<tr>
<td>八十六</td>
<td><a href="http://dockone.io/article/1734" target="_blank" rel="noopener">深入解析DC/OS 1.8——高可靠的微服务及大数据管理平台</a></td>
</tr>
<tr>
<td>八十五</td>
<td><a href="http://dockone.io/article/1729" target="_blank" rel="noopener">Docker存储方式选型建议</a></td>
</tr>
<tr>
<td>八十四</td>
<td><a href="http://dockone.io/article/1724" target="_blank" rel="noopener">Docker在B站的实施之路</a></td>
</tr>
<tr>
<td>八十三</td>
<td><a href="http://dockone.io/article/1713" target="_blank" rel="noopener">Acttao 开发、运维容器化实践</a></td>
</tr>
<tr>
<td>八十二</td>
<td><a href="http://dockone.io/article/1704" target="_blank" rel="noopener">基于Docker技术的CI&amp;CD实践</a></td>
</tr>
<tr>
<td>八十一</td>
<td><a href="http://dockone.io/article/1691" target="_blank" rel="noopener">唯品会数据库备份恢复容器化项目实践经验总结</a></td>
</tr>
<tr>
<td>八十</td>
<td><a href="http://dockone.io/article/1687" target="_blank" rel="noopener">云计算应用技术发展与企业异构资源池统一管理案例分析</a></td>
</tr>
<tr>
<td>七十九</td>
<td><a href="http://dockone.io/article/1658" target="_blank" rel="noopener">基于容器技术构建企业级PaaS云平台实践</a></td>
</tr>
<tr>
<td>七十八</td>
<td><a href="http://dockone.io/article/1651" target="_blank" rel="noopener">中英人寿保险有限公司基于容器技术的实践分享</a></td>
</tr>
<tr>
<td>七十七</td>
<td><a href="http://dockone.io/article/1640" target="_blank" rel="noopener">用Harbor实现容器镜像仓库的管理和运维</a></td>
</tr>
<tr>
<td>七十六</td>
<td><a href="http://dockone.io/article/1636" target="_blank" rel="noopener">容器化ICT融合初体验</a></td>
</tr>
<tr>
<td>七十五</td>
<td><a href="http://dockone.io/article/1616" target="_blank" rel="noopener">应用容器化之Kubernetes实践</a></td>
</tr>
<tr>
<td>七十四</td>
<td><a href="http://dockone.io/article/1610" target="_blank" rel="noopener">传统金融 IT 对混合云管理的一些思考</a></td>
</tr>
<tr>
<td>七十三</td>
<td><a href="http://dockone.io/article/1601" target="_blank" rel="noopener">SAP Anywhere产品背后CD的实现</a></td>
</tr>
<tr>
<td>七十二</td>
<td><a href="http://dockone.io/article/1600" target="_blank" rel="noopener">Kubernetes容器集群中的日志系统集成实践</a></td>
</tr>
<tr>
<td>七十一</td>
<td><a href="http://dockone.io/article/1582" target="_blank" rel="noopener">基于Docker的负载均衡和服务发现</a></td>
</tr>
<tr>
<td>七十</td>
<td><a href="http://dockone.io/article/1573" target="_blank" rel="noopener">浅谈Docker安全合规建设</a></td>
</tr>
<tr>
<td>六十九</td>
<td><a href="http://dockone.io/article/1553" target="_blank" rel="noopener">微服务选型之Modern Node.js</a></td>
</tr>
<tr>
<td>六十八</td>
<td><a href="http://dockone.io/article/1541" target="_blank" rel="noopener">应用容器env化实战</a></td>
</tr>
<tr>
<td>六十七</td>
<td><a href="http://dockone.io/article/1518" target="_blank" rel="noopener">互联网场景下闪存优化测试和应用</a></td>
</tr>
<tr>
<td>六十六</td>
<td><a href="http://dockone.io/article/1489" target="_blank" rel="noopener">Docker 网络方案初探</a></td>
</tr>
<tr>
<td>六十五</td>
<td><a href="http://dockone.io/article/1476" target="_blank" rel="noopener">公有云上的容器实践分享</a></td>
</tr>
<tr>
<td>六十四</td>
<td><a href="http://dockone.io/article/1445" target="_blank" rel="noopener">基于Docker实现DevOps的一些探索</a></td>
</tr>
<tr>
<td>六十三</td>
<td><a href="http://dockone.io/article/1397" target="_blank" rel="noopener">传统企业PaaS平台功能设计与业务上云思考</a></td>
</tr>
<tr>
<td>六十二</td>
<td><a href="http://dockone.io/article/1355" target="_blank" rel="noopener">站在运维的角度讲如何打造一个Docker-Mesos平台</a></td>
</tr>
<tr>
<td>六十一</td>
<td><a href="http://dockone.io/article/1347" target="_blank" rel="noopener">虚拟化老兵介绍虚拟化技术</a></td>
</tr>
<tr>
<td>六十</td>
<td><a href="http://dockone.io/article/1326" target="_blank" rel="noopener">容器的配置管理</a></td>
</tr>
<tr>
<td>五十九</td>
<td><a href="http://dockone.io/article/1289" target="_blank" rel="noopener">基于Docker的分布式服务研发实践</a></td>
</tr>
<tr>
<td>五十八</td>
<td><a href="http://dockone.io/article/1267" target="_blank" rel="noopener">基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系之大二层网络</a></td>
</tr>
<tr>
<td>五十七</td>
<td><a href="http://dockone.io/article/1257" target="_blank" rel="noopener">Docker容器对存储的定义（Volume 与 Volume Plugin</a></td>
</tr>
<tr>
<td>五十六</td>
<td><a href="http://dockone.io/article/1253" target="_blank" rel="noopener">Kubernetes代码贡献者谈Kubernetes的发展动态</a></td>
</tr>
<tr>
<td>五十五</td>
<td><a href="http://dockone.io/article/1232" target="_blank" rel="noopener">阿里云容器服务设计实践</a></td>
</tr>
<tr>
<td>五十四</td>
<td><a href="http://dockone.io/article/1213" target="_blank" rel="noopener">双模IT给你的企业装上双引擎</a></td>
</tr>
<tr>
<td>五十三</td>
<td><a href="http://dockone.io/article/1195" target="_blank" rel="noopener">搜狐基于Docker+Kubernetes的一站式运维管理实践</a></td>
</tr>
<tr>
<td>五十二</td>
<td><a href="http://dockone.io/article/1182" target="_blank" rel="noopener">DCOS中监控和弹性伸缩方案经验分享</a></td>
</tr>
<tr>
<td>五十一</td>
<td><a href="http://dockone.io/article/1172" target="_blank" rel="noopener">基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系</a></td>
</tr>
<tr>
<td>五十</td>
<td><a href="http://dockone.io/article/1169" target="_blank" rel="noopener">太保DCOS平台——微信项目实践</a></td>
</tr>
<tr>
<td>四十九</td>
<td><a href="http://dockone.io/article/1137" target="_blank" rel="noopener">Kubernetes集成外部服务实践</a></td>
</tr>
<tr>
<td>四十八</td>
<td><a href="http://dockone.io/article/1106" target="_blank" rel="noopener">微博的MySQL数据库优化实践经验</a></td>
</tr>
<tr>
<td>四十七</td>
<td><a href="http://dockone.io/article/1091" target="_blank" rel="noopener">Docker在乐视的实践之路</a></td>
</tr>
<tr>
<td>四十六</td>
<td><a href="http://dockone.io/article/1044" target="_blank" rel="noopener">一个关于不可变基础设施的实践案例</a></td>
</tr>
<tr>
<td>四十五</td>
<td><a href="http://dockone.io/article/1017" target="_blank" rel="noopener">基于Docker搭建轻量的私有构建环境</a></td>
</tr>
<tr>
<td>四十四</td>
<td><a href="http://dockone.io/article/996" target="_blank" rel="noopener">IT基础架构的自动化编排</a></td>
</tr>
<tr>
<td>四十三</td>
<td><a href="http://dockone.io/article/982" target="_blank" rel="noopener">基于OVS的Docker多主机互联设计和实践</a></td>
</tr>
<tr>
<td>四十二</td>
<td><a href="http://dockone.io/article/958" target="_blank" rel="noopener">关于混合云的一点思考</a></td>
</tr>
<tr>
<td>四十一</td>
<td><a href="http://dockone.io/article/942" target="_blank" rel="noopener">思源基于Docker和OpenStack的私有云平台实践</a></td>
</tr>
<tr>
<td>四十</td>
<td><a href="http://dockone.io/article/930" target="_blank" rel="noopener">用Docker和Git搭建在线开发环境</a></td>
</tr>
<tr>
<td>三十九</td>
<td><a href="http://dockone.io/article/916" target="_blank" rel="noopener">基于Docker和Git的持续集成工作流</a></td>
</tr>
<tr>
<td>三十八</td>
<td><a href="http://dockone.io/article/904" target="_blank" rel="noopener">容器服务如何在企业客户落地？Rancher解决之道分享。</a></td>
</tr>
<tr>
<td>三十七</td>
<td><a href="http://dockone.io/article/883" target="_blank" rel="noopener">玩转Docker镜像和镜像构建</a></td>
</tr>
<tr>
<td>三十六</td>
<td><a href="http://dockone.io/article/869" target="_blank" rel="noopener">基于Mesos，面向业务企业级云平台的实战分享</a></td>
</tr>
<tr>
<td>三十五</td>
<td><a href="http://dockone.io/article/860" target="_blank" rel="noopener">微服务架构云端应用</a></td>
</tr>
<tr>
<td>三十四</td>
<td><a href="http://dockone.io/article/852" target="_blank" rel="noopener">搭建企业私有Docker Registry实战分享</a></td>
</tr>
<tr>
<td>三十三</td>
<td><a href="http://dockone.io/article/831" target="_blank" rel="noopener">接触AWS近5年，谈谈我的运维经验</a></td>
</tr>
<tr>
<td>三十二</td>
<td><a href="http://dockone.io/article/812" target="_blank" rel="noopener"> 一篇文章带你了解Cloud Native</a></td>
</tr>
<tr>
<td>三十一</td>
<td><a href="http://dockone.io/article/801" target="_blank" rel="noopener">细节｜谈谈CoreOS的etcd</a></td>
</tr>
<tr>
<td>三十</td>
<td><a href="http://dockone.io/article/799" target="_blank" rel="noopener">Docker1.9新特性解读</a></td>
</tr>
<tr>
<td>二十九</td>
<td><a href="http://dockone.io/article/795" target="_blank" rel="noopener">蘑菇街基于Docker的私有云实践</a></td>
</tr>
<tr>
<td>二十八</td>
<td><a href="http://dockone.io/article/776" target="_blank" rel="noopener">OCI标准和runC原理解读</a></td>
</tr>
<tr>
<td>二十七</td>
<td><a href="http://dockone.io/article/753" target="_blank" rel="noopener">中兴软创（ZTEsoft基于Jenkins和Docker的CI实践</a></td>
</tr>
<tr>
<td>二十六</td>
<td><a href="http://dockone.io/article/747" target="_blank" rel="noopener">Docker Registry V1 to V2</a></td>
</tr>
<tr>
<td>二十五</td>
<td><a href="http://dockone.io/article/740" target="_blank" rel="noopener">企业级云平台的实践和思考</a></td>
</tr>
<tr>
<td>二十四</td>
<td><a href="http://dockone.io/article/722" target="_blank" rel="noopener">容器和IaaS：谁动了谁的奶酪</a></td>
</tr>
<tr>
<td>二十三</td>
<td><a href="http://dockone.io/article/718" target="_blank" rel="noopener">暴走漫画的Docker实践</a></td>
</tr>
<tr>
<td>二十二</td>
<td><a href="http://dockone.io/article/700" target="_blank" rel="noopener">基于Docker和Java的持续集成实践</a></td>
</tr>
<tr>
<td>二十一</td>
<td><a href="http://dockone.io/article/675" target="_blank" rel="noopener">Mesos在去哪儿网的应用</a></td>
</tr>
<tr>
<td>二十</td>
<td><a href="http://dockone.io/article/662" target="_blank" rel="noopener">Docker三剑客之Swarm介绍</a></td>
</tr>
<tr>
<td>十九</td>
<td><a href="http://dockone.io/article/635" target="_blank" rel="noopener">畅谈PaaS</a></td>
</tr>
<tr>
<td>十八</td>
<td><a href="http://dockone.io/article/618" target="_blank" rel="noopener">一篇文章带你了解Flannel</a></td>
</tr>
<tr>
<td>十七</td>
<td><a href="http://dockone.io/article/600" target="_blank" rel="noopener">360的容器化之路</a></td>
</tr>
<tr>
<td>十六</td>
<td><a href="http://dockone.io/article/578" target="_blank" rel="noopener">闲谈Kubernetes的主要特性和经验分享</a></td>
</tr>
<tr>
<td>十五</td>
<td><a href="http://dockone.io/article/563" target="_blank" rel="noopener">如何在裸机中自动安装部署CoreOS和Kubernetes</a></td>
</tr>
<tr>
<td>十四</td>
<td><a href="http://dockone.io/article/537" target="_blank" rel="noopener">腾讯蓝鲸数据平台之告警系统</a></td>
</tr>
<tr>
<td>十三</td>
<td><a href="http://dockone.io/article/519" target="_blank" rel="noopener">十个问题带你了解WindowsDocker</a></td>
</tr>
<tr>
<td>十二</td>
<td><a href="http://dockone.io/article/505" target="_blank" rel="noopener">新浪是如何分析处理32亿条实时日志的？</a></td>
</tr>
<tr>
<td>十一</td>
<td><a href="http://dockone.io/article/487" target="_blank" rel="noopener">DockerCon 见闻</a></td>
</tr>
<tr>
<td>十</td>
<td><a href="http://dockone.io/article/478" target="_blank" rel="noopener">跨主机的 –link</a></td>
</tr>
<tr>
<td>九</td>
<td><a href="http://dockone.io/article/470" target="_blank" rel="noopener">持续集成和”云”</a></td>
</tr>
<tr>
<td>八</td>
<td><a href="http://dockone.io/article/445" target="_blank" rel="noopener">OpenStack Magnum社区及项目介绍</a></td>
</tr>
<tr>
<td>七</td>
<td><a href="http://dockone.io/article/425" target="_blank" rel="noopener">基于Hypervisor的Docker引擎——Hyper</a></td>
</tr>
<tr>
<td>六</td>
<td><a href="http://dockone.io/article/416" target="_blank" rel="noopener">新浪SCE Docker最佳实践</a></td>
</tr>
<tr>
<td>五</td>
<td><a href="http://dockone.io/article/402" target="_blank" rel="noopener">Docker网络详解及Libnetwork前瞻</a></td>
</tr>
<tr>
<td>四</td>
<td><a href="http://dockone.io/article/383" target="_blank" rel="noopener">AppC和Docker的对比</a></td>
</tr>
<tr>
<td>三</td>
<td><a href="http://dockone.io/article/375" target="_blank" rel="noopener">Docker Registry的定制和性能分析</a></td>
</tr>
<tr>
<td>二</td>
<td><a href="http://dockone.io/article/355" target="_blank" rel="noopener">集群规模下日志处理和网络方案</a></td>
</tr>
<tr>
<td>一</td>
<td><a href="http://dockone.io/article/346" target="_blank" rel="noopener">Dockerfile与Docker构建流程解读</a></td>
</tr>
</tbody>
</table>
]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>docker</tag>
        <tag>分享</tag>
        <tag>DockOne 微信分享汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>给 VMware vSphere 用户的 Kubernetes 简介</title>
    <url>/archives/Kubernetes-Introduction-for-VMware-Users-zh.html</url>
    <content><![CDATA[<h2 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h2><ul>
<li>2019-12-10 初步开始翻译</li>
<li>2019-12-11 补充完整</li>
<li>2019-12-20 校稿</li>
</ul>
<h2 id="README"><a href="#README" class="headerlink" title="README"></a>README</h2><p>本文翻译自 <a href="https://blogs.vmware.com/cloudnative/2017/10/25/kubernetes-introduction-vmware-users/" target="_blank" rel="noopener">Kubernetes Introduction for VMware Users – Part 1: The Theory</a></p>
<p>By Hany Michaels, Senior Staff Solutions Architect NSBU, VMware</p>
<p>October 25, 2017</p>
<p>四六级未过的工地英语翻译、希望各位读者雅正翻译不当的部分😁</p>
<blockquote>
<h2 id="Kubernetes-Introduction-for-VMware-Users-–-Part-1-The-Theory"><a href="#Kubernetes-Introduction-for-VMware-Users-–-Part-1-The-Theory" class="headerlink" title="Kubernetes Introduction for VMware Users – Part 1: The Theory"></a>Kubernetes Introduction for VMware Users – Part 1: The Theory</h2></blockquote>
<h2 id="给-VMware-用户的-Kubernetes-简介——第一部分：理论"><a href="#给-VMware-用户的-Kubernetes-简介——第一部分：理论" class="headerlink" title="给 VMware 用户的 Kubernetes 简介——第一部分：理论"></a>给 VMware 用户的 Kubernetes 简介——第一部分：理论</h2><blockquote>
<p>This is the second part of my “Kubernetes in the Enterprise” blog series. As I mentioned in my <a href="http://www.hanymichaels.com/2017/10/04/kubernetes-in-the-enterprise-a-vmware-guide-on-how-to-design-deploy-and-operate-k8saas-with-nsx-t-and-vra/" target="_blank" rel="noopener">last article</a>, it is important to get everyone to the same level of understanding about Kubernetes (<a href="https://kubernetes.io/" target="_blank" rel="noopener">K8s</a>) before we can proceed to the design and implementation guides.</p>
</blockquote>
<p>这是我的“ kubernetes 在企业中应用” 博客系列的第二篇文章。正如我在上一篇文章提到的，在我们继续设计与实现指南之前，重要的是让每个人对 kubernetes 的理解都是相同水平的。</p>
<blockquote>
<p>I am not going to take the traditional approach here to explain the Kubernetes architecture and technologies. I will explain everything through comparisons with the <a href="https://www.vmware.com/products/vsphere.html" target="_blank" rel="noopener">vSphere platform</a> that you, as a VMware user, are already familiar with. You can say that this was the approach I would have liked someone to use to introduce K8s to me. The latter could be very confusing and overwhelming to understand at the beginning. I’d like to add also that I used this approach internally at VMware to introduce Kubernetes to some audiences from different practices, and it has proven to work great and get people up to speed with the core concepts.</p>
</blockquote>
<p>在这里，我不打算采用传统的方法来讲解 Kubernetes 的架构和技术。我将通过与 <a href="https://www.vmware.com/products/vsphere.html" target="_blank" rel="noopener">vSphere 平台</a> 的比较来为你解释所有的概念，对你来讲 VMware 已经相当熟悉了。你可以说，这就是我希望别人向我介绍 k8s 的方法。后者在一开始可能会让人感到非常困惑和难以理解。我还想补充一点，我在 VMware 内部也是使用这种方法向来自不同实践的听众们介绍 Kubernetes。</p>
<blockquote>
<p>An important note before we kick this off: I am not using this comparison for the sake of it, or to prove any similarities or differences between vSphere and Kubernetes. Both are distributed systems at heart, and they must have similarities like any other similar system out there. What I am trying to achieve here at the end of the day is to introduce an incredible technology like Kubernetes to the broader VMware community.</p>
</blockquote>
<p>在此之前有一个重要提示：我不是为了介绍 Kubernetes 而使用这个比较，也不是为了证明 vSphere 和 Kubernetes 之间存在的任何异同之处。两者的核心都是分布式系统，它们肯定有着其他分布式系统的相似之处。最后，我想在这里实现的目标是向更广泛的 VMware 社区介绍像 Kubernetes 这样不可思议的技术。</p>
<p><img src="../img/kubernetes-architecture-1024x512.png" alt="Kubernetes"></p>
<blockquote>
<p>Figure: The Kubernetes overall architecture compared to vSphere</p>
</blockquote>
<p>图片：Kubernetes 和 vSphere 整体架构对比</p>
<blockquote>
<h2 id="A-little-bit-of-history"><a href="#A-little-bit-of-history" class="headerlink" title="A little bit of history"></a>A little bit of history</h2></blockquote>
<h2 id="插曲"><a href="#插曲" class="headerlink" title="插曲"></a>插曲</h2><blockquote>
<p>You should already be familiar with containers before reading this post. I am not going to go through those basics as I am sure there are so many resources out there that talk about this. What I see very often though when I speak with my customers is that they cannot make much sense of why containers have taken our industry by storm and become very popular in record time. To answer this question, and in fact set the context for what is coming, I may have to tell you a little bit about my history as a practical example of how I personally made sense of all the shift that is happening in our industry.</p>
</blockquote>
<p>在阅读这篇文章之前，你应该已经熟悉容器技术了。在此我就不再赘述这些基础知识了，因为我敢肯定网上有很多教程在讲解这些。不过，当我与客户交谈时，我经常注意到，他们无法理解为什么容器技术席有史以来席卷了我们的行业并变得非常流行。为了回答这个问题，并为接下来的内容做铺垫，我可能需要向你介绍一下我的历史，以此作为一个实际的例子，来阐述我个人如何理解行业中正在发生的转变。</p>
<blockquote>
<p>I used to be a web developer back in 2003 before I got introduced to the telecom world, and it was my second paying job after being a network engineer/admin. (I know, I was a jack-of-all-trades back then). I used to code in PHP, and I’ve done all sorts of applications from small internal apps used by my employer, to professional voting apps for TV programs, to telco apps interfacing with VSAT hubs and interacting with satellite systems. Life was great, except for one major hurdle that I am sure every developer can relate to: the dependencies.</p>
</blockquote>
<p>早在 2003 年进入电信行业之前，我刚成为一名 web 开发者，这是我在成为网络工程师/管理员之后的第二份有薪工作。（我知道，那时的我是个万事通）。我过去使用 PHP 编写代码，我开发过各种各样的应用，从我的雇主使用的小型内部应用，到电视节目的专业投票应用，再到与 VSAT 集线器接口和卫星系统交互的电信应用程序。生活是美好的，除了一个主要的障碍，我相信每个开发人员涉及到：依赖。</p>
<blockquote>
<p>I first code my app on my laptop using something like the LAMP stack, and when it works well, I upload the source code to the servers, be it hosted out on the internet (anyone remember RackShack?) or on private servers for our end-customers. As you can imagine, as soon as I do that, my app is broken and it just won’t work on those servers. The reason, of course, is that the dependencies I use (like Apache, PHP, MySQL, etc.) have different releases than what I used on my laptop. So I have to figure out a way to either upgrade those releases on the remote servers (bad idea) or just re-code what I did on my laptop to match the remote stacks (worse idea). It was a nightmare, and sometimes I hated myself and questioned why I’m doing this for a living.</p>
</blockquote>
<p>首先我在我的笔记本电脑上用 LAMP 技术栈编写我的应用程序。当就绪时，我上传源代码到托管在互联网的服务器上（谁还记得 RackShack？）或者我们终端客户的私有服务器上。可以想象，只要我这样做，我的应用程序是不完整的，它就无法在这些服务器上运行。原因当然是我在这些服务器上所使用的依赖环境（如 Apache、PHP、MySQL 等）的版本与我在笔记本电脑上使用的版本不同。因此，我必须想办法升级远程服务器上的这些版本（馊主意），或者只是重新编写我在笔记本电脑上所做的代码，以匹配远程技术栈（更糟糕的办法）。那是一场噩梦，有时我恨自己并质疑我为什么要这么做。</p>
<blockquote>
<p>Fast forward 10 years, and along came a company called Docker. I was a VMware consultant in professional services (2013) when I heard about Docker, and let me tell you that I couldn’t make any sense of that technology back in those days. I kept saying things like: “Why would I run containers when I can do that with VMs?” “Why would I give up important features like vSphere HA, DRS or vMotion for those weird benefits of booting up a container instantly or skipping the “hypervisor” layer?” In short, I was looking at this from a pure infrastructure perspective.</p>
</blockquote>
<p>快进10年，随之而来的是一家名为 Docker 的公司。当我听说 Docker 时，我是一名 VMware 专业服务顾问（2013 年）。你有所不知，那时的我对这种技术一无所知。我总是这样说：”为什么当我能够使用 VM 时非要运行容器呢？“，”我为什么要放弃重要特性，如 vSphere HA、DRS 或 vMotion，为了快速启动容器或跳过 <code>虚拟机管理程序</code>层所带来的好处？”。简而言之，我是从纯粹的基础架构角度来看待这个问题的。</p>
<blockquote>
<p>But then I started looking closer until it just hit me. Everything Docker is all about relates to developers. Only when I started thinking like one did it click. What if I had this technology back in 2003 and packaged my dependencies? My web apps would work no matter what server they run on. Better yet, I don’t have to keep uploading source code or setting up anything special. I can just “package” my app in an image and tell my customer to download that image and run it. That’s a web developer’s dream!</p>
</blockquote>
<p>但后来我开始基础容器技术，直到它刚刚冲击到我。Docker 的所有内容都与开发者有关。只有当我开始像一个人一样思考时，它才击中要害。如果我在 2003 年拥有此技术并打包了依赖关系，该怎么办？无论在什么服务器上运行，我的 Web 应用都会工作。更好的是，我不需要继续上传源代码或设置任何特别的东西。我可以在镜像中”打包”我的应用程序，并告诉我的客户下载该镜像并运行它。这是一个 web 开发者的梦想！</p>
<blockquote>
<p>Docker solved a huge issue for interop and packaging, but now what? As an enterprise customer, how can I operate this app at scale? I still want my HA, my DRS, my vMotion and my DR. It solved my developer problems and it created a whole bunch of new ones for my DevOps team. They need a platform to run those containers the same way they used to run VMs.</p>
</blockquote>
<p>Docker 解决了交互和打包的一个大问题，但现在怎么办？作为企业客户，我如何大规模操作此应用程序？我仍然想要我的 HA、我的 DRS、我的 vMotion 和我的 DR。它解决了我的开发人员的问题，并为我的 DevOps 团队创建了一大堆新的问题。他们需要一个平台来运行这些容器，就像他们用来运行 VM 一样。</p>
<blockquote>
<p>But then along came Google to tell the world that it has been actually running containers for years (and in fact invented them – Google: cgroups), and that the proper way to do that is through a platform they called Kubernetes. They then open sourced it, gave it as gift to the community, and that changed everything again.</p>
</blockquote>
<p>但是后来 Google 告诉世界，他们实际上运行容器很多年了（其实是他们发明的 - Google: cgroups），而这样做的正确方法是通过一个称为 Kubernetes平台，然后他们把 Kubernetes 作为礼物开源给了社区 ，这再次改变了一切。</p>
<blockquote>
<h2 id="Understanding-Kubernetes-by-comparing-it-to-vSphere"><a href="#Understanding-Kubernetes-by-comparing-it-to-vSphere" class="headerlink" title="Understanding Kubernetes by comparing it to vSphere"></a>Understanding Kubernetes by comparing it to vSphere</h2></blockquote>
<h2 id="通过和-vSphere-的比较来理解-Kubernetes"><a href="#通过和-vSphere-的比较来理解-Kubernetes" class="headerlink" title="通过和 vSphere 的比较来理解 Kubernetes"></a>通过和 vSphere 的比较来理解 Kubernetes</h2><blockquote>
<p>So what is Kubernetes? Simply put: it is to containers what vSphere was for VMs to make them data center ready. If you used to run VMware Workstation back in the early 2000s, you know that they were not seriously considered for running inside data centers. Kubernetes brings a way to run and operate containers in a production-ready manner. This is why we will start to compare vSphere side-by-side with Kubernetes in order to explain the details of this distributed system and get you up to speed on its features and technologies.</p>
</blockquote>
<p>那么什么是 Kubernetes 呢？简单地说：Kubernetes 之于容器就像 vSphere 之于 VM 为 VM 准备好数据中心。如果你曾经在 21 世纪初运行过 VMware 工作站，你知道他们并未认真考虑在数据中心内部运行。Kubernetes 带来了一种以生产可用的方式来运行和操作容器的方法。这就是为什么我们将开始将 vSphere 与 Kubernetes 进行横向比较，以便解释此分布式系统的细节，并让你快速了解 Kubernetes 的特性和技术。</p>
<p><img src="../img/p2p3-1024x375.png" alt="Kubernetes"></p>
<blockquote>
<p>Figure: The VM evolution from Workstation to vSphere compared to the current evolution for containers to Kubernetes</p>
</blockquote>
<p>图片：从容器到 Kubernetes 的与VM 从 Workstation 到 vSphere 演进的对比</p>
<blockquote>
<h2 id="System-Overview"><a href="#System-Overview" class="headerlink" title="System Overview"></a>System Overview</h2></blockquote>
<h2 id="系统概览"><a href="#系统概览" class="headerlink" title="系统概览"></a>系统概览</h2><blockquote>
<p>Just like vSphere’s vCenter and ESXi hosts, Kuberentes has the concept of master and nodes. In this context, the K8s master is equivalent to vCenter in that it is the management plane of the distributed system. It is also the APIs’ entry point where you interact with your workloads management. Similarly, the K8s nodes act as the compute resources like ESXi hosts. This is where you run your actual workloads (in K8s’ case we call them pods). The nodes could be virtual machines or physical servers. In vSphere’s case, of course, the ESXi hosts have to be physical always.</p>
</blockquote>
<p>与 vSphere 的 vCenter 和 ESXi 主机一样，Kuberentes 具有 master 节点和 node 节点的概念。在此处，K8s 中的 master 等效于 vCenter，因为它是分布式系统中的控制平面。也是你在集群中管理工作负载的 API 的入口。同样，K8s 中的节点充当像 ESXi 主机一样的计算资源。这里运行着实际工作负载（在 K8s 的实例中，我们称之为 Pod）。节点可以是虚拟机或物理服务器。当然，在 vSphere 中，ESXi 主机必须是物理机。</p>
<p><img src="../img/kubernetes-system-1024x624.png" alt="Kubernetes"></p>
<p>You can see also that K8s has a key-value store called “etcd.” It is similar to vCenter Server DB in that you store the cluster configuration as the desired state you want to adhere to there.</p>
<blockquote>
<p>你还可以看到 K8s 具有名为”etcd”的数据库来存储键值对。它类似于 vCenter 服务器 DB，将群集配置存储为你期望的期望状态。</p>
</blockquote>
<blockquote>
<p>On the differences side, K8s master can also run workloads, but vCenter cannot. The latter is just a virtual appliance dedicated to management. In K8s master case, it’s still considered a compute resource, but it’s not a good idea to run enterprise apps on it. Only system related apps would be fine.</p>
</blockquote>
<p>不同的是，K8s master 节点也可以运行工作负载，但 vCenter 不能运行。后者只是专用于管理的虚拟机。在 K8s master 节点，它仍然被视为计算资源，但并不建议用来运行企业应用。 master 节点只适合运行与 kubernetes 系统相关的应用。</p>
<blockquote>
<p>So, how does this look in the real world? You will mainly use CLI to interact with this system (GUI is also a viable option). In the screenshot below, you can see that I am using a Windows machine to connect to my Kubernetes cluster via command like (I am using cmder in case you are wondering). We see in the screenshot that I have one master and 4 x nodes. They run K8s v1.6.5, and the nodes operating system is Ubuntu 16.04. At the time of this writing, we are mainly living in a Linux world where your master and nodes are always based on Linux distributions.</p>
</blockquote>
<p>那么，在现实世界中是怎样的呢？你将主要使用 CLI 与此系统进行交互（GUI 也是一个可行的选项）。在下面的截图中，你可以看到我在 Windows 计算机上使用类似的命令（使用的是 cmder）连接到我的 Kubernetes 群集。我们在截图中看到，我有一个 master 节点和 4 个 node 节点。集群运行 K8s v1.6.5，节点操作系统为 Ubuntu 16.04。在撰写本文时，我们主要生活在 Linux 世界中，master 节点和 node 节点始终基于 Linux 发行版。</p>
<p><img src="../img/clidash-1024x563.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Workloads-Form-factor"><a href="#Workloads-Form-factor" class="headerlink" title="Workloads Form-factor"></a>Workloads Form-factor</h2></blockquote>
<h2 id="工作负载"><a href="#工作负载" class="headerlink" title="工作负载"></a>工作负载</h2><blockquote>
<p>In vSphere, a virtual machine is the logical boundary of an operating system. In Kubernetes, pods are the boundaries for containers. Just like an ESXi host that can run multiple VMs, a K8s node can run multiple pods. Each Pod gets a routed IP address just like VMs to communicate with other pods.</p>
</blockquote>
<p>在 vSphere 中，虚拟机是操作系统的逻辑边界。而在 Kubernetes ，pods 是容器的边界。与可以运行多个 VM 的 ESXi 主机一样，K8s 节点可以运行多个 Pod。每个 Pod 获取路由 IP 地址，就像 VM 一样与其他 Pod 进行通信。</p>
<blockquote>
<p>In vSphere, applications run inside OS. In Kubernetes, applications run inside containers. A VM can run one single OS, while a Pod can run multiple containers.</p>
</blockquote>
<p>在 vSphere 中，应用程序在操作系统内运行。而在 Kubernetes 中，应用程序在容器内运行。VM 可以运行单个操作系统，而 Pod 却可以运行多个容器。</p>
<p><img src="../img/kubernetes-pods-1024x486.png" alt="Kubernetes"></p>
<blockquote>
<p>This is how you can list the pods inside a K8s cluster using the kubectl tool from the CLI. You can check the health of the pods, the age, the IP addresses and the nodes they are currently running inside.</p>
</blockquote>
<p>这是使用 CLI 中的 kubectl 工具列出 K8s 群集中的 Pod 的方式。你可以检查 Pod 的运行状况、创建时间、IP 地址以及它们当前运行在哪个节点。</p>
<p><img src="../img/cli2-1024x450.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Management"><a href="#Management" class="headerlink" title="Management"></a>Management</h2></blockquote>
<h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><blockquote>
<p>So how do we manage our master, nodes and pods? In vSphere, we use the Web Client to manage most (if not all) the components in our virtual infrastructure. This is almost the same with Kubernetes with the use of the Dashboard. It is a nice GUI-based web portal where you can access your browser similarly to  Web Client. We’ve also seen in the previous sections that you can manage your K8s cluster using the kubectl command from the CLI. It’s always debatable where you will spend most of your time — the CLI or the Dashboard, especially because the latter is becoming more powerful every day (check <a href="https://www.youtube.com/watch?v=3lhf7T9Bp2E" target="_blank" rel="noopener">this video</a> for more details). I personally find the Dashboard very convenient for quickly monitoring the health or showing the details of the various K8s components rather than typing long commands. It’s a preference, and you will find the balance between them naturally.</p>
</blockquote>
<p>那么，我们如何管理主机、节点和 Pod 呢？在 vSphere 中，我们使用 Web 客户端来管理虚拟化基础架构中的大多数（如果不是全部）组件。这和在 Kubernetes 使用仪表盘一样。这是一个通过浏览器访问、基于 GUI 、类似于 web 客户端的门户网站。我们在前几节中还看到，你可以使用  kubectl 命令来管理 K8s 群集。你总是在大部分时间里花在哪里——CLI 或仪表盘，特别是因为后者每天都在变得更强大（请查看<a href="https://www.youtube.com/watch?v3lhf7T9Bp2E" target="_blank" rel="noopener">此视频</a>，了解更多详情）。我个人认为仪表盘非常方便，可以快速查看运行状况或显示各种 k8s 组件的详细信息，而不是输入很长的命令。这是个人喜好，你会自然地在两者之间找到平衡。</p>
<p><img src="../img/kubernetes-management-1024x469.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Configurations"><a href="#Configurations" class="headerlink" title="Configurations"></a>Configurations</h2></blockquote>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><blockquote>
<p>One of the very profound concepts in Kubernetes is the desired state of configurations. You declare what you want for almost any Kubernetes component through a YAML file, and you create that using your kubectl (or through dashboard) as your desired state. Kubernetes will always strive from this moment on to keep that as a running state in your environment. For example, if you want to have four replicas of one pod, K8s will keep monitoring those pods. If one dies or the nodes it’s running have issues, it will self-heal and automatically create that pod somewhere else.</p>
</blockquote>
<p>Kubernetes 中非常重要的概念之一是所描述的配置状态。通过 YAML 文件几乎可以声明任何 Kubernetes 组件所需的资源，并使用 kubectl 命令（或通过仪表盘）创建该对象作为所描述的状态。从创建后开始，在你的集群中Kubernetes 始终会努力将保持为所描述的运行状态。例如，如果要有一个 pod 的四个副本，K8s 将继续监视这些pod。如果一个 pod 挂掉或它正在运行的节点有问题，它将自我修复，并自动在其他节点创建该 pod 。</p>
<blockquote>
<p>Back to our YAML configuration files — you can think of them like a .VMX file for a VM, or a .OVF descriptor for a virtual appliance that you want to deploy in vSphere. Those files define the configuration of the workload/component you want to run. Unlike VMX/OVF files that are exclusive to VMs/Appliances, the YAML configuration files are used to define any K8s component like ReplicaSets, Services, Deployments, etc. as we will see in the coming sections.</p>
</blockquote>
<p>回到我们的 YAML 配置文件 — 你可以将它们想象成 一个描述 VM 或 的 .VMX 文件或者在 vSphere 中部署虚拟设备所需的 .OVF 描述符文件。这些文件定义要运行的工作负载/组件的配置。与 VMX/OVF 文件是 VM/设备独有的不同的是，YAML 配置文件用于定义任何 K8s 组件，如 ReplicaSets、Services、 Deployments 等，我们将在下一节中讨论。</p>
<p><img src="../img/kubernetes-confiugrations-1024x511.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Virtual-Clusters"><a href="#Virtual-Clusters" class="headerlink" title="Virtual Clusters"></a>Virtual Clusters</h2></blockquote>
<h2 id="虚拟化集群"><a href="#虚拟化集群" class="headerlink" title="虚拟化集群"></a>虚拟化集群</h2><p>In vSphere, we have physical ESXi hosts grouped logically to form clusters. We can slice those clusters into other virtual clusters called “Resource Pools.” Those resource pools are mostly used for capping resources. In Kubernetes, we have something very similar. We call them “namespaces,” and they could also be used to ensure resource quotas as we will see in the next section. They are most commonly used, however, as a means of multi-tenancy across applications (or users if you are using shared K8s clusters). This is also one of the ways  we can perform security segmentation with NSX-T across those namespaces as we will see in future posts.</p>
<p>在 vSphere 中，我们将 ESXi 物理机逻辑分组以形成群集。我们可以将这些群集分割成其他虚拟化群集，称为”资源池”。这些资源池主要用于限制资源。在 Kubernetes 中，我们有一些非常相似的东西。我们称之为”命名空间”，它们还可用于确保资源配额，我们将在下一节中看到。但是，它们最常用作跨应用程序（或者使用共享 K8s 群集的用户）的多租户方法。这也是我们可以在这些命名空间使用 NSX-T 执行安全分段的方法之一，我们将在以后的帖子中看到。</p>
<p><img src="../img/kubernetes-namespaces-1024x651.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Resource-Management"><a href="#Resource-Management" class="headerlink" title="Resource Management"></a>Resource Management</h2></blockquote>
<h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><blockquote>
<p>As I mentioned in the previous section, namespaces in Kubernetes are commonly used as a means of segmentation. The other use case for it is resource allocation, and it is referred to as “Resource Quotas.” As we saw in previous sections, the definition of that is through YAML configuration files where we declare the desirted state. In vSphere, we similarly define this from the Resource Pools settings as you see in the screenshot below.</p>
</blockquote>
<p>正如我在上一节中提到的那样，Kubernetes 中通常用命名空间来进行划分。它的另一个用途是资源分配，称之为”资源配额”。正如我们在前面各节中所看到的，它的定义是通过 YAML 配置文件来声明期所望的状态。在 vSphere 中，我们同样从资源池设置中定义这一点，如下图所示。</p>
<p><img src="../img/kubernetes-resource-quotas.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Workloads-Identification"><a href="#Workloads-Identification" class="headerlink" title="Workloads Identification"></a>Workloads Identification</h2></blockquote>
<h2 id="标记工作负载"><a href="#标记工作负载" class="headerlink" title="标记工作负载"></a>标记工作负载</h2><blockquote>
<p>This is fairly easy and almost identical between vSphere and Kubernetes. In the former, we use the concepts of tags to identify or group similar workloads, while in the latter we use the term “labels” to do this. In Kubernetes’ case, this is mandatory where we use things like “selectors” to identify our containers and apply the different configurations for them.</p>
</blockquote>
<p>标记工作负载相当容易且 vSphere 和 Kubernetes 几乎一样。在 vSphere 中，我们使用 tags 的概念来识别或分组相似的工作负载，而在 Kubernetes 中，我们使用术语”labels”来执行此操作。在 Kubernetes 的案例中，我们强制使用”选择器”之类来识别我们的容器并为其应用不同的配置。</p>
<p><img src="../img/kubernetes-labels-1024x331.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Redundancy"><a href="#Redundancy" class="headerlink" title="Redundancy"></a>Redundancy</h2></blockquote>
<h2 id="冗余"><a href="#冗余" class="headerlink" title="冗余"></a>冗余</h2><blockquote>
<p>Now to the real fun. If you were/are a big fan of vSphere FT like me, you will love this feature in Kubernetes despite some differences in the two technologies. In vSphere, this is a VM with a running instance and a shadow one in a lock-step. We record the instructions from the running instance and replay it in the shadow VM. If the running instance goes down, the shadow VM kicks in immediately. vSphere then tries to find another ESXi host to bring another shadow instance to maintain the same redundancy. In Kubernetes, we have something very similar here. The ReplicaSets are a number you specify to run multiple instances of a pod. If one pod goes down, the other instances are available to serve the traffic. In the same time, K8s will try to bring up a substitute for that pod on any available node to maintain the desired state of the configuration. The major difference, as you may have already noticed, is that in the case of K8s, the pod instances are always live and service traffic. They are not shadowed workloads.</p>
</blockquote>
<p>精彩现在开始。如果你和我一样热衷于 vSphere FT，在 Kubernetes 中你会喜欢这个特性，尽管这两个技术有一些差异。在 vSphere 中，vSphere FT 是一个具有正在运行的 VM 影子实例 。我们记录正在运行的实例中的指令，并在卷影 VM 中重新执行它。如果正在运行的实例出现故障，则卷影 VM 会立即启动。然后，vSphere 会尝试寻找另一台 ESXi 主机，来导入另一个卷影 VM 实例以维护相同的冗余。在 Kubernetes 中也有类似的特性。副本集用来运行指定的数量 pod 的实例。如果一个 pod 出现故障，则其他 pod 实例可继续对外流量提服务。与此同时，K8s 将尝试将该 pod 调度到任何可用节点上，以维持配置文件所描述的状态。你可能已经注意到，主要区别是，在 K8s 中，pod 实例始终是存活状态并对外提供服务，它们并不是隐藏的工作负载。</p>
<p><img src="../img/kuberentes-replicasets-1024x546.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Load-Balancing"><a href="#Load-Balancing" class="headerlink" title="Load Balancing"></a>Load Balancing</h2></blockquote>
<h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><blockquote>
<p>While this might not be a built-in feature in vSphere, it is still a common thing to run load-balancers on that platform. In the vSphere world, we have either virtual or physical load-balancers to distribute the network traffic across multiple VMs. This could be running in many different configuration modes, but let’s assume here that we are referring to the one-armed configuration. In this case, you are load-balancing your network traffic east-west to your VMs.</p>
</blockquote>
<p>虽然负载均衡可能不是 vSphere 中的内置功能，但在该平台上运行负载均衡器很普遍。在 vSphere 中，我们有虚拟或物理负载均衡器，用于在多个 VM 之间均衡网络流量。这可能在许多不同的配置模式下运行，但让我们在这里假设我们指的是单兵配置。在这种情况下，你将从东到西到 VM 的网络流量进行负载平衡。</p>
<blockquote>
<p>Similarly in Kubernetes, we have the concepts of “Services.” A K8s Service could also be used in different configuration modes, but let’s pick the “ClusterIP” configuration here to compare to the one-armed LB. In this case, our K8s Service will have a virtual IP (VIP) that is always static and does not change. This VIP will distribute the traffic across multiple pods. This is especially important in the Kubernetes world were pods are ephemeral by nature and where you lose the pod IP address the moment it dies or gets deleted. So you have to always be able to maintain a static VIP.</p>
</blockquote>
<p>同样，在 Kubernetes 中，我们有”服务”的概念。K8s 服务，但让我们在这里选择”ClusterIP”配置，以便与单臂 LB 进行比较。在这种情况下，我们的 K8s 服务将有一个始终静态且不会更改的虚拟 IP （VIP）。此 VIP 将在多个 Pod 上分配流量。这一点在 Kubernetes 世界尤其重要，因为吊舱本质上是短暂的，当你死或被删除的时候，你失去了 pod IP地址。因此，你必须始终能够维护静态 VIP。</p>
<blockquote>
<p>As I mentioned, the Services have many other configurations like “NodePort,” where you basically assign a port on the node level and then do a port-address-translation down to the pods. There is also the “LoadBalancer,” where you spin up an LB instance from a 3rd-party or a cloud provider.</p>
</blockquote>
<p>正如我提到的， Services 具有许多其他配置，如”NodePort”，其中你基本上在节点级别上分配一个端口，然后向下到 Pod 执行端口地址转换。还有”LoadBalancer”，从第三方或云提供商启动 LB 实例。</p>
<p><img src="../img/kubernetes-services-1024x389.png" alt="Kubernetes"></p>
<blockquote>
<p>There is another very important load-balancing mechanism in Kuberentes called “Ingress Controller.” You can think of this like an in-line application load-balancer. The core concept behind this is that an ingress-controller (in a form of pod) would be spun up with an externally visible IP address, and that IP could have something like a wild card DNS record. When traffic hits an ingress-controller using the external IP, it will inspect the headers and determine through a set of rules you pre-define to which pod that hostname should belong. Example: <em>sphinx-v1</em>.esxcloud.net will be directed to the service “sphinx-svc-1”, while the <em>sphinx-v2</em>.esxcloud.net will be directed to the service “sphinx-svc2” and so on and so forth.</p>
</blockquote>
<p>在 Kuberentes 中还有另一个非常重要的负载均衡机制，称之为” Ingress 控制器”。你可以把它当作一个在线应用负载均衡器。The core concept behind this is that an ingress-controller (in a form of pod) would be spun up with an externally visible IP address, and that IP could have something like a wild card DNS record. 当流量使用 external IP 进入 ingress 控制器时，它将检查请求头部并通过主机名来判断流量应属于哪个一组 pod 。示例：<em>sphinx-v1</em>.esxcloud.net 将定向到服务”sphinx-svc-1”，而 <em>sphinx-v2</em>.esxcloud.net 将重定向到服务”sphinx-svc2”等。</p>
<p><img src="../img/kubernetes-ingress-1024x532.png" alt="Kubernetes"></p>
<blockquote>
<h2 id="Storage-amp-Networking"><a href="#Storage-amp-Networking" class="headerlink" title="Storage &amp; Networking"></a>Storage &amp; Networking</h2></blockquote>
<h2 id="存储和网络"><a href="#存储和网络" class="headerlink" title="存储和网络"></a>存储和网络</h2><blockquote>
<p>Storage and networking are rich topics when it comes to Kubernetes. It is almost impossible to talk briefly about these two topics in an introduction blog post, but you can be sure that I will be blogging in details soon about the different concepts and options for each subject. For now, let’s quickly examine how the networking stack works in Kubernetes since we will have a dependency on it in a later section.</p>
</blockquote>
<p>当谈到到 Kubernetes 时，存储和网络是重点关注的话题。在介绍性的博客文章中简要地谈论这两个主题几乎是不可能的，但你可以肯定，我将很快在博客上详细介绍每个主题的不同概念和特性。现在，让我们快速研究一下网络堆栈在 Kubernetes 中是如何工作的，因为我们将在后面的一节中依赖于它。</p>
<blockquote>
<p>Kubernetes has different networking “plugins” that you can use to set up your nodes and pods network. One of the common plugins is “kubenet,” which is currently used on mega-clouds like Google Cloud Provider (GCP) and Amazon Web Services. I am going to talk briefly here about the GCP implementation and then show you a practical example later to examine this yourself on Google Container Engine (GKE).</p>
</blockquote>
<p>Kubernetes 具有不同的网络”插件”，你可以使用这些插件来设置节点和 Pod 网络。常见的插件之一是”kubenet”，它目前用于像谷歌云提供商（GCP）和亚马逊网络服务这样的云服务商巨头。我将在这里简要地谈谈 GCP 的实现，然后向你展示一个可以在谷歌容器引擎（GKE）上亲自研究的实例。</p>
<p><img src="../img/gke-kubernetes-networking-1024x747.png" alt="Kubernetes"></p>
<blockquote>
<p>This might be a bit too much to take in from a first glance, but hopefully you will be able to make sense of all that by the end of this blog post. First, we see that we have two Kubernetes nodes here: node 1 and node (m). Each node has an eth0 interface like any Linux machine, and that interface has an IP address to the external world—in our case here on subnet 10.140.0.0/24. The upstream L3 device is acting as our default gateway to route our traffic. This could be a L3 switch in your data center or a VPC router in a public cloud like GCP as we will see later. So far so good?</p>
</blockquote>
<p>乍一看，这也许有点太过分了，但希望你能在博客文章的结尾理解这一切。首先，我们看到我们这里有两个 Kubernetes 节点：节点 1 和节点 （m）。每个节点都像其他 Linux 机器一样具有 eth0 接口，并且该接口具有 10.140.0.0/24 子网内的 IP 地址。上游 L3 设备充当我们的默认网关，用于路由我们的流量。这可能是数据中心中的 L3 交换机，也可以是公共云中的 VPC 路由器（如 GCP），我们稍后将对此进行介绍。目前为止，还可以理解吗？</p>
<blockquote>
<p>Next, we see inside the node that we have a <strong>cbr0</strong> bridge interface. That interface has the default gateway of an IP subnet—10.40.1.0/24 in case of node 1. This subnet gets assigned by Kubernetes to each node. The latter usually get a /24 subnet, but you can control that in case of NSX-T as we will see in future posts. For now, this subnet is the one that we will allocate the pod’s IP addresses from. Any pod inside node 1 will get an IP address from this subnet rage—in our case here, Pod 1 has an IP address of 10.40.1.10. Notice however that this pod has two nested containers within. Remember, a pod can run one or more containers that are tightly coupled together in terms of functionality. This is what we see here. Container 1 is listening to port 80, while container 2 is listening to port 90. Both containers share the same IP address of 10.40.1.10. but they do not own that networking namespace. Alright, so who owns this networking stack then? It’s actually a special container that we call the “Pause Container.” You see it in the diagram as the interface of that pod to the outer world. It owns this networking stack, including the IP address 10.40.1.10 and, of course, it forwards the traffic to container 1 using port 80 and traffic to container 2 using port 90.</p>
</blockquote>
<p>接下来，我们看到在节点内，有一个 <code>cbr0</code> 网桥接口。该接口具有 IP 子网的默认网关 —在节点 1 的情况下—：10.40.1.0/24。此子网由 Kubernetes 分配给每个节点。后者通常得到一个 24 位的子网，但你可以控制在 NSX-T 的情况下，我们将在以后的帖子中看到。现在，此子网是我们将从中分配 Pod 的 IP 地址的子网。节点 1 内的任何 pod 都将从此子网中获得 IP 地址， 在我们的实例中，Pod 1 的 IP 地址为 10.40.1.10。但请注意，此 pod 内有两个容器。请记住，pod 可以运行一个或多个在功能方面紧密相关的容器。这就是我们在这里看到的。容器 1 监听端口 80，而容器 2 监听端口 90。两个容器共享同一个 IP 地址 10.40.1.10。但他们并不独自拥有网络命名空间。好吧，那么谁拥有这个网络堆栈呢？它实际上是一个特殊容器，我们称之为” puse 容器”。在图中，你将其视为该 pod 与外部世界的接口。它拥有此网络堆栈，包括 IP 地址 10.40.1.10，当然，它使用端口 80 将流量转发到容器 1，使用端口 90 将流量转发到容器 2。</p>
<blockquote>
<p>Now you should be asking, how is traffic forwarded to the external world? You see that we have a standard Linux IP forwarding enabled here to forward the traffic from cbr0 to eth0. This is great, but then how does the L3 device know how to forward this to the destination? We do not have dynamic routing here to advertise this network in this particular example. And so, this is why we need to have some kind of “static route” on that L3 device to know that in order to reach subnet 10.40.1.0/24, your entry point is the external IP of node 1 (10.140.0.11), and in order to reach subnet 10.40.2.0/24, your next hope is node (m) with the IP address 10.140.0.12.</p>
</blockquote>
<p>现在你可能会问，流量是如何转发到集群外的呢？你看，我们在此启用了标准的 Linux IP 转发功能，将流量从 cbr0 转发到 eth0。这是非常棒的，但然后 L3 设备如何知道如何转发到目的地？在此特定示例中，我们没有动态路由来通告此网络。因此，这就是为什么我们需要有某种”静态路由”在 L3 设备上知道，为了达到子网10.40.1.0/24，你的入口点是节点1（10.140.0.11）的外部IP，并为了达到子网10.40.2.0/24，你的下一跳（m） 与 IP 地址 10.140.0.12。</p>
<blockquote>
<p>This is great, but you must be thinking that it’s a very unpractical way to manage your networks. This would be an absolute nightmare for network administrators to maintain all those routes as you scale with your cluster. And you’re right—this is why we need some kind of solution like the CNI (container network plugin) in Kubernetes to use a networking mechanism to manage this for you. NSX-T is one of those solutions with a powerful design for both the networking and security stacks.</p>
</blockquote>
<p>这太好了，但你一定认为，这是一个非常不实际的方式来管理你的网络。对于网络管理员来说，在与群集进行扩展时维护所有这些路由绝对是一场噩梦。你说得对，这就是为什么我们需要某种解决方案，如 Kubernetes 中的CNI（容器网络插件），以使用网络机制为你管理。NSX-T 是这些解决方案之一，具有强大的网络和安全堆栈设计。</p>
<blockquote>
<p>Remember, we are examining here the kubernetes plugin, not CNI. The former is what GKE uses, and the way they do this is quite fascinating as it’s completely programmable and automated on their cloud. Those subnet allocations and associated routes are taken care of by GCP for you, as we will see in the next part.</p>
</blockquote>
<p>请记住，我们正在测试 kubernetes 插件而不是CNI。前者是 GKE 使用的，他们这样做的方式是相当棒的，因为它是完全可编程和自动化的云。这些子网分配和相关路由由 GCP 为你负责，我们将在下一部分中看到。</p>
]]></content>
      <tags>
        <tag>翻译</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>(2000个) kubernetes 社群分享 QA 汇总</title>
    <url>/archives/kubernetes-QA.html</url>
    <content><![CDATA[<h3 id="README"><a href="#README" class="headerlink" title="README"></a>README</h3><p>内容主要来自在社群里<a href="http://dockone.io/" target="_blank" rel="noopener">dockone</a>有关企业 Kubernetes 实践过程的直播分享，下面截取聊天记录的自 QA 部分 。由于提问链接在石墨文档上协作编辑，而石墨文档里的内容是无法被搜索引擎检索到的。这些问题不整理起来就永远地躺尸在石墨文档了，所以就把这些提问的问题汇总到一起，方便大家自查。</p>
<h3 id="2020-01-07：电视云服务的容器化实践"><a href="#2020-01-07：电视云服务的容器化实践" class="headerlink" title="2020-01-07：电视云服务的容器化实践"></a>2020-01-07：电视云服务的容器化实践</h3><p><a href="https://shimo.im/docs/PvCx8HcKPXPjdhHd" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q1：微服务代理，能详细说说嘛？</p>
</blockquote>
<p>A：一般两个作用，统一服务地址和负载均衡，可以用 LVS + Nginx 。在我们的业务中，有些业务逻辑解耦给了代理服务（统一网关），比如 JWT 用户统一认证等等，还有一些涉及业务逻辑的，比如电视抢红包，用随机算法只将一部分流量放到后端，进而使用了 OpenResty/Lua 组合。</p>
<blockquote>
<p>Q2：监控使用的啥？</p>
</blockquote>
<p>A：当前监控使用 sysinner/innerstack 内置的监控功能，基于 docker/sdk-golang 和 leveldb-go, 结合一些前端开发工作（主要是 chart 展现）</p>
<blockquote>
<p>Q3：微服务改动时，代理是如何感知的？是否要频繁重启代理？这一块是怎么实现的?</p>
</blockquote>
<p>A：微服务改动，先将配置推送到代理服务，再操作容器，LVS和Nginx/OpenResty变更配置不需要重启，当然这个地方也需要容器应用配合，避免容器之间直接通信。</p>
<blockquote>
<p>Q5：lxcfs部分的说明缺失，你们是怎么处理容器内读取cpu memory一些指标反而读取到宿主机配置的呢？(目前已知JDK8 131之前也存在这个问题，另外可以通过修改文件系统获取到正确指标)希望得到解答，谢谢。</p>
</blockquote>
<p>A：lxcfs 部分我们是参考了 pouch-container 里面的方案，只不过是创建容器时把 lxcfs 包含的目录 mount 到容器中即可</p>
<blockquote>
<p>Q6：使用XFS限制容器挂载的目录大小具体是怎么做的呢？能否说下思路和相关参考</p>
</blockquote>
<p>A：一般前端业务，容器挂载目录只存放日志，10GB左右。后端涉及到数据持久的应用，比如 MySQL ，SSDB 这个按照业务预估，一般 50 ~ 500 GB 。具体可以搜索 “xfs quota , project quota”</p>
<blockquote>
<p>Q7：你们线上基于Docker单节点部署服务吗？</p>
</blockquote>
<p>A：单节点有测试服务器；其实单结点和集群对于 docker 的操作时一样的</p>
<blockquote>
<p>Q8：有没有根据业务负载来操作容器伸缩（增减）的功能</p>
</blockquote>
<p>A：有，比如元旦、春节前期，按照预估扩容VPS时，会预留部分资源，正式上线运行中如果有模块负载高，会实时把这个模块推送到预留资源；如果没有富余机器了，就按照优先级把部分模块降级服务</p>
<blockquote>
<p>Q9：CPU 限制这一块能细说一下吗？貌似用的更多的是CPUshare？</p>
</blockquote>
<p>A：比如给一个容器 2 cores 资源，则 –cpu-period=1000000 –cpu-quota=20000000 –cpusets-cpus=0,1 (cat /proc/cpuinfo)</p>
<blockquote>
<p>Q10：可以问一下视频存储用什么，还有搜索服务用什么搜索引擎，还有发布版本的时候，数据库结构更改怎么做到不停机更新的，作为一个小白我很好奇</p>
</blockquote>
<p>A：视频存储用传统企业盘柜； 搜索用 sphinxsearch + 定制修改；数据库一般准备两套，如果升级涉及数据库变更（可能锁表），则是暂停写业务，再操作 （这个期间查询业务不受影响）</p>
<blockquote>
<p>Q11:公有云的流媒体视频资源怎么做到低延时高带宽分发到不同地域的终端上的的，多地部署、运营商专线？</p>
</blockquote>
<p>A： 这个当然是公有云服务商 CDN</p>
<hr>
<h3 id="2020-01-02-：为你写诗：3-步搭建-Serverless-AI-应用"><a href="#2020-01-02-：为你写诗：3-步搭建-Serverless-AI-应用" class="headerlink" title="2020-01-02 ：为你写诗：3 步搭建 Serverless AI 应用"></a>2020-01-02 ：为你写诗：3 步搭建 Serverless AI 应用</h3><p><a href="https://shimo.im/docs/WjgJJR3pTQKyYDJj" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q1：这个FUNCRAFT是ALI YUN定制的吗？有没有可以量化可以说明的支持并发计算量的内容呢?我理解是通过API屏蔽了容器和ECS对吗？</p>
</blockquote>
<p>A1：Funcraft 是 aliyun 函数计算自己开发的工具。函数计算的默认最大并发度是100（更高的值需要开工单），每秒请求数 * 请求处理时间（秒） = 最大并发度， 更多细节可以参考<a href="https://help.aliyun.com/knowledge_detail/56103.html?spm=a2c4g.11186623.6.739.1958265ayXAmXW#concurrency-limit" target="_blank" rel="noopener">函数计算的文档</a> 。函数计算不仅仅屏蔽了容器和 ECS 这些计算资源，还屏蔽了负载均衡，自动伸缩，网络资源和共享存储等一系列的基础设置，所以才被称作 Serverless。</p>
<blockquote>
<p>Q2：预留资源的函数计算不就和弹性容器一样了吗？那么函数计算的最大优势并不能体现出来?</p>
</blockquote>
<p>A2: 预留和按量是可以结合使用的。真实业务的负载往往是有基础的部分和变化的部分，所以函数计算推出预留可以以更低的成本来处理掉那基础不变部分的负载。当然弹性容器也可以处理基础部分。但是如果让用户把应用部署成弹性容器和函数计算相结合形式，那对应用的架构要求会比较高，所以预留和按量的结合的形式也可以降低用户的使用门槛。</p>
<blockquote>
<p>Q3: 在做微服务开发本身就是把各类应用逻辑接口化!这个函数式计算是否就是微服务的先决环节呢？</p>
</blockquote>
<p>A3: 函数计算也可以理解为微服务的一种形式。有人认为FaaS 是下一代的微服务。微服务相对于单体服务来说，解决了两方面的问题。一方面，不同业务模块有更清晰的边界，不同模块支持以不同速度进行迭代。另外一方面，不同部署模块的负载和对稳定性的要求不同，可以更细粒度的去调节不同模块的实例个数。而函数计算（FaaS）采用了按量或者按照请求进行调度的方式，也就是说在 FaaS 平台下，如果某些业务模块没有访问量，实例个数可以收缩到零。虽然微服务架构也能弹性收缩，但是没法收缩到零。理论上 FaaS 进一步提高资源的利用率。</p>
<blockquote>
<p>Q4: 对于数据面与控制面分开funcraft有没更好的理解呢?(指的是函数式计算接口是只考虑时延，速度以及成本，还是有从数据和控制层面整体优化考虑的呢)谢谢!</p>
</blockquote>
<p>A4:  funcraft 只是函数计算的工程工具，一个命令行而已。函数计算平台是有分数据平面和控制平面的。控制平面又有细分，用户可操作的和平台可操作的。函数计算暴露给用户的控制比较少，比如扩缩容是自动的，不需要用户干预。</p>
<blockquote>
<p>Q5: FaaS 场景下文件过大问题,具体是什么问题？</p>
</blockquote>
<p>A5: FaaS 为了达到百毫秒的延时，会要求应用的打包不大于 50M，这个限制会影响到很多应用，比如 Python 装一个 Tenserflow 就上百 M，java 随便搞个 web 应用也可以大几十 M。我们通过将 FC 和 NAS 服务结合，把一部分库和数据放到了 NAS 上，然后运行时加载，以解决大文件包冷启动过慢的问题。</p>
<hr>
<h3 id="2019-12-26：如何在Kubernetes中编写自定义控制器"><a href="#2019-12-26：如何在Kubernetes中编写自定义控制器" class="headerlink" title="2019-12-26：如何在Kubernetes中编写自定义控制器"></a>2019-12-26：如何在Kubernetes中编写自定义控制器</h3><p><a href="https://shimo.im/docs/RCj3QYjQcjxJQhrC" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q1：crd如何解决验证参数合法性的问题？</p>
</blockquote>
<p>A：这个知识点也是本文欠缺的，可以通过 Open API v3 schema 进行验证</p>
<blockquote>
<p>Q2：yaml文件如果最小化展示</p>
</blockquote>
<p>A：kubernetes 有很多默认属性的，这需要具体查文档呀</p>
<blockquote>
<p>Q3：operator本身挂了怎么办？依赖其他系统重新调度吗？</p>
</blockquote>
<p>A：operator 本身要是挂了，自定义资源的控制器是不能工作的，这时其他的调度系统也不能代替的</p>
<blockquote>
<p>Q4：有什么方法可以监控并保存pod的cpu，mem使用情况，并将他们保存入数据库或者生成cvs文件？</p>
</blockquote>
<p>A：prometheus，可以看看 prometheus operator</p>
<blockquote>
<p>Q5：怎么解决crd升级的问题，比如更改字段，但是已有服务已经运行</p>
</blockquote>
<p>A：这是 kubernetes 的控制器通过获取资源资源的实际运行状态与期望的状态对比，如果不相同则删除老的pod然后拉起期望的pod</p>
<blockquote>
<p>Q6：假如我想通过cpu负载的预测值改变pod数量，我如何将预测函数加入自定义控制器，从而改变pod数量？</p>
</blockquote>
<p>A：理论上讲这部分逻辑写到控制器的 reconcile 函数中是没问题的。但是我觉得更应该从调度策略上解决这个问题，即在调度时通过策略选择合适的节点。</p>
<blockquote>
<p>Q7：接着上面问题，改变pod数量时，可否通过函数判断，先使用垂直伸缩在进行水平伸缩，那请问如何实现垂直伸缩？</p>
</blockquote>
<p>A：不知你说的垂直伸缩是不是意味给pod分配更多的资源。如果是可以通过自编控制时定义资源属性，用户可以自定义对应的资源属性实现垂直伸缩</p>
<blockquote>
<p>Q9：能否讲解下reflector具体工作原理</p>
</blockquote>
<p>A：大致为下面：1. 通过反射器实现对指定类型对象的监控 2. DeltaFiFo队列，将上一步监控到有变化的对象加入到队列中3.并将队列缓存到本地，并根据事件类型注册相应的事件4. 最后将对象pop到work queue供control loop触发上一步注册的事件函数</p>
<blockquote>
<p>Q10：触发更新事件时，代码里如何获取到cr更新之前的状态？</p>
</blockquote>
<p>A：通过包 k8s.io/api/core/v1</p>
<blockquote>
<p>Q12: 如何在一个对象控制器的eventHander中触发另外一个资源controller的Reconcile入队呢?</p>
</blockquote>
<p>A： 理论上kubernetes控制器是在监测到资源的创建/更新/删除事件后，会自动去触发reconcile函数。我觉得我们做kubernetes二次开发首先要遵循kubernetes的编程规范呀</p>
<hr>
<h3 id="2019-12-19：阿里云如何基于标准-K8s-打造边缘计算云原生基础设施"><a href="#2019-12-19：阿里云如何基于标准-K8s-打造边缘计算云原生基础设施" class="headerlink" title="2019-12-19：阿里云如何基于标准 K8s 打造边缘计算云原生基础设施"></a>2019-12-19：阿里云如何基于标准 K8s 打造边缘计算云原生基础设施</h3><p><a href="https://shimo.im/docs/KH6cCkrKHW33CJx6" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q1：如何适配不同的平台？OS不同（linux及各种发行版、非linux）、硬件架构不同（x86、ARM等等）。不同平台的节点能在同一个集群内管理吗？</p>
</blockquote>
<p>A1：可以的；当前ack@edge支持OS类型：linux（centos、ubuntu），windows server；CPU架构：X86，arm边缘节点接入；支持异构节点在同一个集群管理；k8s管控托管在云上，异构节点的支持主要在边缘端实施；</p>
<blockquote>
<p>Q2：如何应对worker节点网络不一定通的问题，通过servicename或者clusterIP是否还能访问？</p>
</blockquote>
<p>A2: 分两个角度：1. ACK@Edge提供了完整的标准的k8s能力，所以servicename和clusterIP默认是可以work的；2. 如果worker节点间网络不通，那么Pod间东西向流量是不可达的；所以我们扩展了service的scope能力，service的流量只会被限制在一组网络可达的节点之间转发（就是分享中提到的edgeunit）；</p>
<blockquote>
<p>Q： 边缘能自治到什么程度，还能正常做增删改查吗？apiserver资源发生变化时节点还能感知和同步吗？目前如果触发了边缘自治，对我的应用程序会有哪些影响？</p>
</blockquote>
<p>A3: 首先，明确边缘自治工作的时机是在边缘节点和云端管控失联后，此时为了防止脑裂云端会限制相关应用和节点资源的操作；apiserver资源的变化只能够在网络恢复后同步到worker节点，并且网络恢复后，woker节点相关的资源状态仍然以apiserver数据为准；进入自治状态后，节点上agent和应用都只能够消费断网前一刻的资源状态，自治组件edgehub替代apiserver接管了所有发往apiserver的请求；</p>
<blockquote>
<p>Q： k8s具备很好的应用容灾能力，ack@edge在应用容灾方面具备哪些能力？</p>
</blockquote>
<p>A4: ack@edge就是标准的k8s；除了具备k8s原生的应用、资源管理能力之外，在边缘场景还提供了断网自治，元信息保持等等能力，这些也都是为应用容灾考虑；除此之外，因为提供的标准k8s完整能力，k8s周边生态servicemesh、knative等都能很好支持；</p>
<blockquote>
<p>Q： 项目是否有开源的计划</p>
</blockquote>
<p>A5: edgehub、edgetunnel、edgeunit、knative-edge等相关边缘能力都在开源流程中，敬请期待；</p>
<blockquote>
<p>Q：可否直接打通云，边，端的网络，比如我边上的pod访问云上的服务，直接通过servicename.namespace.cluster.svc.local，而不是用ingress暴露云上服务，目前kubeedge经过定制是具备这个能力的，还未做生产验证。,,,阿里的和kubeedge及k3s有什么区别</p>
</blockquote>
<p>A6: 这个问题的本质是容器网络能否跨云，边，端；在ack@edge中我们也支持overlay跨公网的安全方案，支持反向网络穿透打通云、边，支持VPN网络等；</p>
<blockquote>
<p>Q：ack@edge是否有提供原生k8s API?还是经过封装后的API?云边直连的安全问题，要把apiserver直接暴露到外网是不是不太安全？</p>
</blockquote>
<p>A7: ack@edge的设计理念是将原生的k8s托管在云上，支持接入边缘算力；用户可以很便捷的通过产品界面配置并生产出一个原生的高可用的k8s集群，并默认安装上支持边缘能力的addons和operator，因此边缘k8s提供了原生的API；云上apiserver通过阿里云slb暴露，对外提供服务，通过云上slb服务的安全能力结合k8s的认证、鉴权能力保证了云上apiserver的安全；</p>
<blockquote>
<p>Q： ack@edge容器化后的程序与激光雷达、深度相机、imu、com通信协议的底层控制板等传感器的通信和数据交互是如何进行的？是否能够提供稳定的数据交互通道？点云及图像数据的传输与直接运行在操作系统上的程序是否会有差别 ？</p>
</blockquote>
<p>A8: 应用容器化与否和对物联网协议的支持不冲突；传统的裸进程部署和容器化部署对应用而言是不感知的；数据通道需要依赖其他的物联网协议支持</p>
<blockquote>
<p>Q9：ack@edge在面向IoT设备接入是通过什么实现的？是通过容器加载的IoT PaaS还是有一些专门的组件支持，例如设备接入、M2M引擎、MQTT Broker、设备影子这些。</p>
<p>Q10: 请问operator为k8s带来的意义是什么呢？operator的应用现状可以给简单介绍吗。</p>
</blockquote>
<hr>
<h3 id="2019-12-18-：Open-Policy-Agent在Kubernetes中的应用"><a href="#2019-12-18-：Open-Policy-Agent在Kubernetes中的应用" class="headerlink" title="2019-12-18:：Open Policy Agent在Kubernetes中的应用"></a>2019-12-18:：Open Policy Agent在Kubernetes中的应用</h3><p><a href="https://shimo.im/docs/thXyGRP36CHpjvTk" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：规则是否会对性能有影响，是否有压测的数据</p>
</blockquote>
<p>A：决策过程就是一次RPC调用，因为策略的定义是声明式的数据都是静态存储，决策耗时可以忽略不计（在整个请求阶段中），即使是内部代理也会带来网络上的损耗。</p>
<blockquote>
<p>Q：规则是否可以动态修改，即使生效，不需要重启服务</p>
</blockquote>
<p>A：不需要重启服务，实时生效，这也是OPA的目的，不会因为策略的变动而改动代码或是重启服务。</p>
<blockquote>
<p>Q：是否可以与istio结合，实现微服务权限管理下沉到网格？</p>
</blockquote>
<p>A：当然可以，社区有相关的实现，这个得去关注具体的项目，我还没有深入了解。</p>
<blockquote>
<p>Q：是否可以与spring cloud结合使用，或是与docker配合使用，因为没有用到k8s</p>
</blockquote>
<p>A：当然可以，OPA可以用做第三方库集成到你的代码中，通过API进行调用，一次决策就是一次RPC调用，OPA的核心理念在于把决策这个步骤给解耦出来，而不是和上下文逻辑混在一起。</p>
<blockquote>
<p>Q：OPA可以调用数据库吗？它能实现鉴权吗？</p>
</blockquote>
<p>A：可以，可以自己实现外部调用的模块，但通用的做法是事先把需要决策的数据查询组装好发送给OPA进行决策。鉴权就是一种特殊的策略，策略需要关联到用户、用户组。可以把OPA和网关进行整合，每次用户请求都进行鉴权（通过OPA进行决策，该次请求是否放行）。</p>
<blockquote>
<p>Q：微服务和OPA是不是结合的更紧密？可以把决策提出来？</p>
</blockquote>
<p>A：和微服务概念本身关系不大，即使是单体应用，只要你可以把决策过程剥离出来就可以用到OPA，这个很符合微服务的理念，OPA就是一个集中的决策服务。</p>
<hr>
<h3 id="2019-12-10：Volcano介绍及其在深度学习场景下的应用"><a href="#2019-12-10：Volcano介绍及其在深度学习场景下的应用" class="headerlink" title="2019-12-10：Volcano介绍及其在深度学习场景下的应用"></a>2019-12-10：Volcano介绍及其在深度学习场景下的应用</h3><p><a href="https://shimo.im/docs/RtV63PGyjPhGKCvk" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q1：针对kubeflow这种工作流有没有计划做出针对性优化？#274号PR提出要做拓扑优化，最后也close了，这是为什么？</p>
</blockquote>
<p>A：针对volcano与kubeflow的结合，volcano社区一直在推动，希望kubeflow下各个operator对接volcano，现在，这一推动在kubeflow中的一些计算框架已经取得了比较明显的进展。task-topology的算法已在内网实现，推入github的计划正在制定中，如您有切实需求，可到volcano社区留言<a href="https://github.com/volcano-sh/volcano/issues" target="_blank" rel="noopener">讨论</a></p>
<blockquote>
<p>Q2：针对数据局部性有没有优化</p>
</blockquote>
<p>A： data aware scheduling 已列入特性计划</p>
<blockquote>
<p>Q3：资源敏感型的深度学习任务具体有什么挑战？</p>
</blockquote>
<p>A：本次分享，针对解决为深度学习提供算力方面的挑战，其他方面的挑战，不能为您解答。关于算力方面的挑战和应对策略，请留意后续分享文档。</p>
<blockquote>
<p>Q4：请问对一个分布式tensorflow训练，worker节点的gpu型号不同，会不会有问题，比如v100和p40混用</p>
</blockquote>
<p>A：v100和p40均为扩展资源，在调度过程中均同等对待，是否指定多个gpu卡对调度进程无影响，欢迎您使用volcano进行相关测试。</p>
<blockquote>
<p>Q5：在使用k8s中，对于IB网络和RDMA的支持会不会有什么问题</p>
</blockquote>
<p>A：没有问题，支持过程中，k8s需要做一些适配。据我所知，一些云厂商使用k8s对IB网络和RDMA的支持已经商用。</p>
<blockquote>
<p>Q6：对于tf的分布式训练，worker节点之间共享数据集，您推荐用哪种分布式存储</p>
</blockquote>
<p>A：对象存储和NFS均可以，取决于您使用的底层存储的读取和写入速度。</p>
<blockquote>
<p>Q7：虽然一开始批调度成功。但是如果一个训练作业时间比较长，运行过程中一个pod挂了怎么办，重新调度之后ip端口等相关的信息可能都变了？</p>
</blockquote>
<p>A：volcano支持为job配置生命周期管理策略，支持配置计算节点失败后，计算集群重启。如果计算模型不支持容错，可进行相关配置。</p>
<blockquote>
<p>Q8：大佬，最后这个分享内容能同步到 github 嘛，讲的很详细，使用 kubeflow 开发中，对 volcano 很感兴趣</p>
</blockquote>
<p>A：下周公众号会发，发出后再同步。</p>
<blockquote>
<p>Q9：volcano是并行调度多个pod吗？调度过程中会不会发生冲突。</p>
</blockquote>
<p>A：是并行调度，不会冲突。batch调度，主要针对于同一批计算任务下任务的批量调度。调度过程中，仍然存在多个维度的优先级。优先级内有先后。</p>
<blockquote>
<p>Q10：现在volcano是先来先服务模型是吗？有没有考虑通过调整作业顺序提高集群资源利用率和作业完成时间。比如一个作业有资源请求量和运行时间两个维度的话，就可以贪心的使执行时间少的作业排在前面以减少总体执行时间。《Y. Fan, Z. Lan, P. Rich, W. Allcock, M. Papka, B. Austin, and D. Paul, “Scheduling Beyond CPUs for HPC”, Proc. of HPDC’19 , 2019.》这篇论文就是通过滑动窗口调整顺序优化了集群资源利用率。</p>
</blockquote>
<p>A：volcano调度过程遵循优先级调度，优先级高的pod具有更高的优先级获取集群资源。优先级有多个维度，namespace、queue、job等。随着集群下资源状况和pod运行情况不同，各维度优先级均会动态调整。虽有多个优先级维度，但均没有涵盖您提到的这种场景，欢迎到volcano社区留言<a href="https://github.com/volcano-sh/volcano/issues" target="_blank" rel="noopener">讨论</a></p>
<blockquote>
<p>Q11：提交VCJOB时可否只指定任务GPU总数，由调度器自己根据集群GPU空闲情况决定分配几个worker以及每个worker的卡数呢？</p>
</blockquote>
<p>A：不支持</p>
<blockquote>
<p>Q12：请问volcano和原生的kube-scheduler有做到调度cache的共享吗？也就是同一个节点可以同时被这俩个调度器管理而不冲突？</p>
</blockquote>
<p>A：不支持。使用两个调度器调度同一个pod，不可避免会出现调度冲突。目前，volcano只处理配置调度器名称为volcano的pod调度</p>
<hr>
<h3 id="2019-12-05：Knative-Serverless-之道-如何-0-运维、低成本实现应用托管？"><a href="#2019-12-05：Knative-Serverless-之道-如何-0-运维、低成本实现应用托管？" class="headerlink" title="2019-12-05：Knative Serverless 之道 - 如何 0 运维、低成本实现应用托管？"></a>2019-12-05：Knative Serverless 之道 - 如何 0 运维、低成本实现应用托管？</h3><p><a href="https://shimo.im/docs/RhvYRWy8W3RqGYtW" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q1：开发怎么远程调试k8s中的应用</p>
</blockquote>
<p>A1：Kubernetes 底层首先是一个容器，那咱们就从容器谈起。容器相对于宿主机来说其实只是把业务进程限制在一个更合理的权限范围内。在调试容器里面的业务进程时可以直接 docker exec 到容器内。到了容器内部就和一个 vm 没有什么差别了。而 Kubernetes 的 Deployment 可以认为是编排很多容器，每一个 容器都可以通过 宿主机 docker exec 进去。当然也可以通过 Kubernetes 的方式 kubectl exec 到容器内进行调试。如果实在初期调试阶段建议使用比较完整的 CentOS 或者 Ubuntu 镜像，基础镜像内要有一些基本的调试工具。摸索熟悉了之后可以使用精简的基础镜像，这样更经济。</p>
<blockquote>
<p>Q2：knative的build和开发流程管理可以代替jenkins吗</p>
</blockquote>
<p>A2：Knative 的 Build 现在长大了，单独开启了一个项目就是  Tekton。Tekton 的定位不是替换 Jenkins ，这两者在使用方式上差别还是很大的。对于比较习惯 Jenkins 的用户来说切换成 Tekton 是需要一个适应过程的。那么为什么要搞一个 Tekton 呢，Jenkins 不是已经很好了吗？具体 Tekton 的详细设计和实现咱们以后可以单独说明，这里选几个重要的介绍一下区别：Tekton 的 Kubernetes 原生特性体现在如下几点：</p>
<ul>
<li><p>Tekton 的所有 Task 都是以 Pod 的粒度执行的，每一个 Task 可以包含很多个 Step。一个 Task 的所有 Step 在同一个 Pod 内串行执行。不同的 Task 通过 Tekton Controller 编排，是跨 Node 节点执行的；</p>
</li>
<li><p>Tekton 的最基本的执行单元是 Pod，这和 Kubernetes 云原生操作系统是非常契合的。一个人如果掌握了 Kubernetes，再学习 Tekton 就是一件非常容易的事情。但是想一下如果掌握了 Kubernetes 会对学习 Jenkins 有所帮助吗？不太可能。随着 Kubernetes 的流行这种影响也会变的越来越明显；</p>
</li>
<li><p>再说一下被集成的特性，Tekton 如果现在和 Jenkins 拼生态现在资历还不够，但是他的设计和云原生生态位决定了他可以很容易的通过 Kubernetes api 被集成，而 Jenkins 的 API 需要单独学习，这些都是成本；</p>
</li>
<li><p>Kubernetes 生态的很多已有的工具，比如 Chart 等等都可以和 Tekton 非常容易的契合在一起，Jenkins 的生态自己比较孤单。长远看 Tekton 是有优势的，但 Tekton 自己的领域能力也需要不断完善；</p>
</li>
</ul>
<blockquote>
<p>Q3：knative编排和K8S应用编排的区别及应用场景?</p>
</blockquote>
<p>A3：Kubernetes 的最大价值是把对 IaaS 资源的操作标准化了，比如无论是在 aws 还是在阿里云上面使用计算、存储、网络等资源都可以直接通过 Kubernetes 语义完成，不需要关心不同厂商底层差异化的实现。而 Knative 才是面向应用的编排。Knative 对应用的 Serverless 编排主要体现在对：流量的管理、灰度策略和弹性的管理。并且流量、灰度和弹性这三者是完美的契合在一起的。从另一个角度来说 Knative 是建立在 Kubernetes 之上的，Knative 需要使用 Kubernetes 提供的对 IaaS 的标准化服务。这二者是上下层的依赖和被依赖的关系，不是竞争关系。</p>
<blockquote>
<p>Q4：knative有哪些成功的行业应用实践？</p>
</blockquote>
<p>A4：在阿里云上面已经有很多用户在使用了。另外 Google 的 CloudRun 产品完全是建立在 Knative 之上的。</p>
<blockquote>
<p>Q5：knative的现状和预期达到的目的?</p>
</blockquote>
<p>A5：Knative 现在已经被众多厂商开始支持了，Knative 的目标是标准化应用 Serverless 编排模型。比如：通过 Knative 对应用进行编排；通过 Knative 支撑上层 faas 系统实现。这里说的应用其实不限于在线服务，很多 AI 任务也是通过 Knative 驱动的，比如分享中提到的 KFServing</p>
<blockquote>
<p>Q6：缩容时，怎么才能当pod内的流量消耗完？在销毁？</p>
</blockquote>
<p>A6：Kubernetes 中 Pod 是可以设置 Prestop 的，Prestop 可以保证先卸载流量，然后再摘除服务</p>
<blockquote>
<p>Q7：k8s 应用服务器内网无网络，入口只有一台nginx 在dmz区域可以出公网（nginx 与应用服务器网络只开放访问31380/31390），当pods 容器直接回调第三方域名时，该如何解决这个问题。</p>
</blockquote>
<p>A7：这个涉及到了具体业务模型和系统架构，可以单独联系我下线沟通</p>
<blockquote>
<p>Q8：感觉knative就是另一种形式的配置即服务，和jenkins X发展的异同?</p>
</blockquote>
<p>A8：Knative 是一个应用 Serverless 编排引擎，可以快速给普通应用赋予 Serverless 能力。比如流量、灰度和弹性的完美结合。另外 Knative 的事件模型可以对接外部事件做基于事件驱动的 Serverless 模型。</p>
<blockquote>
<p>Q9：在企业私有云环境部署knative会有哪些挑战？</p>
</blockquote>
<p>A9：只要是标准的 Kubernetes 集群之上就能部署 Knative，不过很多镜像需要翻墙</p>
<blockquote>
<p>Q10：阿里云上的容器镜像服务是如何处理鉴权的？</p>
</blockquote>
<p>A10：可以参考阿里云镜像仓库的官方文档：<a href="https://cr.console.aliyun.com/cn-hangzhou/instances/authorize" target="_blank" rel="noopener">cn-hangzhou/instances/authorize</a>， <a href="https://cr.console.aliyun.com/cn-hangzhou/instances/credentials" target="_blank" rel="noopener">cn-hangzhou/instances/credentials</a></p>
<blockquote>
<p>Q11: istio层面的管控和维护成本比较高，如envoy性能问题，网络问题等，这部分工作是由云平台负责的吗，knative这边有没有相应措施</p>
</blockquote>
<p>A11: 目前阿里云容器服务 Kubernetes 集群控制台可以通过 UI 管理 Istio 和 Knative，可以快速上手。控制台也提供了很多便捷操作降低运维成本。Knative 主要依赖了 Istio 的 Gateway，Gateway 本身是可以横向扩展的，不会有太大影响。</p>
<blockquote>
<p>Q12：容器的冷启动问题如何解决，第一个流量岂不是延时很高?</p>
</blockquote>
<p>A12: 如果缩容到零以后，到一个请求的延时是会很高。第一个请求冷启动的问题是一个公认的业界难题，这也是各大云厂商在竞相解决的问题。相比使用云的客户而言，云厂商自己其实更迫切解决这个问题，敬请关注….</p>
<blockquote>
<p>Q13: knative的组件本身怎么部署？如何保证HA？谢谢</p>
</blockquote>
<p>A13: Knative 是建立在 Kubernetes 之上的，Knative 组件其实就是 CRD 的 Controller。在 Kubernetes 中 Controller 是可以部署多个实例，通过抢锁保证只有一个 Controller 可以执行写操作。HA 的问题容易解决。</p>
<hr>
<h3 id="2019-12-03：Kubernetes-在信也科技的落地实战"><a href="#2019-12-03：Kubernetes-在信也科技的落地实战" class="headerlink" title="2019-12-03：Kubernetes 在信也科技的落地实战"></a>2019-12-03：Kubernetes 在信也科技的落地实战</h3><p><a href="https://shimo.im/docs/3RkcgcPq3JjVtxwr" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：dns记录是如何维护的，还有maclvlan的记录的维护？谢谢老师回答</p>
</blockquote>
<p>A：dns系统我们实现了2个服务，一个是监听在53端口提供dns查询的服务，一个是前台管理站点，前台站点负责dns记录的增删改查。支持单独设置和批量导入功能。这2个服务共享同一个数据库。内容的话是由信也科技各个研发团队共同维护的。macvlan是在每台宿主机上创建的。我们一般会在每台宿主机上创建多个macvlan网段。</p>
<blockquote>
<p>Q：Macvlan是没有service，选择MacVLan是基于哪些考虑呢？MacVLan使用过程中，对于不同的内核版本，不同的高可用组网，是存在兼容性问题的，这一块实践能分享下么？</p>
</blockquote>
<p>A：选择macvlan一是因为它的简单，使用docker命令就可以创建出来，不需要其他配套的服务或数据库来管理。二是因为它有独立的IP和MAC地址，这样可以让信也科技之前跑在虚拟机上的服务能够快速的迁移到容器。我们对于宿主机的内核版本是严格控制的，不存在内核版本不同的情况。但是macvlan的缺点也比较明显，它依赖于硬件，宿主机需要连到交换机trunk口。并且它的灵活性也不够高，不适合大规模的组网。由于目前信也科技内部的网络结构还是比较简单的，并没有遇到兼容性的问题。</p>
<blockquote>
<p>Q：为什么不试着对k8s自动更新呢，每一次手动更新都需要一定的时间成本吧？</p>
</blockquote>
<p>A：目前我们认为手动更新比较稳妥，并且更新不是一个频繁的操作，时间成本还好。</p>
<blockquote>
<p>Q：请问下，这个是自建机房环境上的集群？是否适用公有云环境？外部访问流量是如何接入的呢？ingress controller基于什么考虑来选择的，谢谢。</p>
</blockquote>
<p>A：这个是自建机房环境上的集群。外部的流量会先经过F5，然后经过nginx集群，所有的容器实例和虚拟机都是通过nginx负载均衡的。在nginx上面我们使用了新浪微博的nginx-upsync-module模块，可以从consul同步upstream中的实例。我们并没有使用ingress controller，而是通过用户在我们的容器发布平台上去手动的拉入和拉出流量。用户拉入流量的操作会在consul里面添加实例的IP和端口，nginx自动从consul同步实例后该实例就接入流量了。</p>
<blockquote>
<p>Q：直接使用Pod的话，副本控制是如何做的</p>
</blockquote>
<p>A：副本控制目前是比较静态的。用户在容器发布平台部署可以选择副本数。此后如果用户不添加和删除实例那么副本数是不会变的。</p>
<blockquote>
<p>Q: 如何更新证书</p>
</blockquote>
<p>A：先重新生成证书，然后先在master节点上更新，需要依次重启etcd、apiserver、controller-manager和scheduler服务。master更新完毕后，再把所有的node节点上证书更新一下，需要重启kubelet。证书的更新过程中除了造成集群的短暂不可用之外不会影响已经运行的容器的，所以是安全的。</p>
<blockquote>
<p>Q：蓝绿发布和灰度发布是如何实现的？</p>
</blockquote>
<p>A：这2个都是通过我们的容器发布平台实现。蓝绿发布是通过创建2个发布组，每个发布组含有相同的实例数。通常一个发布组含有当前版本的实例并且是接入流量的，另外一个发布组包含上一版本的实例或者是即将上线版本的实例。通过在2个发布组切换流量来上线新版本或回滚到旧版本。灰度发布可以先上线一个实例的流量，没问题之后可以把剩下的实例都接入流量。这些操作目前都是平台上用户手动操作实现的。</p>
<blockquote>
<p>Q：集群平台的高可用是怎么做了？有没有做多集群多活或者灾备？</p>
</blockquote>
<p>A：我们生产环境有部署多个k8s集群，也有2个不同的机房部署。我们的容器发布平台会把实例均衡分发到不同的k8s集群。</p>
<blockquote>
<p>Q：开发测试环境的镜像仓库如何同步到生产镜像仓库？</p>
</blockquote>
<p>A：镜像仓库我们测试和生产用的是同一套。 公司使用的是阿里云的托管版k8s与,发现托管版的k8s并没有多个主节点,问一下阿里的托管版k8s与标准版k8s</p>
<blockquote>
<p>Q：问一个细节问题，请问k8s集群扩容是通过什么手段实现的？</p>
</blockquote>
<p>A：我们实现了一套ansible脚本去实现自动添加node节点。</p>
<blockquote>
<p>Q：我们也是用的macvlan，这个模式下，你们为什么没用cni配置网络，而是用的docker来配置，这样维护成本高一些。另外，macvlan模式，主机无法访问本机内的容器，这个怎么解决的？</p>
</blockquote>
<p>A：我们是用docker命令去创建macvlan，实际还是使用k8s的cni。使用vlan之后可以解决主机无法访问本机内的容器。</p>
<blockquote>
<p>Q：ingress用的什么，为什么选择它？</p>
</blockquote>
<p>A：见Q5问题的回答</p>
<blockquote>
<p>Q：刚才提到节点证书过期导致集群异常，k8s本身会在节点异常以后，调度迁移非正常节点的实例的。我的问题是，如果证书更新需要一个过程，那么，节点恢复也是一个过程，这个时候，仍在异常的节点实例，会迁移到正常节点，而且，因为coredns和ingress对接的是apiserver，那么，节点异常基本上等同于这个节点上的实例，都会被apisercer摘掉，虽然容器也还在，但是流量入口和dns侧实例不在了，这样一来，证书过期，不就等同于所有实例全部不可用嘛？</p>
</blockquote>
<p>A：因为我们只用了k8s中的pod，并且关闭了k8s中的异常节点自动迁移实例的功能。这些高可用功能我们自己实现了一个类似的，这样可以按我们的需要去定制。coredns我们只是简单的用来作为dns服务器，并没有和apiserver对接，也没有使用ingress，见Q5的回答。</p>
<blockquote>
<p>Q：想问下老师你们目前是前后端完全分离的么？目前的前端应用部署方式是怎样的？如何控制一些前端的发布工作流？以及与前端相关的后端微服务部分，是如何保证发布顺序以及关联性的。</p>
</blockquote>
<p>A：目前我们上容器的还是以java为主的后端服务偏多。目前能了解到的是前端应用都是放到nginx中来对外提供服务的。对于前端发布的工作流以及如何保证发布顺序以及关联性的目前都是通过人肉去控制和完成的，没有做到自动化。</p>
<hr>
<h3 id="2019-11-26：基于CDN的边缘计算平台设计和思考"><a href="#2019-11-26：基于CDN的边缘计算平台设计和思考" class="headerlink" title="2019-11-26：基于CDN的边缘计算平台设计和思考"></a>2019-11-26：基于CDN的边缘计算平台设计和思考</h3><p><a href="https://shimo.im/docs/pkxrK9PGDcVgXpkx" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：阿里的edge 有用在阿里的cdn上吗</p>
</blockquote>
<p>A：目前我们以及有对外的产品ENS，形态上就是在CDN节点售卖虚拟机。另外我们在做的另一见事情，就是把CDN业务迁移到容器里面，这样到目的就是最大化释放CDN的资源和能力。</p>
<blockquote>
<p>Q：能否介绍一下，目前cdn节点改造成边缘计算节点，主要涉及哪些方面改造，阿里的实践情况，谢谢。</p>
</blockquote>
<p>A：目前CDN改造有3个部分：基础设施到改造（交换机、机型)，软件层面的改造（容器化)，CDN节点架构的改造（比如把传统的7层负载均衡改成K8S的Ingress Controller)</p>
<blockquote>
<p>Q：目前在边缘的ENS节点，有提供GPU，物理机等产品吗？</p>
</blockquote>
<p>A：ENS能力上是对齐阿里云ECS的，目前提供CPU和GPU，神龙裸金属如果有需要也是可以支持的。</p>
<blockquote>
<p>Q：CDN场景的落地场景来说，形态上就是在云中心部署Kuberentes Master，将云中心所在Region附近的CDN节点接入到Kubrentes中 ，指的是在各个Region 里面的节点当作k8的node 处理吗 ？</p>
</blockquote>
<p>A：比如我们在阿里云中心的杭州Region创建一个K8S Master，然后会把杭州整个省的CDN节点，全部接入到这个K8S Master里面，CDN节点指的是一个机房，一个机房会有1～100台机器，整个CDN节点的机器都会接入。</p>
<blockquote>
<p>Q：请问阿里边缘计算有和5g结合的计划吗?具体有哪些结合点?</p>
</blockquote>
<p>A：在今年云栖大会上，我们以及发布了5G边缘计算战略，这个可以网上找下视频回放。具体的结合点目前来看是城市大脑和城市云。不过因为5G还未大规模商用，所以我们也在探索。<a href="https://yunqi.youku.com/2019/hangzhou/review?spm=a2c4e.11165380.1395223.1" target="_blank" rel="noopener">link</a></p>
<blockquote>
<p>Q：请问未来docker会向安全容器转型嘛？安全容器是趋势,作为开发者要注意哪些点？</p>
</blockquote>
<p>A：其实kata和普通runc容器，在行为上没有太大差别，如果非要说关注点的话，目前我觉得是内核部分，因为kata容器对于内核要求是比较高的，稳定性方面还需要打磨。</p>
<blockquote>
<p>Q：目前阿里有没有什么比较成熟的或者已经在计划中的边缘计算相关项目？公司内部对于边缘计算的支持程度是怎么样的?（落点很多，结合5g等新形式，相对感觉视频分析等传统cv方面可能应用性更强一点</p>
</blockquote>
<p>A：ENS就是我们成熟的对外产品，我们对于边缘计算的投入也是不惜代价的。具体场景我们现在也在跟我们的客户、运营商都有广泛合作。只要有需求或者合作意向都可以找我沟通。</p>
<blockquote>
<p>Q：在云上部署k8s master节点，cdn节点作为边缘节点。对k8s来说，节点之前的网络通讯要求会比较高，那当网络不稳定时，边缘节点和master节点断开，这时如何实现边缘节点上的服务自治呢？</p>
</blockquote>
<p>A：这个就是ACK@Edge解决的问题了，ACK@Edge在边缘测机器上部署了一个Edgehub的组件，kubelet并不是直接请求kube-apiserver，而是通过edgehub然后再请求到APIServer。edgehub做了缓存和代理的能力，即使在断网的情况下，也能保障边缘节点的kubelet正常工作。这个能力叫做边缘自治，是ACK加强的能力。</p>
<blockquote>
<p>Q：请谈谈阿里看到的边缘计算cover的真实价值场景或者客户群，感觉很多现有场景中心计算也能满足，不一定要用边缘计算。特别是边缘计算节点也卖虚机，价值不大。谢谢。</p>
</blockquote>
<p>A：以cdn为例，cdn就是通过边缘做加速来提高用户体验。虚拟只是一种形态，比如你购买虚拟机自建cdn。所以边缘的场景肯定是跟中心不一样，比如城市大脑，就是需要在就近有个节点可以做接入，如果全部回中心，对中心的压力也很大。</p>
<blockquote>
<p>Q：阿里在边缘存储上有什么计划吗，能介绍一下是否有业务会需要把大量数据存储在边缘？</p>
</blockquote>
<p>A：ENS节点的虚拟机提供云盘的，但是并不建议把大量存储放在 边缘。因为边缘的存储冗余并没有中心那么高，就像我说的，目前不建议在边缘部署对数据可靠性要求非常高的业务。</p>
<blockquote>
<p>Q：请问安全容器的存储性能有考虑过么？接入点在边缘还是放云端？</p>
</blockquote>
<p>A：安全容器最终是跑着边缘上的，安全容器的存储目前是一个大的问题，kata开源的存储方案性能并不好。阿里云的内核团队做了大量的优化，目前应该有了比较大的性能改进。</p>
<blockquote>
<p>Q：请问ACK@Edge是开源的吗？</p>
</blockquote>
<p>A：ACK@Edge是阿里云上的产品，目前已经在公测中，可以直接在阿里云官网开通使用。</p>
<blockquote>
<p>Q：容器安全方面有什么需要注意的？除了kata之外，使用dockerd 与k8s有什么安全建议psp之类的？</p>
</blockquote>
<p>A：安全容器的使用，第一K8S需要做适配runtimeClass，第二内核也要求比较高（应该是要4.*内核比较文档)<br>安全建议：就是加证书、改端口，不然容易被外部注入容器。其他的安全建议：就是直接使用云上产品，云上产品具备了比较高的安全能力。</p>
<blockquote>
<p>Q：接Q8问题，如果云上master和边缘节点网络恢复了，但master节点上的pod的状态和边缘节点上的服务的状态不一致（断开时间长后，云上pod的状态通常是terminating状态，而边缘节点上的服务仍能正常工作)，这时候如何解决呢？网络恢复后，会将边缘节点的服务重启吗？比如pod重建？</p>
</blockquote>
<p>A：网络恢复后，就是继续往K8S设置的终态变化了，比如中心把Pod删了，那么网络恢复后自然相应的Pod就会被删除。因为有edghub的存在，pod是不会处于terminating状态的。不过具体细节可以仔细ACK的同学，场景和需求可能不大一样。</p>
<blockquote>
<p>Q：CDN的流量分配是在哪里做的？是DNS还是GSLB那种?异地灾备也可以用同样的方式?</p>
</blockquote>
<p>A：CDN的流量分配就有DNS、HTTPDNS、302调度，CDN 本身就是成熟的技术了，调度这块都是非常成熟的技术。</p>
<blockquote>
<p>Q：想问edge节点的升级问题？比如有了重大CVE 或者 0day？或者和master版本差太多？</p>
</blockquote>
<p>A：升级的话，我们目标保持跟ACK中心同步的节奏。主要根据ACK提供的信息。</p>
<blockquote>
<p>Q：请问您那块容器主要跑在虚拟机还是物理机上？</p>
</blockquote>
<p>A：都有</p>
<hr>
<h3 id="2019-11-21：给-K8s-API-“做减法”：阿里云原生应用管理的挑战和实践"><a href="#2019-11-21：给-K8s-API-“做减法”：阿里云原生应用管理的挑战和实践" class="headerlink" title="2019-11-21：给 K8s API “做减法”：阿里云原生应用管理的挑战和实践"></a>2019-11-21：给 K8s API “做减法”：阿里云原生应用管理的挑战和实践</h3><p><a href="https://shimo.im/docs/TX63YhJ8VjVvYXkW" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q： rudr是有某公司实际线上使用后开源的，还是纯开源项目？</p>
</blockquote>
<p>A1：rudr是一个reference项目，意思是用来做OAM实现的一个参考，目前是纯开源项目，不排除以后会演进为生产可用的项目。</p>
<blockquote>
<p>Q：oam spec中目前还没有看到属于infra operator的管理对象（补充：Component是面向app developer， Traits和AppConfiguration面向app operator，哪个对象是面向infra operator的？)</p>
</blockquote>
<p>A2：OAM本身就是基础设施运维手里的武器，包括Kubernetes、Terraform等一系列平台层的开源项目，基础设施运维可以通过这些开源项目构建OAM的实现（如rudr基于Kubernetes)。所以OAM的实现层就是基础设施运维提供的，他们不需要额外的对象来使用OAM。</p>
<blockquote>
<p>Q：oam controller和admission controller的分工标准是什么</p>
</blockquote>
<p>A3：OAM项目中的 admission controller用于转换和检验spec，定位完全等价于K8s中admission controller。目前实现的功能包括转换 [fromVariable(VAR)] 这种spec中的函数，检验AppConfig、Component、Trait、Scope等CR是否符合规范，是否合法等。<br>OAM Controller，即目前的开源项目rudr，就是整个OAM的实现层，它负责解释OAM的spec并转换为真实运行的资源，这里的资源可以是K8s原有的一些，也可以是像阿里云上的RDS这类云资源。目前rudr项目是Rust语言写的，考虑到K8s生态大多数都是用Go语言写的，我们后续也会开源一个go语言编写的OAM-Framework，用于快速实现像rudr这样的OAM实现层。</p>
<blockquote>
<p>Q：计划啥时候开源go的oam-framework呀？</p>
</blockquote>
<p>A4： 已经在走内部流程了。同时我们也需要进一步打磨oam-framework，让它适配大家的场景。</p>
<blockquote>
<p>Q：想问个问题，阿里是如何降低k8s的复杂度来满足运维和研发一些共性诉求的？在k8s中的用户user角色可能是开发也可能是运维。</p>
</blockquote>
<p>A5：目前我们遇到的大多数场景都能区分哪些是运维要关心的，哪些是研发要关心的。OAM降低K8s复杂度的主要方法就是关注点分离，给K8s的API 做减法，尽量让某一方可以少关注一些内容。如果你有这样一个无法分割的场景，其实我们也很感兴趣，欢迎把case提出来一起探讨。另一方面，我们并不是屏蔽掉K8s，OAM spec预留了充足的扩展性，完全可以把K8s原有的能力提供给用户。</p>
<blockquote>
<p>Q：我认为OAM是基于k8s针对于不同应用上的抽象层，现在我们有很多应用都是用Helm包包装好的，如果切换成OAM的话，我们需要注意哪些地方呢？</p>
</blockquote>
<p>A6：其实我们上半年一直在推广helm在国内的使用，包括提供了阿里的helm<a href="https://developer.aliyun.com/hub" target="_blank" rel="noopener">镜像站</a>等，所以OAM跟helm也是相辅相成的。简单的说，OAM其实就是helm包里面template文件夹里面的内容。Helm是OAM做参数渲染（template)和打包（chart)的工具。如果切换到OAM，helm的使用方式不需要变，里面的spec换成OAM的spec即可。</p>
<blockquote>
<p>Q：请问，rudr 用起来了吗，效果如何。rudr 的架构有没更丰富的资料</p>
</blockquote>
<p>A7: rudr一直是可以用的，大家要是用不起来可以提issue，想要什么方面的资料或者疑问也可以提issue，我们也在完善文档。目前相关的材料都在这里：<a href="https://github.com/oam-dev/rudr/tree/master/docs" target="_blank" rel="noopener">oam-dev/rudr/tree/master/docs</a></p>
<blockquote>
<p>Q：rudr的hello world没跑起来，是不是k8s版本需要&gt;1.14 ?</p>
</blockquote>
<p>A8：具体这个问题就在github上提issue吧，我们每天都会关注issue，可以贴一些错误日志之类的。</p>
<blockquote>
<p>Q：我们一直在用helm打包我们的应用，去做gitops ，一个通用的chart 对应不同的values.yaml 做到了复用。听了分享，很期待OAM，当然还有openkruise。</p>
</blockquote>
<p>A9：openkruise 是开源的哈，大家可以关注 <a href="https://github.com/openkruise/kruise" target="_blank" rel="noopener">openkruise kruise</a> 我们也一直在迭代。</p>
<blockquote>
<p>Q：oam有哪些公司在用？实际体验反馈如何？</p>
</blockquote>
<p>A10：OAM刚刚发布一个月左右，具体有哪些公司已经在使用我们还没有来得及统计。阿里和微软内部都已经在使用，并且都有对外的产品使用OAM。就我们接触到的用户来说，无论是社区的用户还是阿里内部，都对OAM的关注点分离等理念非常认同，也都在积极落地。</p>
<blockquote>
<p>Q： rust 内部有哪些场景和业务使用了？贵司后续会继续运用在哪些场景？</p>
</blockquote>
<p>目前有一些小的场景在使用，具体还没有统计过，后续会继续用在一些需要较高性能的场景。</p>
<hr>
<h3 id="2019-11-19：基于云原生日志分类处理方案与落地实践"><a href="#2019-11-19：基于云原生日志分类处理方案与落地实践" class="headerlink" title="2019-11-19：基于云原生日志分类处理方案与落地实践"></a>2019-11-19：基于云原生日志分类处理方案与落地实践</h3><p><a href="https://shimo.im/docs/RKYXGj6hvYJWTPQD" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：filebeat 与flunted的区别大不？该如何选择</p>
</blockquote>
<p>A：Fluentd 针对结构化的数据，灵活性是一个考量。</p>
<blockquote>
<p>Q：filebeat单纯采集docker日志发现不能获取docker.container.name，docker.container.image信息不知为何？</p>
</blockquote>
<p>A：filebeat支持多种采集方式，可以将filebeat以进程运行在docker容器中，收集容器日志，也可以单独部署filebeat采集docker生成的日志文件，可以参考filebeat官方yaml配置文件。</p>
<blockquote>
<p>Q：能否对采集到的日志信息做到告警处理？</p>
</blockquote>
<p>A：告警需要分场景，入库ES可以通过sentinl插件接入告警。 规范处理方式应将各类落地日志对接中心告警平台。</p>
<blockquote>
<p>Q: es的机器学习功能是否有实际价值？</p>
</blockquote>
<p>A：在机器学习方面没有太多接触。</p>
<blockquote>
<p>Q：采集agent是sidecar还是daemon模式？</p>
</blockquote>
<p>A：守护进程与二进制部署。分场景部署，大部分采集场景使用daemonset，部分集群外中间件等组件以systemd部署。</p>
<blockquote>
<p>Q：有没有EFKoperator相关项目推荐？</p>
</blockquote>
<p>A：暂时没有相关推荐。</p>
<blockquote>
<p>Q：对于日志采集系统占用资源过多，怎么解决？</p>
</blockquote>
<p>A：需要从各方面优化，技术层面也是优化项，如提取偏移量方式对流量有很大影响，如文件扫描频率，对cpu有很大影响。 优化点首先从原生参数根据业务场景进行适配调整，特殊场景考虑原生扩展。</p>
<blockquote>
<p>Q：能用filebeat采集journald日志吗？怎么将系统日志和pod日志用同一个filebeat采集？</p>
</blockquote>
<p>A：有journalbeat 开源插件可以采集journald日志。系统日志和pod日志都落地文件，以多源目录采集，一般采用对接logstash做区分处理，若转发不采用logstash，需要扩展filebeat组件支持多目录指定不同的输出采集。</p>
<blockquote>
<p>Q：有没有调研过阿里开源的log-pilot来采集pod日志？</p>
</blockquote>
<p>A：没有做过相关调研。</p>
<blockquote>
<p>Q：beats组件之间是否会有互相影响？比如filebeat MySQL的采集器 redis的采集器 docker的各种，部署很多是否会相互之间有影响</p>
</blockquote>
<p>A：你指的是filebeat内置module模块和对外部采集方式如何统一一套部署采集而不相互有影响么？ 如果是这样，通过filebeat配置文件指定module采集以及docker产生的文件配置进行采集。</p>
<blockquote>
<p>Q：日志告警是用的开源项目还是自研的呢？</p>
</blockquote>
<p>A：根据自身的平台确定方案，本案例的场景可以通过开源方案做一些简单告警，如ES通过sentinl做告警，Loki通过grafana告警，若自有大数据平台或者单独的告警平台，按照平台规则对接告警。</p>
<blockquote>
<p>Q：日志系统接入消息队列的意义是什么？</p>
</blockquote>
<p>A：消息队列是缓冲，重要日志接入消息队列可以提供缓冲存储，多次消费。</p>
<blockquote>
<p>Q：都是默认json日志么，有没比较其他log driver 使用场景</p>
</blockquote>
<p>A：</p>
<blockquote>
<p>Q：用loki主要目的是什么？是某些场景下es的替代品吗？二次开发考虑开源吗？promtail的性能瓶颈具体表现在哪里？和filebeat相比有什么优缺点？</p>
</blockquote>
<p>A：</p>
<blockquote>
<p>Q: 我看loki现在还是在beta阶段，为什么考虑用？</p>
</blockquote>
<hr>
<h3 id="2019-11-12：扇贝-Service-Mesh-发展历程"><a href="#2019-11-12：扇贝-Service-Mesh-发展历程" class="headerlink" title="2019-11-12：扇贝 Service Mesh 发展历程"></a>2019-11-12：扇贝 Service Mesh 发展历程</h3><p><a href="https://shimo.im/docs/C9xJT8Hj66cg8Chc" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：istio 相关的ymal配置文件，比如流量百分比，在哪里配置，直接操作文件吗？</p>
</blockquote>
<p>A：你是指单纯使用 Envoy 的时候如何如何实现 Istio 里流量百分比的功能吗？这个可以通过给 endpoints 配置不同的权重来做到</p>
<blockquote>
<p>Q：这个现在是在哪里操作的是运维手工修改ymal文件？</p>
</blockquote>
<p>A：不是的，举个例子，你可以在 xds 服务端实现根据不同 deployment pod数量来下发新的配置</p>
<blockquote>
<p>Q：service mesh  有对mq 相关研究吗</p>
</blockquote>
<p>A：我们的 mq 没有部署在集群里，Envoy 对这块协议也没有相应的支持<br>A： istio应该暂时还不支持kafka和amqp，gRPC/websocket等可以实现异步调用。</p>
<blockquote>
<p>Q：为啥自己实现xds服务器？有现成的为啥不用？例如istio-pilot/rotor? istio-pilot可以单独使用的。</p>
</blockquote>
<p>A：其实是早期遗留问题，一开始我们用的 Istio 不稳定，后续的选择就趋于保守了。当时rotor应该还没有 release 版本</p>
<p>A：好吧，Rotor一年前也没有更新了，他们团队好像被twitter招安了</p>
<blockquote>
<p>Q：你们只用envoy做front-proxy吗？如果是这样，这就不叫service mesh了</p>
</blockquote>
<p>A：分享里说了哈，既有front-proxy，也有服务间的</p>
<blockquote>
<p>Q：如何保证envoy对业务性能影响最小？</p>
</blockquote>
<p>A：envoy 本身性能没什么问题，要注意的是配置的 filter这些跟外部服务交互的地方，比如 ratelimit 之类的，要配置好超时时间以及失败后的策略</p>
<blockquote>
<p>Q：被sidecar inject过的prometheus如何去scrap每个pod的metrics?服务是基于springboot的。这个研究过吗？</p>
</blockquote>
<p>A：抱歉，这个没有研究过。你是要抓取 sidecar 的数据？<br>A： 谢谢，没关系。我目前只能让prometheus直接去抓pod的metrics。sidecar的数据不用抓:)</p>
<blockquote>
<p>Q：把istio mixer里的jaeger暴露出来，给k8s外部的服务使用，这个需要考虑些什么？</p>
</blockquote>
<p>A：我们单纯的使用的 Envoy 哈</p>
<blockquote>
<p>Q：istio的配套监控体系如何，是直接用开源搭建还是自建？</p>
</blockquote>
<p>A：我们的监控是 Prometheus 那一套技术栈</p>
<blockquote>
<p>Q：你们的服务是基于gRPC还是REST/http1.1的？gRPC要求至少http2，如果需要把gRPC服务暴露给外部，对于ingress controller你有什么推荐？你们服务部署的是阿里云吗？Edge Proxy用的阿里的服务?</p>
</blockquote>
<p>A：我们对外的 rest，内部服务是 gRPC。Envoy 也是有做ingress controller 的产品的，比如Contour，不过我们没有实践过，谈不上推荐。是的，阿里云。最外面有一层阿里云的 slb<br>A： cool</p>
<blockquote>
<p>Q： 你们目前网关怎么做健康检查的？lstio，第二个问题，sidecar如何实现链路监控，自己日志文件怎么处理的？麻烦分享一下你们的监控指标和维度针对service me sh</p>
</blockquote>
<p>A：既可以让 Envoy 对 cluster 做主动健康检查，也可以在 xDS 服务端那边主动更新 envoy的 endpoints，比如依赖 pod 配置的探活指针。我们日志都是到 pod 的标准输出，然后 ELK 那一套做收集处理<br>A：日志是怎么收集的呢？链路监控目前怎么用的呢？那个技术栈</p>
<blockquote>
<p>Q：nginx+consul+consul-template这个用nginx做edge proxy?nginx这一层如何做cluster?</p>
</blockquote>
<p>A：nginx 我们是部署多台，前面还有一层阿里云的 slb对 nginx做主动健康检查</p>
<blockquote>
<p>Q：daemonset模式下，如果一个服务挂掉了例如timeout，如果实现circuit-breaker? 服务挂了。</p>
</blockquote>
<p>A：服务熔断我们最近刚开始调研，现在给不出实践经验<br>A：哦，那只好还是编码在代码里面</p>
<blockquote>
<p>Q：网关怎么处理健康检查的，pod日志怎么处理，统一收集吗？链路监控又是如何接入的？</p>
</blockquote>
<p>不好意思，问题重复了</p>
<blockquote>
<p>Q：istio不好用，为什么不考虑sofa mesh来代替？</p>
</blockquote>
<p>A：早期 0点几版本的时候不稳定哈。现在不是特别在意大集群性能问题的话，istio 是可用的<br>A：实测过一下，istio sidecar injection大概平均一次增加1ms的latency，感觉不是很厉害。一般远程调用都是十毫秒以上的返回。</p>
<blockquote>
<p>Q：请问如何实现的灰度发布和蓝绿部署</p>
</blockquote>
<p>A：灰度发布也是基于配置不同 endpoints 权重这个思路来的，也可以部署不同的deployment，基于 pod 比例来做。蓝绿部署实践不多哈</p>
<blockquote>
<p>Q：你们服务tracing和流量监控是怎么做的呢？</p>
</blockquote>
<p>A：traceing 目前还是原始的日志方式，在研究替代方案，后续有进展可以再分享一下。流量监控我们有做 pod 的进出流量统计，也有从 Envoy metrics 获取的请求统计</p>
<hr>
<h3 id="2019-11-10：蔚来汽车的Kubernetes实践"><a href="#2019-11-10：蔚来汽车的Kubernetes实践" class="headerlink" title="2019-11-10：蔚来汽车的Kubernetes实践"></a>2019-11-10：蔚来汽车的Kubernetes实践</h3><p><a href="https://shimo.im/docs/DRgJKGJdvV9cXDKD" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：请问Kubernetes数据备份与恢复，这个是包括kubectl-proxy，etcd，网络配置等吗？如果进行多集群下的数据备份？</p>
</blockquote>
<p>A：备份的其实就是etcd中的数据，我们网络是用的flannel，一些关键网段信息也是存在etcd中的，对于多集群来看的话，还是要针对数据存放对应的etcd集群数据去进行备份</p>
<blockquote>
<p>Q：请问一下业务日志太多，一天一个节点的业务日志有200G，怎么做日志收集及监控告警。</p>
</blockquote>
<p>A：一天一个节点200G的话，这个要看你们集群节点多不多，我们上百个节点，一个节点的量大概在100G左右，线上日志量都是几十T的数据，用我分享的方案去落地应该是没问题的，ELK的整体性能还是非常不错的，filebeat现在最高的性能分配是占用500m cpu 1G内存，收集起来也是能应对的，这个根据你的量再调整，监控的话肯定就用prometheus就好，官方都是有自动发现的配置，很便利，当然如果你要对日志进行分析，这块就比较复杂了，可以通过es接口去聚合数据，当然日志的字段也要规范好。</p>
<blockquote>
<p>Q：生产环境 k8s 采用二进制方式搭建还是 kubeadm ，还是其他方案？</p>
</blockquote>
<p>A：线上采用的是二进制的方法，因为我们上k8s的时候 kubeadm还是测试版本，当然现在高版本的kubeadm应该已经是正式版本，但是觉得还是二进制更方便一些，你改配置，以及自定义一些参数会方便一些。</p>
<blockquote>
<p>Q：生产环境k8s都用哪种网络模式</p>
</blockquote>
<p>A：我们用的是flannel，不过后续会考虑打算换成calico，现在发现线上有一定网络限制的需求，calico的性能相对也会更好，但是维护的复杂度比较高，在集群节点多的情况下，要添加路由反射器，这个比较关键，而且网络选型前一定对未来的规模有个规划，规划好使用的网段。</p>
<blockquote>
<p>Q：请问生产环境中etcd的数据需要备份吗？怎么备份？还有二进制安装etcd集群由3个节点增加到5个节点，需要重新生e成证书后再重启etcd服务吗？增加节点重启策略是一个一个节点依次重启吗</p>
</blockquote>
<p>A：建议备份，其实主要用到的就是etcd的snapshot功能，不复杂，看下我分享的脚本即可，扩容的话需要修改server端证书对应的host，逐台重启没有问题的，官方的方法也是要一台一台执行的，线上etcd节点我做过测试，即使操作失误都down掉的话也不会影响你现有服务的运行，而且保证法定节点的存在就更好。</p>
<blockquote>
<p>Q：你分享的prometheus是operator方式吗？你的监控数据是有经过二次开发后作为标准格式输出吗？对于nginx和java监控如何实现呀？</p>
</blockquote>
<p>A：prometheus没有用operator的方式，是用的官方的yaml文件创建的，我们线上java服务居多，都是通过spring官方的prometheus插件就可以自定义监控数据，nginx的话我们还真的不多，这个估计你要用相应的exporter就好，监控数据是开发自定义上传的，我们没有做限制。</p>
<blockquote>
<p>Q：pod挂掉之后如何保留现场，比如做内存dump有什么好的方案没？</p>
</blockquote>
<p>A：我们这边是这样，对于健康检查没有添加liveness的检查，也是防止容器的重启，尤其是在第一次项目上线，难免无法正常启动，如果加了liveness就会一直，重启，不太方便查问题，所以只加了readiness,只是保证不影响线上访问，对于生产中，java项目遇到最多的就是OOM问题，这个我们也对POD重启的原因加了报警，至于dump我们还没这方面的操作，需要开发自行检查了。</p>
<blockquote>
<p>Q：传统系统架构如何改造成k8s架构？</p>
</blockquote>
<p>A：这个问题有点宽泛呢，还是得看您这边实际的场景，我觉得更多的也是得需要开发一起的配合，尽量保证服务模块都能够做到微服务话，不要耦合的太紧，您可以先搭建一个测试集群，然后从开发那边找一个模块进行docker化的转换，然后一点一点再去试吧。</p>
<blockquote>
<p>Q：是否有ingress tcp/udp应用的生产级网络方案？</p>
</blockquote>
<p>A：我们没有用ingress，我们的用法也算是一种比较简单的用法，我们是把网关直接加入到k8s集群中，这样网关就可以调用到k8s的service，因为我们以网关为中心，做了一些安全及认证功能，所以之前的网关必须要用到，而且加了ingress相当于多加了一层性能消耗，所以也没有用，最后我们把之前部署在虚拟机上的网关也变成docker化去部署到集群内部。</p>
<blockquote>
<p>Q：传统数据库负载过高时查询缓慢，但是会有结果，k8s架构数据库负载过高直接pod重启，导致没有结果返回，请问应该如何处理的。</p>
</blockquote>
<p>A：我们集群还没有跑数据库这种有状态的服务，但是听您描述，还是得看看pod重启的具体原因，如果pod都重启了，理论上跑在机器上一定也会有问题，还是在上云之前做好充分的性能压测，并且您可以考虑取消liveness的健康检查，只保留readness访问的检查。</p>
<blockquote>
<p>Q：采集日志过程中，fluentd或fluent bit通过读取node节点docker log目录采集日志，该目录包含了所有服务的日志。请问如何在output阶段中根据namespace和container_name创建elasticsearch的index，并作为index的命名前缀？</p>
</blockquote>
<p>A：首先不建议通过docker目录的方式采集，日志还是落盘到具体路径为好，因为我也碰到过您这个困惑，因为docker的目录都是软链接，而且当docker 重启后路径会改变，当然我们线上用的是filebeat采集，不知道fluentd能不能解决这个问题，由于是软链接，很难用相对路径，必须用绝对路径采集到真正存放的那个目录日志，我们对于es index名称的创建是通过日志提供的一个index名称字段去匹配的，索引名称会引用这个变量进行区分不同的index。</p>
<blockquote>
<p>Q：fileneat node模式采集，多个相同pod在同一节点情况下，如何映射日志目录耳不互相干扰，另外如何配置filebeat做到pod变动时的采集</p>
</blockquote>
<p>A：您这个情况我们也遇到过，多个pod跑在同一个节点确实存在这个问题，因为你的deploy yaml是定死的，很难处理这种情况，我们的解决方法是添加pod的亲和性，保证每个节点都尽量只跑一个pod，当然如果节点非常小的情况下，这种做法有一定问题，以生产使用上来看，我们最初多个pod跑在一个节点同时写一个文件的话也是还可接受。</p>
<blockquote>
<p>Q：持续集成系统具体的细节可以透露下吗？基于gitlab ci，jekins？或者小公司可以直接用Spinnaker 这些吗？</p>
</blockquote>
<p>A：ci cd的话因为我们有自己现有的发布平台，背后的原理实际上还是调用jenkins去处理</p>
<blockquote>
<p>Q：日志收集的sidectar模式具体是咋部署的。filebeat和应用部署在一个pod里吗</p>
</blockquote>
<p>A：对的，部署在一个pod里，相当于你的deploy yaml里会有两个image配置，一个是你的服务，另一个是filebeat，具体的配置看下我的截图，把这部分配置放到你的服务配置后面即可，但是就像我分享说的，这种方式可能会比较消耗资源，但是确实自定义比较方便，但也增加了yaml配置</p>
<blockquote>
<p>Q：我司测试环境搭建的Harbor版本是1.5，使用docker-compose来按照Harbor各个组件的依赖顺序来启动的，但是当系统或者docker重启后，Harbor的容器就无法按照依赖顺序来启动，经常会有容器启动失败。请问下这个该如何优化呢？</p>
</blockquote>
<p>A：其实你需要在docker中注意一个参数，live-restore : true，这个参数很有用，你可能没有添加，这个参数能保证在你维护重启docker的时候，还能保证不影响正在运行的docker 容器，另外你可以对harbor进行监控，如果down了的话大不了做个自动重启的操作也不妨大碍。</p>
<blockquote>
<p>Q：（1)k8s平台上线前有什么测试？如何测试？可以上线的依据？（2)常见互联网架构的业务，需要改造才可以在k8s跑吗？需要如何改造？有什么坑？（3)你们多个业务线都共用同一套k8s？如何实现不会因为一个业务的高峰影响其他业务？（4)有什么方案可以实现最大限度的不丢日志？</p>
</blockquote>
<p>A：1.因为我不是测试，对于测试这块可能干涉的不是很多，对于运维来讲可能更多的是比较关注上线之前的压力测试，这块会跟后续的稳定性有很大关系 2. 常见的架构业务理论上改造应该不需要很大，最主要的是解决docker镜像化，遇到的坑可能更多的是对于dockerfile打镜像理解的不好，导致一些启动问题以及配置的丢失等等，3. 我们是通过namespace区分业务线，需要提前规划好业务，指定的业务线只跑在对应的机器上比较关键。 4. 我使用的ELK过程中还真的很少遇到过丢日志，只要你架构足够健壮应该是没什么问题的，另外ELK中一定要用消息队列，降低你消息传递的压力，保证每个组件都不要出现性能瓶颈，如果实在怕丢日志，可以让logstash在消费的时候把消息落盘，es也要合理配置好刷新的频率以及内存多大落盘等参数，提前做好各个组件的压测是保障。</p>
<blockquote>
<p>Q： 你好，我是蔚来es8车主，很高兴看到蔚来的分享。我想了解下你们存储的方案，之前听说是用的portworx，具体方案透露一下。你们这个team在北京还是上海？ 用aws的话有没有考虑直接使用aws的k8s服务？es也运行在k8s里吗？</p>
</blockquote>
<p>A： 您好，我们team在北京，因为我们的集群还未上有状态服务，所以暂时还未考虑分布式存储的问题，这块确实是很重要的一个环节，我们线上的服务基本也是通过S3去存储一些数据使用，portworx这个好像也出了很久了，当时在还没有k8s的时候调研过，不过想大面积使用貌似是要花钱用商业版，建议还是用现在比较流行的ceph可能会更好一些吧，我们还未用到aws自己的k8s服务，es有运行在k8s里的业务，但是不是通过operator部署，后端数据也没用到分布式存储，由于量不大，只是落在本地了，后期会进一步调研ceph以支持后期的有状态服务的迁移。</p>
<blockquote>
<p>Q： 请问是否考虑过 fluent-bit ，目前 filebeat 有没有性能上的问题呢？</p>
</blockquote>
<p>A： 因为在虚拟机的时候我们就用的filebeat，就沿用下去了，filebeat暂时还未发现性能问题，可以直接使用，总日志量我们应该有几十T的样子，在生产使用的过程中感觉filebeat还是比较靠谱的。</p>
<blockquote>
<p>Q：k8s一年的证书问题，你们怎么解决的呢？</p>
</blockquote>
<p>A： k8s的证书我们的时间都设置的是十年，kubelet可能是一年，这个我们最初疏忽了，碰到过一次，最终通过删除现有的配置，让kubelet重启自动生成，当然如果您是最初规划的话，可以加上证书自动到期认证的功能，据了解好像现在高版本的k8s已经不存在这个问题，我还没了解的那么多，您可以再查查</p>
<blockquote>
<p>Q：k8s生产环境上的安全相关的配置有哪些呢？</p>
</blockquote>
<p>A： 安全的话这个比较宽泛啊，这个还是要从各个方面完善，首先起码要保证流量流入方向的各个环节的安全限制，以及服务接口调用上的安全认证，以及开发人员使用时候的权限控制等等。</p>
<blockquote>
<p>Q：prometheus自定义监控具体怎么搞得，比如想要监控容器的端口连接数?</p>
</blockquote>
<p>A：容器端口的连接数监控确实还未添加，在原来宿主机的时候是有的，这块有些忽略了，加的话也不是很费劲，可以通过你们自己自定义的exporter去监控。</p>
<blockquote>
<p>Q：落盘的日志怎么定期清理</p>
</blockquote>
<p>A： 落盘的日志通过写好的清理任务进行清理，因为我们的日志都是规范的落到统一的目录，并且目录名称也是很规范的，所以清理起来很方便，写个简单的脚本就可以啦，定时清理就OK</p>
<blockquote>
<p>Q：k8s里java服务，你们是怎么做资源限制的？</p>
</blockquote>
<p>A： 我们是在yaml注入了能获取设置资源的env参数，然后在ci打镜像的时候统一规范了服务启动的start脚本，jvm里配置的是k8s配置的资源，所以java服务的使用也不会超过我们分配资源的使用。</p>
<blockquote>
<p>Q：想了解下你们日志收集 你们的服务数也就是日志数大概多少？每个k8s节点分配到的pod大概多少 因为是daemonset部署想了解一下filebeat的配置文件是怎么管理的？  后端日志分析完全靠es么？日志有没有入hadoop的需求？有MR或spark</p>
</blockquote>
<p>A： 我们一天的日志量最多能达到近10T的数据，当然这不全是k8s这边的日志，1个节点最多的话大概能跑到30多个pod，filebeat我们是走的统一的一份配置，因为日志都是json规范好字段传输，也无需做过多处理，因为日志分析主要不在这个场景做，我们这个场景只是提供开发看日志，当然其中一些网关数据我们会做报警和具体的图示，需要分析的大数据专门走我们的hadoop集群，我们这边有用到MR 和 spark，但是大数据相关的东西都没有在K8S上面。</p>
<hr>
<h3 id="2019-10-10：超大规模商用-K8s-场景下，阿里巴巴如何动态解决容器资源的按需分配问题？"><a href="#2019-10-10：超大规模商用-K8s-场景下，阿里巴巴如何动态解决容器资源的按需分配问题？" class="headerlink" title="2019-10-10：超大规模商用 K8s 场景下，阿里巴巴如何动态解决容器资源的按需分配问题？"></a>2019-10-10：超大规模商用 K8s 场景下，阿里巴巴如何动态解决容器资源的按需分配问题？</h3><p><a href="https://shimo.im/docs/Jc6yppJhcDYdPXRH" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：请问heapster中采集到的MetricMemoryWorkingSet指标与ps命令获取到的RSS有何区别？heapster的源码中对该指标的描述是“Total working set usage. Working set is the memory being used and not easily dropped by the kernel”，同时heapster也采集了MetricMemoryRSS，kubectl top为何采用MetricMemoryWorkingSet而不采用MetricMemoryRSS？在Kubernets 1.10版本下，部分运行Java应用的pod出现kubectl top值超过ps RSS值的情况。</p>
</blockquote>
<p>A1：阿里巴巴内部并不使用heapster，我们是通过直接去读取容器cgroup值，获取容器实时资源使用情况。据我所知，社区对于heapster完全废弃。建议通过主流工具采集，汇聚，聚合数据。试试 <a href="https://github.com/kubernetes-incubator/custom-metrics-apiserver" target="_blank" rel="noopener">custom-metrics-apiserver</a> 和 <a href="https://github.com/kubernetes/kube-state-metrics/tree/master/docs" target="_blank" rel="noopener">kube-state-metrics</a> 。在大规模场景下社区的很多开源工具都存在性能问题，一般这类工具我们倾向于自研。</p>
<blockquote>
<p>Q：如何看待suse 放弃openstack?</p>
</blockquote>
<p>A2：Openstack是款伟大的软件，它给IaaS的研发和周边生态带了很多意想不到的成果，例如ceph等。SUSE放弃OpenStack可能出于多种原因。或许是技术选型，或许是财政收益等等。顺便说说，SUSE目前在Kubernetes相关领域的投入还是挺多的。最近的Kubecon上，SUSE均展示了相关技术成果。</p>
<blockquote>
<p>Q：直接修改 cgroup 容器一定会获得资源吗？</p>
</blockquote>
<p>A3：容器技术隔离的技术基础就是cgroup层面。在宿主机腾出足够资源的情况下，给cgroup设置更大的值可以获取更多的资源。同理，对于一般优先级不高的应用，设置较低的cgroup资源值就会达到抑制容器运行的效果。</p>
<blockquote>
<p>Q：底层是如何区分在线和离线优先级的？</p>
</blockquote>
<p>A4：底层是无法自动获取谁是在线，谁是离线，或者谁的优先级高，谁的优先级低的。这个我们可以通过各种Kubernetes提供的扩展实现。最简单的是通过label，Annotation标识。当然通过扩展QoS class也是一种思路。社区版本的QoS class设置太过于保守，给予用户发挥的空间不大。我们通过这些方面也进行了增强。在合适的时候或许会推向社区。自来来来动感知是个方向，感知谁是干扰源，感知谁是某种资源型应用，这块我们还在研发中。做到真正的动态，肯定是具备自动感知的智能系统。</p>
<blockquote>
<p>Q： “与社区版  Vertical-Pod-Autoscaler 不同，Policy engine 不主动驱逐腾挪容器，而是直接修改容器的 cgroup 文件；“，想问一下，不主动驱逐的话，如果Node的资源达到上线了会怎么处理？</p>
</blockquote>
<p>A5：这是一个好问题。首先这里要先区分是哪种资源，如果是CPU型的，我们可以调整低优先级容器的cgroup下cpu quota的值，首先抑制低优先级的容器对于CPU的争抢。然后再适当上调高优先级容器的相关资源值。如果是内存型资源，这个不能直接去缩小低优先级容器的cgroup值，否则会造成OOM，对于学习学习内存型资源的调整，我们会在其他分享中继续讨论。这个技术比较特殊。</p>
<blockquote>
<p>Q： 只修改cgroup，怎么保证k8s 对单个物理机能够分配更多的容器</p>
</blockquote>
<p>A6：文字直播有了一定说明，容器的资源消耗并非是一成不变的，很多时候它们的资源消耗呈现潮汐现象，相同的资源条件下部署更多应用，完成更多作业就是达到资源利用的最大化的效果。资源出现超卖才是我们这个主题讨论的最大价值。</p>
<blockquote>
<p>Q：也就是说 低优先级的容器，request 设置的比limit 小很多，然后你们再动态的调整cgroup？</p>
</blockquote>
<p>A7：在现有QoS场景下，你可以理解被调整的Pod都是burstable的。但是我们并不是直接调整Pod元数据的limit的值，而是调整limit在cgroup反映的值，这个值在资源竞争缓和的时候还会被调整回去的。我们并不建议单机的cgroup数据和etcd的中心数据割裂太久。如果长期偏离，我们会像VPA发出警报，联动VPA做调整。当然在容器运行的高峰期，任何重建容器的操作都是不明智的。</p>
<blockquote>
<p>Q：你们现在cpu 超卖的比例是多少？</p>
</blockquote>
<p>A8：这个不方便回答，哈哈。等我确认可以回答的时候再修改这里。</p>
<blockquote>
<p>Q：谢谢了，整体的理解就是你们开始就让物理机超配了一定比例的pod，然后通过策略动态调整容器的cgroup值</p>
</blockquote>
<p>A9：如果资源完全是富足冗余的，这个动态调整也有一定意义。就是并非资源用满场景下，高优先级应用会被干扰，实际上，当主机的CPU达到一定比例，打个比方例如50%，应用的时延就变大。为了完全确保高优先级应用的SLO，牺牲低优先级的CPU正常运行也是有价值的。</p>
<blockquote>
<p>Q：如何确保一定是低优先级的容器和高优先级的服务部署在一起的，而不都是高优先级或者不都是低优先级，只用packing 算法就可以？</p>
</blockquote>
<p>A10：这个方法比较多，可以配置亲和性和非亲和性。可以通过预编排等手段。预编排就是在应用部署前，首先规划好各个应用部署在哪些node上。</p>
<blockquote>
<p>Q：Policy engine 有没有考虑开源？</p>
</blockquote>
<p>A12：有计划进行开源，Policy engine更多的是和自身的应用属性相关，电商应用或者大数据处理应用的策略都是不相同的，我们开源会首先开源框架和附带一些简单的策略，更多的策略可以用户自定义。</p>
<blockquote>
<p>Q：只是调整 Cgroup 的配置，对于应用中的配置如何改变？比如 JVM 根据中的一些参数？如果不重启 jvm 如何让 Cgroup 的限制生效？</p>
</blockquote>
<p>A8: Java进程还是比较特殊的。很多时候容器重启才能适配的参数才能生效。我们这里针对的是一种通用的方式。对于你提到的这类应用，压制低优先级的容器有效，但是给高优先级应用再分配资源应该无效。</p>
<blockquote>
<p>Q：我之前遇到的大部分应用都无法正确感知 cgroup 的配置，因此很多情况都需要在启动参数里面根据 cpu 或者 mem 设置参数，那么也就是说即使改变了 cgroup 对于他们来说都无效，那么使用场景也就有限了</p>
</blockquote>
<p>A14：限制容器的资源使用这个还是有价值的。限制低优先级应用本身也可以提升高优先级应用的SLO，虽然效果没有那么明显。稳定性的考量同样也很重要。</p>
<blockquote>
<p>Q：Policy engine 目前在阿里的使用如何？在生产上有多上的规模使用这种方式进行动态调整？是否和社区的 HPA VPA 配合使用？</p>
</blockquote>
<p>A15: Policy engine在阿里某些集群已经使用。至于规模暂时无法透漏。涉及到很多组件之间的联动，社区的HPA和VPA目前都不太能满足我们的需求。因此阿里的HPA和VPA都是我们自行开发的，但是和社区的原理是一致的。阿里HPA的开源可以关注 openkruise社区。VPA开源计划我这里还没有确切消息。</p>
<blockquote>
<p>Q：data aggregator 通过什么方式采集数据?</p>
</blockquote>
<p>A16：类似cadvisor方式直接从node的cgroup获取实时资源消耗数据。然后根据容器，node为单位再进行聚合。</p>
<blockquote>
<p>Q：当单机节点资源不足以提供容器扩容时，目前是否可以进行HPA或VPA扩容呢</p>
</blockquote>
<p>A17：单机节点不足的时候，应用可以通过HPA进行增加副本应对。但是VPA如果选择原节点进行更新的话，是失败的。只能调度到其他资源丰富的节点。在流量陡升的场景下，重建容器未h h必能满足需求，很可能导致雪崩，即重建过程中，整个应用其他未升级的副本接受更多流量，OOM掉，新启动的容器再瞬间被OOM，所以重启容器需要慎重。快速扩容（HPA)或者快速提升高优先级资源，抑制低优先级容器资源的方式效果更明显。</p>
<hr>
<h3 id="2019-11-07：如何实现-K8s-一键部署？开发部署提速-8-倍？带你上手一款下载超-10-万次的-IDEA-插件"><a href="#2019-11-07：如何实现-K8s-一键部署？开发部署提速-8-倍？带你上手一款下载超-10-万次的-IDEA-插件" class="headerlink" title="2019-11-07：如何实现 K8s 一键部署？开发部署提速 8 倍？带你上手一款下载超 10 万次的 IDEA 插件"></a>2019-11-07：如何实现 K8s 一键部署？开发部署提速 8 倍？带你上手一款下载超 10 万次的 IDEA 插件</h3><p><a href="https://shimo.im/docs/6HDpcqJ3yQx8yHh3" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q： k8s各组件，比如etcd，建议部署在容器内还是物理机？有什么区别或者优劣吗？</p>
</blockquote>
<p>A1：etcd可以部署在容器里，物理机的话就是性能更好一点。</p>
<blockquote>
<p>Q：如果登录是堡垒机，并且是动态密码，那个配置保存必须要密码，所以不方便吧！能动态密码登陆局域网服务器吗？</p>
</blockquote>
<p>A2：这是个非常好的建议，我们需要在后续的版本中开发这些能力。</p>
<blockquote>
<p>Q：如何在本地电脑(如mac)部署k8s玩玩，以及写Go代码增删改查k8s资源，这块有啥玩一玩的优良经验嘛？目的是想本地开发测试k8s，更加去熟悉k8s内部机制。</p>
</blockquote>
<p>A3：本地mac要玩k8s可以去搜一下minikube。</p>
<blockquote>
<p>Q：k8s一键部署是用kubeadm部署么，本地虚拟机部署多节点k8s集群，虚拟机网络应该怎么处理。由于是自己部署着玩玩，在公司里虚拟机网络不能使用桥接的方式。而使用网络地址转换NET+hostonly 在起calico网络的时候worker节点calico起不来，提示网络冲突。谢谢</p>
</blockquote>
<p>A4：nat模式两个机器会用同一个IP，所以会冲突，可以给虚拟机配两个网卡，1个网卡用NET+hostonly用来访问外部网络，1个网卡用private network用来节点间Pod的网络</p>
<blockquote>
<p>Q：对于后端开发者来说(写Go)，有必要去更加熟悉k8s么？毕竟k8s就是个运维工具，为了更爽的去部署软件以及扩容等等，有必要去深入了解k8s内部机制么，这块有没有什么建议和见解？</p>
</blockquote>
<p>A5：首先，Kubernetes 本身是用 Go 语言写的，就是一个最好的 Go 语言开发和架构的最佳学习物。</p>
<blockquote>
<p>Q：k8s 网络组件calico和自带的flannel，请问建议采用哪一个？</p>
</blockquote>
<p>A6：简单上手选flannel，看重功能选calico</p>
<blockquote>
<p>Q：有哪些开源的管理k8s Web UI 软件，这样可以部署在公司内，所有团队直接在该软件内傻瓜式操作k8s资源，自己部署上线代码？</p>
</blockquote>
<p>A8：K8s自带的dashboard可以试试</p>
<blockquote>
<p>Q：我想深入学k8s，但是k8s内部使用了 etcd/coredns，以及监控这块使用 prometheus，这些技术是不是先深入学习下，再去深入学习 k8s呢，毕竟 k8s 太大了，一上来就深入会容易找不到门路，这块大大有啥经验没？</p>
</blockquote>
<p>A9：建议从K8s核心开始学习，再学习周边组件。从中心到外围的顺序。推荐学习下CNCF和阿里云联合做的这个免费公开课：<a href="https://edu.aliyun.com/roadmap/cloudnative" target="_blank" rel="noopener">roadmap/cloudnative</a></p>
<blockquote>
<p>Q：若k8s集群服务器宕机，请问如何快速恢复集群能力（除拉起kubelet等待其他组件自动拉起，是否还有其他方式)？</p>
</blockquote>
<p>A10：配置3master高可用可降低宕机带来的损失，另外备份组件的配置文件。</p>
<blockquote>
<p>Q：Master节点如果同时作为node节点，请问存在哪些风险？</p>
</blockquote>
<p>A11：master节点不宜作为node节点部署应用，会导致集群不稳定。</p>
<blockquote>
<p>Q： 您好！现在使用了jenkins pipeline做为ci工具，cd1: helm chart 对每个应用编写对应的chart，通过questions.yaml在rancher定制化接口. cd2: 通过argocd 和helm chart 形成的git ops  ,请问有没有更好的工具推荐？ 想解决批量升级，现在每次升级都需要人工干预.</p>
</blockquote>
<p>A12:</p>
<hr>
<h3 id="2019-11-07：k3s在边缘计算中的应用实践"><a href="#2019-11-07：k3s在边缘计算中的应用实践" class="headerlink" title="2019-11-07：k3s在边缘计算中的应用实践"></a>2019-11-07：k3s在边缘计算中的应用实践</h3><p><a href="https://shimo.im/docs/x3WjRWHhdJVPkdQG" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：一台阿里云杭州服务器，一台阿里云美国服务器，都有公网IP，如何方便，快捷的（并且不购买网络带宽费用)的搭建一个2台服务器的K3S集群？</p>
</blockquote>
<p>A：你这个问题的话主要就是你的这个路由的问题，pod网络和service网络的一个拉平的问题，涉及到这个路由的跳转需要你自己去去配置的。</p>
<blockquote>
<p>Q：边缘节点的K3S集群可以很方便的被中心节点的K8S集群来管理吗？如何 管理？数据如何同步？中心节点需要存放边缘节点的数据吗？边缘节点挂了之后中心节点能拉起或管理吗？现在我们也计划做这放面的工作。我们有多个分公司？想在分公司部署集群，但没有维护人员，还有一个问题就是，现在集群 联邦不成熟，也不能很好纳管多个集群做资源调度？</p>
</blockquote>
<p>A：这个k3s集群和k8s集群，它是一个平级的关系。他属于多个集群如果要管理多个集群我们可以采用向rancher这样的集群管理平台去管理它，我们现在就是这么做的在阿里云上有一个rancher的平台，然后管着我们在阿里云平台的业务集群和我们的多个边缘集群。然后你的第二个问题就是中心节点会存储我整个集群的所有的数据，因此我们应该周期性的对这个中心节点的这个数据进行一个备份，而且在未来的版本当中，k3s会支持HA，它是，它是通过实现后端存储，如postgresql、MySQL的一个高可用性保证我们的集群的可靠性的，这个现在已经是实验的特性了，估计在未来很快就会发布了。工作节点挂了的话分两种情况吧一种是你这个节点直接就不能工作了，还有一种情况点跟我的指甲想不通啊，那么前一种情况的话肯定是我的业务也不能正常工作了，后一种情况的话，其实我的业务还是在正常运行的，只不过是不能通过我的主节点去调度了，但是一旦它恢复这个通信的话，所有的都会自动恢复，因为这个边缘的这个设备的他有个特点就是网络不稳定，还有，还有就是经常会掉件这种情况，我们这个集群已经在跑了有两三个月了，表现一直是很好的。</p>
<blockquote>
<p>Q：k3s 去哪获取 资料了？</p>
</blockquote>
<p>A：k3s相关的文档我们可以在rancher的官方网站上获取的。也可以到它的github主页上面去获取相关的材料。<br>补充：这题我会！k3s的官网是：<a href="https://k3s.io" target="_blank" rel="noopener">k3s.io</a>，GitHub的主页是：<a href="https://github.com/rancher/k3s" target="_blank" rel="noopener">k3s</a>，最新开始运营的官方微信公众号ID是：Dockerlab</p>
<blockquote>
<p>Q：K3s的list-watch请求没有走tunel-proxy吗？</p>
</blockquote>
<p>A：k3s的主节点和agent节点之间通信都是走的tunnel通道的。</p>
<blockquote>
<p>Q：边缘网络不稳定的场景，list-watch请求会有问题吗？K3s有针对边缘网络不稳定场景做优化不？</p>
</blockquote>
<p>A：这个场景其实就是kubelet跟我的主节点失联，一旦这个通信恢复的话，主节点他会直接把状态重新传到这个工作节点上去。</p>
<blockquote>
<p>Q：k3s在使用上和k8s相比有什么限制和优势？目前我理解来看主要就是占用较少资源。</p>
</blockquote>
<p>A：对，因为边缘设备的话都是很小的工，一般都是公用的，工业用的工控机，工控机一般都是一个低压的CPU啊，然后还有一个就是内存比较小。实际上来讲的话我目前没有发现根k8s有太大的区别，基本上在我k8s上部署的应用全部可以部署在我的边缘端。</p>
<blockquote>
<p>Q：k3s的主节点和agent节点之间通信都是走的tunnel通道的。 List-watch请求也走tunnel通道的吗，据我看源码，并没有走tunnel，只有logs和exec接口走了tunnel。</p>
</blockquote>
<p>A：这里相关的源代码我没有深入去研究过，下来我详细去了解下k3s这里的机制。<br>补充：list-watch就是直接访问kube-apiserver的端口。</p>
<blockquote>
<p>Q：k3s集群直接更改设备IP是否可用，如果不支持更改IP，对于更改IP的需求有什么应对方案？</p>
</blockquote>
<p>A：这里分两种情况，在集群部署完成后，如果要更改server节点的IP，那么我们需要重新去将所有的agent节点重新加入到集群中，如果更改agent的节点IP，那么可能导致agent节点对应存储在server节点中的身份凭证失效，也就是需要移除失效的节点，将修改后的节点重新加入，当然这种情况是在同一个子网内的情况，如果跨网段的话，那就会更复杂一些了。</p>
<blockquote>
<p>Q：Rancher管理k3s集群，k3s的master要暴露公网IP吗？主讲人的多个边缘</p>
</blockquote>
<p>A：server节点不需要暴露公网IP，只需要能从server节点内部访问rancher即可。通过import的形式将k3s集群导入到Rancher中即可管理起来，也可以管理应用和配置。</p>
<blockquote>
<p>Q：k3s server 也支持docker吧</p>
</blockquote>
<p>A：是的，agent节点提供了–docker参数，可以指定它的容器运行时为docker</p>
<blockquote>
<p>Q：rancher 可以自己部署，管理自己的 k3s?</p>
</blockquote>
<p>A：是的，我们的rancher是部署在阿里云端，同时管理了我们的中枢业务k8s集群和多个客户的k3s边缘集群。</p>
<blockquote>
<p>Q：有在Android上成功运行的经验或者案例么</p>
</blockquote>
<p>A：我们暂时还没有涉及到arm的设备，也没有可供测试的arm设备，因此暂时没有这方面的实践。</p>
<blockquote>
<p>Q：运行单个Docker容器来安装Ranche？可以满足管理吗？</p>
</blockquote>
<p>A：可以，但是这样可靠性会不好，推荐还是多实例通过负载均衡的形式来部署。</p>
<blockquote>
<p>Q： k3s 支持master高可用吗？</p>
</blockquote>
<p>A：暂时还不支持，但是已经发布了实验特性的版本，通过对k3s集群数据存储的高可用来实现的，我们可以部署高可用的postgresql作为k3s集群的管理节点的数据存储。这个特性应该不久就会GA了。</p>
<blockquote>
<p>Q：边缘资源充足，是否可以直接用k8s?</p>
</blockquote>
<p>A：如果边缘设备资源充足的情况下，也可以使用k8s来维护，但是需要考虑的是边缘设备网络的复杂性和不稳定性。</p>
<blockquote>
<p>Q： K3s针对边缘设备网络的复杂性和不稳定性做了哪些改进</p>
</blockquote>
<p>A：譬如刚刚有同学提到的list-watch问题，k3s的我没有深入研究过，但是之前在调研kubeedge的时候，了解到其实就是在断网的情况下仍旧能够实现区域内自治，保证业务的稳定和持续性。</p>
<blockquote>
<p>Q：针对kubeedge实现的区域内自治，K3s当前没有实现的话，商用是否有风险呢，在边缘网络不稳定</p>
</blockquote>
<p>A：这个还是还是得从那个边缘端的得从那个边缘端的这个特点来说。边缘端设备比较分散，每个节点的责任其实很有限，当然肯定有一些非常重要的节点，那这一部分我们可以采取一些额外的措施来保证可靠性，譬如直接从硬件上冗余来保证这一个区域的业务不中断。不是说k3s不能实现区域自治，譬如worker节点在于主节点失联不受控了之后，我怎么管理这台节点的应用，这种情况一般发生有两种情形，一种是断网，一种是断电，当然，断电的情形就不说了，断网的情况下。</p>
<blockquote>
<p>Q：请问k3s,k8s,kube,openflow,现在名词越来越多了,有没有办法在去区别这些名词是处在哪些的阶段，用于什么功能？</p>
</blockquote>
<p>A：这个问题的话，首先还是根据项目需求来做对比调研工作，新技术层出不穷，不需要追求最新的，当下比较流行的一定是适应性最好的，一般经过了众多的验证。</p>
<blockquote>
<p>Q：k3s 启动个helm的时候，由于众所周知的原因，经常下载不到镜像，怎么解决呢？</p>
</blockquote>
<p>A：官方提供了离线镜像包，大约200MB不到，这个镜像包包含了我们启动server和agent节点所需的所有镜像，能够保证集群自身功能正常。helm 我们可以使用国内的charts源来代替，例如azure的源。</p>
<blockquote>
<p>Q：containerd可以配置morror么？</p>
</blockquote>
<p>A：可以配置，但是比较麻烦，docker提供了比较好的人际接口，所以推荐使用docker。</p>
<blockquote>
<p>Q：k3s和k8s搭建的容器系统是否可以无缝的相互切换，如果不是，应该怎么做适配才能相互转化？</p>
</blockquote>
<p>A：我不太清楚你这个无缝切换是什么意思，是业务迁移还是？首先这个需求可能并不常见，而且两者面向的场景不同。</p>
<blockquote>
<p>Q：备份k3s的集群数据为什么是备份那几个目录而不是备份sqlite的db文件？k3s的server支持类似rke对etcd定期自动备份配置吗？</p>
</blockquote>
<p>A：因为还涉及到一些认证文件，譬如agent节点在server端存储有一个身份标记，agent节点的恢复是会判断这些身份的。一旦丢失，重新注册相当于是一个新的节点了。</p>
<blockquote>
<p>Q：请教老师，不管是基于containerd还是docker，它们都是共享内核的，那么如何做到安全隔离呢？</p>
</blockquote>
<p>A：在底层的资源隔离上，还是依赖于系统的各种命名空间，这块建议可以详细研究一下pod的安全策略。</p>
<blockquote>
<p>Q：离线镜像文件是否只要放在images目录即可，文件名并不重要，都可以被识别出来？</p>
</blockquote>
<p>A：是的，使用containerd作为runtime时，不需要手动导入，启动时会自动从这里获取镜像，如果使用docker作为运行时，需要手动load镜像，因为国内直接访问不了gcr.io下面的镜像。</p>
<blockquote>
<p>Q：请问一个问题，单机版K3S，容器内访问本机的一个服务端口，无法访问，这个问题官方测试过吗？</p>
</blockquote>
<p>A：这个可能有很多种情形了，看是否是主机安全策略限制。例如selinux或者iptables规则限制了。</p>
<blockquote>
<p>Q：centos在边缘设备小内存设备上能装吗？也是有内存限制的吧，最小支持多少？</p>
</blockquote>
<p>A：k3s server官方给的需求是512MB就能满足，但是实际的观察中，一般情况下用到200多MB，剩下的就看你部署的应用的资源需求了。另外我们需要保证应用不能把系统资源全部抢占了。</p>
<blockquote>
<p>Q：k8与k3在api上使用上有啥具体差别比如是否支持crd?另外k8的网络组网方案有flannel和calico，k3是怎么组网的?</p>
</blockquote>
<p>A：K3s默认使用的是flannel网络。<br>补充：k3s也支持手动指定其他的CNI，都是比较灵活的配置。</p>
<blockquote>
<p>Q：k3s可以用来部署安全网关么？</p>
</blockquote>
<p>A：暂时没有进行过相关的实践。</p>
<blockquote>
<p>Q：iot client设备没有固定公网ip下如何进行部署？需要自行组网吗？</p>
</blockquote>
<p>A：这里是一个大家都会遇到的问题，一般来说，IOT设备都是客户内网的，不可能给你在防火墙上打洞，我们现在是自己开发了一套系统，只用来偶尔维护边缘设备的后台，类似ssh反向代理就可以实现。</p>
<blockquote>
<p>Q：容器运行时的查看的资源怎么跟宿主技做区分，比如我在运行的容器里面，free -h看到的是宿主技的，怎么做饭只能看到容器本身的呢？</p>
</blockquote>
<p>A：是否对容器做了资源限制。</p>
<blockquote>
<p>Q：边缘设备是怎么被监控的，有的什么方案呢？是否也有监控的实时界面？？</p>
</blockquote>
<p>A：我们可以考虑采取prometheus pushgateway的形式来在边缘内网部署监控代理，然后再介入到统一的监控平台。</p>
<blockquote>
<p>Q：内网环境(可通过代理上网)，需要为containerd配制代理吗？还是containerd可以识别主机的代理配制？如果需要配制的话应该如何配制？</p>
</blockquote>
<p>A：如果是全局代理的话，应该是支持的。</p>
<blockquote>
<p>Q：k3s跟k8s的迭代关系是什么，每发布新版k8s，k3s都要修剪出相应的版本，还是增量开发？用k3s需不需要定期升级？</p>
</blockquote>
<p>A：我们一直在持续关注相关release notes，当有重大新特性和安全问题、功能Bug修复时我们会考虑升级版本。</p>
<blockquote>
<p>Q：Kubeedge提供的设备管理能力，K3s是否有相应的计划？</p>
</blockquote>
<p>A：已经有了相应的计划，明年会在k3s的辅助产品中体现。不过，我们会更专注核心引擎k3s的迭代。</p>
<blockquote>
<p>Q：Dind 中创建出来的容器 MTU 不正常，什么原因导致的？</p>
</blockquote>
<p>A：Dind不是本次分享的讨论范畴。dind内部的docker也是可以指定mtu的，都是灵活的配置。</p>
<blockquote>
<p>Q：请问一个问题，单机版K3S，容器内访问本机的一个服务端口，无法访问。这个端口是我服务器上一个加密狗端口，程序需要从容器中调用这个加密狗。补充一下，我加密狗调用包含tcp和UDP</p>
</blockquote>
<p>A：没有在社区中收到过类似反馈，这里不适合讨论这种很细节技术的问题，建议您提一个issue到<a href="https://github.com/rancher/k3s" target="_blank" rel="noopener">k3s</a>，我们在comment中讨论。</p>
<blockquote>
<p>Q：我尝试给containerd配了代理，单独安装的containerd可以拉镜像，但是k3s内嵌的containerd确一直没法拉镜像。这个需要怎么解决</p>
</blockquote>
<p>A：不确定你在k3s的containerd中如何配置的，k3s的containerd中的配置文件会被重置，你需要以模版方式配置<a href="https://rancher.com/docs/k3s/latest/en/configuration/#containerd-and-docker" target="_blank" rel="noopener">containerd-and-docker</a>。详细问题可以提issue到k3s来讨论。</p>
<blockquote>
<p>Q：centos在边缘设备小内存设备上能装吗？也是有内存限制的吧，最小支持多少？</p>
</blockquote>
<p>A：官方给出的内存需求是512MB，据我观察，在没有部署很多应用的情况下，内存占用一般在200多MB，占用的内存会随着部署的应用增加而增加，但是一般边缘用的工控机内存最大一般8GB，而且边缘不宜过重。</p>
<blockquote>
<p>Q： 边缘设备上做 k3s ，岂不是增加运维人员工作量吗？本来是个简单应用，变成系统了！</p>
</blockquote>
<p>A：因为边缘设备分散、网络情况不好，要统一管理和运维的话，是有难度的，后期的应用维护更新、配置变更、升级等等都是需要考虑的。如果采用传统的部署形式，虽然可以采用类似Ansible这样的自动化工具来做，但是要考虑到网络不稳定，部分设备离线情形的运维工作。所以采用类似k3s这样的统一管理平台是比较好的方案，在实践过程中发现，工作量下降了很多。如果不使用，你需要自己去watch你的应用的运行情况。自己去做类似supervisord这样的守护等等。</p>
<blockquote>
<p>Q： 边缘设备及应用，监控用的是什么方案</p>
</blockquote>
<p>A：采用在节点上部署prometheus exporter, 然后再部署一个pushgateway来做。</p>
<blockquote>
<p>Q： 最大支持多少个agent，一个server带多少agent</p>
</blockquote>
<p>A：这个没有真正的去验证过，不过我们目前的集群状态已经达到100+（1 server,剩余的全是agent)，</p>
<blockquote>
<p>Q： k3s 和 k8s 具体有多大的差别，有实例吗 ？或者数据对比。</p>
</blockquote>
<p>A：在实际的应用部署中，几乎没有任何差异，至少到目前为止，我所遇到的场景,k8s能满足的，k3s也能满足，相信，通过不断的迭代，k3s在未来会更完善边缘场景。</p>
<p><code>来自 18群 的无痕 2019-11-07 22:38:44，睡觉了拜拜！</code></p>
<hr>
<h3 id="2019-10-31：Jenkins-X：基于-Kubernetes-的-Serverless-Jenkins"><a href="#2019-10-31：Jenkins-X：基于-Kubernetes-的-Serverless-Jenkins" class="headerlink" title="2019-10-31：Jenkins X：基于 Kubernetes 的 Serverless Jenkins"></a>2019-10-31：Jenkins X：基于 Kubernetes 的 Serverless Jenkins</h3><p><a href="https://shimo.im/docs/rXvrqchvXx63QtVy" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：这是干嘛的</p>
</blockquote>
<p>A：在分享有关 Kubernetes 之上的 DevOps 产品 Jenkins X，有兴趣的话可以了解一下。可以加速软件的交付速度与可靠性。</p>
<blockquote>
<p>Q：有实际应用案例吗？自己怎么快速体验JenkinsX的特性？</p>
</blockquote>
<p>A：现在国内的应用案例相对较少，是属于下一代的 CI/CD 产品，在国外的用户会更多一些。jenkins x 支持一键在大型云厂商/现有 kubernetes 集群上进行部署，可以参考官网文档安装一下。</p>
<blockquote>
<p>Q：和gitlab ci相比有什么优势</p>
</blockquote>
<p>A： 和 gitlab ci 相比的优势可以参考下 jenkins 与 jenkins x的对比。在用户角度来说，以应用为视角使用起来会更加方便，也方便利用社区资源。从架构和可维护性来说，Jenkins X 的架构会相对更加先进（与诞生年代有直接关系)。</p>
<blockquote>
<p>Q：prow现在支持gitlab了吗？现在大多数企业的代码仓库其实更多使用gitlab。</p>
</blockquote>
<p>A：prow 目前还没有支持gitlab，这也是jenkins x目前最大的一个问题，据我所知目前 jenkins x项目组在主要解决这部分问题，现在在 jenkins x当中开发最活跃的模块 lighthouse 是做这部分工作的，有兴趣的话可以了解一下。</p>
<blockquote>
<p>Q：从Jenkins迁移到X似乎需要大量功夫？</p>
</blockquote>
<p>A：现在 Jenkins X 是有两个版本的，其中一种是使用传统的 Jenkins 架构，这个迁移过去相对平滑一些，但具体也和组织情况相关。不过社区主推的是基于 tekton 的方案，也被称为下一代 CI/CD 产品，如果是迁移到这种方案的话可以忘掉原来 Jenkins 所带来的经验，重新开始。</p>
<blockquote>
<p>Q：KubeSphere 计划把 Jenkins X 用进去吗？</p>
</blockquote>
<p>A：在目前版本当中还没有计划把 jenkins x 用进去，很大的原因是因为 Q4，现在 prow 支持的scm 类型太过于单一了，不太适合企业客户。</p>
<blockquote>
<p>Q：Jenkins X可以直接用于生产环境的CD吗？可以结合公司的审批流吗？与kubnetes如何协作？</p>
</blockquote>
<p>A：Jenkins X 是可以用于生产环境CD的，结合审批流应该有一定的开发量。可以看下分享有关 Jenkins X 的环境管理部分，Jenkins X 本身就是和 k8s 深度融合的。</p>
<blockquote>
<p>Q：KubeSphere DevOps 对比原生的 Jenkins 有哪些优势呢？</p>
</blockquote>
<p>A：KubeSphere DevOps 没有对原生 Jenkins 进行很大的改造。但是用户如果自己搭建 Jenkins 需要自己去了解 Jenkins 的原理以及各种和 k8s结合的方案、如何运行的更稳定。如果使用 KubeSphere 的话用户可以直接使用流水线，避免掉了自己搭积木的过程。并且对于一些普遍的问题，我们会向 Jenkins 提交 PR 来改进 Jenkins的功能。例如下面链接所对应的 PR 让 kubernetes 的 agent 调度从10s 左右优化到了 10ms 左右<a href="https://github.com/jenkinsci/kubernetes-plugin/pull/598" target="_blank" rel="noopener">pull/598</a></p>
<blockquote>
<p>Q：谢谢</p>
</blockquote>
<p>A：所有人都在这里提问。</p>
<blockquote>
<p>Q：其实gitops完全落地在一般企业是有难度的，考虑到有一些上线审批等流程。gitops落地有什么好的建议和思考？</p>
</blockquote>
<p>A：个人认为理想状况下最好的方案还是利用 PR/MR 的方式进行开发，在 PR/MR 里面进行审核，这可能和很多企业的现状不太符合，但其实这种方案在某种程度上也是可以落地上线审批流程的。可以先推行开发过程利用 PR/MR，用数据证明这种方式是可行的，再去推动生产环境部署切换工作方式。</p>
<blockquote>
<p>Q：jenkins如何做备份恢复</p>
</blockquote>
<p>A： Jenkins 的备份有很多种方案。其中一种最常见也是比较暴力的方案就是备份下整个 Jenkins Home 目录，恢复的时候直接恢复整个目录就可以了。另外一种常见方案是 jenkins kubernetes operator 所采用的方案，在这个方案里面把 jenkins 的配置和操作历史记录进行了分离，配置（包括流水线的创建)都存储在 git 仓库中，而构建记录、日志等信息单独进行备份，有兴趣的话可以在 github 上找到这个项目了解一下。</p>
<blockquote>
<p>Q： jenkins X能支持jenkins现有的插件嘛？</p>
</blockquote>
<hr>
<h3 id="2019-10-29：基于-Ceph-的-Kubernetes-数据持久化"><a href="#2019-10-29：基于-Ceph-的-Kubernetes-数据持久化" class="headerlink" title="2019-10-29：基于 Ceph 的 Kubernetes 数据持久化"></a>2019-10-29：基于 Ceph 的 Kubernetes 数据持久化</h3><p><a href="https://shimo.im/docs/Px6xTrqGdDCJp8hW" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：k8s 里面使用 ceph，假设 ceph 出问题。这样会导致节点 hang 住吗？导致集群不可用情况。如果会，那该如何避免。谢谢。</p>
</blockquote>
<p>A： 并不会，因为Ceph 本身是分布式高可用的，而且即使Ceph节点全挂， 也仅仅会影响使用Ceph 的Pod，而不是节点。</p>
<blockquote>
<p>Q：ceph是通过k8s部署还是原生部署。ceph和k8s节点超融合吗，还是分开。</p>
</blockquote>
<p>A：一般生产环境中都是独立部署的，3 或 5 Monitor， 3 ～ 60+ OSD 等规模。</p>
<blockquote>
<p>Q：K8S中如果使用RBD作为数据库的存储，如果库比较大的情况下，对于数据日常的备份和维护是怎么做的？</p>
</blockquote>
<p>A：可以利用快照，快速备份和恢复。在去年的KubeCon 上，华为和谷歌的小姐姐们演示过ceph与glusterfs的优缺点</p>
<blockquote>
<p>Q：在K8S中对于需要共享的存储，使用CephFS需要注意什么，会不会存在一些坑？</p>
</blockquote>
<p>A：目前存在一种说法，就是CephFS不稳定，不推荐使用。具体如何不稳定、如何触发、怎么避免就很少有人知道了，另外还有，如果CephFS不稳定，那么我们还有其它哪些替代品呢？</p>
<blockquote>
<p>Q：学习ceph有什么比较好的方式？以及如何比较有效率的实践？</p>
</blockquote>
<p>A：快速阅读一下官方文档，然后自己安装一套，再结合文档深入研究。模仿需求场景测试使用。多实践。</p>
<blockquote>
<p>Q：K8S对外暴露服务用的是那种方式呢？ 如果在一个集群里面跑不同的业务，在对他们做对外的域名解析，访问控制是怎样实现的，会不会存在一些性能问题或端口的冲突？</p>
</blockquote>
<p>A： 一般比较常见的就是单节点访问的NodePort, 配置高可用模式的Ingress等等。<br>由于每个Pod/Service端口都是独立的，所以并不用担心会跟其它冲突。除非使用了NodePort且指定了端口。</p>
<blockquote>
<p>Q：rook 和 原生的Ceph 部署方式在性能和维护上是否有区别，这两种方式如何选择？</p>
</blockquote>
<p>A：抱歉， rook还没有使用过，不过相对来说，Ceph 集群维护的重点一般都在OSD。在生产环境，一般也会独立部署Ceph, 毕竟即使快速的重新调度Monitor，也可能会对集群产生轻微影响。</p>
<blockquote>
<p>Q：对于小中型公司来说ceph是个好选择么？自行维护，可以从多个方面说说k8s下如何进行存储选型么？谢谢！</p>
</blockquote>
<p>A：相对可以接受，运维并不复杂。目前k8s 上存储还是以rbd比较多一些。当然也有一些NFS，不过因为其性能与稳定性，所以不推荐使用。</p>
<blockquote>
<p>Q：如果使用BlueStore的方式，osd磁盘文件的划分是怎样的，比如WAL, DB这种文件是单独存放在SSD盘中吗，还是都存储在SAS盘中?</p>
</blockquote>
<p>A：有条件的话，且存储需求性能高的情况下，使用更高性能的SSD通常都会有更好的效果。</p>
<blockquote>
<p>Q：Ceph 中pool 数量是如何设定的，如果对集群进行扩容，PG的数量是否需要调整，调整的时候需注意什么？ 网络方面怎么去规划比较合理，谢谢</p>
</blockquote>
<p>A：目前PG的限制多一些，因为Pool里面PG是存在一定数量的，而PG数量又跟硬盘数量挂钩，所以调整时需要计算Pool的数量与OSD数量。网络方面的话，在生产环境，推荐使用至少10Gbps网络，双网卡以便分离业务和集群网络，提升性能。</p>
<blockquote>
<p>Q：1.osd 是否需要做阵列？20台物理机，单台物理机1个OSD阵列还是单台物理机8个OSD裸盘？2.当大量osd出现slow ops如何处理？3.纠删码和三副本，应该如何选择</p>
</blockquote>
<p>A：磁盘数量较少时，不推荐RAID，建议由Ceph直接管理磁盘，通过并行获取更好性能。另外PG的数量计算方式也跟OSD数量有关，所以需要综合考虑。这个可能需要结合监控系统，及时发现异常情况，是设备还是服务或者节点呀网络原因等等判断处理。可以结合业务场景需求与集群规模和硬件配置等情况来综合考虑决定采用哪种方式。</p>
<blockquote>
<p>Q：rbd分配给具体应用比如挂载到mysql后，如果空间不足，该如何扩容？谢谢</p>
</blockquote>
<p>A：目前支持在线动态扩容。</p>
<blockquote>
<p>Q：分布式存储应用于hdfs是否可行，相对于本地存储，分布式存储的读写性能如何提高，另外ceph的bluestore效果怎么样呢？</p>
</blockquote>
<p>A：这个不太合适，因为HDFS本身自己就是做分布式的文件系统，且业务场景也不相同。Ceph 的性能提升无外乎两个方面：更快的磁盘/SSD 和 更大带宽的网络。由于直接管理了硬盘，所以其性能还是很好的。</p>
<blockquote>
<p>Q：块存储模式下，磁盘在宿主机上的数据是加密的，如果要在容器外部操作这部分持久化的数据，需要怎么操作呢？</p>
</blockquote>
<p>A：可以挂载操作。</p>
<blockquote>
<p>Q：ceph图形管理界面需安装什么软件？</p>
</blockquote>
<p>A：现在不需要额外安装软件了，已经内置。</p>
<blockquote>
<p>Q：请问怎样在k8s中，实现多个容器共享一个ceph文件系统，共享文件存储建议用哪种方式？</p>
</blockquote>
<p>A： 这种需求就需要用 cephfs了。共享文件存储的话，看最终客户场景，如果是给Windows等客户端使用的共享，那么可以通过ISCSI来挂载RBD到Windows共享服务器。</p>
<blockquote>
<p>Q： Cephfs 之前在海量小文件读写测试时性能非常差，性能问题目前有没有解决？</p>
</blockquote>
<p>A：性能需要靠硬件去堆。</p>
<blockquote>
<p>Q： Ceph最大支持多大的存储容量不影响性能，与分布式存储HDFS的区别有哪些？pgp和pg什么关系</p>
</blockquote>
<p>A：官方号称是PB级的。HDFS适合大文件，上白G的那种单个文件。PG 是指定存储池存储对象的目录有多少个，PGP 是存储池 PG 的 OSD 分布组合个数。</p>
<blockquote>
<p>Q： kubernes 中现在的块存储是一个部署绑定一个块，能否做成一个pod绑定一个块，有过这方便的实践吗？可否分享一下。</p>
</blockquote>
<p>A：使用 StatefulSet即可，会自动创建和绑定PVC。</p>
<blockquote>
<p>Q： 目前业界ceph集群的最大规模能达到多少个节点（大致的数量级)？是怎样的一种应用场景？</p>
</blockquote>
<hr>
<h3 id="2019-10-15：Kubernetes在SHAREit的落地实战"><a href="#2019-10-15：Kubernetes在SHAREit的落地实战" class="headerlink" title="2019-10-15：Kubernetes在SHAREit的落地实战"></a>2019-10-15：Kubernetes在SHAREit的落地实战</h3><p><a href="https://shimo.im/docs/KDWHyyPCtYCPcVdy" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：直接采用物理机还是有先做IaaS层虚拟化？</p>
</blockquote>
<p>A：我们做的是出海业务，基本上考虑到合规等问题，我们主要项目全部运行在公有云上。</p>
<blockquote>
<p>Q：有没有碰到调度的问题，某台服务器CPU或内存高了仍调度到这台上？</p>
</blockquote>
<p>A：遇到过，一般情况下，需要考虑你的应用是否加了很多亲和性或是nodeselector。正常的调度器，是会优先考虑资源平衡的。</p>
<blockquote>
<p>Q：请问一下coredns如何反解析pod的IP地址？不用svc的情况下，是否可以解析pod的名字？是否有用coredns的rewrite插件。</p>
</blockquote>
<p>A：这个不清楚，我们没有这样的场景。但是coredns，支持编写自己的插件。</p>
<blockquote>
<p>Q：请问下，不同云之间的延时怎么解决?你们是一朵云就部署一个完整的业务么？</p>
</blockquote>
<p>A：我们会在不同云之间通过专线打通。基本上相关联的业务会部署在一家云上。但是我们会尽量保证同一个业务部署在不同的AZ。</p>
<blockquote>
<p>Q：告警策略上有没有最佳实践分享？</p>
</blockquote>
<p>A：我们的统一报警平台基于alertmanager实现，基本上用到了它提供的静默，分组，抑制等特性。只不过我们对接了它的api，也集成到scmp当中。</p>
<blockquote>
<p>Q：配置管理是怎么做到不同环境，不同配置？</p>
</blockquote>
<p>A：我们的配置是在configmap结合数据库来实现版本管理，本质上每个集群都需要单独设置。所以不同的环境，设置不同的configmap即可。</p>
<blockquote>
<p>Q：业务的数据库是在k8s里面运行，还是单独搭集群？</p>
</blockquote>
<p>A：我们除了prometheus和一些mq，我们目前还没有尝试有状态应用。</p>
<blockquote>
<p>Q：linux内核参数优化具体你们碰到过哪些坑呢，怎么优化的呢？线上使用的centos版本和内核如何选择的？</p>
</blockquote>
<p>A：我们使用的是公有云，内核版本一般公有云提供版本中最新的。其实不同的主机类型，相应的参数不一样，需要在选型主机的时候，做大规模测试。比如 net.netfiletr 下的参数。我们会基于公有云镜像，做优化，然后利用pakcer打成新的镜像使用。</p>
<blockquote>
<p>Q：自研组件，可以开源吗？比如日志的那个</p>
</blockquote>
<p>A：SHAREit 是一个技术非常open的单位。我们从上到下，鼓励技术人员去分享。所以如果大家有需要，我们会做一下内部的整理，开源出去。同时，我也会写一些具体的文章，来讲具体的细节。</p>
<blockquote>
<p>Q：alertmanager报警，我使用的prometheus operator安装的，使用默认的微信报警，这个报警时区问题，是修改源码解决，还是使用一个webhook？报警的模板文件是如何管理的？</p>
</blockquote>
<p>A：我觉得你应该需要重新定制alertmanager的镜像，在dockerfile中修改时区。其实我们这边也fork了alertmanager，做了一些优化和功能增强，比如直接将dingtalk集成进来，避免引入webhook组件，所以我们也是自己打的镜像。至于报警模板，我们这边先把报警模板数据存放到数据库当中，然后结合confd来实现altermanager 配置文件刷新的。</p>
<blockquote>
<p>Q：hpa部分你们怎么做到根据不同业务选择不同的策略?</p>
</blockquote>
<p>目前最大的不太清楚，不少大公司可能不会公布。存储日志、备份数据等等。</p>
<hr>
<h3 id="2019-09-17：Prometheus架构与实践分享"><a href="#2019-09-17：Prometheus架构与实践分享" class="headerlink" title="2019-09-17：Prometheus架构与实践分享"></a>2019-09-17：Prometheus架构与实践分享</h3><p><a href="https://shimo.im/docs/HPdrhHpP3DVk9wDk" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：您好，我们prometheus监控系统需要持久化监控数据，目前约存储了1.8T数据，严重影响了查询速度，gafana基本无法刷新数据了，请问有优雅的解决办法吗？</p>
</blockquote>
<p>A：1.8T都是保存在本地吗？SSD有一定的加速作用。如果数据量比较大建议使用m3db、clickhouse、opentsdb等。</p>
<blockquote>
<p>Q：如何登录prometheus数据库?</p>
</blockquote>
<p>A：prometheus本地tsdb没有登录入口，只有go的api。</p>
<blockquote>
<p>Q：企业级的promtheus监控的数据存储是基于什么呢？ES吗，还是其他的存储？</p>
</blockquote>
<p>A：我们使用m3db，集群版本的influxdb、opentsdb等都支持</p>
<blockquote>
<p>Q：现在有高可用方案吗？</p>
</blockquote>
<p>A：prometheus的联邦或者Improbable开源的Thanos都是高可用方案</p>
<blockquote>
<p>Q：promethues占用内存很好，我们的环境下45w指标大概要占用8G左右的内存，经常出现prometheus容器OOM，请注意有什么办法可以优化内存占用吗？</p>
</blockquote>
<p>A：数据指标如果确实比较大可以考虑prometheus的hash采集，分摊压力。在生产过程中很多指标都是可以省去的，譬如kubernetes中的sandbox容器的指标。</p>
<blockquote>
<p>Q：面对海量微服务，好上千个k8s节点，日钧上千上万亿的时序点数据，如何解决prometheus高可用，如何选择和解决远程存储问题？宜信目前有多大规模？有多少指标，一天大概有多少量数据</p>
</blockquote>
<p>A：目前宜信的容器大约4000左右，规模还并不大，很多服务都还部署在虚拟机里面。每天的监控数据量不到100G。历史数据通过M3db存储。</p>
<blockquote>
<p>Q：选择普通远程存储，面对持久化数据相对prometheus本地数据几十倍放大的问题如何解决，如何处理日TB级海量存储，后期如何取出数据进行分析？</p>
</blockquote>
<p>A：prometheus设计的初衷并非解决大容量存储。如果是TB数据建议保存到远端的opentsdb中。</p>
<blockquote>
<p>Q：目前prometheus能否支持对网络设备的监控，如何支持采用snmp  ssh 等协议方式的监控；能否实现与Zibbix的对接？</p>
</blockquote>
<p>A：prometheus有snmp的exporter可以实现网络监控。目前还没听说可以对接zabbix。</p>
<blockquote>
<p>Q：目前prometheus的报警rules规则是怎么管理的？报警阀值是否可动态调整？</p>
</blockquote>
<p>A：rules也是通过yaml文件配置，可以动态调整，但需要reload配置。</p>
<blockquote>
<p>Q：Prometheus的push方式（push推送给pushgateway)和pull正常的方式方式的性能比较，谁更好呢？</p>
</blockquote>
<p>A：pushgateway本身作为数据转发的代理，本身性能损耗很少。建议直接提供prometheus的pull支持</p>
<blockquote>
<p>Q：联邦配置时，实测抓取多个job的metrics存在延迟现像极其严重，不知道有没有好的解决办法？目前我是通过grafana直接获取两个prometheus集群作为后端数据库</p>
</blockquote>
<p>A：这个主要看延迟的原因，是下面的prometheus采集慢还是联邦节点二次汇聚的慢。具体情况后续可以一起加微信排查一下。2次汇聚，本地prometheus与线上prometheus,本地配置联邦，本地汇聚线上job的metrics，当job数量多了就会出现”federation failed” err=”write tcp 192.168.243.145:9090-&gt;10.0.0.12:33508: write: broken pipe”</p>
<blockquote>
<p>Q：针对于一些公司自有业务的进程数据监控是依赖于自研 的go-clent上报吗？还是说一些三方的client？</p>
</blockquote>
<p>A：如果可以二次开发建议直接在代码里面加入prometheus采集的支持，处理go 以外还有java，Python的sdk支持。如果不能二次开发也可以在外部通过exporter方式。</p>
<blockquote>
<p>Q：如果有多个副本 CPU利用率 还是用container_name来算就有问题了吧？另外问一下  不同版本的pod（比如发版之后)怎么比较其CPU利用率？另外histogram的metrics有分析过吗？另外 查询一个月的数据应该蛮有压力的吧还是做了优化是否有必要？</p>
</blockquote>
<p>A：嗯，多副本需要group。不同版本数据都在prometheus存储，可以通过容器名称汇聚查询出来，一个月数据step可以调整的大一些。目前看一个月内的查询基本控制在2s以内。发版之后 pod name名字是不一样的。一种方式是通过保持container name，另外一种方式是通过前缀，正则匹配。我用得后者 不过会出现很多空线条 因为前面版本不存在这个pod name标签的metrics，这个和多副本的container_name 也算是有点冲突，暂时用正则的方式 多谢。metric名称应该是固定的啊，你用正则匹配，不会有问题的，历史都会查出来。另外我发现histogram的metrics超过7天之后就没有什么参考价值了 所以对于查询一个月感觉意义不大，比如 prometheus_http_request_duration_seconds， metrics还是重在实时性。</p>
<blockquote>
<p>Q：Prometheus的数据不知道宜信是否有存储，是存到opentsdb还是influxdb呢？</p>
</blockquote>
<p>A：本地+m3db</p>
<blockquote>
<p>Q：prometheus告警延时比较高，如果要做到秒级告警有什么方案！调整抓取频率不太靠谱</p>
</blockquote>
<p>A：目前告警都是在几秒，你说的延迟是多长时间？</p>
<blockquote>
<p>Q： 请问针对Prometheus 不能监控日志的瑕疵，有什么好的方案可以和Prometheus 形成互补呢？</p>
</blockquote>
<p>A：公司自研了watchdog日志采集。社区常用filebeat + es+kibana方案</p>
<blockquote>
<p>Q：宜信目前用Prometheus监控了多少个服务target了？Prometheus使用的资源大概是多少？</p>
</blockquote>
<p>A：宜信正在从zabbix迁移到prometheus，目前是三台物理机。</p>
<blockquote>
<p>Q：m3db数据存储有没有放大？相对prometheus 的tsdb，有 大概有多少倍？</p>
</blockquote>
<p>A：放大是啥意思？比如一天的数据pro 的tsdb存储是多少g，通过远程存储，就会放大几十倍，比如100个变成1t</p>
<blockquote>
<p>Q：请问应用进程http接口的性能监控是怎么实现的？</p>
</blockquote>
<p>A：有java和go、Python的sdk</p>
<blockquote>
<p>Q：怎么过滤掉不需要的metrics?通过prom</p>
</blockquote>
<p>A：这个可以在pro配置里面drop</p>
<blockquote>
<p>Q：本地存储用来做查询吗？多个prometheus是如何统一查询的？数据都存在汇聚的prometheus上吗</p>
</blockquote>
<p>A：</p>
<blockquote>
<p>Q：怎么实现tsdb历史数据保存到别的地方的？通过什么技术方式分开的？</p>
</blockquote>
<p>A：remote write read</p>
<blockquote>
<p>Q：时序数据库跟传统数据库的优势在哪？应该如何进行选型？</p>
</blockquote>
<p>A：时序数据是保存随时间变化的量，查询也是时间维度，从而实现高压缩比。关系型数据有事在于数据管理。</p>
<blockquote>
<p>Q：请问m3db能不能满足ha prometheus 的数据去重？还是存两份？</p>
</blockquote>
<p>A：m3db不需要存两份</p>
<blockquote>
<p>Q：比如要做每日用户登录数统计，具体应该怎么做？需要哪些流程和步骤？</p>
</blockquote>
<p>A：需要程序里面集成sdk，并提供查询累计登录用户的http接口，并在prometheus配置这个target。</p>
<blockquote>
<p>Q： 选型的时候为什么选择m3？没考虑其他远程存储吗，是有什么考虑。远程存储你们只是用来备份一份吗还是也会一起从远程读数据？之前远程读的性能比较烂，目前prom新版本的stream远程读你们有试验吗</p>
</blockquote>
<hr>
<h3 id="2019-09-19：云原生可观察性之日志管理"><a href="#2019-09-19：云原生可观察性之日志管理" class="headerlink" title="2019-09-19：云原生可观察性之日志管理"></a>2019-09-19：云原生可观察性之日志管理</h3><p><a href="https://shimo.im/docs/KWJqTyw9Q3pqPDcv" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：fluentd bit 在收集的容器pod中 启用fluentd.io/parser选项 采用正则表达式匹配，发现一个正则很难试用全部场景，而且发现匹配不到日志内容的时候 节点会hung住 再重启会无法启动 一直报404启动不了 请问这个如何解决的</p>
</blockquote>
<p>A： 这个问题可以给 fluentbit 提 issue。KubeSphere 目前只用到 Parser 插件的 Decorders，主要是用 fluentbit 添加/删除/修改日志接收者，也会进行一些日志的过滤</p>
<blockquote>
<p>Q：如何debug Prometheus</p>
</blockquote>
<p>A：如果您是要参与 Prometheus 的开发，可以参考 Prometheus Github 的开发指南。如果是使用中遇到问题可以结合日志，或者查看 Prometheus Console UI 有一些直观的异常提示，到 Prometheus 社区 slack 或 Google group 请教。</p>
<blockquote>
<p>Q：Loki你们在生产上有用到吗？有没有什么最佳实践？</p>
</blockquote>
<p>A： 我们正在调研 Loki，Grafana Labs 已经用 loki 提供日志服务了。他们的部署方式参考 <a href="https://github.com/grafana/loki/tree/master/production/ksonnet" target="_blank" rel="noopener">ksonnet</a> 。建议就是几个组件要分开部署，每个组件可以有多个副本以实现高可用；另外就是根据情况选择 index 和 chunk 分别使用适合的存储。</p>
<blockquote>
<p>Q：请问一下，用户想自定义日志解析，如何实现？目前我们实现方式是 fluentd parser作为agent以deamonset的方式部署到k8s的每个节点上，一边收集一边解析，缺点是占用节点资源太多，请问咋们这边如何实现的呢？</p>
</blockquote>
<p>A：收集日志的 agent 最好用比较轻量一点的比如 fluentbit，可以把 fluentd 作为 fluentbit 的接收者，用 fluentd 实现集中的解析后再发到最终的存储，这样就不用每个节点去部署 fluentd 了。类似这样的架构</p>
<p><img src="../img/1575857978783.png" alt="-"></p>
<blockquote>
<p>Q：请问一下，单台日志量多少？</p>
</blockquote>
<p>A：这个不太好说，看工作负载输出日志的情况。</p>
<blockquote>
<p>Q：日志展示？ 是kibana 还是自己单独</p>
</blockquote>
<p>A：日志展示KubeSphere 没用 kibana，是我们自己开发的日志 console</p>
<blockquote>
<p>Q：接Q4，谢谢您的答疑，目前我们想的是用户自定义解析策略不用通知任何人，日志就可以以流的方式输出到es或者其它终端，目前的问题就是如果用fluentd解析 如果添加一个解析规则就要修改fluentd的配置 就要重启下 这些感觉很不好，请问这边有什么建议吗？之所以用fluentd bit解析就是因为可以在 pod上用annotation 自定义fluentd.io parser 解析策略</p>
</blockquote>
<p>A：如果想每个节点都有自己的解析方式，而且不想频繁重启的话， 并且想用一个比较轻量的 agent 的话 可以试试 filebeat，filebeat 有自动加载配置的功能，解析日志也比较强大。</p>
<blockquote>
<p>Q：KubeSphere 的日志系统看起来很漂亮啊，也是开源的吧</p>
</blockquote>
<p>A：目前后端是开源的，前端也即将开源。目前的所有版本都是免费安装可用的。安装下载链接：<a href="https://kubesphere.io/zh-CN/install/" target="_blank" rel="noopener">kubesphere.io/zh-CN/install</a></p>
<blockquote>
<p>Q：KubeSphere的日志在多集群设计上是会用 Thanos 去实现吗？优点是什么</p>
</blockquote>
<p>A：Thanos 适用于监控的多集群实现，可用实现多个 Prometheus 的全局查询。日志多集群的话用 es 实现的话 Elasticsearch 较新版本支持的。<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/modules-cross-cluster-search.html" target="_blank" rel="noopener">modules-cross-cluster-search</a></p>
<blockquote>
<p>Q：fluent和filebeat有做过压测吗？还是因为fluentd是cncf的项目才选择这个的？</p>
</blockquote>
<p>A：ruby也有GIL锁，只能压榨单核性能。选择 fluentbit 主要是因为内存占用少。filebeat 也很流行，go 写的，内存占用据我说知会比 fluentbit 多一些。fluentbit 是完全用 C 写的，不是用 ruby。Fluentd 核心用的 c，插件用的 ruby</p>
<blockquote>
<p>Q：不同服务的日志都是混在一起的？而不是不同的index？容器内的日志怎么采集呢？</p>
</blockquote>
<p>A：目前是不同服务的日志每天一个index，如果想不同index的话应该要用filter加tag实现。容器内没有输出到stdout 落盘的日志可以用在容器内添加sidecar的方式将落盘日志转发到stdout。kubesphere 2.1 即将发布，自带了收集落盘日志sidecar自动注入的功能</p>
<blockquote>
<p>Q：标准输出，数据回落盘吗？怎么清理？</p>
</blockquote>
<p>A：标准输出，日志不会落到容器内挂载的盘，但是会落到容器所在的节点的盘上，通常这个节点的容器日志会有 rotation 设置，定期清理</p>
<hr>
<h3 id="2019-09-19：当-K8s-集群达到万级规模，阿里巴巴如何解决系统各组件性能问题？"><a href="#2019-09-19：当-K8s-集群达到万级规模，阿里巴巴如何解决系统各组件性能问题？" class="headerlink" title="2019-09-19：当 K8s 集群达到万级规模，阿里巴巴如何解决系统各组件性能问题？"></a>2019-09-19：当 K8s 集群达到万级规模，阿里巴巴如何解决系统各组件性能问题？</h3><p><a href="https://shimo.im/docs/6KwX3CR3yRHWdtYV" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：calico网络中，如果节点跨三层，路由器不支持BGP，RR同步如何实现？</p>
</blockquote>
<p>A：这个不清楚。</p>
<blockquote>
<p>Q：由于节点IO，网络，负载过高等问题，etcd频繁选主，导致kube-apiserver方向超时。如何应对这种问题？</p>
</blockquote>
<p>A：最重要的，我们需要为 etcd 配置相对稳定的资源，CPU/Mem 视集群规模而定，Disk 最好是 SSD，因为 disk io 性能对 etcd 写性能影响巨大。我们需要检查 etcd heartbeat timeout 和 election timeout，是否适合当前集群的环境。如果有条件，建议大家能去实践 etcd 3.4，pre-vote 的引入能有效减小异常情形下的抖动。此外，今天也给大家提到了 kube-apiserver 层面的优化，通过在 kube-apiserver cache 上实现 linearizable read，避免大量的读请求打到 etcd，从而可以大幅降低 kubernetes 集群中 etcd 的压力。</p>
<blockquote>
<p>Q：当集群需要进行版本升级时，k8s各组件应该怎么操作。需要遵循顺序吗？为什么？</p>
</blockquote>
<p>A：一般遵循先升级 Server，再升级 Client 的做法。对 kubernetes 来说，先升级 kube-apiserver，再升级 controllers，最后灰度升级 kubelet。先升级 kube-apiserver 的原因是 server 是对外提供服务（接口)的，kubernetes 遵循向前兼容两个版本的机制，确保集群的兼容性，最后升级 kubelet 是因为在节点数非常多的情况下，kubelet 的升级需要一个较长的观察周期去灰度。同时提醒大家，一定要注意 kubelet 升级对节点上运行容器的影响。</p>
<blockquote>
<p>Q：在etcd里面有三个Instance，比如发生了以下场景:A作为leader，B和C作为follower，这时候用户通过curl指令发送了一个Put操作，A收到后通知了B和C，然后B，C回了response,这个时候A提交日志到状态机，然后回复给用户，但在回复用户的过程中挂掉了。这时候假设用户不再发起请求，但B和C选出主机后会提交该日志，也就说用户认为失败了，但etcd内部已经提交了该操作。这种情况下etcd是怎么处理的？</p>
</blockquote>
<p>A：这种情况只是告诉用户超时了（结果未知)，并未告诉用户你的请求成功或者失败了（结果已知)。理解了分布式系统调用的三态，用户系统为了确保正确性，可以选择重试或者其他的方式确认自身状态的推进。</p>
<blockquote>
<p>Q：能否讲解以下etcd的幂等性的实现？</p>
</blockquote>
<p>A：幂等简单理解多次调用同一个操作不会破坏系统的正确性，典型的 put key value 操作是幂等的，delete key 也是幂等的，因为这不会破坏系统的数据状态。试想一下如果提供一个操作叫做 inc key 对 key 做 +1 操作（比如 redis 提供了类似的操作)，用户很难“正确”的使用该 API 构建正确、一致的分布式系统。当然并不是说 redis inc 不好，它可以很好的应用于某一些对一致性要求不高的场景，一个典型的例子是统计微博的点赞次数。</p>
<blockquote>
<p>Q：etcdctl在最新版本中get一个不存在的key的时候为什么不返回key not found了（标准输出中)，没有任何的提示和返回，版本3.5。</p>
</blockquote>
<p>A：因为真实语意实际上是一个 range 操作，既然是 range，当然不存在 key not found 的错误了，如果需要可以根据返回的条目确定结果。</p>
<blockquote>
<p>Q：在3.3etcd中有一个etcd处于故障状态，集群api暂时不可用这个问题除了升级etcd还有其余解决方案嘛</p>
</blockquote>
<p>A：生产环境一定要配置定期的数据备份策略，用于极端情况下的集群恢复。当然对于超过 quorum 节点，理论上我们可以扩展支持 “不安全” 的 member 调整方案，用于最大可能的恢复最近的数据，欢迎到社区发起类似 issue 的讨论，或许它就会成为我们的下一个增强。</p>
<blockquote>
<p>Q：Objects是什么呢</p>
</blockquote>
<p>A：指 kubernetes 中的 pod/node/configmap 等资源对象</p>
<blockquote>
<p>Q：能不能整理出三个东西：名词列表、问题场景、解决办法图解版😃👍</p>
</blockquote>
<p>A：敬请期待</p>
<blockquote>
<p>Q：kubelet 升级对节点上运行容器的影响大致有哪些呢？</p>
</blockquote>
<p>A：比如因 spechash 的兼容性问题导致容器被意外重启</p>
<blockquote>
<p>Q：为什么acs上node节点的最大pod数量是110，和性能有关系吗？阿里云容器服务不是acs吗？</p>
</blockquote>
<p>A：acs？还是 ack，大规模的 ack 集群也是支持的，非常欢迎提工单骚扰</p>
<blockquote>
<p>Q：etcd 集群的dbsize 的存储空间和pod等数量是正比增长吗？我们一个集群400个pod db竟然达到2G，感觉不正常，另外一个集群才几十M？</p>
</blockquote>
<p>A：也和单个 pod 的数据量大小，etcd compaction 策略有关系，etcd 会储存数据的多个版本。一般从经验上，400 pod 2G 是不太正常的，确认是否存在其他用户数据（比如超大的 configmap)，确认 compaction 正常工作。</p>
<blockquote>
<p>Q：k8s的调度时延都和什么有关系？</p>
</blockquote>
<p>A：和集群中的节点数量，节点的 label 数量和 affinity/anti-affinity 复杂性，以及集群的资源空闲层度有关系。前两者比较好理解，最后一个是因为对于一个资源分配较满的集群，从中找到可以容纳待调度的节点需要更多的尝试次数。</p>
<blockquote>
<p>Q：目前您讲到的特性中有是否有贡献给社区的? 如果有的话,能简单说说吗?</p>
</blockquote>
<p>A：etcd 增强已经回馈社区并且在 etcd 3.4 中发布，kubernetes bookmark 已经发布到 1.15,后续版本请保持关注。我们的策略是尽最大的努力回馈到社区中，请大家放心。</p>
<blockquote>
<p>Q：请问在k8s中，遇到同一个接口对数据库查询时快时慢，然后整个系统中有很多应用都出现时快时慢的情况。这种情况下有什么好的方法去定位问题吗？感觉问题主要在statefulset的性能，和k8s内部网络上，但是却没有什么好的方法去定位.</p>
</blockquote>
<p>A：不是特别明白你的问题。</p>
<blockquote>
<p>Q：对于一个JAVA应用的pod的资源限制有什么好的经验？不知道到底应该限制多少合适？</p>
</blockquote>
<p>A：这是一个比较复杂的话题（VPA)，一般来说我们可以通过放宽 resource limit 来观察应用实际的运行情况，并通过实际经验来判断应该采用多少的 request 值。</p>
<blockquote>
<p>Q：如果kube-apiserver/kube-controller-manager/kube-scheduler是static pod形式部署的，那对这些pod做资源预留的方式，除了request/limit还有其他方法吗？</p>
</blockquote>
<p>A：一般建议隔离 control planes 节点与其他 worker 节点，避免运维上的风险。如果一定要这么做，目前没有好的方法来确保他们。</p>
<blockquote>
<p>Q：针对etcd集群，如何进行有效的监控，阿里云采用什么的方案监控集群的cpu和网络流量等，如果单节点冲高，有什么预警和排查思路吗？</p>
</blockquote>
<p>A：阿里云一般采用 kubernetes on kubernetes 的方案，用户的 kubernetes 集群部署在一个叫做管控的 kubernetes 集群之上，因此用户集群上应用的监控采用典型的 Prometheus 的方案即可。kubernetes 到 etcd 流量不均衡问题，导致单个 etcd 流量偏高，实际上我们已经做了修复方案，这一块大家也可以关注 etcd 3.4 中的 load balancer 机制。</p>
<blockquote>
<p>Q：能否再多介绍一些apiserver上实现</p>
</blockquote>
<p>linearizable read以及通过cache实现的对客户端查询的优化那部分。2.etcd、API server、Controller及调度器优化实例</p>
<hr>
<h3 id="2019-09-03：基于Kubernetes的DevOps平台实战"><a href="#2019-09-03：基于Kubernetes的DevOps平台实战" class="headerlink" title="2019-09-03：基于Kubernetes的DevOps平台实战"></a>2019-09-03：基于Kubernetes的DevOps平台实战</h3><p><a href="https://shimo.im/docs/vjw3P6rD8pyGJXqQ" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：请问老师是通过 Jenkinsfile 来控制版本管理吗，是否使用了 jenkins library，多个环境的情况下，是部署一个Jenkins master，还是每个K8s集群都带有一个 jenkins master？</p>
</blockquote>
<p>A：jenkinsfile实现整个CICD流程，使用git对jenkinsfile代码进行版本管理；目前没有使用jenkins library，但是jenkins library的方式正在重写过程中，还没有完成；多环境的实现是只在一个集群部署一套jenkins master+jenkins agent，不同的环境通过不同agent实现</p>
<blockquote>
<p>Q：我想知道这个分享有什么用？文字直播？</p>
</blockquote>
<p>A：这个我来答一下，感觉没用可以不看，没有强制要求。</p>
<blockquote>
<p>Q：每个jenkins的job里写一个jenkinsfile的repo？这样是不是太浪费了。每个repo就一个jenkinsfile文件（多环境可能有多个分支)。我们是直接写成了jenkinsfile模板，然后jenkins 构建参数传入的。不知道老师是如何权衡的</p>
</blockquote>
<p>A：不是的，所有job使用一个jenkiJenkinsnsfile。每个job就是传递一些基础参数，大多数配如编译命令，部署配置等，都是在devops平台先行配置好之后，触发job构建之后从devops拉取参数配置)</p>
<blockquote>
<p>Q：为什么拉取代码后就要进行Sonar代码扫描呢？研发的代码都没有集成编译验证，扫描代码有什么意义？</p>
</blockquote>
<p>A：不是拉取代码前进行的扫描，是拉取代码完成后进行的扫描。方便对接多语言。这个看取舍的，我们因为涉及语言种类比较多，不太容易顾全所有的语言，而且前期我们php语言的业务较多。</p>
<blockquote>
<p>Q：你们生产环境也关闭防火墙了吗？不用防火墙吗？还是你们用的其他的安全措施</p>
</blockquote>
<p>A：我们生产环境防火墙是关闭的，因为我们使用的是公有云环境，策略都是通过公有云安全组实现的。</p>
<blockquote>
<p>Q：同ansible集成那部分怎么实现的？中间涉及到传参数，例如IP地址，端口号，服务名称，是通过什么控制的？</p>
</blockquote>
<p>A：基础环境信息，都在inventory里维护。其他的一些参数放在一个group_vars中</p>
<blockquote>
<p>Q：node节点使用的是动态token还是apiserver内置的静态的token进行bootstrap的？</p>
</blockquote>
<p>A：动态token，不在apiserver的配置里指定token.csv</p>
<blockquote>
<p>Q：你们master节点和node节点都部署了多少台</p>
</blockquote>
<p>A：master节点3台，16c64G的。node有600台，配置种类比较多</p>
<blockquote>
<p>Q：能否提供一下你们基于pipeline的jenkinsfile示例？</p>
</blockquote>
<p>A：这个因为涉及公司隐私，不方便提供。但是后期基于jenkins library的代码完成后，会进行开源，请后续关注。</p>
<blockquote>
<p>Q：knative和istio现在未来前景咋样，国内有用到生产上去的吗？</p>
</blockquote>
<p>A：我们暂时还没有使用到生产上去，只是调研阶段</p>
<blockquote>
<p>Q：600个node calico用的反射模式还是node mesh?有做pod带宽限制么，谢谢！</p>
</blockquote>
<p>A：node-mesh，目前没有对带宽做任何限制，calico也遇到了不少坑，暂时也没精力进一步的使用功能</p>
<blockquote>
<p>Q：感谢老师分享。想请问下您们的运维团队是怎么配置的，谢谢？！</p>
</blockquote>
<p>A：我们分业务运维、系统运维、dba</p>
<blockquote>
<p>Q：Jenkinsfile 使用文档较少，可以提供在此遇到的坑列举几个典型吗？谢谢！</p>
</blockquote>
<p>A：使用的话，可以去参考有一本groovy的书。遇到的坑的话，大多数是CI/CD逻辑的问题，比如说，我们会有一个容器运行用户的配置，实际业务场景中有使用root的，有使用普通用户的，还会针对不同的环境适配不同的用户配置，逻辑处理出错就会导致实际部署后，pod运行异常。</p>
<blockquote>
<p>Q：请问 主机系统初始化 这一块对系统的发行版和内核版本有什么要求和建议？看到一些docker的问题是因为系统内核版本太低 （3.10 内核 kmem account 泄漏 bugs 导致节点 NotReady)，请问你们是如何选择的？</p>
</blockquote>
<p>A：目前仅支持Redhat、CentOS，内核版本是3.10,没有进行升级。以我们集群运行这么长时间看，虽然有NotReady现象，但是概率比较小，固没对考虑对内核升级</p>
<blockquote>
<p>Q： 请问下集群规模是怎么样的，node节点是怎么做资源保护的？</p>
</blockquote>
<p>A：目前600个node节点，我们目前是监控整体集群水位，在达到60%左右就会对集群进行扩容</p>
<blockquote>
<p>Q：如何实现灰度发布以及蓝绿部署</p>
</blockquote>
<p>A：基于ingress实现的，部分是使用公有云的负载均衡，通过api实现切换</p>
<blockquote>
<p>Q： 目前我们使用的gitlab-ci-runner 部署于k8s之外实现ci/cd。发现gitlab-ci在实际使用中，经常会遇到卡死报错。请问下，相比jenkins 做ci/cd 是会有什么优势，之前并没有使用过jenkins.</p>
</blockquote>
<p>A：gitlab-ci生产环境中，我们也没有使用，我们调研的结果是1、有侵入性 2、pipeline功能较弱，但是有一个好处是遇到错误好像还可以继续执行。jenkins遇到错误会中断流程。</p>
<blockquote>
<p>Q：基于kubeadm+calico，空闲时CPU占用达到30-40%是否正常？</p>
</blockquote>
<p>A：实际使用中没有使用过kubeadm部署，因为封装东西太多，不易于排查问题。空闲时cpu到30-40，需要具体情况分析。</p>
<blockquote>
<p>Q：600个node节点都遇到过什么问题， 有什么需要注意的？</p>
</blockquote>
<p>A：前期网络上遇到的问题比较多，还包含calico bug。后面多数是一些业务使用上导致的问题，还有业务增量之后引发的各种问题。</p>
<blockquote>
<p>Q：请问是怎么配置的多个不同功能的jenkins-slave pod的还有jenkins-slave镜像怎么做的，还有一个任务中有发布和回滚怎么做呢，老师的cicd人工干预的地方在哪里?</p>
</blockquote>
<p>A：jenkins-slave镜像实际就是把jenkins的agent.jar运行在容器中。发布就如同前面所讲。回滚最终是调用helm rollback。cicd人工干预的话都是通过配置项来控制的。</p>
<blockquote>
<p>Q：容器web应用，有没有做安全防护呢 有遇到用户恶意模拟XFF，频繁访问接口么?</p>
</blockquote>
<p>A：这个我们是在入口去做的，因为使用的公有云，直接就上了waf、各种安全产品。</p>
<blockquote>
<p>Q： k8s的编排资源是怎么弄到cmdb上的–anonymous-auth=false 设置后，liveness 访问报401错误，我Kube-apiserver在不停重启，这个需要怎么配置？用insecure ip和port,有不符合安全要求。</p>
</blockquote>
<p>A：这个是没有通过验证，要确认证书或者相关配置，具体的配置可以参考我的文档<a href="https://github.com/k8sre/docs/blob/master/kubernetes/kubernetes高可用集群之二进制部署.md" target="_blank" rel="noopener">kubernetes高可用集群之二进制部署</a></p>
<hr>
<h3 id="2019-08-29：Porter：面向裸金属环境的-Kubernetes-的开源负载均衡器"><a href="#2019-08-29：Porter：面向裸金属环境的-Kubernetes-的开源负载均衡器" class="headerlink" title="2019-08-29：Porter：面向裸金属环境的 Kubernetes 的开源负载均衡器"></a>2019-08-29：Porter：面向裸金属环境的 Kubernetes 的开源负载均衡器</h3><p><a href="https://shimo.im/docs/wG6tjHJyQDGgDTQK" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q1：Porter 和calico有啥区别，简单了看了下都是用的BGP</p>
</blockquote>
<p>A：Porter是一个负载均衡器，而calico是CNI插件，用途不一样。</p>
<blockquote>
<p>Q2：porter有没有竞品？</p>
</blockquote>
<p>A：有一个metallb，以及基于F5的负载均衡器插件</p>
<blockquote>
<p>Q3：leaf节点是不是也需要部署服务?</p>
</blockquote>
<p>A：不需要，只需要开启BGP就可以了</p>
<blockquote>
<p>Q5：公司服务器就十台左右，部署的 Node 节点也比较少，网络方案使用静态路由是不是最好的选择？就是直接在上级路由器上添加 pod 的路由规则。性能方面是不是最好的选择？</p>
</blockquote>
<p>A：pod会有漂移情况的发生，手动更新一是比较麻烦，二是延迟较大。静态配置路由相比于开启BGP的路由器性能上会有一点优势，但是在pod漂移到手动更新路由中间，可能会出现服务中断，如果能承受应该是没问题的</p>
<hr>
<h3 id="2019-08-27：eBay-Kubernetes集群的存储实践"><a href="#2019-08-27：eBay-Kubernetes集群的存储实践" class="headerlink" title="2019-08-27：eBay Kubernetes集群的存储实践"></a>2019-08-27：eBay Kubernetes集群的存储实践</h3><p><a href="https://shimo.im/docs/dJ6Gccp3JrdrCtrP" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：分布式数据库例如MongoDB在k8s上有实现方案吗?</p>
</blockquote>
<p>A：有的，我们内部NoSQL就是完全运行在容器云上的，pod部署由应用自己管理，通过svc暴露服务，存储上使用local PV，并实现了backup restore。社区应该也有比较多的实现参考。</p>
<blockquote>
<p>Q：由于环境，如网络因素，出现短时间暂时大规模掉node的情况怎么处理？</p>
</blockquote>
<p>A：如网络问题导致node连不通，对于网络存储来说，需要在网络恢复之后重连，比如cephfs kernel client和fuse都实现了reconnect</p>
<blockquote>
<p>Q：etcd集群中，v2和数据和v3的数据备份方式不一样，如何备份整个etcd数据呢？</p>
</blockquote>
<p>A：etcd server只能有一种版本，不会并存，所以按照各自版本的方式备份即可</p>
<blockquote>
<p>Q：PVC的anti affinity调度特性是k8s原生支持的吗？自研方案有计划贡献到k8s仓库吗？</p>
</blockquote>
<p>A：不是，我们是在使用MongoDB的过程中，发现master pod的io load很高，所以基于此自己开发了这个功能。</p>
<blockquote>
<p>Q：数据如何做容灾？</p>
</blockquote>
<p>A：网络存储自己有多replica和rack awareness的分布，本地存储需要应用自己实现多拷贝，对于可靠性要求比较高的数据，需要做备份还原。</p>
<blockquote>
<p>Q：本地存储能说的更清楚点么？比如registar是怎么把信息同步到kubernetesnode中的。pv的删除是csi那个组件来做的？信息有哪些信息。谢谢。</p>
</blockquote>
<p>A：registar在注册节点的时候会将vg的相关信息以annotation的方式写到node对象中，pv的删除由csi-provisioner sidecar完成，大体思路可参考社区的design doc。</p>
<blockquote>
<p>Q：容器镜像如何存储和管理？</p>
</blockquote>
<p>A：我们目前用的是quay，用swift存储镜像层</p>
<blockquote>
<p>Q：redis集群，3主3从这种，如何跑在k8s上</p>
</blockquote>
<p>A：可以用statefulset的方式，具体可以参考社区的做法</p>
<blockquote>
<p>Q：使用ceph rbd会出现multiattach error，导致新pod一直处于creating状态，需要人工介入，有无自动处理方案？比如，kubelet挂掉</p>
</blockquote>
<p>A：如出现kubelet挂掉或者node hung导致kubelet不工作，有可能出现这种情况，需要实现节点的remediation，监控这些情况，重启或者下架节点，保证原来的连接断掉。</p>
<blockquote>
<p>Q：请问日志存储是在专有的节点吗？如果不是会和业务数据存储产生影响吗？空间占用,cpu，内存方面的影响。</p>
</blockquote>
<p>A：每个节点组件本身的日志和容器的日志都是通过beats来收集并上报到监控系统，不会和业务数据冲突或干扰。</p>
<blockquote>
<p>Q：存储限制是怎么做的？</p>
</blockquote>
<p>A：对于emptydir，我们使用xfs quota限制。对于PV/PVC，我们在controller层面做了每个namespace的quota limit。</p>
<blockquote>
<p>Q：ceph rbd和本地磁盘有做过benchmark么？cg v2应该只能限制本地盘吧？</p>
</blockquote>
<p>A：<img src="../img/1575857922468.png" alt="-"></p>
<blockquote>
<p>Q：kernel network storage有没有什么好的学习材料？</p>
</blockquote>
<p>A：具体是哪类存储类型，可以参见 <a href="https://www.oreilly.com/library/view/linux-device-drivers" target="_blank" rel="noopener">linux-device-drivers</a></p>
<blockquote>
<p>Q：有没有可能通过StatfulSet 实现分布式存储？来做异地容灾</p>
</blockquote>
<p>A：异地容灾是federation层面的部署，感觉和用哪类workload api没太大关系</p>
<blockquote>
<p>Q：本地存储不需要另外的scheduler-extender么？用原有的scheduler就可以了？</p>
</blockquote>
<p>A：我们是直接在原有的scheduler基础上做了修改，当时还没有extender机制，后续会考虑以extend方式放到外部</p>
<hr>
<h3 id="2019-08-20：小公司如何优雅地推进应用上Kubernetes容器云"><a href="#2019-08-20：小公司如何优雅地推进应用上Kubernetes容器云" class="headerlink" title="2019-08-20：小公司如何优雅地推进应用上Kubernetes容器云"></a>2019-08-20：小公司如何优雅地推进应用上Kubernetes容器云</h3><p><a href="https://shimo.im/docs/wrhTKPcqcp3htR6h" target="_blank" rel="noopener">提问链接</a></p>
<blockquote>
<p>Q：有状态springcloud 微服务如何进行管理和版本控制的？</p>
</blockquote>
<p>A：微服务尽量做到无状态好。</p>
<blockquote>
<p>Q：如何开发微服务应用operator?</p>
</blockquote>
<p>A：这个我看了三次，不太懂想问的问题是啥，我理解微服务应用与operatorr貌似没有什么必然的联系。</p>
<blockquote>
<p>Q：Grafana相比Zabbix有哪些优势和不足呢？</p>
</blockquote>
<p>A：这两者是互补的，应该是问普罗米修斯吧。</p>
<blockquote>
<p>Q：helm如何落地？是否有方案开发替代的系统完成版本管理功能？</p>
</blockquote>
<p>A：暂时没有使用helm，公司使用版本管理是通过调用官方API接口来实现更新、回滚、重启等操作。</p>
<blockquote>
<p>Q5：你们部署k8s应用  是有用到通用的yaml模板结合helm使用嘛 ？</p>
</blockquote>
<p>A：是的，使用通用的yaml模板，但是并没有使用helm。首先再运维平台网页上配置相关参数，发布时候传入变量值，例如启动参数、镜像地址、等生成yaml配置，然后通过API方式调用来实现部署应用。</p>
<blockquote>
<p>Q：promethues server 后端存储tsdb高可用有做么 promethues server起了多个么 ？有遇到过server会偶尔挂掉么</p>
</blockquote>
<p>A：没有做高可用，server端主动挂情况并没有出现，检查下日志看看是否有报错。</p>
<blockquote>
<p>Q：请问从虚拟机正式环境迁移到k8s正式环境，需要做些什么准备，迁移过程会不会中断业务，数据库如何切换</p>
</blockquote>
<p>A：不需要中断任务，应用部署后验证没有问题才切换负载，数据库其实不需要做啥操作，除非你是问数据库上容器的话，数据库这块暂时还没有迁移上去。</p>
<blockquote>
<p>Q：前端和后端是不是改造完全分离的，有没有耦合在一起的项目，这些项目能用ingress吗</p>
</blockquote>
<p>A：大部分项目前后端分离，耦合一起的也能用，关键如何做好转发，现在逻辑上是SLB–&gt;负载层–&gt;ingress-&gt;-service–&gt;pod</p>
<blockquote>
<p>Q：开发环境中需要提供给开发使用的一些有状态的公共服务，在k8s，网络部分如何处理，如注册在zookeeper的服务等等？</p>
</blockquote>
<p>A：容器外访问容器内采取路由跳转，暂时通过node节点网络转发，这块后继需要优化。容器内访问容器外的，可以基于内网DNS配置公共服务地址即可。</p>
<blockquote>
<p>Q：生产部署二进制还是kubeadm？</p>
</blockquote>
<p>A：开发、测试、预发布、生产环境都是使用二进制安装，主要基于ansible剧本安装，只需要修改部分地址变量（例如vip、etcd地址等)即可</p>
<blockquote>
<p>Q：自建的k8s集群，当node节点资源不足时，你们公司是如何做自动扩展node节点的？</p>
</blockquote>
<p>A：还没有实现自动扩容，暂时提供网页版扩容方案，这个也是下一步需要实现的功能之一。</p>
<blockquote>
<p>Q：老师你们公司有做蓝绿发布或金丝雀部署吗？在容器云平台上是通过什么方式去实现的？</p>
</blockquote>
<p>A：金丝雀部署功能已提供，容器这块暂时还没有开放出去，跑在原来服务器的已开发，不过公司有点特殊，金丝雀暂时只开放给测试人员测试使用。、方式以下两种：a、不同的入口，测试人员可以通过切换hosts。b、浏览器设置header参数即可，负载层会判断来源实现不同转发。</p>
<blockquote>
<p>Q：平时这么多微服务的yml文件是如何管理的？通过什么方式编辑和修改</p>
</blockquote>
<p>A：文件其实是不存在的，是直接脚本生成yaml数据，通过api调用，python脚本会写好基本变量，只需要传值即可，脚本截取部分你应该能看明白。</p>
<p><img src="../img/1575858093193.png" alt="-"></p>
<blockquote>
<p>Q：听说你们汇桔网大裁员啊！还有几个运维？？</p>
</blockquote>
<p>A： 现在运维1个</p>
<blockquote>
<p>Q：一个微服务yml文件是deployment和svc配置一起，还是分开的2个文件？</p>
</blockquote>
<p>A：文件其实是不存在的，是直接脚本生成yaml数据，通过api调用。</p>
<blockquote>
<p>Q：etcd看到v2的数据和v3的数据备份方式不一样。如何一起备份？是直接拷贝任意节点的数据文件备份就行了么？</p>
</blockquote>
<p>A：备份需要了解网络和pod数据存放在v2还是v3，明白了就可以确定那些需要备份了，容器的IP对业务应该来说是不影响的，也就是说网络地址变更后，业务还是可以正常运行。</p>
<blockquote>
<p>Q：网络用的canal还是flannel？有测试过性能么。能否满足需求？</p>
</blockquote>
<p>A：网络使用flannel，测试过暂时满足性能需要，后继这块有考虑替换其他，但短时间先不动为主。</p>
<blockquote>
<p>Q：有让开发人员看监控么？比如说资源使用情况？</p>
</blockquote>
<p>A： 监控平台是会开放出去的，开发人员能看到对应的pod使用情况。</p>
<blockquote>
<p>Q：请问，我们是java项目，在业务代码打成war包后，war包很大的情况下，在发布流程中，如何完成pod中的容器的代码更新，是采用挂载代码后重启容器方式，还是采用每次重新构建代码镜像，直接更新容器，或者有什么更好的建议吗</p>
</blockquote>
<p>A：配置分离（上配置中心)，参数通过启动鉴权下载配置文件启动，这样子环境的更新只需要基于通过一个包即可。</p>
<blockquote>
<p>Q：请问，那个管理告警并发送告警监控平台是怎么设计和实现的？</p>
</blockquote>
<p>A：告警发送到监控平台不难，监控平台提供接口，数据过来做过滤存库处理，监控平台通过调用微信企业通讯录，绑定工号，发送也是调用api接口，并没有其他，只是简单做了合并收敛，5分钟内非级别为高的，统一合并发送。</p>
<blockquote>
<p>Q：有没有使用volume，集成分布式存储场景？</p>
</blockquote>
<p>A：volume这块后面会上分布式，暂时文件上传暂时上传到oss上。</p>
<blockquote>
<ul>
<li>Q：持续化存储推荐用的是什么，ceph可以吗，这个数据做过持久化后，怎么做高可用</li>
<li>Q：redis有跑在k8s上么？主从或者集群有在k8s有跑么？传统的主从跑到k8s上需要做redis主从么？</li>
<li>Q：  K8S PYTHON client  的对象如何转json的？自己实现decoder？</li>
</ul>
</blockquote>
<hr>
<h3 id="2019-10-24：玩转Kubernetes开发测试环境"><a href="#2019-10-24：玩转Kubernetes开发测试环境" class="headerlink" title="2019-10-24：玩转Kubernetes开发测试环境"></a>2019-10-24：玩转Kubernetes开发测试环境</h3><blockquote>
<p>Q：目前遇到的一个实际问题，就是开发测试环境如何进行数据冷启动？一般需求开发都依赖各类数据，开发人员需要在开发阶段往开发测试环境中灌入数据，还是从线上同步部分数据？请教下阿里内部是如何进行的。</p>
</blockquote>
<p>A：在阿里内部开发测试环境是共用的一个日常测试数据库，不需要冷启动。在刚才介绍的模式里面我们希望日常测试环境足够稳定，只在需要发布的时候做部署和更新，其它的开发和联调测试行为都发生在本地，直接开发和测试</p>
<blockquote>
<p>Q：数据库表的Schema、nginx conf、RabbitMQ的Queue等结构，开发测试环境是怎么和线上实时同步的呢？</p>
</blockquote>
<p>A：会有专门平台做数据结构变更流程，从日常开始执行，测试完成后同步到预发、生产。开发中的Schema本身不够稳定，一定是日常验证通过之后才会往预发同步变更。</p>
<blockquote>
<p>Q：我们公司有上千个应用，如何利用Kubernetes进行多版本并行开发？同时部署开发都非常困难，目前采用各个产品线提供多套服务的IP，利用hosts配置进行联调，能否用Kubernetes改进？</p>
</blockquote>
<p>A：首先应用的数量大，但是并不意味着所有的应用都会有相互间依赖。可能是一组应用共同对外提供了一个业务能力。Kubernetes本身是可以简化应用的部署问题。在上面的分享里面，阿里每个应用在发布之后都会部署一个主干环境，这个主干环境的目标就是为了方便其他应用如果有联调需求的时候有一个相对文档的测试环境可以使用。另外提到的利用hosts配置，在Kubernetes中自带的服务发现能力可以帮忙解决这个问题。不过具体的场景会很多，这里就不展开。可以是按照组织架构的模式来划分，也可以按照应用所属的业务领域来划分。剩下的就是怎么把这些映射到Kubernetes的模型上。</p>
<blockquote>
<p>Q：问一下，Service走的IPVS模式，默认不是轮询的嘛，那么发布后端Pod的时候，哪怕是滚动更新，在旧的Pod消失前，不也会有流量走过来吗，怎么能让Service先把旧的Pod摘掉，在停服务呢？</p>
</blockquote>
<p>A：KT Connect的应用场景主要还是在开发测试环境，这块对本身的稳定性要求和线上环境不太一样。另外如果想确保服务始终可用的话Mesh模式刚好使用与这个场景。原生Kubernetes也提供了探针的能力来确保当服务不可用时，流量不会转发到Pod实例。</p>
<blockquote>
<p>Q：容器化改造，业务转化成容器个数应该怎么评估？</p>
</blockquote>
<p>A：这个问题也是一个很具体的问题，容器化改造和你目前的应用部署逻辑会有很大的关系。容器的个数并不是关键的衡量指标。比如在Kubernetes下一个Pod可以包含1到多个容器，这几个容器共同提供一个服务。所以还是看具体场景哈。</p>
<blockquote>
<p>Q：对于开发人员来说，使用Kubernetes除了可以快速的生成代码运行环境之外，和传统的代码提交、拉取到指定运行环境的方式比较而言，还有什么好处？</p>
</blockquote>
<p>A：在简单场景下直接对比这两种模式，不会有太大差异。不过就像今天的分享内容，我们希望对于开发人员而言，写完代码就不要去提交-部署然后在联调。直接在本地编码，本地运行然后和远端的服务进行集成。这样效率会明显提升很多</p>
<blockquote>
<p>Q：KT和kubectl exec的区别是？</p>
</blockquote>
<p>A：KT Connect主要是解决本地与集群内服务集成联调的问题，kubectl exec是在已有的Pod上运行命令，不是一个维度的问题。</p>
<hr>
<h3 id="2019-09-25：HC-Bridge容器网络模式分享"><a href="#2019-09-25：HC-Bridge容器网络模式分享" class="headerlink" title="2019-09-25：HC Bridge容器网络模式分享"></a>2019-09-25：HC Bridge容器网络模式分享</h3><blockquote>
<p>Q：HC Bridge支持Kubernetes的Service吗？</p>
</blockquote>
<p>A：HC Bridge原生就是支持ClusterIP和Service的。安装Kubernetes是就会开启br_netfilter的特性，基于Netfilter的ClusterIP仍然能够使用，所以ServiceName也是支持的。</p>
<blockquote>
<p>Q：能讲讲HC Bridge负载均衡是怎么做的吗？</p>
</blockquote>
<p>A：HC Bridge采用Linux Bridge，不同于MacVLAN/SRIOV，本身具备Kubernetes原生的ClusterIP的机制。</p>
<blockquote>
<p>Q：HC Bridge对于MacVLAN有什么优劣势？</p>
</blockquote>
<p>A：MacVLAN性能略高于Bridge，Pod和Node二层隔离，需要借助三层才能通信；HC Bridge能够使用VLAN使Pod和Node在二层隔离，使用HC Bridge的Pod网络流量能够经过Node的协议栈，Pod流量能在Node层面统一管理和控制，并且具备ClusterIP。</p>
<blockquote>
<p>Q：多租户/VPC模式下是否可以互相之间网段冲突？</p>
</blockquote>
<p>A：HC Bridge网段是否可以冲突取决于底层基础设施。</p>
<blockquote>
<p>Q：HC Bridge的监控怎么做的？</p>
</blockquote>
<p>A：对于平台层面的网络质量监控、TCP层的监控，kubelet自带的cAdvisor就能够监控的要求；对于更加细粒度的业务层面的监控，我们自研的基于业务链路的监控来满足要求。</p>
<blockquote>
<p>Q：HC Bridge对于硬件交换机有要求么？</p>
</blockquote>
<p>A：几乎没有要求，只要交换机允许一个端口能够转发多个Mac地址的流量即可，大部分交换机都能够满足要求。</p>
<blockquote>
<p>Q：通常在什么情况下会选择使用HC Bridge，而不是Calico？</p>
</blockquote>
<p>A：希望容器能够被集群外应用直接访问，业务能够感知PodIP，而不是通过Ingress和NodePort。例如中间件集群、Dubbo集群、Spring Cloud集群。在传统行业，网络管理员希望容器网络和物理网络一样，能够被传统的硬件设备管控。</p>
<blockquote>
<p>Q：HC Bridge在OpenStack环境下的兼容性怎么样？</p>
</blockquote>
<p>A：如果使用Neutron网络，底层是使用的是Linux ridge当做网络驱动，则是可以兼容的；如果底层是OVS作为网络驱动，则默认情况下是不兼容的。</p>
<blockquote>
<p>Q：HC Bridge在VMWare环境下的兼容性怎么样？</p>
</blockquote>
<p>A：在VMWare的绑定环境下的分布式交换机，要求网络是混杂网络，并且要求在宿主机上开启阻止混杂模式的重复数据包。</p>
<blockquote>
<p>Q：为什么要自己在弄一个etcd？</p>
</blockquote>
<p>A：结构图只是示意，etcd仍然可以复用Kubernetes本身的etcd，对于大规模场景，也可以考虑使用独立的etcd。</p>
<blockquote>
<p>Q：HC Bridge支持和OpenStack资源池互通吗？</p>
</blockquote>
<p>A：可以的互通的，容器网络可以和物理网络、虚拟机网络在同一个层。</p>
<blockquote>
<p>Q：是不是你们Pod直接挂在虚拟机网卡上，Node之间是VLAN通信是不是二层互通？</p>
</blockquote>
<p>A：这种设计应该也可以，但是动态扩展和容器网络管理完全依赖于虚拟机网络。我们没有直接使用虚拟机网卡，只是通过Bridge把容器网卡和虚拟机网卡连接起来，需要借助虚拟机网卡通信。</p>
<blockquote>
<p>Q：HC Bridge和SDN结合紧密吗？</p>
</blockquote>
<p>A：谈不上紧密结合，HC Bridge可以利用SDN的管理能力，这样HC Bridge本身不用做太多的网络管理。目前更多的是直接与传统网络对接。</p>
<blockquote>
<p>Q：默认Bridge如果拉平网络，容器网关就是路由器的地址，Service就用不了。HC Bridge是如何支持Sercice的？</p>
</blockquote>
<p>A：我们Pod的网关也是路由器地址，目前我们遇到Service不能使用的场景，主要是因为没有开启br_netfilter。</p>
<blockquote>
<p>Q：Contiv的VLAN模式支持Service吗，还在学习中？</p>
</blockquote>
<p>A：Contiv Service应该是可以支持Service的，但是不能依赖于Netfilter来实现。</p>
<blockquote>
<p>Q：既然同一个二层，为何不用flannel hostgateway模式？集群规模可扩展性也较差吧？</p>
</blockquote>
<p>A：flannel host-gw模式，跨Node的Pod通信时基于路由的，是三层；Flannel是基于路由的方案，需要借助BGP才能实现与其他网络的互通，对交换机有一定的要求；对于规模而言，HCBridge的规模主要受限于VLAN数量和IP地址余量；对于扩展性而言，HC Bridge能够给Pod网络动态增加VLAN 和IPPool，能够保证扩展性。</p>
<blockquote>
<p>Q：HC Bridge方式有什么缺点？下一步发展方向是什么？</p>
</blockquote>
<p>A：二层网络在虚拟机平台，都需要在虚拟机平台的网络开启混杂模式，这一点是比较消耗性能的；目前主要是继续关注双栈的支持、容器网络流量监控和流量管理方面的事情。</p>
<blockquote>
<p>Q：IP是如何分配的？追问：IPAM部署在哪里呢？IP地址段配置数据存在etcd里面是吗。</p>
</blockquote>
<p>A：HC Bridge提供IPAM管理的功能，可以根据IP地址CIDR、VLAN等创建IPPool；然后可以根据业务、根据分区划分IP地址。HC Bridge的CNI和IPAM都会以DaemonSet形式分发到每个Node中。IP地址的相关信息肯定是存在etcd的。</p>
<hr>
<h3 id="2019-08-16：初探云原生应用管理之：聊聊-Tekton-项目"><a href="#2019-08-16：初探云原生应用管理之：聊聊-Tekton-项目" class="headerlink" title="2019-08-16：初探云原生应用管理之：聊聊 Tekton 项目"></a>2019-08-16：初探云原生应用管理之：聊聊 Tekton 项目</h3><blockquote>
<p>Q：请比较一下 Drone 和 Tekton，thx！</p>
</blockquote>
<p>A：Drone 是一个 CI/CD 工具，Tekton 是用来做 CI/CD 的框架。Tekton 在更底层，也更为灵活。</p>
<blockquote>
<p>Q：Tekton 作为一个执行引擎，可能会有很多执行节点串联运行，不同节点中运行状态和日志是如何反馈的？</p>
</blockquote>
<p>A：Tekton Pipeline 本身就是 Kubernetes API object，我们通过汇总 Status 来透出运行状态。由于 Tekton Pipeline 启动的都是 Kubernetes Pod，我们可以复用原有的基础设施去收集，然后做一遍汇总。</p>
<blockquote>
<p>Q：Tekton 如何与 GitOps 结合？</p>
</blockquote>
<p>A：我们做了一个类似于flux<a href="https://github.com/fluxcd/flux" target="_blank" rel="noopener">fluxcd/flux</a>的 Operator，通过监听 webhook事件等来触发操作。</p>
<blockquote>
<p>Q：Tekton 集成方面有哪些特性？</p>
</blockquote>
<p>A：灵活以及非常云原生。比传统工具更好在 Kubernetes 跟其他组件做集成。比方说，跟 Flagger 等在 Kubernetes 提供金丝雀发布策略的组件结合，做云原生应用发布。</p>
<blockquote>
<p>Q： Tekton 既然作为 Knative 项目里面一个叫做 build-pipeline 的子项目，那请问下 Tekton 和 Knative 有什么不同或者对比优缺点吗，我最近有准备做 Knative，今天有幸看到这个分享，正好请教一下？</p>
</blockquote>
<p>A：Knative 是 Serverless Framework，跟 Tekton 解决的不是一个层面的事情，没有比较性。相反，他们可以inter-operate，Knative 里就使用了 Tekton。</p>
<blockquote>
<p>Q：我的看法是 CD 和 CI 都只是 Tekton 的 Task，能否讲下你们的 CI？</p>
</blockquote>
<p>A：你好，我们做的是CD。不只是 Tekton Task，也用了其他的 Tekton 原生功能，比如Pipeline、PipelineResource等。我们做的是面向多云/多集群交付的、面向复杂有状态的阿里巴巴中间件应用的发布平台。</p>
<blockquote>
<p>Q：你们做的这个和 Jenkins X Pipeline Operator and Tekton的区别和两者的优缺点？</p>
</blockquote>
<p>A：Jenkins X 是 CloudBees 团队基于原来 Jenkins 的需求，再使用 Tekton、Prow 等搭建的 CI/CD 平台。这也侧面说明了 Tekton 等云原生工具的优势。但 Jenkins X 做的比较重。而且以 CI端为主，不支持复杂的发布策略。</p>
<blockquote>
<p>Q：请问有什么好的 GitOpstrigger？我们使用的的是 Phabricator， 一直没有找到适合的trigger。</p>
</blockquote>
<p>A：这个主要看工具本身（比如 Phabricator）提供什么样的 Git trigger，然后才能集成到如 flux 这样的 GitOps 工具中。</p>
<blockquote>
<p>Q：请比较一下 Prow 和 Tekton，发现 Kubernetes，Prometheus 以及 Tenkton 本身都是使用了 Prow。</p>
</blockquote>
<p>A：Prow 是一款基于 GitHub 做的 Chatbot 工具。Tekton则是用来实现后面对接的 CI/CD 的底层框架。本人恰好也是早期参与 Prow项目，所以多说一点这个工具的历史。一开始 GitHub功能不够强大，这个工具只是为了弥补 GitHub 的不足之处，主要是要经过review 不能让人手动合并代码。后来功能做着做着变多了，有些被 GitHub重复了。但是功能集合还是比 GitHub 多，而且 CNCF 里的 infra 默认使用。</p>
<hr>
<h3 id="2019-08-14：PPmoney基于Kubernetes的DevOps实践"><a href="#2019-08-14：PPmoney基于Kubernetes的DevOps实践" class="headerlink" title="2019-08-14：PPmoney基于Kubernetes的DevOps实践"></a>2019-08-14：PPmoney基于Kubernetes的DevOps实践</h3><blockquote>
<p>Q：怎么支持多租户不同流程定制使用及数据隔离需要？</p>
</blockquote>
<p>A：这里我理解的是CI流程的定制？当前我们都是按照标准默认的Jenkinsfile/Dockerfile来接入，用户可自定义这两个文件。</p>
<blockquote>
<p>Q：集群外部网络访问流量走向是：Client -&gt; LVS -&gt; nginx-ingress-controller -&gt; Endpoints，不是 Ingress -&gt; SVC -&gt; 微服务？</p>
</blockquote>
<p>A：ingress-controller其实是通过SVC来获取到提供服务的微服务即Endpoints。</p>
<blockquote>
<p>Q：某个微服务节点比较，每次升级耗时特别长。有什么好的方式？</p>
</blockquote>
<p>A：服务升级主要关系到的是Kubernetes的rollingUpdate策略，升级慢大部分时候其实是启动慢，服务没有很快达到ready状态。这个跟resource的limit以及request也有关系。</p>
<blockquote>
<p>Q：目前生产环境Kubernetes是部署在公有云主机，还是物理机器上？有无做个性能测试对比？</p>
</blockquote>
<p>A：生产环境我们目前还是小部分试点在IDC机房，之前也有在Azure上部署过AKS集群，AKS的话会有一些网络的问题，例如SVC的模式只能是使用iptables而不能使用ipvs。性能测试对比的话，对比过AKS上的实例跟内部云平台上的实例QPS，大概是1/3这样子。</p>
<blockquote>
<p>Q：请问你们日志收集是怎么做的呢？</p>
</blockquote>
<p>A：分享内容里边有写到，Filebeat收集之后发送到Kafka，再由消费者取出做处理再入到ES集群。</p>
<blockquote>
<p>Q：你们用过Istio吗，对容器性能有影响吗？</p>
</blockquote>
<p>A：Istio还在调研阶段，当然测试集群也有部署，对于用户可见的命名空间是disable的。对容器性能，应该说是对服务的性能影响，因为多了几次iptables的转发，开启mixer影响会更大些。性能与服务治理之间会有取舍。</p>
<blockquote>
<p>Q：如何通过更改源码的方式来修改kubeadm证书期限问题？</p>
</blockquote>
<p>A：1年期的默认值是hardcode到kubeadm的源码中（在<code>k8s.io/kubernetes/cmd/kubeadm/app/util/pkiutil/pki_helpers.go</code>{.prettyprint}文件中的<code>duration365d</code>{.prettyprint}变量）的，改这个重新打包kubeadm的binary即可（非常不建议这种操作）。</p>
<blockquote>
<p>Q：Istio部署在Kubernetes高可用集群上，是每个Master都要安装吗？</p>
</blockquote>
<p>A：不需要喔，如果是使用官方Helm部署安装的话ControlPlane默认会有HPA的。</p>
<blockquote>
<p>Q：Istio存在高可用吗？</p>
</blockquote>
<p>A：上面指的我理解是控制层面的高可用。</p>
<blockquote>
<p>Q：混沌测试怎么做，有介绍吗？</p>
</blockquote>
<p>A：混沌测试借鉴了Chaoskube项目，我记得是，因为我们需要的混沌测试功能相对比较简单。阿里开源的ChaosBlade也非常不错。如果说有使用到Istio的同学试试fault injection。</p>
<blockquote>
<p>Q：监控方面有平台化吗，没有的话报警规则增加是谁来做的？</p>
</blockquote>
<p>A：现在告警规则还是管理员来处理，其实平台化实现，prometheus-operator中，Prometheus的规则是从CRD即PrometheusRule生成再生成到ConfigMap中，我们只需要实现创建这个PrometheusRule的接口即可（还需要对应到ruleSelector）。</p>
<blockquote>
<p>Q：同一个宿主机上多个相同Pod，日志文件怎么收集？</p>
</blockquote>
<p>A：Pod是不会有相同的ID的，通过filebeat/fluent-bit这类日志Agent收集都会有内置功能来支持将Pod的metadata信息也包含在每一条日志记录中。</p>
<blockquote>
<p>Q：请问从开发到测试到生产的发布用到了哪些工具栈？分别起什么作用？</p>
</blockquote>
<p>A：开发其实就只需要提交代码到SCM，之后的工作由云平台来触发，在分享中的CI/CD图里边有画出来。涉及的工具主要还是Jenkins，测试的同学会在Jenkins中做相应的任务。这种做法的缺点上面也有说到”似乎跟云原生背道而驰”。</p>
<hr>
<h3 id="2019-08-05：基于OVS自研容器网络插件在金融类企业的落地实践"><a href="#2019-08-05：基于OVS自研容器网络插件在金融类企业的落地实践" class="headerlink" title="2019-08-05：基于OVS自研容器网络插件在金融类企业的落地实践"></a>2019-08-05：基于OVS自研容器网络插件在金融类企业的落地实践</h3><blockquote>
<p>Q：IPAM的固定IP是怎么实现的？IP与Pod UID关联吗？</p>
</blockquote>
<p>A：管理员录入网络信息后，Fabric会将所有IP地址存储到etcd中统一管理。目前固定IP是通过给deployment等workload对象增加Annotation实现的。IP不与Pod UID关联。</p>
<blockquote>
<p>Q：这里面提到的三层网络和二层网络是指七层协议的三层二层吗？</p>
</blockquote>
<p>A：是的，比如交换机工作在2层，路由器工作在三层。</p>
<blockquote>
<p>Q：服务负载均衡怎么实现的呢？</p>
</blockquote>
<p>A：外部流量导入集群的负载均衡是通过另外一个组件，ingresscontroller实现的，没有实现在CNI里面。 Kubernetes svc的负载均衡是通过iptables实现的，Fabric项目也会往iptables里面加入一些规则，主要是跨节点SNAT。</p>
<blockquote>
<p>Q：支持流量限流么？</p>
</blockquote>
<p>A：支持Ingress/Egress限速，通过给容器加Annotation即可以实现容器的限速。</p>
<blockquote>
<p>Q：有和Contiv做过对比吗？</p>
</blockquote>
<p>A：选型阶段做过，比较早了，那时候貌似Contiv还不太成熟，所以没深入研究。</p>
<blockquote>
<p>Q：这些网络方案有什么好的学习方式吗？</p>
</blockquote>
<p>A：网络虽然很复杂，但万变不离其宗。容器网络这个词最近几年比较流行，是因为网络再容器环境下遇到了一些挑战，但网络本质的概念还是过去非常成熟的那一套。所以首先得学习基本的网络知识，然后去看下容器环境快速弹性等带来的痛点。</p>
<blockquote>
<p>Q：TC怎么实现的？</p>
</blockquote>
<p>A：这个实现的比较久了，早在过去重点支持Calico的时候就已经做了。有些细节模糊了，但基本是通过Linux tc实现的，因为本质是veth pair，所以限速可以在主机侧veth端实现。基本的限速命令可以查找tc机制就可以了，我们碰到限速不太准确，最后也通过调整参数解决了，误差控制在百分之几吧。</p>
<blockquote>
<p>Q：与Kube-OVN做过对比吗？</p>
</blockquote>
<p>A：Kube-OVN是友商开源的产品，我了解过。首先Kube-OVN和Fabric项目都是基于OVS进行研发的，都支持Overylay/underlay模式，都可以实现CNI协议。但其实差别还是比较大。OVN项目源于OpenStack，OpenStack里的网络模型是非常重的，概念、组件都比较多，OVN也在试图统一Kubernetes/OpenStack的网络模型，所以Kube-OVN里有一些能力其实已经不在CNI spec的范围内了，比如负载均衡，DNS等，其实在社区都有对应的实现。而Fabric会简单很多，是一个标准的CNI实现，网络模型也非常清晰，能够把容器直接融入现网环境，企业的网管一般都能掌控，对安全监管等已有体系兼容性比较好。</p>
<hr>
<h3 id="2019-07-24：TiDB-Operator-的设计与实现"><a href="#2019-07-24：TiDB-Operator-的设计与实现" class="headerlink" title="2019-07-24：TiDB Operator 的设计与实现"></a>2019-07-24：TiDB Operator 的设计与实现</h3><blockquote>
<p>Q：升级开始时，partition = 节点数 - 1，也就是所有的 Pod 都不升级，为啥是partition = 节点数 - 1？</p>
</blockquote>
<p>A：这里要纠错一下，是 pod ordinal 从 0开始计数，大于或等于 partition 序号的 Pod 会被升级，所以最大的序号是节点数 - 1，最开始的 partition是等于节点数，分享时表达错了（我自己也记错了），抱歉。</p>
<blockquote>
<p>Q：还有就是驱逐 leader 成功了怎么防止要升级的 Pod 重新被选为leader？</p>
</blockquote>
<p>A：我们实际上是在 PD 中提交了一个驱逐 leader 的任务，PD会持续保证驱逐完毕后没有新 leader进来，直到升级完毕后，由控制器移除这个任务。</p>
<blockquote>
<p>Q：集群规模多大？多少Pod Node？</p>
</blockquote>
<p>A：我们在 Kubernetes 上内部测试的规模较大的集群有 100 + TiKV节点 50+ TiDB 节点，而每位研发都会部署自己的集群进行性能测试或功能测试。</p>
<blockquote>
<p>Q：想了解下数据库容器化，推荐使用 Local PV吗，有没有哪些坑或最佳实践推荐？我们在考虑 MySQL数据库容器化以及中间件容器化，是选择 Local PV 还是线下自建 Ceph 集群？</p>
</blockquote>
<p>A：Local PV 其实不是一个选项，而是一个强制因素，因为网络盘的 IOPS是达不到在线存储应用的生产环境需求的，或者说不是说线上完全不能用，而是没法支撑对性能要求比较高的场景。MySQL的运维我相对不是很清楚，假如 MM能够做到双副本冗余强一致的话，那理论上就能用。大多数中间件比如Kafka、Cassandra 都有数据冗余，这些使用 Local PV 在理论上都是没问题的。</p>
<blockquote>
<p>Q：看你的方案感觉 Kubernetes 和 PD的逻辑结合在一起了，二者之间如何互通？会有代码互相侵入吗？明白了，就好像问题2驱逐问题，pd收到驱逐任务，Kubernetes控制器不断的检查是否驱逐成功，如果成功就开始升级，对吧？</p>
</blockquote>
<p>A：这就是自定义控制器的绝佳场景了，Kubernetes 和 PD本身完全没有交互，是控制循环在同步两边的状态，一方面控制循环会把 PD记录的集群状态塞到 TidbCluster 对象的 status里面，另一方面控制循环在将实际状态向期望状态转移时，也会生成一些 PD的任务和操作子（Opeartor）提交到 PD 中来调谐集群状态。</p>
<hr>
<h3 id="2019-07-17：基于Istio的灰度平台实践"><a href="#2019-07-17：基于Istio的灰度平台实践" class="headerlink" title="2019-07-17：基于Istio的灰度平台实践"></a>2019-07-17：基于Istio的灰度平台实践</h3><blockquote>
<p>Q：如何判断check、quota下放istio-proxy引入的问题？</p>
</blockquote>
<p>A：得通过压测了，看性能损耗了。我们后续会加入Mixer的功能再压测一轮。现在做的压测还是不开Mixer功能的场景下压的。因为我们线上目前还不打算开Mixer。</p>
<blockquote>
<p>Q：能否给个demo？</p>
</blockquote>
<p>A：目前还没有开放在外面的demo。可以给些思路，请问你想要什么要的功能的demo？没实践过，听理论总是有点虚！可以实践一下。我们主要是用的Istio（Envoy）的流量管理的功能。主要是要配置Istio的流量管理策略。给业务人员再给他们配置yaml文件，学习成本太大，所以做了可视化，有按流量，按用户，自定义三种方式。主要是把页面配置编译成yaml流量配置。</p>
<blockquote>
<p>Q：Istio每个服务中得到的访问IP都是127.0.0.1，这个该怎么搞？能拿到realclient ip？</p>
</blockquote>
<p>A：kubectl getsvc应该可以查到clusterip，接着Q3，app拿到外面访问的address都是127.0.0.1的。</p>
<blockquote>
<p>Q：服务的应用运行日志在Istio中如何获取或者查看，例如log4j控制台的输出？</p>
</blockquote>
<p>A：应用运行日志就在应用容器上看啊。我们是通过标准输出收集到了InfluxDB中。</p>
<blockquote>
<p>Q：Envoy的CPU、内存的request、limit一般配置多少？</p>
</blockquote>
<p>A：我们压测的是默认的Envoy的资源限制。没有修改默认的资源限制。</p>
<blockquote>
<p>Q：里面在配合Spring Clund有必要吗？</p>
</blockquote>
<p>A：感觉没必要，重复了，Istio让程序员更关注业务，将维护管理分离</p>
<blockquote>
<p>Q：有配合Alibaba Nacos试试吗实验落地的最好，consul.etcd选哪个好点？</p>
</blockquote>
<p>A：没有使用过AlibabaNacos，我们未来会走Kubernetes的服务发现，所以会选择etcd吧。</p>
<blockquote>
<p>Q：SpringCloud向Istio迁移好迁移吗？</p>
</blockquote>
<p>A：比较好迁移。我们遇到的问题主要就是通讯的问题。涉及到Feign和gRPC两种。需要升级一下starter，传递一下header。因为我们的流量标签是在header中传递。还有一个重要的就是分享里提到的，服务发现问题。因为要做渐进式升级，不能一下就给所有的服务上Istio，边缘服务先上，热门服务后上，所以要兼容之前的服务发现（Consul），同时有两个服务发现机制的时候会有些问题。</p>
<hr>
<h3 id="2019-07-10：Kube-OVN-的设计思路和实现原理"><a href="#2019-07-10：Kube-OVN-的设计思路和实现原理" class="headerlink" title="2019-07-10：Kube-OVN 的设计思路和实现原理"></a>2019-07-10：Kube-OVN 的设计思路和实现原理</h3><blockquote>
<p>Q：能说说组件 kube-ovn-cni 具体是做什么的？OVN 本身不是已经是 OVS的控制面了么？</p>
</blockquote>
<p>A：其实做的是容器网卡和 OVS 的对接，OVN 那边生成了 port的信息，需要 kube-ovn-cni 把这个信息同步到 OVS 和容器网卡。</p>
<blockquote>
<p>Q：能讲讲Kube-OVN 负载均衡和会话保持是怎么做的吗？已经支持哪些策略？</p>
</blockquote>
<p>A：目前的负载均衡用的是 OVN 的 L2Loadbalancer，这一块的负载均衡还比较简单只支持 IP Hash。</p>
<blockquote>
<p>Q：多租户/vpc 模式下是否可以互相之间网段冲突，如何实现 livenessProbe？</p>
</blockquote>
<p>A：这块暂时还不支持，主要是 kubelet 是在主机的 network namespace 进行probe，其实可以改 kubelete 代码进入到对应容器的 ns 再 probe就可以了，但是这块需要 upstream 来进行支持，自己魔改现在倒也是个方案。</p>
<blockquote>
<p>Q：Kubernetes的业务使用本身就是有局限的，这种无限制扩大虚拟网络的做法，基于业务风险和成本来讲，真的很勇敢，如果原有的Kubernetes 生态被改掉了，怎么保证开源的东西可以业务延续？</p>
</blockquote>
<p>A：这个问题有点大，我们现在看到的趋势还是 Kubernetes不断的发展，各个业务都在往 Kubernetes 走，我们做这个其实也希望能尽量和Upstream 同步，并且之后可以去影响 Upstream。还有很多复杂的功能，比如IPv4/IPv6 的双栈，多租户我们暂时也还没开始，也是因为 Upstream现在对这块的支持还不好</p>
<blockquote>
<p>Q：和<a href="https://github.com/ovn-org/ovn-kubernetes" target="_blank" rel="noopener">ovn-kubernetes</a> 的区别是什么？</p>
</blockquote>
<p>A：ovn-kubernetes 我们之前调研主要问题在于他们是和 Flannel类似的一个节点一个子网的模型，再就是看他们的代码过程中发现控制平面存在着丢消息的隐患。最后看到网络模型和控制平面都要改，工作量太大了我们就自己从头来了。</p>
<blockquote>
<p>Q：容器内流量采集监控有没有什么实战和想法？</p>
</blockquote>
<p>A：目前还是用的标准的采集网卡上 TX、RX 的一些指标的做法。不过 Kube-OVN上现在有流量镜像的能力，未来其实可以做更详细的应用层数据包分析。</p>
<blockquote>
<p>Q：使用 Flow 负载均衡器的性能怎么样，是否适合上生产环境？</p>
</blockquote>
<p>A：大部分的Flow 性能问题都可以用 DPDK来解决，我们之前问过一些公有云的厂商性能方面是可以的，但是可能功能方面有些简单。</p>
<blockquote>
<p>Q：请问网络相关的功能支持，目前是只针对以太网络吗，你们有对其它高速网络有支持不？</p>
</blockquote>
<p>A：目前是只有以太网，但是其他形式的理论上只要 OVS支持，适配起来应该都比较方便。</p>
<blockquote>
<p>Q：使用 OVS 对 Host机器的性能压迫有多大？</p>
</blockquote>
<p>A：我们目前看来还好，OVS 本身带 cache的机制，主要还是业务对性能用的比较多一些。</p>
<blockquote>
<p>Q：Tracing方面跟踪流表有没有想过做自动化？</p>
</blockquote>
<p>A：有过这个计划，打算结合ovn-tracing，ovs-tracing再加上宿主机的探针做一个端到端的数据包跟踪，来解决网络不通排查方面的问题。</p>
<blockquote>
<p>Q：kube-ovn-controller 如果来不及写入 podIP 这些信息，CNI插件获取不到分配的 IP 信息，会不会导致 Pod 创建失败，还有 ovn-cni是能过什么协议和 ovn-cni-server 进行协作的？</p>
</blockquote>
<p>A：来不及写入的情况下CNIServer 会重试等待 annotation ready，如果超时的话会失败等 kubelet下次调用 CNI 的时候重新获取信息。CNI 和 CNIServer 现在是通过一个本机的socket 走 http 协议进行通信。</p>
<blockquote>
<p>Q：DPDK 怎么满足需求？使用容器，可以用DPDK 加速么？</p>
</blockquote>
<p>A：DPDK 主要做 OVS 的流表加速，社区由 ovs-dpdk 的binding，容器相当于用的是 OVS 的网卡，这样 DPDK 就可以加速容器的网络。</p>
<blockquote>
<p>Q：请问你们在使用网络相关的功能时，会在某些场景对特权模式有强需求吗？</p>
</blockquote>
<p>A：需要使用特权模式，因为要对宿主机的网络进行一些操作。</p>
<blockquote>
<p>Q：在没有硬件交换机的情况，这个网络插件怎么利用虚拟机模拟交换机呢？</p>
</blockquote>
<p>A：还是要有硬件交换机做物理上的网络连通的，虚拟交换机是在机器中用软件的方式来模拟交换机的行为，这样一台机器上的多个容器或者虚拟机就好像接在了一个物理交换机上。</p>
<hr>
<h3 id="2019-07-03：震坤行的容器云实践"><a href="#2019-07-03：震坤行的容器云实践" class="headerlink" title="2019-07-03：震坤行的容器云实践"></a>2019-07-03：震坤行的容器云实践</h3><blockquote>
<p>Q：Kubernetes云平台和物理机平台，在性能对比上，Kubernetes 差多少？</p>
</blockquote>
<p>A： Kubernetes的最小单元是 Pod，Pod 是跑在云主机上的。整个 Kubernetes都是基于云主机/物理机来完成的。</p>
<blockquote>
<p>Q：数据库集群是否适合丢在 Kubernetes上，如果千万级的日活是否有好的解决架构？</p>
</blockquote>
<p>A： 首先数据库是可以跑在Kubernetes 上的，数据库集群直接互连的 IP 是可以通过 Kubernetes 的内部.svc.cluster.local 来代替。如果跑数据库集群，则需要将 Pod 使用硬盘volume mount 将数据映射到硬盘上。目前我们 DEV，UAT环境的数据库在集群中。针对千万级的日活，主要是看瓶颈卡在那一块。</p>
<blockquote>
<p>Q：根据你的描述：你们是从 18 年 8 月份开始使用容器的，到现在一共是 11个月，把 Kubernetes这套生态落地到生产，你们的筹备是几个阶段，然后难点是什么？是否发生重大的生产事故，怎么处理的？你们的后端存储使用的是商业存储数据库还是自己搭建的Ceph 等开源数据库？电商活动临时购买阿里或者腾讯云机器，新增不同机房 Node节点之间网络延迟如何解决的？</p>
</blockquote>
<p>A：我们是分为了三个阶段，一个是测试Kubernetes，一个是测试业务接入，一个是测试接入业务的稳定性。难点就在于以前的架构整改，包括Kubernetes 结合微服务。重大的生产事故未发生过，因为涉及到Ingress、网关等入口服务，一般都是多备份。我们后端的数据库，是在阿里云购买的，DEV，UAT数据库是开源自建的。电商活动前，我们一般是会购买按量付费的机器，我们购买的都是阿里云。</p>
<blockquote>
<p>Q：生产环境会跟着社区版本积极更新 Kubernetes 版本不？或者什么频率？</p>
</blockquote>
<p>A：这个一般不会跟着社区积极更新，除非是当前版本出现重大bug，或者新功能比较适用于我们，才会考虑更新。</p>
<blockquote>
<p>Q：Istio 有没有进行优化，QPS大概是多少？如有优化都是从那些方面进行优化的？</p>
</blockquote>
<p>A：Istio目前是进行过优化的，优化的细节暂时还未统计。当前的 QPS 我们大约是每秒5000 个左右吧。更具体的要看业务。</p>
<blockquote>
<p>Q：有在用统一的文件存储吗？不同用户间会考虑做隔离不？</p>
</blockquote>
<p>A：统一的文件存储有，但是目前主要是拿来放日志，共享等。不通用户间的隔离不太清楚是啥意思，但是每个Pod 之间是隔离的。我们在 DevOps 平台是有权限管理模块的。</p>
<blockquote>
<p>Q：问下你们的日志采集方案是怎么做的？日志是否写在容器里？另外再问下Kubernetes 的 CRI 是用的 Docker 吗？还是用其他的，谢谢。</p>
</blockquote>
<p>A：日志收集是通过 ELK + 二次开发来完成的。日志也会也在容器里，写容器里边随着下一次发布日志就会消失。是 Docker。</p>
<blockquote>
<p>Q：Eureka 和 Istio 不是同一类东西吧，作用都不一样，怎么理解替换不替换？</p>
</blockquote>
<p>A：看架构类型用到那个组件吧，Istio本身具备服务发现功能，我们刚好是服务发现这一块有问题。</p>
<blockquote>
<p>Q：你们的 Kubernetes 集群节点规模有多大？日活？Kubernetes运维团队多少人？</p>
</blockquote>
<p>A： Kubernetes 集群节点有，dev 24台 4C 32G，UAT 30台 4C32G，生产 67台 8C 64G，Kubernetes 运维团队2个人。</p>
<blockquote>
<p>Q：更换成 Istio之后，就不需要单独部署 Ingress 了吧？</p>
</blockquote>
<p>A：需不需要不用Ingress，具体还是得看下业务类型。我们是微服务 API 类的，走的Istio，静态页面类，CDN –&gt; Ingress 。或者是CDN –&gt; SLB –&gt; Pod。</p>
<blockquote>
<p>Q：请问 Kubernetes如何和云服务的弹性伸缩配合使用，例如，因为业务需要，短时间内从 2台节点扩展到十多台节点。可以做到像云服务的弹性伸缩那样吗？不提前配置节点，或者如何让Kubernetes 自己触发云服务的弹性，自动添加云服务的弹性节点。</p>
</blockquote>
<p>A：我们一般会对容器云的 ECS 资源保留20%-25%。如果发现资源不够了，就会提前购买 ECS 加进去。短时间扩容 Node几点的话，就多购买几台 ECS 同时加进去就可以了。Pod是可以做弹性伸缩，ECS云主机也可以做弹性伸缩增加到 Kubernetes集群里边，这个阿里云提供服务的。</p>
<blockquote>
<p>Q：Eureka 是类似 Dubbo的注册中心吗？</p>
</blockquote>
<p>A：是的，Eureka也提供页面，可以查看到有多少个服务注册进来。</p>
<blockquote>
<p>Q：请问一下注册到注册中心的 IP 是容器内 IP 的问题如何解决？</p>
</blockquote>
<p>A：我们是将注册中心部署到 Kubernetes 集群中的。注册中心的内网 IP 和Kubernetes 的内网是互相可以通信的。</p>
<hr>
<h3 id="2019-06-26：智能工厂的容器云实践"><a href="#2019-06-26：智能工厂的容器云实践" class="headerlink" title="2019-06-26：智能工厂的容器云实践"></a>2019-06-26：智能工厂的容器云实践</h3><blockquote>
<p>Q：您认为未来工业PaaS云平台的发展前景和发展模式有哪些？</p>
</blockquote>
<p>A：工业场景本身是千差万别的，石油、金属、制造业等等，都有自己各自的需求，目前来看的话，主要还是要先完成信息化改造，然后才能以此为基础去做后续的比如工艺优化等等。后续应该会公有云、私有云并存，大集团型公司走私有云模式，中小型公司走公有云模式。</p>
<blockquote>
<p>Q：生产很在乎高可用和数据的安全性，Kubernetes如何保证持续存储和稳定性，单靠副本集和集群在网络事故发生后，如何快速迁移恢复？腾讯的王者荣耀采用了比较老的Kubernetes版本并进行了开发，才使用在了生产，中小型企业如何依靠自己的研发实力去处理生产事故。</p>
</blockquote>
<p>A：目前我们遇到的生产事故主要在于机房的偶发性断电导致存储节点上的数据出现故障，现在的话是采用3个存储节点的3副本方式，来保障数据的可靠性。高可用目前还是依赖副本集的形式来保障。对于工厂来说，很少会出现互联网这样的流量峰值，基本都是平稳的。</p>
<blockquote>
<p>Q：Kubernetes的在线热升级容易做吗，请问是不是踩过很多坑呢？</p>
</blockquote>
<p>A：目前对于Kubernetes的热升级，主要是大版本变动会带来一些配置上的改动，因为全部容器化，所以升级本身不复杂。</p>
<blockquote>
<p>Q：现在生产服务的规模多大，服务数量，流水线是每个项目类型一个公共构建项目吗？针对多分支构建如何快速持续集成？针对服务的特殊化需求比如Pipeline的某个stage要跳过怎么办，每个项目一个标准的Jenkinsfile吗？</p>
</blockquote>
<p>A：服务数量根据不同的项目规模，各有不同，智能工厂项目本身是一个很庞大的项目，下面会分很多的子项目，目前来看，一般的子项目服务数量是在50个以内。目前我们还没考虑多分支情况，因为项目不像自己运维的产品，不会存在频繁的更新，我们是按版本形式去走，所有的提交最后都要汇总到主干分支后，再打包发到现场。目前还没有跳过stage的需求。</p>
<blockquote>
<p>Q：Jenkins对开发和测试人员可见吗？如果可见，有没有考虑封装Jenkins，如果不可见，Jenkins日志怎么暴露的？每次构建都要填那么多信息感觉很复杂？有没有改建措施？</p>
</blockquote>
<p>A：目前是可见的，但是没有修改权限，可以直接去看构建日志。</p>
<blockquote>
<p>Q：Windows节点支持情况？</p>
</blockquote>
<p>A：我们会有一些场景需要用到Windows服务器，并且它需要跟容器云内部的服务进行通信。</p>
<blockquote>
<p>Q：请问Jenkinswebhook那些构建参数如何传入GitLab触发？</p>
</blockquote>
<p>A：webhook的触发和界面参数会有一些区别，我们在脚本里面做了处理。</p>
<blockquote>
<p>Q：离线部署，是不是通过打出镜像压缩包，然后带着镜像包到现场部署的容器云平台上，上传部署的方式？</p>
</blockquote>
<p>A：是在家里打出镜像压缩包，然后到现场解压出来，根据镜像类型进行处理，比如一些基础镜像，会直接上传到节点，业务的镜像会在部署完成后上传到Harbor，然后节点从Harbor去拉取。</p>
<hr>
<h3 id="2019-06-05：基于Actor模型的CQRS-ES解决方案分享"><a href="#2019-06-05：基于Actor模型的CQRS-ES解决方案分享" class="headerlink" title="2019-06-05：基于Actor模型的CQRS/ES解决方案分享"></a>2019-06-05：基于Actor模型的CQRS/ES解决方案分享</h3><blockquote>
<p>Q：单点故障后，正在处理的Cache数据如何处理的，例如，http、tcp请求……毕竟涉及到钱？</p>
</blockquote>
<p>A：actor有激活和失活的生命周期，激活的时候使用快照和Events来恢复最新内存状态，失活的时候保存快照。actor框架保证系统中同一个key只会存在同一个actor，当单点故障后，actor会在其它节点重建并恢复最新状态。</p>
<blockquote>
<p>Q：eventID生成的速度如何保证有效的scale？有没有遇到需要后期插入一些event，修正前期系统运行的bug？有没有遇到需要把前期已经定好的event再拆细的情况？有遇到系统错误，需要replayevent的情况？</p>
</blockquote>
<p>A：当时项目中eventID采用了MongoDB的ObjectId生成算法，没有遇到问题；有遇到后期插入event修正之前bug的情况；有遇到将已定好的event修改的情况，采用的方式是加版本号；没有，遇到过系统重新迁移删除快照重新replayevent的情况。</p>
<blockquote>
<p>Q：数据落地得策略是什么？还是说就是直接落地？</p>
</blockquote>
<p>A：event数据直接落地；用于支持查询的数据，是Handler消费event后异步落库。</p>
<blockquote>
<p>Q：actor跨物理机器集群事务怎么处理？</p>
</blockquote>
<p>A：结合事件溯源，采用最终一致性。</p>
<blockquote>
<p>Q：Grain Persistence使用RelationalStorage容量和速度会不会是瓶颈？</p>
</blockquote>
<p>A：GrainPersistence存的是Grain的快照和event，event是只增的，速度没有出现瓶颈，而且开源版本测试中PostgreSQL性能优于MongoDB，在存储中针对这两个方面做了优化：比如分表、归档处理、快照处理、批量处理。</p>
<p>A：开发语言是C#。Golang我了解的不多，proto.actor可以了解一下：<a href="https://github.com/AsynkronIT/protoactor-go" target="_blank" rel="noopener">AsynkronIT/protoactor-go</a>。</p>
<blockquote>
<p>Q：每个Pod的actor都不一样，如何用Kubernetes部署actor，失败的节点如何监控，并借助Kubernetes自动恢复？</p>
</blockquote>
<p>A：actor是无状态的，失败恢复依靠重新激活时事件溯源机制。Kubernetes部署actor官方有支持，可以参考官方示例。在实际项目中使用Kubernetes部署Orleans，我没有实践过，后来有同事验证过可以，具体如何监控不清楚。</p>
<blockquote>
<p>Q：Orleans中，持久化事件时，是否有支持并发冲突的检测，是如何实现的？</p>
</blockquote>
<p>A：Orleans不支持；工作中，在事件持久化时做了这方面的工作，方式是根据版本号。</p>
<blockquote>
<p>Q：Orleans中，如何判断消息是否重复处理的？因为分布式环境下，同一个消息可能会被重复发送到actormailbox中的，而actor本身无法检测消息是否重复过来。</p>
</blockquote>
<p>A：是的，在具体项目中，通过框架封装实现了幂等性控制，具体细节是通过插入事件的唯一索引。</p>
<blockquote>
<p>Q：同一个actor是否会存在于集群中的多台机器？如果可能，怎样的场景下可能会出现这种情况？</p>
</blockquote>
<p>A：一个Id对应的Actor只会在集群种存在一个。</p>
<hr>
<h3 id="2019-05-29：平安证券Kubernetes容器集群的DevOps实践"><a href="#2019-05-29：平安证券Kubernetes容器集群的DevOps实践" class="headerlink" title="2019-05-29：平安证券Kubernetes容器集群的DevOps实践"></a>2019-05-29：平安证券Kubernetes容器集群的DevOps实践</h3><blockquote>
<p>Q：镜像有进行安全扫描吗：</p>
</blockquote>
<p>A：外部基本镜像进入公司内部，我们基于Harbor内置的安全功能进行扫描。</p>
<blockquote>
<p>Q：Harbor有没有做相关监控，比如发布了多少镜像，以及镜像同步时长之类的？</p>
</blockquote>
<p>A：我们没有在Harbor上作扩展，只是在我们自己的Prism4k上，会统计各个项目的一些镜像发布数据。</p>
<blockquote>
<p>Q：有没有用Helm来管理镜像包？后端存储是用的什么，原因是？</p>
</blockquote>
<p>A：没有使用Helm。目前集群有存储需求时，使用的是NFS。正在考虑建基于Ceph的存储，因为现在接入项目越来越多，不同的需求会导致不同的存储。</p>
<blockquote>
<p>Q：想了解下目前贵公司监控的纬度和监控的指标和告警这块。</p>
</blockquote>
<p>A：监控方面，我公司也是大致大致划分为基础资源，中间件，业务指标三大块监控。方法论上也是努力在向业界提倡的RED原则靠拢。</p>
<blockquote>
<p>Q：想了解下，Yaml文件怎么管理的，可以自定义生成吗？</p>
</blockquote>
<p>A：我们的Yaml文件，都统一纳到Prism4k平台管理，有一些资源是可以自定义的，且针对不同的项目，有不同的Yaml模板，然后，透过django的模块功能统一作解析。熟悉Yaml书写的研发同事可以自己定义自己项目的Yaml模板。</p>
<blockquote>
<p>Q：Pipeline会使用Jenkinfile来灵活code化Pipeline，把Pipeline的灵活性和创新性还给开发团队，这比一个模板化的统一Pipeline有哪些优势？</p>
</blockquote>
<p>A：Pipeline的运行模式，采用单一Job和每个项目自定义Job，各有不同的应用场景。因为我们的Jenkins是隐于幕后的组件，研发主要基于Prism4k操作，可以相对减少研发的学习成本。相对来说，Jenkins的维护人力也会减少。对于研发各种权限比较高的公司，那统一的Job可能并不合适。</p>
<blockquote>
<p>Q：想了解下贵公司使用什么网络方案？Pod的网络访问权限控制怎么实现的？</p>
</blockquote>
<p>A：公司现在用的是Flannel网络CNI方案。同时，在不同的集群，也有作Calico网络方案的对比测试。Pod的网络权限，这块暂时没有，只是尝试Istio的可行性研究。</p>
<blockquote>
<p>Q：一个Job生成所有的Docker镜像，如果构建遇到问题，怎么去追踪这些记录？</p>
</blockquote>
<p>A：在项目前期接入时，生成镜像的流程都作了宣传和推广。标准化的流程，会减少产生问题的机率。如果在构建中遇到问题，Prism4k的界面中，会直接有链接到本次建的次序号。点击链接，可直接定位到Console输出。</p>
<blockquote>
<p>Q：遇到节点Node上出现100+Pod，Node会卡住，贵公司Pod资源怎么做限制的？</p>
</blockquote>
<p>A：我们的业务Pod资源，都作了limit和request限制。如果出现有卡住的情况，现行的方案是基于项目作拆分。Prism4k本身对多环境和多集群都是支持的。</p>
<blockquote>
<p>Q：多环境下，集中化的配置管理方案，你们选用的是哪个，或是自研的？</p>
</blockquote>
<p>A：我们现在正在研发的Prism4k，前提就是要支持多环境多集群的部署，本身的功能里，yaml文件的配置管理，都是其内置功能。</p>
<blockquote>
<p>Q：etcd的 –initial-cluster-state选项设置为new，重启etcd后会不会创建新的etcd集群？还是加入原有的etcd集群？</p>
</blockquote>
<p>A：我们测试过轮流将服务器（3Master）完全重启，ectd集群的功能均未受影响。但全部关机重启，还未测试过。所以不好意思，这个问题，我暂时没有考虑过。</p>
<blockquote>
<p>Q：网络方案用的什么？在选型的时候有没有对比？</p>
</blockquote>
<p>A：目前主要应用的还是Flannel方案，今年春节以来，还测试过Flannel、Caclico、kube-router方案。因为我们的集群有可能越机房，而涉及到BGP协议时，节点无法加入，所以一直选用了Flannel。</p>
<blockquote>
<p>Q：部署的动态过程是在Jenkins的Web界面上看还是在自研的Prism4k上能看到，如果是Prism4k的话，整个可视化过程的展示这些等等也是自己开发的吗？Prism4k是用什么语言开发的，Python吗？</p>
</blockquote>
<p>A：部署的动态过程，是在Prism4k上显示。可视化方案，也只是简单的使用ajax及websocket。Prism4k后端是基于Django2.0以上开发，其中使用了RESTfulframework、channels等库，前端使用了一些js插件。</p>
<hr>
<h3 id="2019-04-30：荔枝运维平台容器化实践"><a href="#2019-04-30：荔枝运维平台容器化实践" class="headerlink" title="2019-04-30：荔枝运维平台容器化实践"></a>2019-04-30：荔枝运维平台容器化实践</h3><blockquote>
<p>Q：容器的Pod网络和外部网络全部打通吗，如何实现的？</p>
</blockquote>
<p>A：因为kube-router是基于三层路由，所以只要在顶层交换上指定PodIP的静态路由即可，比如宿主机是192.168.0.1，该宿主机上的pod iprange是10.0.0.1/24，那只要在交换机或需要访问Pod的外部主机上添加路由 10.0.0.1/24 via 192.168.0.1 …即可。</p>
<blockquote>
<p>Q：你们如何去保证io的隔离？</p>
</blockquote>
<p>A：目前网络和硬盘的io没有做隔离，暂时还没有这方面的刚需。kube-router对网络IO这方面控制比较弱。硬盘IO方面Docker支持IOPS控制，但Kubernetes我还不太清楚是否支持。</p>
<blockquote>
<p>Q：Job和dind如何配合去实现打包镜像的呢？</p>
</blockquote>
<p>A：首先是dind技术，通过挂载宿主机的docker client和dockersock，可以实现在容器内调用宿主机的Docker来做一些事情，这里我们主要就用于build。Kubernetes的Job则是用于执行这个构建worker的方式，利用Kubernetes的Job来调度构建任务，充分利用测试集群的空闲资源。</p>
<blockquote>
<p>Q：从宿主机部署直接跨步到Kubernetes部署，不仅需要强力的power来推动，在落地实施的过程中，应该也会经历应用架构上的调整，能阐述你们在这方面遇到的困难和解决方式吗？</p>
</blockquote>
<p>A：Pod网络是最大的痛点，解决方式如文中所说。架构方面我们很早就是微服务去中心化的部署，API网关，服务注册发现等也是在容器化之前就已经完成改造的，所以应用架构反倒是没遇到多大的难题。</p>
<blockquote>
<p>Q：你们Kubernetes里面统一配置是用的ConfigMap还是集成了第三方工具，例如Disconf。你们在Kubernetes中，APM用的是什么呢？Pinpoint还是Sky还是Jeager？还是其他？</p>
</blockquote>
<p>A：过去的项目配置文件是放运维平台上的，所以只要ConfigMap挂进去就可以了。后来新的项目开始采用携程的Apollo，Kubernetes上就只要通过ENV把Apollo的一些相关敏感信息传给Pod即可。APM方面因为我们是Java栈所以使用的skywalking，也是开篇提到的Javaagent技术。</p>
<blockquote>
<p>Q：镜像仓库为什么选用Harbor，选型上有什么考虑？</p>
</blockquote>
<p>A：Harbor主要有UI方便管理，相对来说也容易部署和使用，尤其是权限管理这方面。</p>
<blockquote>
<p>Q：Macvlan和IPvlan性能非常好，几乎没有损耗，但默认都是容器和宿主机网络隔离的，但是也有解决方案，你们这边是没有考虑还是使用了一些解决方案发现有问题又放弃的？如果是后者，有什么问题让你们选择放弃？</p>
</blockquote>
<p>A：Macvlan之类的方式需要交换机层面上做一些配置打通VLAN，并且性能上并不会比基于三层的解决方案要高非常多，权衡之下我们还是选择比较易用的基于三层的方案，甚至为了易用而选择了更为激进的kube-router。</p>
<blockquote>
<p>Q：容器的多行日志收集如何解决？或者是，很多业务日志需要上下文关系，但是ELK只能查询到单条，这种情况怎么处理呢？</p>
</blockquote>
<p>A：容器多行日志的问题只存在于标准输出里，我们应用的日志是输出到指定目录下的，Filebeat有一些通用的多行日志解决方案。因为日志是存放在ES里的，所以可以通过调ES接口拿到某个Pod一个时间段里的日志，在UI上把它展示出来即可。</p>
<blockquote>
<p>Q：请问用的存储是什么？如何集成的？存储架构是怎样的？有考虑过Ceph吗？</p>
</blockquote>
<p>A：只有极少部分项目需要接分布式存储，并且对存储的管理，IOPS限制等没有硬性要求，所以我们把已有的MFS集群挂载到宿主机，再挂到容器里来实现。</p>
<blockquote>
<p>Q：Jenkins的Slave是用PodTemplate创建的吗？Slave是Job共享还是需要时自动创建？</p>
</blockquote>
<p>A：Jenkins还是传统的master-slave单机部署模式，因为版本比较旧连KubernetesSlave都不支持，所以我们只是调用了Jenkins的API来完成这个部署的过程。</p>
<blockquote>
<p>Q：Kubernetes在做存储挂载的时候，怎么保证容器漂移依然可以读取到共享存储？</p>
</blockquote>
<p>A：MFS挂载的话，文件是写入到MFS集群中的，那么挂载同样的MFS即可读到同一个文件。</p>
<blockquote>
<p>Q：关于命名空间，这边有哪些应用场景呢？</p>
</blockquote>
<p>A：按部门和场景区分ns，按ns分配节点和资源。未来打算基于ns做网络上的隔离和控制。</p>
<blockquote>
<p>Q：请问镜像大小是否有做优化？生产中有用alpine之类的base镜像吗？</p>
</blockquote>
<p>A：暂时没有，我们镜像的大小大约在100-300M之间。而且比起镜像大小的优化，运行环境的稳定和调试的便利更为重要。镜像有分层的策略，即使是很大的镜像，只要每次版本部署时更新的是最底层的镜像就不会导致每次都要拉取完整镜像。</p>
<hr>
<h3 id="2019-04-24：华尔街见闻Istio生产实践"><a href="#2019-04-24：华尔街见闻Istio生产实践" class="headerlink" title="2019-04-24：华尔街见闻Istio生产实践"></a>2019-04-24：华尔街见闻Istio生产实践</h3><blockquote>
<p>Q：学Service Mesh什么用？</p>
</blockquote>
<p>A：ServiceMesh是最近比较火的一个概念，和微服务、Kubernetes有密切关系。出于以后业务发展需要，可以学习下，增加知识储备。见闻上Istio的主要目的在文章已说明，主要是基础服务的下沉，解决了语言兼容性问题，还有一个就是灰度发布。</p>
<blockquote>
<p>Q：链路追踪的采集方式是怎样的，比如Nodejs，C++等多语言如何支持的？</p>
</blockquote>
<p>A：Envoy本身支持链路追踪，也就是将Envoy会在请求head中增加链路追踪相关的数据头，比如x-b3-traceid，x-b3-spanid等等。业务要做的就是将这些head沿着调用链路传递下去即可。所以多语言的话需要在自己的业务侧实现该逻辑。所以Istio的链路追踪对业务代码还是有很小的侵入性的（这个分享中有说明）。</p>
<blockquote>
<p>Q：Istio与Spring Cloud两者的优缺点与今后的发展趋势会是怎么样？</p>
</blockquote>
<p>A：见闻技术栈是Golang，所以没太认真对比过两者。从社区活跃度上将，Istio ，Spring Cloud，稳定性方面，Spring Cloud是更有优势，更适合Java沉淀较深的企业。但个人感觉对于更多企业来讲，跨越了语言兼容性的Istio未来发展很值得期待。</p>
<blockquote>
<p>Q：Docker镜像部署可以做到代码保护吗，比如像Nodejs这种非二进制执行程序的项目？</p>
</blockquote>
<p>A：代码保护可以通过将镜像上传至指定云服务商上的镜像仓库中，见闻是将自己的业务镜像提交保存在了腾讯云。如果镜像泄露，那么非二进制执行程序的代码还是有泄露风险的。</p>
<blockquote>
<p>Q：选型时为什么没考虑Linkerd？</p>
</blockquote>
<p>A：选型之初也调研了Linkerd，对比下来，Istio拥有更多活跃的开源贡献者，迭代速度快，以及Istio架构相较于见闻有较大可行性，所以选择了Istio作为实践方案。</p>
<blockquote>
<p>Q：Istio在做运维部署时没有UI工具，你们如何实现运维人员更加便捷地使用？</p>
</blockquote>
<p>A：见闻基于Kubernetes官方的Dashboard，对内容进行了扩充，增加了对Gateway，VirtualService等Istio crd资源的支持，同时增加了灰度部署等和见闻运维业务相关的功能，所以一定程度上解决了运维部署的问题。</p>
<blockquote>
<p>Q：流量从Sidecar代理势必会对请求响应时间有影响，这个有没有更详细案例的说明性能上的损耗情况？</p>
</blockquote>
<p>A：Sidecar的转发其实带来了性能一定的性能损耗。4核8G服务器，上面运行Proxy服务和API服务，API服务只返回ok字样。（此测试只测试极限QPS）单独测试API服务的QPS在59k+，平均延时在1.68ms，CPU占用4核。通过代理访问的QPS6.8k+，平均延时14.97ms，代理CPU占用2核，API服务CPU占用2核。CPU消耗以及转发消耗降低了QPS，增加了延时，通过增加机器核数并增加服务部署数量缓解该问题，经过测试环境测试，延时可以接受。</p>
<blockquote>
<p>Q：Sidecar在生产中资源占用为多少？是否会对集群资源占用很多？</p>
</blockquote>
<p>A：以单个Pod为例，见闻业务单个Pod中Sidecar所占资源约占整个Pod所耗资源的1/10。</p>
<blockquote>
<p>Q：Jeager你们是进行了代码埋点吗？更为底层代码级别的追踪，有用其他方案吗？</p>
</blockquote>
<p>A：Envoy本身对tracing有良好的支持，所以业务端所做的改动只需将其所产生的追踪数据延续下去即可。上Istio之前，见闻在相关微服务中通过在基础库中增加链路追踪逻辑（Zipkin）实现了链路追踪，不过只做了Golang版，多语言兼容开发运维难度较大。</p>
<blockquote>
<p>Q：相信咱们的mixer在生产环境中，也出现过瓶颈，咱们从哪几个大方向优化的？如何优化的？方面讲解一下吗？</p>
</blockquote>
<p>A：mixer见闻在生产过程中所遇的坑在于Policy组件， 会疯狂的listpod，导致API server负载骤增，之后见闻基于自身业务关闭了Policy。</p>
<blockquote>
<p>Q：Istio组件实现了高可用么？</p>
</blockquote>
<p>A：Istio本身也是基于Kubernetes，所以可用性还是有较好保证的。</p>
<hr>
<h3 id="2019-04-17：瓜子云平台的实践经验"><a href="#2019-04-17：瓜子云平台的实践经验" class="headerlink" title="2019-04-17：瓜子云平台的实践经验"></a>2019-04-17：瓜子云平台的实践经验</h3><blockquote>
<p>Q：请问瓜子私有云是一朵独立的云还是多云部署？如果是多云部署，云间网络是采用的什么技术？如何打通多云之间的网络的？谢谢</p>
</blockquote>
<p>A：我们在设计之初就考虑多集群 / 多 IDC 部署的，这也是选择 Calico 的一个原因。通过 BGP 协议将容器 IP 广播出去后，云间互联和普通虚拟机互联没有区别，当然这需要网络设备支持。</p>
<blockquote>
<p>Q：云平台在 PaaS层，采用的编排工具是什么，如何打通容器之间的部署，在容器的架构上是怎么实现负载均衡的？</p>
</blockquote>
<p>A：采用的是 Kubernetes，打通使用的是 Calico，负载均衡使用的是 IstioIngress。</p>
<blockquote>
<p>Q：新版本实例发布的时候怎么切Istio才能保障灰度的流量不丢失呢？</p>
</blockquote>
<p>A：在流程发布里面，我们相当于先新建一组新的实例，在它们的 Readiness检查通过后，切换 Istio 规则指向新实例做到的。</p>
<blockquote>
<p>Q：稳定性方面有没有出现过比较大的问题，怎么解决的？</p>
</blockquote>
<p>A：有两个时期稳定性故障较多，一个是 Istio版本比较低的时候，这个只能说一路趟坑趟过来，我们甚至自己改过 Istio代码，现在的版本已经没出过问题了；一个是集群用的太狠，当集群接近满载时，Kubernetes会出现很多连锁问题，这个主要是靠监控来做及时扩容。</p>
<blockquote>
<p>Q：自建机房的话为什么不接着使用 Macvlan + IPAM方案呢？是为了之后上公有云做准备吗？</p>
</blockquote>
<p>A：当时面临一个本机 Macvlan容器互相不通的问题，再加上有熟悉的团队已经在生产跑了很久 Calico了，所以就直接换到了 Calico。</p>
<blockquote>
<p>Q：如果服务发现是基于 Dubbo +ZooKeeper，那 Kubernetes 自身的 Service 还有在使用吗？</p>
</blockquote>
<p>A：Kubernetes自己的 Service 我们现在内部管理工具在使用，在 2.x版本也开始开放给业务使用了（文中截图能看到内部域名）。</p>
<blockquote>
<p>Q：请问几秒的时延对一些高效的服务来讲也是不可接受的。咱们有想过通过何种方式去避免灰度的流量损失问题么？</p>
</blockquote>
<p>A：还真没遇到过这个需求。我理解如果有一个服务如此关键，那么在整个流量变更环节（从机房入口开始）到灰度策略上都得仔细考虑。如果接受不了Istio 这个延时，一个思路是完全抛弃 IstioIngress，直接使用一个切换迅速的负载均衡器。因为容器 IP是直通的，完全可以从集群外直接连进来，只要解决服务发现的问题就行。</p>
<blockquote>
<p>Q：应用服务追踪怎么处理的？对接Istio？</p>
</blockquote>
<p>A：语言栈比较多的情况下这是个痛点，目前我们也是在尝试，即使是 Sidecar也不能完全对业务没侵入。公司内部 Java 技术栈更喜欢 Skywalking这种完全无侵入的方式。</p>
<blockquote>
<p>Q：使用 Istio 时，怎么解决性能损坏问题的？</p>
</blockquote>
<p>A：目前还没有启用 Mixer这些对性能影响比较大的组件，所以目前性能损耗还是比较小的。如果对性能有严格的要求，我们会建议他使用service name 做直连。</p>
<blockquote>
<p>Q：Prometheus 的告警是靠编辑大量的rule.yml，请问生产中是怎么管理的？规则编辑比较麻烦，怎么解决？Prometheus是单点，有没有扩容方案？</p>
</blockquote>
<p>A：就是靠 Nier这个组件，将规则抽象成模板，甚至在云平台上面对于简单的规则直接变成了选项。然后模板渲染成规则。我们的Prometheus 用的官方的联邦集群模式，存储放在了 Ceph 上面。</p>
<blockquote>
<p>Q：为什么Kubernetes 默认的滚动更新不能满足要求？哪里有问题？</p>
</blockquote>
<p>A：没办法精细控制灰度粒度，比如部署了 4 个实例，我要求切 10%的流量灰度，这就做不到了。另外，滚动更新回滚也比较慢。</p>
<blockquote>
<p>Q：注册到ZooKeeper 的 IP 是 Pod IP？ZooKeeper 从外部直接访问Pod IP 吗？</p>
</blockquote>
<p>A：对的，Pod 和 VM 能直通，也就是说一个 Dubbo 服务能同时部署在 VM和容器里面。</p>
<blockquote>
<p>Q：目前支撑的生产应用服务规模和云平台的规模能介绍下？包括一些指标，比如多少应用进行灰度更新耗时？</p>
</blockquote>
<p>A：应用规模的话目前超过 1000 了，每个月发布次数超过10000。灰度更新是用户自行控制整个发布进度的，所以耗时不太有参考意义。</p>
<hr>
<h3 id="2019-04-03：容器环境下的持续集成最佳实践"><a href="#2019-04-03：容器环境下的持续集成最佳实践" class="headerlink" title="2019-04-03：容器环境下的持续集成最佳实践"></a>2019-04-03：容器环境下的持续集成最佳实践</h3><blockquote>
<p>Q：Kubernetes 上主流的 CI/CD 方案是啥？</p>
</blockquote>
<p>A：其实这无关Kubernetes，从市场占有率来看，前三名分别是 Jenkins、JetBrains TeamCity、CircleCI。<a href="https://www.datanyze.com/market-share/ci" target="_blank" rel="noopener">来源：</a></p>
<blockquote>
<p>Q：GitLab 自带的 CI 与Jenkins 和 GitLab 结合的 CI，该如何选择？想知道更深层次的理解。</p>
</blockquote>
<p>A：还是要结合自己团队的实际情况做选择。从成熟度来说，肯定是 Jenkins用户最多，成熟度最高，缺点是侧重 Java，配置相对繁琐。GitLab 自带的 CI相对简单，可以用 yaml，和 GitLab 结合的最好，但功能肯定没有 Jenkins全面。如果是小团队新项目，GitLab CI 又已经可以满足需求的话，并不需要上Jenkins，如果是较大的团队，又是偏 Java 的，个人更偏向 Jenkins。</p>
<blockquote>
<p>Q：Jenkins 如果不想运行在 Kubernetes 里面，该怎么和 Kubernetes 集成？</p>
</blockquote>
<p>A：从 CI 的流程来说，CI 应用是不是跑在 Kubernetes 的并不重要，CI只要能访问代码库，有权限在生产环境发布，是不是跑在容器里从效果来说其实没有区别，只是用Kubernetes 部署 Jenkins的话，运维的一致性比较好，运维团队不用额外花时间维护一套物理机的部署方案。</p>
<blockquote>
<p>Q：Kubernetes的回滚方案是回滚代码，重做镜像，还是先切流量，后做修改？</p>
</blockquote>
<p>A：代码一定是打包到镜像里的，镜像的版本就是代码的版本，所以一定是切镜像。至于回滚操作本身，Kubernetes已经内置了很多滚动发布（Rollingupdate）的策略，无论是发新版本还是回滚版本，都可以做到用户无感知。</p>
<blockquote>
<p>Q：镜像大到几 G 的话如何更新部署，有什么好的实践呢，以及如何回滚？</p>
</blockquote>
<p>A：几个要点：&gt; Q：Drone 开放 API 服务吗？这样方便其他系统集成。</p>
<p>A：可以调整一下思路，直接把需要的功能做成镜像在 Drone 里调用就好了。</p>
<blockquote>
<p>Q：如果有 Drone 的 Server怎么做高可用？</p>
</blockquote>
<p>A：Drone serve r用 Kubernetes部署的话本身只起到了一个任务调度的作用，很难会遇到性能瓶颈。真的有性能问题可以尝试水平扩展Drone server，共享同一数据库。</p>
<hr>
<h3 id="2019-03-28：基于OVN的Kubernetes网络架构解析"><a href="#2019-03-28：基于OVN的Kubernetes网络架构解析" class="headerlink" title="2019-03-28：基于OVN的Kubernetes网络架构解析"></a>2019-03-28：基于OVN的Kubernetes网络架构解析</h3><blockquote>
<p>Q：OVS方案与基于三层交换机方案对比，各有什么优缺点？</p>
</blockquote>
<p>A：OVS最大的优点在于可编程，灵活性比较好。虚拟网络不用手动插网线，而且有OpenFlow加持，可以实现一些普通交换机无法实现的流量控制。物理交换机的主要有点就是性能好，而且比较稳定，不容易出问题。</p>
<blockquote>
<p>Q：OVN不支持ECMP，貌似现在还是active-standby机制，你们怎么解决Gateway瓶颈问题？</p>
</blockquote>
<p>A：有几种方式：1. Gateway用DPDK这样的高速DataPath；2. 多Gateway，用策略路不同的IP段走不同Gateway，可以分担流量；3. 不使用OVN概念的Gateway，自己做一些手脚从每台宿主机直接出去，也是分担流量降低单点的风险。</p>
<blockquote>
<p>Q：OVN-Kubernetes好像只支持每个部署节点一个虚拟网络网段。如何避免IP池浪费和不均衡？</p>
</blockquote>
<p>A：这个其实是这个项目实现的网络模型的一个局限性。在我们的实现里是以namespace为粒度划分子网，可以对每个namespace进行控制，情况会好很多。</p>
<blockquote>
<p>Q：OVN如果有不同的Chassis，但是相同IP就会造成网络异常（比如物理机，VM装上OVN，注册到远端后，被重建，后面又注册到远端，但是Chassis已经改变），会导致大量节点Geneve网络异常。你们怎么解决这个问题？</p>
</blockquote>
<p>A：暂时没碰到这个问题，但是我们在实现的一个原则就是尽可能保证所有的操作都是幂等的。向这种可能需要在重连前做一个检查，判断是否有过期的数据需要清理，再连接，或者复用旧的连接信息去连接。</p>
<blockquote>
<p>Q：如何debug OVN逻辑拓扑是否配置有问题？</p>
</blockquote>
<p>A：目前debug确实很多情况只能靠眼看，也可以使用ovn-trace这个工具可以打印数据包在逻辑流里的链路来排查。</p>
<blockquote>
<p>Q：OVS跟Calico等有啥区别？</p>
</blockquote>
<p>A：Calico主要依赖Linux的路由功能做网络打通，OVS是在软件交换机层面实现网络打通，并提供了更丰富的网络功能。</p>
<blockquote>
<p>Q：OVS的封包支持有STT和Geneve，你们选用哪种，为什么？</p>
</blockquote>
<p>A：其实还支持VXLAN，我们选的Geneve。原因比较简单，Geneve是第一个OVN支持的封包协议，而且看了一些评测，据说在搞内核开启UDP Checksum的情况下性能会比VXLAN要好一些。</p>
<blockquote>
<p>Q：OVS如何实现固定容器IP？</p>
</blockquote>
<p>A：这个其实OVS有对应的设置可以给每个端口设定IP和MACE，这样网卡启动时配置相同的信息就可以了，难点其实是如何控制OVN来分配 IP，感觉这个话题可以再开一场分享来讨论了。</p>
<blockquote>
<p>Q：可以简单介绍下你们准备开源的网络功能吗？</p>
</blockquote>
<p>A：每个namespace和一个logical_switch绑定，支持子网分配，支持固定 IP，支持 QoS，支持NetworkPolicy，内置的LB，内置的DNS，大致就是把OVN的概念映射到Kubernetes。</p>
<blockquote>
<p>Q：想了解一下，如果采用OVN，是不是意味着使用OpenStack平台和Kubernetes网络可以直接互通？完成业务在虚拟机和Pod之间的全新负载方式？</p>
</blockquote>
<p>A：是这样的，如果涉及的合理可以做到容器和VM使用同一个底层网络基础设施，VM和容器之间可以IP直达，所有的ACL、LB都是打通的。</p>
<blockquote>
<p>Q：直接把OpenShift OVS抽出来做Kubernetes的网络插件和灵雀云做的这个区别在哪？</p>
</blockquote>
<p>A：功能上有很多是相同的，因为底层都是OVS。如果关注Roadmap会发现OpenShift之后也会采用OVS的模式。从架构的角度来看，现在openshift-multitenant的实现很类似Neutron之前那一套，各种Agent，之后会统一到OVN。另一方面OpenShift的网络插件绑定的太死了，所以我们决定还是自己抽出来，顺便能实现我们的一些特殊功能，比如固定IP，子网共享，以及一些网关控制层面的功能。</p>
<blockquote>
<p>Q：请问Geneve和VXLAN的区别有哪些？</p>
</blockquote>
<p>A：Geneve可以理解为下一代VXLAN，VXLAN相对VLAN来说头部更长可以支持更多的VLAN，但是由于是固定长度的封装头，不能任意加控制信息。Geneve采用变长的封装头，可以加很多自定义的控制信息，方便之后做更复杂的网络管控。</p>
<blockquote>
<p>Q：Docker CNM也支持固定IP，和你说的固定IP是一回事吗？另外，基于OVS建立的网络是CNI还是CNM的呢？</p>
</blockquote>
<p>A：基于CNI，因为我们依赖Kubernetes的模型。不过话说回来我很喜欢Docker CNM那套模型，比CNI要实用很多。固定IP其实只是个功能，各种模型下都可以实现，效果就是可以给Pod指定IP启动，Workload下的多个Pod实用的是一组固定的地址。</p>
<blockquote>
<p>Q：目前你们对企业的解决方案里会默认采用这种网络模式么？</p>
</blockquote>
<p>A：这个方案是我们这几年需求和碰到坑的一个积累吧，现在还不会直接给企业用，我们还需要一些功能的开发和测试，但是之后Overlay的场景这个肯定是主推了，主要是取代原来的Flannel VXLAN网络。</p>
<blockquote>
<p>Q：你了解Contiv网络方案吗，和贵公司的实现有哪些区别？</p>
</blockquote>
<p>A：Contiv是思科做的，也是OVS实现的，不过它的实现比较早，自己手动实现了整个控制平面，可以认为自己写了个跟OVN类似的东西来控制 OVS。不过看它最近已经很少更新了。用OVN能用很少的代码就实现基本相同的功能。Contiv有个比较独特的功能就是支持BGP的网络间通信，这个是OVN暂时不支持的。</p>
<hr>
<h3 id="2019-03-21：小团队微服务落地实践"><a href="#2019-03-21：小团队微服务落地实践" class="headerlink" title="2019-03-21：小团队微服务落地实践"></a>2019-03-21：小团队微服务落地实践</h3><blockquote>
<p>Q：服务治理问题，服务多了，调用方请求服务方，超时或者网络抖动等需要可能需要重试，客户端等不及了怎么办？比如A-&gt; B-&gt; C，等待超时时间都是6s，因为C服务不稳定，B做了重试，那么增加了A访问B的时长，导致连锁反应？</p>
</blockquote>
<p>A：服务发现有两种，一种是客户端发现，一种是服务端发现。如果是客户端发现的话，客户端需要设置超时时间，如果超时客户端需要自己重试，此时如果是轮询应该可以调用到正常的服务提供方。Spring Coud的Ribbon就是对这一流程做了封装。至于连锁反应的问题，需要有降级熔断，配置Hystrix相关参数并实现fallback方法。看源码能够发现hystrixTimeout要大于ribbonTimeout，即Hystrix熔断了以后就不会重试了，防止雪崩。</p>
<blockquote>
<p>Q：JVM如何export，是多container吗，监控数据，搜刮到Prometheus？</p>
</blockquote>
<p>A：JVM的用的是Prometheus埋点，Java里面的路径是/actuator/prometheus，在yaml里面定义prometheus.io/path:/actuator/prometheu prometheus.io/port:’8090’ prometheus.io/scrape:\’true\’，再在Prometheus里面进行相应的配置，就可以去搜刮到这些暴露的指标。</p>
<blockquote>
<p>Q：Kubernetes和OpenShift哪个更适合微服务的使用？</p>
</blockquote>
<p>A：OpenShift是Kubernetes的下游产品，是Kubernetes企业级的封装，都是一样的。OpenShift封装有功能更强大的监控管理工具，并且拥有Kubernetes不太好做的权限管理系统。</p>
<blockquote>
<p>Q：可以介绍一下你们在优化镜像体积上面做了哪些工作吗？</p>
</blockquote>
<p>A：RUN命令写在一行上，产生的临时文件再删掉。只安装必须要的包。JDK和Node.Js都有slim镜像，一般都是以那个为基础镜像去做。</p>
<blockquote>
<p>Q：数据库是否真的适合最容器化？</p>
</blockquote>
<p>A：我们生产数据库用的是RDS，开发测试环境用的是Docker Compose起的。从理论上，数据库最好做容器化，模块的独立性高，需要考虑好的是数据库容器的数据永久化存储。</p>
<blockquote>
<p>Q：为什么选择了OpenShift？</p>
</blockquote>
<p>A：因为OpenShift有个很方便的UI，大多数都可以在UI里面操作，包括yaml文件的修改，重新部署回退等操作。对于开发测试来讲，学习的成本比较低，不需要花时间熟悉CLI操作。</p>
<blockquote>
<p>Q：Python基础镜像怎么制作最好，如果加入GCC，C++等编译需要的工具，镜像会特别大？</p>
</blockquote>
<p>A：Python基础镜像直接从Python官方Docker镜像上做就行了。GCC，C++那个做出来的镜像大也没办法。如果没这个需求的话，可以用Python slim镜像去做。</p>
<blockquote>
<p>Q：在Gateway中Ribbon如何根据客户端的IP负载到对应的IP注册的服务？</p>
</blockquote>
<p>A：如果使用了Eureka的话，服务提供方启动时会自注册到Eureka。服务调用方发起请求前会从Eureka上读取提供方的列表，再进行负载均衡定位到具体的IP和Port。如果跟我们一样直接使用Kubernetes的Service，其实就是由Kubernetes控制了，服务调用方访问Kubernetes暴露的Service，然后由Kubernetes负载均衡到这个Service背后的具体的Pod。</p>
<blockquote>
<p>Q：如何实现远程发布、打包？</p>
</blockquote>
<p>A：Jenkins打包镜像发布到Harbor上，Jenkins再调用OpenShift去从Harbor上拉取镜像，重新tag一下就可以实现发布。</p>
<blockquote>
<p>Q：譬如客户端IP是10，希望Gateway负载到10注册的order服务，而不是其他IP注册的order服务，希望开发使用集中的Eureka和Gateway？</p>
</blockquote>
<p>A：是说不需要负载均衡？最简单的可以看下Ribbon的实现，负载均衡算法可以自己定义，如果只是要固定IP的话，那么遍历服务列表再判断就可以了。两次判断，if serviceId=order，if ip = 10。</p>
<blockquote>
<p>Q：Docker管理工具一般用什么？</p>
</blockquote>
<p>A：Kubernetes，简称k8s是目前较热门的Docker管理工具。离线安装Kubernetes比较繁琐，有两款比较好的自动化部署工具，Ubuntu系统的Juju和Red Hat系统的OpenShift，OpenShift又称为企业版的Kubernetes，有收费的企业版和免费版。</p>
<blockquote>
<p>Q：Prometheus是每个集群部署一套吗？存储是怎么处理？存本地还是？</p>
</blockquote>
<p>A：每个集群部署一套，存储暂时存在本地，没有用持久化存储。因为现在环境都是在云上面，本身云厂商就有各种的监控数据，所以Prometheus的监控数据也只是做个辅助作用。</p>
<hr>
<h3 id="2019-02-28：骞云科技DevOps实践"><a href="#2019-02-28：骞云科技DevOps实践" class="headerlink" title="2019-02-28：骞云科技DevOps实践"></a>2019-02-28：骞云科技DevOps实践</h3><blockquote>
<p>Q：CMP和各个云平台打通都使用了平台的jar，并且需要各种资源生成，这个工作量也不小吧？并且如果api更新代码量也大吧？</p>
</blockquote>
<p>A：我们的核心业务就是做云管理平台，我们产品已经完成了对各个云平台的对接，主要调用各个云平台的API。公有云的API更新频率并不是很高，每当API有更新时，我们也及时去适配。</p>
<blockquote>
<p>Q：Jenkins初次提交也能触发构建吗？每次自动化构建版本号是如何更新的呢？</p>
</blockquote>
<p>A：我们的项目代码具备构建条件后，才在Jenkins上创建了项目构建Job，所以并没有在初次提交时触发构建。每次构建的版本号由两部分组成，一部分是产品的Release大版本号，另一部分直接使用的Jenkins build number这个环境变量。</p>
<blockquote>
<p>Q：有了Gerrit，为什么还要GitLab，Gerrit也可以托管代码啊？</p>
</blockquote>
<p>A：这个是有历史背景的，我们是先选择使用GitLab做代码托管，后期才加入Gerrit做code review。Gerrit在代码review方面比GitLab的merge request要方便许多，更适合企业内部使用。关于这个，我的想法是，要么将GitLab迁移到Gerrit，要么不用Gerrit，可以使用GitLab的merge request来进行review，那GitLab其实是可以不要的。</p>
<hr>
<h3 id="2019-02-22：房多多Service-Mesh实践"><a href="#2019-02-22：房多多Service-Mesh实践" class="headerlink" title="2019-02-22：房多多Service Mesh实践"></a>2019-02-22：房多多Service Mesh实践</h3><blockquote>
<p>Q：容器和微服务的区别以及它们的关联性、应用场景、客户群体、带来的价值？</p>
</blockquote>
<p>A：微服务的应用场景主要是解决降低单个服务体积，满足业务的快速开发需求。容器可以说是微服务的载体，容器方面还是运维关注的比较多，带来的标准化流程和环境的提升对整个研发团队都有很大的作用。</p>
<blockquote>
<p>Q：软件实现 Service Mesh，Istio？</p>
</blockquote>
<p>A：我们目前只使用了Envoy，Istio也做过一些选型的调研，不是很符合我们现在的业务场景和业务需求，我们在之后的实践中会考虑使用一部分Istio的功能。</p>
<blockquote>
<p>Q：实施过程当中有使用到Istio吗？有定制一些Mixer适配器吗？</p>
</blockquote>
<p>A：目前还没有用，之后会考虑是用Istio中的pilot，我们目前在流量的控制的精细程度上面还欠缺，粒度还很粗。</p>
<blockquote>
<p>Q：请问，实现微服务过程中有没有考虑分布式跟踪和分布式？</p>
</blockquote>
<p>A：Service Mesh层可以做到简单的分布式追踪，比如可以做到基于请求的追踪，Envoy可以把trace数据接入Zipkin这样的trace系统，但是更细粒度的trace目前还做不到。</p>
<blockquote>
<p>Q：不论是使用都会产生大量的配置（yaml），尤其是Envoy/Istio，系统中会有大量零散的配置文件，维护困难，还有版本管理，有什么很好的维护实践经验吗？谢谢。</p>
</blockquote>
<p>A：是的，据我所知有些团队会使用ConfigMap来管理配置，我们做了一个配置的集中管理服务，从CMDB和DNS定时的抓取数据，数据会存在数据库里面，也会存一定量的副本用于配置回退，这个地方还是要结合你们现在其他配套系统的建设来看看怎么做比较好的。</p>
<blockquote>
<p>Q：有没有遇到过Envoy被oom kill的情况，你们是如何处理的？</p>
</blockquote>
<p>A：这个我有碰到过一次，之前我们在对Envoy做测试的时候，发现Envoy总会尽可能的占满CGroup的内存大小，这个之前在使用TLS的情况下碰到的比较多。但是目前我们内部服务间使用TLS的情况并不多，所以后续这个问题就没有继续跟进了。</p>
<blockquote>
<p>Q：性化方案有哪些？</p>
</blockquote>
<p>A：之前文章中有提到过，对于http服务可以全量接入http2，http2的长连接和多路复用对于一般的业务来说升是很明显的，我们在全量接入http2之后，网站的响应时间几乎下降了50%。另外还可以在底层的依赖上面做一些优化，比如底层的libc库，以及尽可能的减少基础镜像的大小，我们基本上所有业务都使用了alpine，这样可以保证发布性能和速度在一个很好的水平上。</p>
<blockquote>
<p>Q：还是有一个服务治理/配置管理的问题请教，比如CPU，内存，这种资源request，在dev，test，staging，prod环境均不同，那么我们在编写Kubernetes配置的时候不同环境会不同，比如测试环境的replics数跟CPU需求就很低，生产就很高，另外这个配置在不同环境是多个还是一个呢？谢谢。</p>
</blockquote>
<p>A：我们现在会在CMDB里面维护这些配置数据，一般来说在新建项目的时候，我们就会要求业务线评估一下这个业务需要的资源，比如你说到的test和staging环境这种，我们默认会给一个很低的需求，比如1c1g这样的，而且replication也会默认设置为1，除非业务有特殊的需求，然后我们去根据配置的数据去生成yaml格式为配置。</p>
<blockquote>
<p>Q：你们目前的项目中，大量的微服务，以及调度层，瓶颈和容灾是如何处理的？</p>
</blockquote>
<p>A：由于我们的业务类型还是B端业务为主，流量的峰值是可以预估的，很少会出现突发的大流量的情况，我们一般都预留了1倍的容量用于临时的扩容。容灾和调度的话我们主要还是尽可能的隔离工作节点和调度节点，以及大量使用物理机集群，从我们的使用体验上来看，物理机的稳定性还是很不错的。</p>
<blockquote>
<p>Q：如何用Jenkins自动完成Kubernetes部署？</p>
</blockquote>
<p>A：自动部署这块我们有完善的发布系统，如果单纯只要实现Jenkins自动完成Kubernetes的话，Jenkins可以直接调用Kubernetes的API，这个网上有挺多资料的，你可以找找看。</p>
<blockquote>
<p>Q：Service Mesh比传统的微服务治理好在哪里？</p>
</blockquote>
<p>A：降低框架开发成本、代理规则灵活，方便修改策略、框架功能的升级无需依赖业务，最大的好处我觉得就是可以降低框架开发成本。</p>
<blockquote>
<p>Q：我理解房多多目前的Mesh方案没有给每个微服务配一个Envoy作为Sidecar，而是使用一组Enovy并自研了xDS的配置发布管理系统，对吗？我想请问backend微服务之间的请求现在是怎么走的呢？谢谢。</p>
</blockquote>
<p>A：是的，刚刚文章中说了，我们后端SOA服务还是基于Dubbo的，这块目前我们还没有做改动，之后的话我们的初步构想会通过Sidecar的方式把这些Dubbo服务都接入到Mesh里面来。我们目前的Envoy也是会充当网关的角色。</p>
<hr>
<h3 id="2019-01-25：得到App的容器及Kubernetes实践"><a href="#2019-01-25：得到App的容器及Kubernetes实践" class="headerlink" title="2019-01-25：得到App的容器及Kubernetes实践"></a>2019-01-25：得到App的容器及Kubernetes实践</h3><blockquote>
<p>Q：业务环境有跨机房么，还是云环境，是共用一个集群还是不同集群呢？</p>
</blockquote>
<p>A：个人倾向多集群，上层Federation Cluster管理。</p>
<blockquote>
<p>Q：代码使用发布是什么的呢 有使用Helm么？</p>
</blockquote>
<p>A：通过Kubernetes API Server更新Deployment中template的spc里的container image。</p>
<blockquote>
<p>Q：单个应用发布一次耗时多长时间？主要耗时是在哪个阶段呢？</p>
</blockquote>
<p>A：1分钟内，主要耗时在Kubernetes Replication Controller 滚动发布过程中的Pod状态同步。</p>
<blockquote>
<p>Q：开发流程是什么样的，是开发创建镜像还是运维自己创建？谁负责发布到线上环境？</p>
</blockquote>
<p>A：创建镜像有两种方式：CI和开发人员手工操作，线上环境开发提交上线单，QA审核。</p>
<blockquote>
<p>Q：Kubernetes目前是都在阿里云上面吗？有没有跨云去实现平台的搭建，如果使用混合云对你们最大的挑战？</p>
</blockquote>
<p>A：目前还是主要用阿里云，未来会建设混合云，混合云方案还未确定，个人倾向多集群，上层Federation Cluster管理，也不排除自研Controller，混个人认为混合云最大的挑战在于数据的同步，上层的服务容器中运行并且有Kubernetes来调度大大减轻了管理负担，我们正在设计多层次的调度：例如流量层调度、服务层调度、数据层调度。</p>
<blockquote>
<p>Q：Chon和Dozer是自研的平台吗？网上没有找到相关的介绍。</p>
</blockquote>
<p>A：是自研的，可以认为Dozer是容器发版系统，Chons是私有PaaS。</p>
<blockquote>
<p>Q：Overlay为何不能用在生产环境？你们现在不算生产环境吗？Flannel不就是Overlay吗？</p>
</blockquote>
<p>A：Flannel有高性能的HOSTGW，在云上的话，还有各种公有云的backend，借助云的VPC网络API实现。</p>
<blockquote>
<p>Q：为什么大量短链接需要优化DNS？大量短链接会导致什么问题？</p>
</blockquote>
<p>A：Golang默认编译会关闭Glibc中的dns查询实现，使用golang的实现，对于DNS服务有较多查询，会有dns查询失败情况。大量短连接一般情况下不会有问题，会增加少量延迟以及服务器上TCP TIME_WAIT状态连接数量大。</p>
<blockquote>
<p>Q：日志这块使用emptydir的话会不会有日志丢弃的情况？</p>
</blockquote>
<p>A：没有，logtail和filebeat使用的是Watch和tail类似的模式，我们统计过，延迟最大在5秒。</p>
<hr>
<h3 id="2019-01-16：龙腾出行基于Kubernetes的DevOps流水线实战"><a href="#2019-01-16：龙腾出行基于Kubernetes的DevOps流水线实战" class="headerlink" title="2019-01-16：龙腾出行基于Kubernetes的DevOps流水线实战"></a>2019-01-16：龙腾出行基于Kubernetes的DevOps流水线实战</h3><blockquote>
<p>Q：Kubernetes本身技术框架带来的问题在生产环境中有碰到没，请举几个例子。</p>
</blockquote>
<p>A：Kubernetes如果出问题带来的都是雪崩效应，例如网络Calico、存储etcd出现故障是灾难性的，我们也踩过不少这方面的坑，所以要做到高可用才能稳定生产。</p>
<blockquote>
<p>Q：一个开发人员想在开发环境部署一个服务，他必须要懂Kubernetes，去写那些yaml吗，有什么易用的可视化平台？</p>
</blockquote>
<blockquote>
<p>Q：公司环境较复杂：包含Java项目、PHP项目，Java项目目前大多是SpringBoot框架，PHP是ThinkPHP框架，项目架构并不复杂，有少许Java项目需要用Redis到Memcached、缓存机制。最大问题的是多，项目应该如何较好的依托Kubernetes顺利架构，将项目可持续集成？</p>
</blockquote>
<p>A：我们的Redis这一类中间件还放在VM上，目前尚未打算搬移到Kubernetes上，Kubernetes+Docker天然是跨平台的，PHP也可以支持，并且对容器集群（既应用集群）管理非常出色，包含部分自动化运维，并不会因多种开发语言而增加负担，持续集成是另外一块，目前各大CI工具厂商也都支持Kubernetes，比较友好，我们采用的是GitLab-CI。</p>
<blockquote>
<p>Q：Calico网络你们如何解决跨中心的网络通信，BGP只能在同一个交换机才行。</p>
</blockquote>
<p>A：我们目前还没跨机房通讯，不过etcd需要高速网络才能数据同步，跨机房拉专线比较合适，BGP协议还没用到，小规模部署可以考虑添加静态路由的方式打通Kubernetes集群内外的网络。</p>
<blockquote>
<p>Q：应用有是否有状虑使用，用的什么存储解决方案？</p>
</blockquote>
<p>A：我们提倡无状态部署，目前所有应用服务都是无状态，有状态服务存储可以考虑NFS。</p>
<blockquote>
<p>Q：用二进制安装可以不，Kubeadm会有升级些问题，默认的Iptables不太好吧。现在是IPVS。</p>
</blockquote>
<p>A：二进制也可以，比较稳定，Kubeadm滚动升级我们还在踩坑中，升级策略目前我们是另外搭集群，一键部署所有应用（每次部署都会统一存储最新部署yml），对外网关可选择性切换应用，Iptables被Kubernetes捡起来又放弃了，未来的趋势是IPVS，目前我们也在测试环境中试验。</p>
<blockquote>
<p>Q：服务监控和服务器监控这块的取舍，现在监控都是用Prometheus？</p>
</blockquote>
<p>A：Prometheus是CNCF旗下仅次于Kubernetes的项目，对应用程序比较友好，做服务监控非常棒，配合Grafana图形展示体验非常好，跟Zabbix相比各有特色。</p>
<blockquote>
<p>Q：请问你们是创业问团队还是大规模团队？考虑Kubernetes机缘是？对于Kubernetes来说生态所存在的不足，如安全问题是怎么考虑的？</p>
</blockquote>
<p>A：不管创业还是大规模团队，适合自己业务，技术可持续演进、完善并提升效率就是好的方向，考虑Kubernetes是因为它的优秀功能，让技术团队可以站在更高的起点，看得更远；Kubernetes生态已经非常强大，在内网运行，相对较为安全，另外也有启用RBAC权限访问控制，配合其他持续集成工具，安全控制都可以个性化定制。</p>
<blockquote>
<p>Q：Kubernetes集群你们为什么没有部实体机在署上？</p>
</blockquote>
<p>A：虚拟机和实体机都行，我们实体机数量有限，包括中间件那些，做高可用会用占用比较多的Node机。</p>
<hr>
<h3 id="2019-01-11：如何评估Kubernetes持久化存储方案"><a href="#2019-01-11：如何评估Kubernetes持久化存储方案" class="headerlink" title="2019-01-11：如何评估Kubernetes持久化存储方案"></a>2019-01-11：如何评估Kubernetes持久化存储方案</h3><blockquote>
<p>Q：你好，我们公司采用GlusterFS存储，挂载三块盘，现在遇到高并发写小文件（4KB）吞吐量上不去（5MB/S），请问有什么比较好的监控工具或方法么？谢谢！</p>
</blockquote>
<p>A：GlusterFS本身对小文件就很不友好，GlusterFS是针对备份场景设计的，不建议用在小文件场景，如果可以的话，要么程序做优化进行小文件合并，要么选用高性能的分布式文件存储，建议看看Lustre或者YRCloudFile。</p>
<blockquote>
<p>Q：我们用的是Ceph分布式存储，目前有一个场景是客户视频存储，而对于持续的写入小文件存在丢帧的现象，经过我们系统级别和底层文件系统调优，加上Ceph参数的设置，勉强性能得改善，但是数据量上来性能会如何也不得而知道了（经过客户裸盘测试，前面用软RAID方式性能还是可以）请问在这方面你有什么建议么？谢谢！我们客户是在特殊的场景下，属于特定机型，而且是5400的sata盘！rbd块存储！还有一个现象就是磁盘利用率不均，这也是影响性能的一个人原因，即便我们在调pg数，也会有这个问题。在额外请教一个问题，bcache可以用内存做缓存么？FlushCache相比，这两个哪个会更好一点？</p>
</blockquote>
<p>A：您用的是CephFS还是rbdc因为Ceph在性能上缺失做的还不够，有很多队列，导致延迟很不稳定，这个时候，只能忍了，不过还是建议用Bcache做一层缓存，可以有效缓解性能问题。Crush算法虽然比一致性hash要好很多，但是因为没有元数据，还是很难控制磁盘热点问题。FlushCache已经没有人维护了，Bcache还有团队在维护，所以如果自己没有能力，就选用Bcache。</p>
<blockquote>
<p>Q：你好，目前开源在用Rook部署Ceph，Ceph对于块设备存储性能如何？可以提升吗？未来？</p>
</blockquote>
<p>A：我们最近也在关注Rook项目，Rook的理念是很好的，但是现在Rook就是Ceph的封装，把Ceph跑到容器中，复用Kubernetes的监控平台。而Ceph的运维复杂度很高，以目前的做法，项目想要做好，难度会非常大。</p>
<blockquote>
<p>Q：我看您推荐分布式文件存储，文件系统能满足数据库应用的需求吗？块存储会不会好一些？</p>
</blockquote>
<p>A：首先，我推荐的是高性能分布式文件系统。数据库一般对延迟都比较敏感，普通的万兆网络+HDD肯定不行，需要采用SSD，一般能将延迟稳定在毫秒以内，通常能够满足要求。如果对延迟有特别要求，可以采用NVMe+ RoCE的方案，即使在大压力下，延迟也能稳定在300微秒以内。</p>
<blockquote>
<p>Q：您用的分布式文件存储，不同用户间如何隔离？</p>
</blockquote>
<p>A：分布式文件系统有ACL权限控制，也可以加AD/LDAP</p>
<blockquote>
<p>Q：请问为什么说块存储不支持RWX？RWX就是指多个节点同时挂载同一块块设备并同时读写吗？很多FC存储都可以做到。</p>
</blockquote>
<p>A：传统的SAN要支持RWX，需要ALUA机制，而且这是块级别的多读写，如果要再加上文件系统，是没办法做到的，这需要分布式文件系统来做文件元数据信息同步。</p>
<blockquote>
<p>Q：传统SAN支持对同一数据块的并行读写，很多AA阵列都不是用ALUA的，而是多条路径同时有IO，当然要用到多路径软件。相反用ALUA的不是AA阵列。</p>
</blockquote>
<p>A：AA阵列解决的是高可用问题，对同一个lun的并发读写，需要trunk级的锁去保证数据一致性，性能不好。</p>
<blockquote>
<p>Q：的很多传统商业存储，包括块存储，也都做了CSI相关的插件，是不是如果在容器里跑一些性能要求高的业务，这些商业的块存储比文件存储合适？</p>
</blockquote>
<p>A：生产环境中，我强烈建议选用商业存储。至于块存储还是文件存储，要看您的业务场景。首选是商业的文件存储。</p>
<blockquote>
<p>Q：请问现在的Kubernetes环境下，海量小文件RWX场景，有什么相对比较好的开源分布式存储解决方案么？</p>
</blockquote>
<p>A：开源的分布式文件存储项目中，没有能解决海量小文件的，我在文中已经将主流开源文件系统都分析了一遍，在设计之初，都是针对备份场景或者HPC领域。</p>
<blockquote>
<p>Q：请问，为什么说Ceph性能不好，有依据吗？</p>
</blockquote>
<p>A：直接用数据说话，我们用NVMe + Ceph +Bluestore测试出来的，延迟在毫秒级以上，而且很不稳定，我们用YRCloudFile + NVMe + RoCE，延迟能50微秒左右，差了几十倍。</p>
<blockquote>
<p>Q：Lustre没接触过，性能好吗，和Ceph有对比过吗？</p>
</blockquote>
<p>A：网上有很多Lustre的性能指标，在同样的配置下，性能绝对要比Ceph好，不过Lustre全部都是内核态的，容器场景没办法用，而且按照部署以及运维难度非常大。Lustre在超算用的比较广泛。</p>
<blockquote>
<p>Q：Lustre只能靠本地磁盘阵列来保证数据冗余么？</p>
</blockquote>
<p>A：Lustre本身不提供冗余机制，都是靠本地阵列的，不过EC好像已经在开发计划中了。</p>
<blockquote>
<p>Q：（对于小公司）如果不选用商业存储，那么推荐哪款开源实现作为生产存储（可靠，高性能）。我们之前试了NFS发现速度不稳定？</p>
</blockquote>
<p>A：国内还是有很多创业公司，也不贵的。存储不像其他项目，存储经不起折腾，一定要用稳定可靠的，Ceph/GlusterFS做了这么久，大家在采购的时候，还是会依托于某家商业公司来做，自己生产环境用开源项目，风险太大了。</p>
<blockquote>
<p>Q：GPFS用来做Kubernetes的PV，性能怎么样？</p>
</blockquote>
<p>A：用GPFS的话，性能还是有一定保障的，不过GPFS跟Lustre一样，都是带着阵列一起卖的，很贵。</p>
<hr>
<h3 id="2019-01-04：etcd-集群运维实践"><a href="#2019-01-04：etcd-集群运维实践" class="headerlink" title="2019-01-04：etcd 集群运维实践"></a>2019-01-04：etcd 集群运维实践</h3><blockquote>
<p>Q：请问 etcd 监控和告警如何做的？告警项都有哪些？</p>
</blockquote>
<p>A：告警要看用的什么监控吧，和 Kubernetes 配套比较常见的是普罗米修思和 Grafana 了。告警项我没有具体配过，可以关注的点是：endpoint status -w table 里可以看到数据量，endpoints health 看到健康状态，还有内存使用这些，具体可以参考普罗米修思的 exporter 是怎么做的。</p>
<blockquote>
<p>Q：使用 Kubeadm 部署高可用集群是不是相当于先部署三个独立的单点 Master，最后靠 etcd 添加节点操作把数据打通？</p>
</blockquote>
<p>A：不是，Kubeadm 部署会在最开始就先建一个 etcd 集群，apiserver 启动之前就需要准备好 etcd，否则 apiserver 起不了，集群之间就没法通信。可以尝试手动搭一下集群，不用 Kubeadm，一个个把组件开起来，之后对Kubernetes的组件关系会理解更好的。</p>
<blockquote>
<p>Q：etcd 跨机房高可用如何保证呢？管理 etcd 有好的 UI 工具推荐么？</p>
</blockquote>
<p>A：etcd 对时间和网络要求很高，所以跨机房的网络不好的话性能很差，光在那边选请输入链接描述举去了。我分享忘了提一个 etcd 的 mirror，可以去参考下做法。跨机房的话，我觉得高速网络是个前提吧，不过还没做过。UI 工具没找过，都是命令行操作来着。</p>
<blockquote>
<p>Q：Kubeadm 启动的集群内 etcd节 点，kubectl 操作 etcd的备份恢复有尝试过吗？</p>
</blockquote>
<p>A：没有用 kubectl 去处理过 etcd 的备份恢复。etcd 的恢复依赖用 SnapDb 生成数据目录，把 etcd 进程丢进容器里，类似的操作避免不了，还有启动的状态需要修改。kubeadm 启动的 etcd 可以通过 kubectl 查询和 exec，但是数据操作应该不可以，比如恢复 etcd ing 时，无法连接 etcd，kubectl 还怎么工作？</p>
<blockquote>
<p>Q：kubeadm-ha 启动 3 个 Master，有 3 个 etcd 节点，怎么跟集群外的 3 个etcd 做集群，做成 3 Master 6 etcd？</p>
</blockquote>
<p>A：可以参考文档里的扩容部分，只要保证 etcd 的参数正确，即使一个集群一部分容器化，一部分宿主机，都是可以的（当然不建议这么做）。可以先用 kubeadm 搭一个集群，然后用扩容的方式把其他三个节点加进来，或者在 kubeadm 操作之前，先搭一个 etcd 集群。然后 kubeadm 调用它就可以。</p>
<blockquote>
<p>Q：有没有试过 Kubeadm 的滚动升级，etcd 版本变更，各 Master机分别重启，数据同步是否有异常等等？</p>
</blockquote>
<p>A：做过。Kubeadm 的滚动升级公司内部有从 1.7 一步步升级到 1.11、1.12 的文档，或多或少有一点小坑，不过今天主题是 etcd 所以没提这部分。各个 Master 分别重启后数据的一致我们测试时没问题，还有比较极端的是直接把三 Master 停机一天，再启动后也能恢复。</p>
<hr>
<h3 id="2018-12-21：聚美优品云平台实践"><a href="#2018-12-21：聚美优品云平台实践" class="headerlink" title="2018-12-21：聚美优品云平台实践"></a>2018-12-21：聚美优品云平台实践</h3><blockquote>
<p>Q：为啥采用Consul作为容器的服务发现与配置管理，而不采用默认的etcd？</p>
</blockquote>
<p>A：这个问题主要是聚美对于Web类服务已经存在了基于Consul的发现机制，所以云平台在推广时就利用了现有的架构。</p>
<blockquote>
<p>Q：请问IPVLAN网络会不会导致容器内无法访问本地物理网卡？或者说宿主机无法访问本地的容器？</p>
</blockquote>
<p>A：这个问题很好，最初我们采用IPVLAN时也遇到了kubelet在通过Liveness探针时与容器网络不通。后来我们通过将主机网络和容器网络分开，解决了这个问题。</p>
<blockquote>
<p>Q：服务间的Socket通讯原理是通过挂载Volume方式进行访问，这个/var/run/service内容能透露一下吗？是聚美优品的RPC框架通信协议文件吗？</p>
</blockquote>
<p>A：/var/run/service 其实就是一个临时目录，里面就保存了Pod的各个Container中运行进程的Sockets文件。至于服务间（不同Pod间）通讯是聚美这边自己实现的一个私有的RPC框架通信协议。</p>
<blockquote>
<p>Q：问一下，你那边的不同业务分配资源的时候是每个节点都打上labels吗？</p>
</blockquote>
<p>A：是的，我们主要还是通过label的的形式来做容器的调度。另外每个deployment都会通过resourcelimit来做资源限制。目前对于高资源利用的容器还是通过平台kill容器的方式，重新拉起新的容器。</p>
<blockquote>
<p>Q：Prometheus是什么运行方式，拉取数据会有什么问题注意吗，单节点够用吗？</p>
</blockquote>
<p>A：目前我们Prometheus是部署在Kubernetes当中，根据不通过的服务发现模式做了逻辑切分。上层通过Prometheus Federation来统一汇聚数据。</p>
<blockquote>
<p>Q：那不同的业务之间访问有状态应用是通过定义ExternalName吗？比如访问MySQL或Redis等？</p>
</blockquote>
<p>A：目前我们大部分跑在云平台上的容器都是无状态的服务，对于有状态的服务，还是建议通过传统的方式运行。</p>
<blockquote>
<p>Q：请问你那边Pod是直接跑在虚拟机上吗，还是做了一层虚拟化分配使用虚拟机呢？</p>
</blockquote>
<p>A：Pod的运行主要分两块类型。对于DaemonSet方式运行的容器，我们大都通过虚拟机或者云主机来支撑，分享里面也提到我们通过DaemonSet方式来解决我们大促期间快速扩容的需求</p>
<blockquote>
<p>Q：Pod跨节点的访问是怎么做到的，如果两个节点不在同一个swtich下，需要跨路由器的情况下？</p>
</blockquote>
<p>A：IPVLAN的网络是提前规划好的，并保存在网络配置管理平台上。对于IPVLAN不同网段的之间的通信，还是在三层交换机上做路由来实现的。</p>
<hr>
<h3 id="2018-12-07：智融集团基于OpenShift的容器化PaaS平台实践"><a href="#2018-12-07：智融集团基于OpenShift的容器化PaaS平台实践" class="headerlink" title="2018-12-07：智融集团基于OpenShift的容器化PaaS平台实践"></a>2018-12-07：智融集团基于OpenShift的容器化PaaS平台实践</h3><blockquote>
<p>Q：请问通过OpenShift怎么做高可用？</p>
</blockquote>
<p>A：OpenShift的高可用是跟Kubernetes的高可用一致的，就是延用了Kubernetes的Service IP来做服务发现和负载均衡；另外，前面还有DNS服务，（例如：Hostname: service.abc-platform.svc，后端就是指向的Cluster IP）。</p>
<blockquote>
<p>Q：image的版本管理怎么做？配置的版本管理怎么做？</p>
</blockquote>
<p>A：OpenShift本身会创建一个内部的Registry，S2I会根据Build来更新image，image的版本是通过sha256的值对应Build的版本号（例如：Build版本#24对应registry.intra.XXXXX.com/abc/abc-platform\@sha256:b41c8XXXXX）。</p>
<blockquote>
<p>Q：OpenShift的网络方案性能方面有多少损耗？与Kubernetes的其他网络方案如Calico相比如何？</p>
</blockquote>
<p>A：OpenShift的网络方案是选择的OVS，性能上肯定是不如Calico，但对于我们的服务足够了。目前跑了有1000+个常驻Pod，没有出现网络瓶颈。</p>
<blockquote>
<p>Q：如果要做多机房部署，OpenShift能搞吗？</p>
</blockquote>
<p>A：多机房，只要网络能通并比较稳定，是没有问题的。我们的部署方案就是在阿里云上的多个可用区部署的。而且，实际部署中也是鼓励多机房部署的，服务容灾要求一个服务要分布在多个可用区（或者机房）。</p>
<blockquote>
<p>Q：你们平台性能怎么测试的，如何集成？</p>
</blockquote>
<p>A：平台性能测试分两部分。一个是在集群内部不经过Nginx直接压测SVC，另外一个是在集群外部压测内网域名或者公网域名。</p>
<blockquote>
<p>Q：我们之前用自己的镜像仓库，会报tls认证错误，不知道你们有没有遇到过？</p>
</blockquote>
<p>A：我们自己创建的镜像仓库是用Harbor来建的，只是存储了内部服务的基础镜像。OpenShift集群内的镜像仓库有自己的认证，是通过Secrets管理对应权限的token（用户级别的权限是通过LDAP统一认证的）。S2I创建服务镜像的时候就是通过这个来获取权限的。还是比较稳定的，没有出现过tls的问题。</p>
<blockquote>
<p>Q：生产环境的节点磁盘是怎么分区分配的？</p>
</blockquote>
<p>A：生产环境的节点磁盘分为两类，一个是系统盘（40G），另一个是数据盘（100G）；Docker的所有镜像、实例等存储都是放在数据盘，服务的日志是挂载的PV，PV是使用的阿里云的NAS存储。</p>
<blockquote>
<p>Q：我看你们在集群访问前加了个API Gateway，用了OpenResty，这个能详细介绍下不？</p>
</blockquote>
<p>A：可以简单理解为一个自建的Ingress，底层是Nginx+Lua实现的；我们已经在逐渐使用Kong来代替OpenResty了。Kong底层是Nginx+Lua+PostgreSQL，界面管理是使用的Konga。选择Kong和Konga的理由是：1、Kong的管理和插件比较方便，还支持自定义插件；2、Konga的界面更友好，管理、更新都比较方面。</p>
<blockquote>
<p>Q：看到你们是3Master高可用，请问Kubernetes–Master挂了一台，OpenShift如何恢复，etcd是否有做备份？</p>
</blockquote>
<p>A：我们做过演练，Master挂一台或者两台，甚至三台全挂，也不会影响已经运行的服务。只要etcd没有问题，重启Master或者新增一台Master都可以快速恢复集群。etcd的备份是做的全量备份，上传到我们的备份存储中。</p>
<blockquote>
<p>Q：内网域名是怎么跨VPC和经典网络的？</p>
</blockquote>
<p>A：内网域名的DNSPod解析是解析到VPC网络的一台ECS机器上，通过Nginx来管理。经典网络的ECS服务集群可以在前面挂载一个VPC网络的SLB，Nginx的对应Server Name的Upstream设为这个VPC的SLB即可。</p>
<blockquote>
<p>Q：监控和告警好像没有提到，感觉OC这块似乎缺失？</p>
</blockquote>
<p>A：OpenShift本身有很多服务状态，image的Build、pull、push等状态，以及Pod的各种状态；另外还有强大events。我们是通过OpenShift的API来获取这些信息，同步到Open-Falcon上来处理报警信息的。</p>
<blockquote>
<p>Q：日志统一生产、采集用了什么方式能介绍一下吗？</p>
</blockquote>
<p>A：日志是一个比较疑难的问题；我们的解决方案是，所有的日志都打到同一个NaS盘上，服务名来做该服务的日志路径。多个Pod打同一个日志的时候，会出现乱码。我们的解决方案是在日志中间加hostname，例如haadeers.melon-crm-b-9-nb9d5.log，melon-crm-b-9-nb9d5为Pod的hostname。日志收集，是几台ECS机器挂载改NAS盘，启动flume来收集。</p>
<blockquote>
<p>Q：业务应用的自动化发布你们是怎么设计的，能否详细说说思路？</p>
</blockquote>
<p>A：我们是自己定义了S2I的流程。Build镜像统一在代码仓库里加一个Makefile，定义一个assemble的role，来做初始化（依赖包的安装、nodejs的Build等等，这里还是比较灵活的）。自动发布：我们是自定义了部署模板，分享的内容里有（只需要简单的几步就可以部署一套服务）。</p>
<hr>
<h3 id="2018-11-29：猪八戒网DevOps容器云与流水线"><a href="#2018-11-29：猪八戒网DevOps容器云与流水线" class="headerlink" title="2018-11-29：猪八戒网DevOps容器云与流水线"></a>2018-11-29：猪八戒网DevOps容器云与流水线</h3><blockquote>
<p>Q：Ingress是用的那个组建？</p>
</blockquote>
<p>A：这里我再详细补充下，我们没有使用到Ingress Service这些对象，为了维护与虚拟机项目的统一管理，方便运维使用，我们的Nginx是部署在集群外部的，与nginx-ingress-controller一样，使用Lua扩展自己做服务发现，Nginx直接向Pod转发流量。</p>
<blockquote>
<p>Q：Nginx和PHP-FPM采用什么方法部署和更新，Nginx和FPM有分开部署吗？</p>
</blockquote>
<p>A：Nginx部署在集群外部虚拟机里，虚拟机网络与容器内部网络是打通的，直接转发流量给Pod；PHP是老项目，有一小部分做了容器化，基于PHP基础镜像使用deployment部署，PHP项目是无状态的，跟其他项目一样进行滚动更新；Nginx与FPM是分开部署的。</p>
<blockquote>
<p>Q：请问下你们有没有使用API网关，自己开发的还是使用Kubernetes自带的，用户权限是做在API网关吗？</p>
</blockquote>
<p>A：目前没有用到API网关项目，自己使用Nginx做的简单API网关，sahaba api是我们自己开发的Kubernetes管理工具，使用client-go组件向Kubernetes API发起请求调用；用户权限我们对接了DevOps权限管理系统，区分超级管理员，运维人员，项目负责人，普通用户等，确定某个用户对某个项目容器guest或admin权限。</p>
<blockquote>
<p>Q：你们的Kubernetes管理平台，考虑用360开源的wayne吗？<a href="https://github.com/Qihoo360/wayne" target="_blank" rel="noopener">Qihoo360/wayne</a>可以满足用户上线需求，也集成了webshell之类的，看起来挺不错的。</p>
</blockquote>
<p>A：360的wayne项目，我们也关注了，把源码下下来看了一下。我们DevOps平台与wayne的一大不同之处在于：wayne给用户的发布是把Kubernetes的deployment模板放上去了，让用户去填写；我们是用sahaba-metadata项目将deployment模板抽象出来，只给用户填写Git项目分支，以及需要发布的CPU/内存/节点等，镜像url，超开策略等数据不需要用户填写，开发人员不需要关心这些。我们也参考了wayne的webshell实现，跟kube dashboard项目一样的，我们也正在基于他们的代码优化我们自己的webshell。</p>
<blockquote>
<p>Q：Prometheus监控数据是用什么存储的了？采用了什么集群方案？存储没有集群化吗？</p>
</blockquote>
<p>A：Helm install CoreOS/kube-prometheus，目前是完全容器化部署的，使用hostpath挂载，部署在一个专用节点上，公有云上使用PVC。目前给了30G的内存资源够用，没有集群化部署。</p>
<blockquote>
<p>Q：etcd用哪个版本的，3节点以上的etcd集群崩溃后如何用镜像快速恢复？</p>
</blockquote>
<p>A：我们的集群各个版本都有，从1.4到1.11，都是使用当时最新的稳定版部署，具体可以看Kubernetes release note里的dependencies；etcd集群恢复，只要有一个节点etcd的数据在，就可以恢复，先将这个节点force-new，其他节点join进来，数据会自动从leader同步到slave。你提到的使用虚拟机镜像恢复，这个我还没有使用过，我理解的整个云硬盘的数据都可以备份下来，数据恢复也是没问题的，参照公有云数据备份恢复方案。</p>
<blockquote>
<p>Q：web terminal怎么做的，有参考文档吗？</p>
</blockquote>
<p>A：web terminal新版的是参照kube dashboard源码，使用client-go调用kubernetes api，spdyexecutor，然后转为ws连接实现，最近开源了一个<a href="https://github.com/lf1029698952/web-terminal-in-go" target="_blank" rel="noopener">demo：</a></p>
<blockquote>
<p>Q：etcd数据备份是怎么做的，Crontab吗，还是使用Kubernetes里的Job，如何确保备份的数据是没有问题的？</p>
</blockquote>
<p>A：因为etcd是二进制文件部署的，目前我们是使用Crontab定时任务每天备份一次数据，备份的内容包括etcd snapshot，etcd的数据目录，同时备份到本地及远程服务器，公有云上还有云硬盘镜像备份，多种备份方案保证数据正常。</p>
<blockquote>
<p>Q：日志收集工具是否用了Fluentd，日志收集到ES里，用Kibana查询有没有遇到过日志乱序的问题？</p>
</blockquote>
<p>A：我们使用的是Filebeat，将日志收集到Kafka，再转给Logtash，Logtash处理后才转给ES， Filebeat -> Kafka -> Logstash -&gt; ES -&gt; Kibana，乱序问题我没遇到过，应该可以在Logstash处理的时候确认。</p>
<blockquote>
<p>Q：可否实现Kubernetes上容器与主机通讯？</p>
</blockquote>
<p>A：容器与主机通信是可以的，具体可以参见Calico的网络方案，使用calico routereflect路由反射功能与核心交换机做bgp peer进行路由交换，公有云上使用VPC网络方案。</p>
<blockquote>
<p>Q：Prometheus federation有使用吗，关于监控性能这块有没有啥好的经验教训？</p>
</blockquote>
<p>A：Prometheus监控这块，我们只优化了每个Job抓取的时间间隔，保证Prometheus Server的负载不会太高，并给Prometheus足够的CPU内存以及SSD磁盘，查询时优化查询条件。</p>
<blockquote>
<p>Q：日志解析具体用的什么？有什么对服务的日志二次解析？**</p>
</blockquote>
<p>A：Filebeat -&gt; Kafka -&gt; Logstash -&gt; ES -Kibana，在Logstash处会对日志进行二次解析打标，不规范的日志会丢弃掉。</p>
<blockquote>
<p>Q：JVM Xmx是堆内存，硬限制是物理内存，你们的配置是直接读环境变量设置一样了吗？会不会出现内存不足？堆外内存怎么办？</p>
</blockquote>
<p>A：我们的环境变量配置的是Pod容器的limit大小，JVM Xmx是使用limit大小*0.6配置启动的，出现过内存不足，OOM等情况，一般是让开发去调整permsize大小，或不要有内存泄露。</p>
<blockquote>
<p>Q：容器rootfs大小怎么限制的？</p>
</blockquote>
<p>A：在安装Docker时，使用Devicemapper驱动安装，会默认限制大小10G，overlya驱动对rootfs大小的限制不是很完善。</p>
<blockquote>
<p>Q：DaemonSet的日志收集具体是怎么做的？怎么采集日志？</p>
</blockquote>
<p>A：我们参考了阿里云的LogTail日志采集方案，这里给大家推荐一个开源版的日志采集项目：<a href="https://github.com/AliyunContainerService/log-pilot" target="_blank" rel="noopener">AliyunConta/pilot</a>。</p>
<blockquote>
<p>Q：服务监控接口，类似于/zbjcheck这块是怎么做的呢？是否可以发一个返回样例。</p>
</blockquote>
<p>A：要求在每个项目里对/zbjcheck路由进行匹配，根据http返回码做简单的check检测，具体可以参考官方文档：<a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#define-readiness-probes" target="_blank" rel="noopener">kubernetes.io/docs/robes</a>。</p>
<blockquote>
<p>Q：什么时候升级集群，Kubernetes大版本升级的时候怎么做？</p>
</blockquote>
<p>A：我们一般会在进行机房业务迁移的时候去升级集群，如从私有云迁到公有云，直接新建一套新版本集群，把旧集群的deployment文件更新过去。</p>
<blockquote>
<p>Q：相关中间件和DB都没有上吗？有的话请介绍一下。</p>
</blockquote>
<p>A：是的，中间件和DB数据库都有专门的团队来维护，在没有必要的情况下没有去做容器化，我们集群对接了Ceph存储，但IO性能不高，数据库容器化还是应该使用local volume。</p>
<blockquote>
<p>Q：DevOps的资料都存在etcd中的吗？ 这个是怎么做的 能否讲讲设计思路？</p>
</blockquote>
<p>A：是我们的Deployment发布模块及元数据都存在了etcd中，把etcd当做一个K-V数据库来用，当时在数据库选型时也考虑过MySQL，但是我们的数据类型适合KV存储，如我们的每个项目Deployment模板都是不一样的，存放在/deployment/region/env/projectname/这样的路径下，并且etcd更加稳定高可用。</p>
<hr>
<h3 id="2018-11-22：容器化落地实践的一个案例"><a href="#2018-11-22：容器化落地实践的一个案例" class="headerlink" title="2018-11-22：容器化落地实践的一个案例"></a>2018-11-22：容器化落地实践的一个案例</h3><blockquote>
<p>Q：PreStop Hook的参考地址能给个外网地址看嘛？</p>
</blockquote>
<p>A：这个看官方的文档就行吧，我这个场景里只是用了一个curl，让开发提供一个接口就行。具体PreStop Hook官方文档上有详细的举例。</p>
<blockquote>
<p>Q：Apollo配置中心，配置怎么落到服务里的，或者容器里？</p>
</blockquote>
<p>A：我们这边大部分是Java项目，使用的官方提供的SDK，具体可以看下Apollo的使用文档。</p>
<blockquote>
<p>Q：日志怎么采集和展示？用什么方案？</p>
</blockquote>
<p>A：ELK，采集日志主要是程序直接输出到Redis，这点有些不一样。</p>
<blockquote>
<p>Q：CD的配置是怎么管理的？</p>
</blockquote>
<p>A：相关的上线配置都是存在运维平台上，服务的配置使用的Apollo配置中心。</p>
<blockquote>
<p>Q：Kubernetes的HPA组件是原生的吗，只根据CPU内存来进行伸缩，有没有出现过什么问题？</p>
</blockquote>
<p>A：是原生的，出现过的问题是，之前都只采用了一个纬度的扩容（CPU），后来发现该Pod经常OOM，后来加上了内存的扩容，Java服务例外。</p>
<blockquote>
<p>Q：Prometheus数据怎么保存的，每个实例都存在本地目录吗？</p>
</blockquote>
<p>A：我们有专门的Node节点来跑Prometheus Pod通过Node Label调度，采用的本地SSD磁盘，每个服务一个目录，大概这个样子。</p>
<blockquote>
<p>Q：还有就是日志部分现在Redis是瓶颈吗，Redis也是集群？</p>
</blockquote>
<p>A：分享的时候提到了，Redis是瓶颈，后来公司Golang工程师搞了一个Reids--Kafka的代理服务，采用的Redis协议，但是直接写入到了Kafka，解决了性能问题。</p>
<blockquote>
<p>Q：Prometeus也是Kubernetes管理吗，配置文件他的配置文件怎么管理的？</p>
</blockquote>
<p>A：这块我们写了一个简单的服务部署到了Kubernetes的Master节点上，当一个服务接入Kubernetes上以后，运维平台会去掉这个服务的接口，就会创建一个Prometheus Server专门抓取该服务的监控数据，通过Prometheus的配置可以做到只匹配该服务，我们这边是每个服务配置一个单独的Prometheus Server抓取端。</p>
<p>以上内容根据2018年11月20日晚微信群分享内容整理。分享人<strong>吴飞群，一下科技运维工程师</strong>。</p>
<hr>
<h3 id="2018-11-03：Spring-Cloud-Kubernetes容器化实践"><a href="#2018-11-03：Spring-Cloud-Kubernetes容器化实践" class="headerlink" title="2018-11-03：Spring Cloud Kubernetes容器化实践"></a>2018-11-03：Spring Cloud Kubernetes容器化实践</h3><blockquote>
<p>Q：使用NFS有存在性能瓶颈或单点故障的问题吗，如何解决，对于持久化要求高的Redis应该采用哪种存储？</p>
</blockquote>
<p>A：具体看你的规模数量，测试、开发环境，单节点NFS毫无压力，数据是先写到缓存内存，速度很快，我文章中的说的内核注意bug，没必要做高可用，公有云有NAS服务，不必担心，自建机房可以用drbd Keepalived vip。</p>
<blockquote>
<p>Q：为什么网络没有使用Traefik，Spring Cloud的相关组件是怎么部署的，是用yaml文件还是使用Helm方式？</p>
</blockquote>
<p>A：考虑到Traefik性能没有nginx好，所以用nginx，ymal是自己写的模板生成的，没有用Helm。我们正在调研，Eureka可以单独定制多个yml互相注册。与外部服务通过打通网络直通，通过SVC对接。</p>
<blockquote>
<p>Q：请问下所有环境都在一个集群，压测怎么办？</p>
</blockquote>
<p>A：压测只是对应用产生压力，你可以把需要压测的应用调度到不同的节点Node Selecto隔离运行。</p>
<blockquote>
<p>Q：对于局域网微信回调是如何做，没有公网IP？</p>
</blockquote>
<p>A：打通网络之后，设置WIFI指向DNS为Kubernetes DNS，Service直接互通。</p>
<blockquote>
<p>Q：Eureka注册时服务IP用的什么？</p>
</blockquote>
<p>A：Kubernetes集群内会用的pod ip去注册。</p>
<blockquote>
<p>Q：有状态应用的场景，使用容器部署与传统部署有啥区别，容器部署是否存在一些坑？</p>
</blockquote>
<p>A：有状态容器创建后，尽量少动，少迁移，遇到过卡住，容器无法迁移或删除，重要的MySQL之类的建议放外部运行。</p>
<p>以上内容根据2018年10月30日晚微信群分享内容整理。分享人<strong>涂小刚，新浪爱问普惠科技容器平台负责人，负责Kubernetes容器平台的推广与建设</strong>。</p>
<hr>
<h3 id="2018-09-29：有赞容器化实践"><a href="#2018-09-29：有赞容器化实践" class="headerlink" title="2018-09-29：有赞容器化实践"></a>2018-09-29：有赞容器化实践</h3><blockquote>
<p>Q：你们的上线审批流程是怎样的？</p>
</blockquote>
<p>A：我们主要是定义了发布窗口、发布次数等限制，如果在限制以内的，只需要走普通的发布审批流程，否则走紧急发布流程。</p>
<blockquote>
<p>Q：在容器内打镜像怎么避免用户把仓库账号信息打印出来？</p>
</blockquote>
<p>A：Clone代码所使用的私钥是通过Pod的环境变量下发的，这里主要是把镜像集成分成多个步骤，我们会在最开始Clone完代码后就将所有敏感信息清理掉了。</p>
<blockquote>
<p>Q：网络方面可以详细讲一下，没有遇到问题吗？</p>
</blockquote>
<p>A：网络方面因为我上面说的原因，我们一开始就是Macvlan的方案，ipam都是本地配置文件，这样风险确实是最低的，性能也很不错。后面我们随着有赞多云架构，也在使用QCloud的容器服务，当然这里的网络主要还是云厂商解决的。</p>
<blockquote>
<p>Q：请问，你们是如何衡量应用容器发布之后的效率改进的？单纯看用户体验，还是有类似发布效率改进这类的指标？</p>
</blockquote>
<p>A：容器化效率提升其实最主要的还是在开发测试环节，比如很多项目中都是push完代码就开始自动CI、部署、测试等过程的，我们在持续交付里会有很多指标的产出作为参考。</p>
<blockquote>
<p>Q：应用监控方案呢？Docker内基础监控的采集、上报、存储和展示方案，能否分享下？</p>
</blockquote>
<p>A：监控主要用的还是Prometheus，主要包括采集容器的基础Metrics数据、kube-state-metrics数据以及后续Java框架/Nodejs框架统一输出的Metrics数据。这些监控数据会和容器之前的所有监控数据统一到”天网”中，展示是我们自己定制的，实现在我们的基础保障平台里面。</p>
<blockquote>
<p>Q：之前看过有赞SC环境的文章，里面Dubbo的路由规则是否针对环境的逻辑隔离做过改造？关键实现的点是哪些？</p>
</blockquote>
<p>A：是的，我们确实改造过整个调用链里的每个环节，会全链路透传一个环境标签，以及我们灰度实现的方案也是基于这个。</p>
<p>以上内容根据2018年9月25日晚微信群分享内容整理。分享人<strong>王波，十年运维老兵，现担任有赞运维平台负责人，负责有赞基础保障平台的建设，面向有赞开发、测试和运维提供涵盖应用生命周期管理、项目研发生命周期管理（持续交付）等功能的DevOps一站式服务</strong>。</p>
<hr>
<h3 id="2018-09-20：唯品会Noah云平台实现内幕披露"><a href="#2018-09-20：唯品会Noah云平台实现内幕披露" class="headerlink" title="2018-09-20：唯品会Noah云平台实现内幕披露"></a>2018-09-20：唯品会Noah云平台实现内幕披露</h3><blockquote>
<p>Q：灰度发布时，两个应用前要加负载均衡吗？</p>
</blockquote>
<p>A：我在服务注册发现章节提到唯品会有自研的服务化框架，是通过服务化框架的Proxy做LB的，LB是服务治理的一个重要功能。对于HTTP服务，最后还是注册到HAProxy的，因此还是通过它做LB的。</p>
<blockquote>
<p>Q： 有状态的服务比如IP固定，不知道你们有没有这种服务，是怎么解决的？</p>
</blockquote>
<p>A：我们是有写有状态的服务，如Redis和MySQL，是通过CentOS Operator框架，自己编写Operator解决的。固定IP我们正在开发中，因为要结合唯品会的网络拓扑，实现起来稍微复杂点。还有，我们在做的rebuild方案，IP也是相对固定的，如果没有触发Kubernetes的scheduler调度的话，比如node evict。</p>
<blockquote>
<p>Q：请问，外部请求如何路由到Kubernetes集群内，是使用的Ingress吗？</p>
</blockquote>
<p>A：外部流量的接入，唯品会有VGW的Gateway，通过APP上的智能路由找到最优机房的VGW，然后一层一层到容器。</p>
<blockquote>
<p>Q：超配的情况下，如果各个pod load都增大，驱逐策略是怎样的？</p>
</blockquote>
<p>A：这里我没有讲细，你的问题很仔细啊，赞，我们开发了热点迁移容器的API，监控系统如果收到告警（比如CPU过高，IO过高），会调用我们API ，我们API获取实时的监控数据，根据某个算法，迁移走部分热点容器。</p>
<blockquote>
<p>Q：自动缩容的时候是如何选择Pod，如何保证数据不丢失呢？</p>
</blockquote>
<p>A：自动缩容之针对无状态应用的，而且我们要求所有上云平台的应用，都支持Graceful Shutdown，由业务保证。</p>
<blockquote>
<p>Q：Tomcat类应用容器Xmx内存分配多少比例合适，就是Xmx使用百分多少容器内存合适？</p>
</blockquote>
<p>A：JVM内存的计算包括了Heap＋Permgen＋线程数的stack（1M／per线程）＋堆外内存，所以我们监控容器的RSS数据，这是容器真实的内存占用。</p>
<blockquote>
<p>Q：集群空闲率多少合适？我们的集群超过60%上面的容器就不稳定了。</p>
</blockquote>
<p>A：我们为了提高资源利用率，做了很多事情，上面有说到，你说的60%就不稳定，需要具体分析下，因为我们也踩过一些Kubernetes和Docker的坑，同时也需要优化好系统参数，有时候问题也跟内核版本有关。</p>
<p>以上内容根据2018年9月18日晚微信群分享内容整理。分享人<strong>王志雄，唯品会云平台架构师，参与工作15+，其中10多年在亿讯（中国电信），爱立信参与电信领域产品开发研究工作，4年前加入唯品会基础架构部，主要负责服务化平台（唯品会OSP）的研发和推广落地工作，OSP现已经是唯品会主流的服务化框架。17年开始云平台产品相关工作，现是唯品会云平台架构师，主要负责唯品会Noah云平台的产品研发和推广落地工作，Noah云平台已经接入了大部分核心域和其他业务域，并顺利承载了公司的多次大促</strong>。</p>
<hr>
<h3 id="2018-09-09：gVisor是什么？可以解决什么问题？"><a href="#2018-09-09：gVisor是什么？可以解决什么问题？" class="headerlink" title="2018-09-09：gVisor是什么？可以解决什么问题？"></a>2018-09-09：gVisor是什么？可以解决什么问题？</h3><blockquote>
<p>Q：gVisor是yet another container，gVisor = Kata Linux的隔离性 + Docker的隔离低消耗，可以这样理解吗？</p>
</blockquote>
<p>A：基本上可以这样理解，看业界对gVisor的评价普遍认为隔离性与虚拟机方案的隔离性相当，但也有人顾虑是否真能提供到这么高的隔离性，个人觉得需要时间来证明。关于低损耗我觉得得看业务的场景，目前来说对于高性能的场景我觉得是不合适的。</p>
<p>以上内容根据2018年9月4日晚微信群分享内容整理。分享人<strong>王重山，深圳米筐科技有限公司运维总监。2014年底加入米筐，先后参与米筐在线平台以及运维系统的建设，在运维体系建设期间调研和落地了容器相关技术</strong>。</p>
<hr>
<h3 id="2018-08-25：有货基于Kubernetes容器环境的持续交付实践"><a href="#2018-08-25：有货基于Kubernetes容器环境的持续交付实践" class="headerlink" title="2018-08-25：有货基于Kubernetes容器环境的持续交付实践"></a>2018-08-25：有货基于Kubernetes容器环境的持续交付实践</h3><blockquote>
<p>Q：为什么没有和CI结合在一起？使用这个比较重的Spannaker有什么优势？</p>
</blockquote>
<p>A：可以和CI进行结合，比如Webhook的方式，或者采用Jenkins调度的方式。优势在于可以和很多云平台进行结合，而且他的Pipeline比较的完美，参数化程度很高。</p>
<blockquote>
<p>Q：目前IaaS只支持OpenStack和国外的公有云厂商，国内的云服务商如果要支持的话，底层需要怎么做呢（管理云主机而不是容器）？自己实现的话容易吗？怎么入手？</p>
</blockquote>
<p>A：目前我们主要使用Spinnaker用来管理容器这部分的内容，对于国内的云厂商Spinnaker支持都不是非常的好，像LB，安全策略这些都不可在Spinnaker上面控制。若是需要研究可以查看Cloud driver这个组件的功能。</p>
<blockquote>
<p>Q：Spinnaker能不能在Pipeline里通过http API获取一个deployment yaml进行deploy，这个yaml可能是动态生成的？</p>
</blockquote>
<p>A：部署服务有两种方式：1. 在Spinnaker的UI中直接填入Manifest Source，其实就是对应的deployment YAML，只不过这里可以写入Pipeline的参数；2. 可以从GitHub中拉取对应的文件，来部署。</p>
<blockquote>
<p>Q：Spannaker的安全性方面怎么控制？</p>
</blockquote>
<p>A：Spinnaker中Fiat是鉴权的组件，配置权限管理，Auth、SAML、LDAP、GitHub teams、Azure Groups、 Google Groups，我们就采用LDAP，登陆后会在上面显示对应的登陆人员。</p>
<blockquote>
<p>Q： deploy和test以及rollback可以跟helm chart集成吗？</p>
</blockquote>
<p>A：我觉得是可以，很笨的方法最终都是可以借助于Jenkins来实现，但是Spinnaker的回滚与部署技术很强大，在页面上点击就可以进行快速的版本回滚与部署。</p>
<blockquote>
<p>Q：Spannaker之前的截图看到也有对部分用户开发的功能，用Spannaker之后还需要Istio吗？</p>
</blockquote>
<p>A：这两个有不同的功能，【对部分用户开发的功能】这个是依靠创建不同的service以及Ingress来实现的，他的路由能力肯定没有Istio强悍，而且也不具备熔断等等的技术，我们线下这么创建主要为了方便开发人员进行快速的部署与调试。</p>
<hr>
<h3 id="2018-08-13：基于Spring-Cloud的微服务容器化实践"><a href="#2018-08-13：基于Spring-Cloud的微服务容器化实践" class="headerlink" title="2018-08-13：基于Spring Cloud的微服务容器化实践"></a>2018-08-13：基于Spring Cloud的微服务容器化实践</h3><blockquote>
<p>Q：WSO2的APIManager会将所有流量都统一到他这里进出，如何解决统一API网关的大流量问题？</p>
</blockquote>
<p>A：API Manager是可以拆开的，分开部署，比如调用你接口走网关模块，可以做高可用。当然不拆开也可以做高可用，前面加负载均衡。</p>
<blockquote>
<p>Q：Eureka在生产上的Kubernetes中是如何做到高可用和动态扩容的？</p>
</blockquote>
<p>A ：好问题，Eureka我们目前是指定数量，可以结合脚本（或代码）做动态扩容和高可用。目前我们Hadoop就是结合代码做到的。</p>
<blockquote>
<p>Q：服务之间二阶段事务控制一般怎么做？或者说有没有现成工具或代码？服务间用http靠谱还是其他协议靠谱？</p>
</blockquote>
<p>A：这个网上有一些思路比如补偿的方式，还有就是通过流数据库（Kafka），事件驱动的方式。我们目前正在尝试这种方式。</p>
<hr>
<h3 id="2018-08-11：滴滴弹性云Kubernetes实践"><a href="#2018-08-11：滴滴弹性云Kubernetes实践" class="headerlink" title="2018-08-11：滴滴弹性云Kubernetes实践"></a>2018-08-11：滴滴弹性云Kubernetes实践</h3><blockquote>
<p>Q：利用cgroup v2的blk-throttle实现对非driect io场景下的磁盘读写速度隔离，这个怎么做的，Kubernetes支持吗？</p>
</blockquote>
<p>A：如果是3的内核，那么只支持cgroup v1，v1只支持对driect io的磁盘读写限制，而我们知道大多数情况下的写磁盘都是先写到内存里再FLUSH到磁盘上，所以要限制的是从内存到磁盘的这个环节。4的内核支持cgroup v2，这个功能已经比较成熟，你可以尝试升级内核或者将v2的功能移植到v1上。</p>
<blockquote>
<p>Q：是要修改dockerd的配置，还是在Kubernetes上扩展？</p>
</blockquote>
<p>A：如果是接着上面的问题的话，我们是使用了一个Agent的方式，单独的做加强的资源隔离的，没有在Kubernetes上做扩展。</p>
<blockquote>
<p>Q：DGW是基于什么实现的？</p>
</blockquote>
<p>A：DGW其实就是LVS，我们这边的系统组实现了通过接口的方式动态的变更LVS配置的能力。</p>
<blockquote>
<p>Q：容器网络和物理网络类型一样，具体是什么网络？原有的ONOS SDN网络还有用吗？不同name space之间隔离怎么做？</p>
</blockquote>
<p>A：老的集群使用SDN网络，新集群使用物理网络。所谓物理网络就是和物理机同一个网络，只不过每个tor下划分出一段专门给容器分配使用。</p>
<blockquote>
<p>Q：请问下”利用tc实现对容器网络带宽的限制”，具体怎么做的？</p>
</blockquote>
<p>A：参考物理机使用tc对容器做网络流量限制，如果你用了SDN网络DPDK/OVS什么的，限速就更方便了。</p>
<blockquote>
<p>Q：滴滴的卷管理是怎么设计的？有状态服务怎么设计调度，来保证数据持久化的？</p>
</blockquote>
<p>A：目前我们这边有状态服务非常多，无状态非常少，用户的使用习惯还是和物理机趋同，对于这部分”老派”的用户我们提供了类似虚拟机这样的容器。使用本地卷（hostpath），容器只能本地重建不可跨宿主漂移。这也是对业务的一种妥协。另外我们也使用过ceph，但是最后评估风险更大，故暂时放弃使用，或小范围使用。</p>
<blockquote>
<p>Q：通过负载均衡的健康检查测试服务可用性，健康检查的周期内，如何保证流量不丢失？</p>
</blockquote>
<p>A：我们这边LVS默认有7秒的探活间隔，在7秒的间隔内如果容器故障不可用那么确实会有流量的丢失，目前不可避免。</p>
<blockquote>
<p>Q：容器的优雅下线怎么实现的？</p>
</blockquote>
<p>A：我们之前的容器启动都是用Supervisor托管的，后来我们自己写了一个dockerinit，用于用户业务服务的启停，他的功能比较强大能执行单独的一次性程序（类似物理机的rc.local），也能托管进程。于此同时他会保证容器所有的业务进程退出后再销毁容器，避免粗暴的停止容器。</p>
<blockquote>
<p>Q：有没有使用cpu_quota来做精细的限制呢？CPU request绑定CPU，超分的情况怎么处理呢？</p>
</blockquote>
<p>A：你想问的其实是超售的问题，参考业内一些走在前面的大厂，我们的容器会根据容器的服务等级做适当的超售，这样一个48核的宿主就能承载更多的容器。这里面的细节比较多，这里不太好描述。</p>
<blockquote>
<p>Q：我们在运维过程中发现：某些配置了探针的容器因为服务没有成功启动而不断的被Kubernetes杀掉重建，在重建超过几百或数千次之后会偶发性的导致宿主的一些异常。这个问题的原因我们尚未查明，但是这种容器不断的重建本身就显得没有意义，再加上我们使用了自研的服务发现，所以就对每个容器的重启次数做了限制，让负载均衡层去做健康检查。</p>
</blockquote>
<p>A：启动上百个Pod以后我也遇见过这个问题，后来排查问题发现是docker docker_storage的overlay和overlay2没有使用xfs 文件系统导致，不知道你们有没有研究io的问题。我们使用的是overlayfs2，这个我们在生产环境中验证过，还是比较靠谱的。如果你是低版本的Docker的话，需要加一个参数就能使用overlayfs2了。有没有调研过RedHat的OpenShift，感觉网上文档很全也解决了很多问题，听说小米在用，但是你知道基础架构是牵一发而动全身的，不能轻易变化。</p>
<hr>
<h3 id="2018-07-29：基于-GitLab-的-CI-实践"><a href="#2018-07-29：基于-GitLab-的-CI-实践" class="headerlink" title="2018-07-29：基于 GitLab 的 CI 实践"></a>2018-07-29：基于 GitLab 的 CI 实践</h3><blockquote>
<p>Q：您提到把各种依赖都以 Service 的提供，请问是以哪种方式呢？比如Python的依赖，怎么做成Service呢？</p>
</blockquote>
<p>A：Service 化的依赖，主要是指类似 DB / MySQL/ Reids 之类的。 或者是 dind 其实它提供的是 2375 端口的TCP服务。 Python 的依赖，我推荐的做法是， 构建一个换了源的 Python 镜像。 安装依赖的时候，耗时会少很多。 或者说， 可以在定义 Pipeline 的时候， 将虚拟环境的 venv 文件夹作为 cache ，之后的安装也会检查这个，避免不必要的安装。</p>
<blockquote>
<p>Q：请问，你们为什么不用Jenkins Pipeline，而使用GitLab CI？</p>
</blockquote>
<p>A：主要原因是我提到的那几个方面。 集成较好， 界面美观优雅， 使用简单（所有有仓库写权限的人 都可以使用， 只要创建 .gitlab-ci.yml 并且配置了 Runner 即可使用） 。换个角度，我们来看下使用Jenkins 的问题， Jenkins 对于项目的配置其实和 GitLab 的代码是分离的， 两部分的， 用户（或者说我们的开发者）在使用的时候， 需要有两个平台， 并且，大多数时候， Jenkins 的权限是不放开的。 对用户来讲， 那相当于是个黑盒。 那可能的问题是什么呢？ 遇到构建失败了， 但是只有运维知道发生了什么，但是研发无能为力，因为没有权限。 使用GItLab的好处，这个时候就更加突出了， 配置就在代码仓库里面，并且使用 YAML 的配置，很简单。 有啥问题，直接查，直接改。</p>
<blockquote>
<p>Q：关于 Runner 的清理的问题，在长时间使用后，Runner 机器上回产生很多的Cache 容器，如何清理呢。能够在任务中自动清除吗？</p>
</blockquote>
<p>A：这个就相对简单了，首先， 如果你的 Cache 容器确认没用了， 每个 Cache 容器其实都有名字的， 直接按 Cache 的名字过略， 批量删掉。 如果你不确定它是否有用，那你直接删掉也是不影响的， 因为 Docker Excutor 的执行机制是创建完 Service 容器后， 创建 Cache 容器。 要是删掉了，它只是会再创建一次。 如果你想在任务中清除， 目前还没做相关的实践，待我实践后，看看有没有很优雅的方式。</p>
<blockquote>
<p>Q：请问下Maven的settings.xml怎么处理？本地Maven仓库呢？</p>
</blockquote>
<p>A：我们构建了私有的 Maven 镜像， 私有镜像中是默认使用了我们的私有源。 对于项目中用户无需关注 settings.xml 中是否配置repo。</p>
<blockquote>
<p>Q：在GitLab的CD方案中，在部署的时候，需要在变量中配置跳板机的私钥，如果这个项目是对公司整部门开发，那么如何保护这个私钥呢？</p>
</blockquote>
<p>A：可以使用 secret variable 将私钥写入其中， （但是项目的管理员，具备查看该 variable 的权限）开发一个 web server （其实只要暴露 IP 端口之类的就可以） 在 CI 执行的过程中去请求， server 对来源做判断 （比如 执行CI 的时候，会有一些特定的变量，以此来判断，是否真的是 CI 在请求）然后返回私钥。</p>
<blockquote>
<p>Q：GitLab CI适合什么类型的项目呢？国内目前还比较小众吧？</p>
</blockquote>
<p>A：国内目前还较为小众（相比 Jenkins 来说）其实只要需要 CI 的项目，它都适合。</p>
<hr>
<h3 id="2018-07-20：小米弹性调度平台Ocean"><a href="#2018-07-20：小米弹性调度平台Ocean" class="headerlink" title="2018-07-20：小米弹性调度平台Ocean"></a>2018-07-20：小米弹性调度平台Ocean</h3><blockquote>
<p>Q：请教下你们ELB用的什么代理软件，HAProxy、Nginx？是否遇到过缩容时出现部分请求失败的问题，有解决方案吗？</p>
</blockquote>
<p>A：IDC ELB底层封装的是公司的LVS，LVS管理平台提供了完事的API支持，ELB这边调用LVS管理平台的API进行的相关操作。缩容目前没有遇到流量丢失问题，这个是在docker init内接收信号，然后做的回收处理。</p>
<blockquote>
<p>Q：hostgw如何访问外网？</p>
</blockquote>
<p>A：是通过路由出网的，容器的IP是路由上真实存在的IP网段，由网络组提供的API进行的动态配置。</p>
<blockquote>
<p>Q：都劫持了，为啥不用 LXCFS？</p>
</blockquote>
<p>A：LXCFS目前仅支持改变容器的CPU视图（/proc/cpuinfo文件内容）并且只有 –cpuset-cpus 参数可以生效，对于系统调用sysconf(_SC_NPROCESSORS_ONLN)返回的同样还是物理机的CPU核数。另：我们采用的劫持方案已开源，欢迎围观：<a href="https://github.com/agile6v/container_cpu_detection" target="_blank" rel="noopener">agile6v/container_cpu_detection</a></p>
<p>以上内容根据2018年7月17日晚微信群分享内容整理。分享人<strong>赵云，小米云平台运维部SRE，负责小米有品产品线运维工作</strong>。</p>
<hr>
<h3 id="2018-07-13：Hulu大规模容器调度系统Capos"><a href="#2018-07-13：Hulu大规模容器调度系统Capos" class="headerlink" title="2018-07-13：Hulu大规模容器调度系统Capos"></a>2018-07-13：Hulu大规模容器调度系统Capos</h3><blockquote>
<p>Q：Capos如何处理健康检查？之前了解到，Mesos内置的健康检查不是特别完善。</p>
</blockquote>
<p>A：目前Capos focus的作业大部分都是短作业类型，所以我们目前就是通过容器的退出码来判断success或者fail，如果你说的健康检查是针对服务的，一般实现是支持多种健康检查的方式，bash，http等，然后为了大规模容器运行情况下的可用性，建议这种健康检查的发起client和服务instance是在一台机器上，或者是一个Pod中，发现不健康通过某种机制上报，或者退出Container，但是需要控制Threshold以免整个服务downtime。这样可以探测instance的健康，整个服务的健康，可以在通过外部的一些子系统去check。</p>
<blockquote>
<p>Q：关于调度方面，分享中只提到了使用了一系列的可插拔的过滤函数和优先级函数，我想问下能否具体描述下如何被调度的？和yarn里使用的Fair Schedule或者DRF算法的异同有哪些？因为对于多种资源维度的调度是一个很复杂的问题，希望知道Hulu这方面有什么心得和思考？</p>
</blockquote>
<p>A：目前实现是，会针对一个请求，首先根据过滤函数比如一些constraints进行offer过滤，然后剩下的offer apply所有的优先级打分函数，进行打分，打分的时候，会根据一个请求和offer的资源，算CPU和mem的比例，选取出dominate的resource进行主要评分，然后选取最优的offer进行bind，bind之后不会马上调度，而是会delay scheduler，这样一般在比较繁忙的情况下，一次offer launch可以启动多个tasks，这是对于大规模吞吐的考虑。 以上这些实现还是queue-base的调度，借鉴了一些Fair Schedule和drf的思路，具体差别你了解了Capos scheduler策略后，应该就会有自己的想法了。多种资源维度，目前我们是根据dominate resource作为主要评分标准的，当然你也可以看下我最后分享提到的一些flow-base的scheduler算法，比如firmament。希望可以回答你的问题。</p>
<blockquote>
<p>Q：Capos是否支持，数据中心之间的备份/切换。比如Zone-A的数据中心出现网络故障，把服务迁移到另一个指定的区域 Zone-B（仍然考虑恢复以后优先部署到 Zone -A）。之前考虑是类似一个Mask的机制，如果故障就加一定的Mask值（比如Opcacity）在某个集群上，然后调度的时候去参考这个Mask值，不知道Hulu有没有类似的需求或者考虑过这样的机制？</p>
</blockquote>
<p>A：Capos是on Mesos，Mesos是根据zk做选主，而且Capos scheduler中还有一个raft base key value store，所以这些条件，使得Capos是一个datacenter的解决方案。目前Hulu是有多个DataCenter的，所以看架构组件图，你可以看到，我们有一个Capos portal，在这个组件下，是可以选择不同DataCenter去run workload。所以我们目前对于数据中心的备份和切换，主要是依赖Capos portal这个组件，在Gateway的位置做的控制。</p>
<blockquote>
<p>Q：想请问下Capos的鉴权是怎么做的，有没有用户权限认证系统？此外，针对每个用户有没有容器资源使用量的限制？</p>
</blockquote>
<p>A：可以翻到之前share的架构组件图，我们有一个Capos portal组件，这个组件是提供Restful API和Portal，我们在这边集成Hulu SSO，然后关联Hulu yellowpages（Hulu的服务权限控制系统），做的用户的认证，我们分成自己的Capos APP， team的APP，别的组无法操作不属于自己的Capos APP。对于Quota的管理，我们做了Queue/Label机制，每个服务会建一个标识，然后在标识底下配置总的资源使用量，以及可以用的机器列表（通配符），用这样的机制控制Capos的用户资源使用。</p>
<hr>
<h3 id="2018-06-28：基于Pipeline的CI-CD在趣头条的应用实践"><a href="#2018-06-28：基于Pipeline的CI-CD在趣头条的应用实践" class="headerlink" title="2018-06-28：基于Pipeline的CI/CD在趣头条的应用实践"></a>2018-06-28：基于Pipeline的CI/CD在趣头条的应用实践</h3><blockquote>
<p>Q：生成新的镜像怎么自动打新的tag？</p>
</blockquote>
<p>A：我们镜像Tag使用本次构建选定的Git版本，如分支名称或者Tag。</p>
<blockquote>
<p>Q：你们的Jenkins实例有多少，Jenkins实例是怎么规划的？</p>
</blockquote>
<p>A：1个Master节点提供UI界面，几个Agent分别对应不同语言版本和不同环境Kubernetes集群，运行在容器中。规划就是按语言或版本分节点，按集群分节点（Agent）。</p>
<blockquote>
<p>Q：SonarQube跟Jenkins的集成，能否详细介绍一下，能否show一下Groovy代码。</p>
</blockquote>
<p>A：这个比较简单，构建时将项目信息输入到sonar-project.properties文件中，再调用sonar-scanner命令即可。</p>
<blockquote>
<p>Q: 这个Pipeline Jenkinsfile是多个在一起吗？ 还是直接写的Groovy文件？</p>
</blockquote>
<p>A：多个Groovy文件，按类型分函数，一个功能尽量只写一次。</p>
<blockquote>
<p>Q：Jenkins的权限控制能否再细化一下？</p>
</blockquote>
<p>A：我们这边权限实际上是在CMDB中完成的。构建时向CMDB发起查询请求，传递当前项目名称、选择的环境、用户名过去，CMDB判断当前用户是否有权限构建选定的环境，允许则返回项目配置信息，否则返回错误代码，这边收到后报错终止。</p>
<blockquote>
<p>Q：SonarQube的权限控制及性能当面？</p>
</blockquote>
<p>A：权限控制使用SonarQube提供的API，将项目跟GitLab中相应项目权限匹配起来，GitLab中可以查看这个项目代码，那么SonarQube中就能看到这个项目结果和Code。</p>
<blockquote>
<p>Q: 你们是直接将SonarQube、GitLab/Jenkins的权限控制到一起了？怎样做的统一？</p>
</blockquote>
<p>A：使用LDAP认证。</p>
<blockquote>
<p>Q：Sonar使用的sonar-scanner还是mvn sonar：sonar？</p>
</blockquote>
<p>A：使用 SonarScanner。</p>
<blockquote>
<p>Q：Kubernetes的services.yaml文件在哪里管理？</p>
</blockquote>
<p>A：deployment &amp; service &amp; configmap之类文件都是提供Git进行版本控制，针对语言有模版，构建时进行替换。</p>
<blockquote>
<p>Q：Pipeline有回滚机制吗，你们集成覆盖率测试了吗？</p>
</blockquote>
<p>A：回滚机制暂时不打算通过Pipeline进行，后续在另外的平台实现。<br>A：人工触发，因为有必须要人工选择的Git版本。为防止误发布，默认没有选定版本，不选则在预处理时报错终止。</p>
<blockquote>
<p>Q：Pipeline这套机制的脚本如果出错了如何调试？</p>
</blockquote>
<p>A：echo输出调试（手动滑稽）。</p>
<blockquote>
<p>Q：Pipeline语法和使用上有什么参考链接吗？</p>
</blockquote>
<p>A：<a href="http://www.groovy-lang.org/" target="_blank" rel="noopener">www.groovy-lang.org</a>、<a href="https://www.w3cschool.cn/groovy" target="_blank" rel="noopener">www.w3cschool.cn/groovy</a>、<a href="https://jenkins.io/doc/book/pipeline/syntax" target="_blank" rel="noopener">jenkins.io/doc/book/pipeline/syntax</a></p>
<blockquote>
<p>Q：Git Checkout的时候，你们的Git SCM没有考虑隐私安全的事情吗，比如代码权限受限？</p>
</blockquote>
<p>A：Jenkins使用了一个最小权限用户去GitLab上拉代码。安全方面，Jenkins所有节点都是可控的。</p>
<blockquote>
<p>Q: 你们的各工具间，有没有做集成？比如使用Pipeline来操作Jira相关issue等？或其他问题管理工具。</p>
</blockquote>
<p>A：我们这边目前还没集成Jira。如果有这需求肯定会对接起来。 &gt; 至于其它的则根据需要在不同阶段进行上报。</p>
<blockquote>
<p>Q：构建及部署都在容器中？要构建的文件或制品文件怎么存放与管理的？</p>
</blockquote>
<p>A：Agent容器启动时挂载了一个目录，里面有全套附属文件及Jenkins &gt; home目录。build节点完成自己工作后，其它节点按需接手处理。</p>
<hr>
<h3 id="2018-06-24：苏宁容器云基于Kubernetes和Contiv的网络架构技术实现"><a href="#2018-06-24：苏宁容器云基于Kubernetes和Contiv的网络架构技术实现" class="headerlink" title="2018-06-24：苏宁容器云基于Kubernetes和Contiv的网络架构技术实现"></a>2018-06-24：苏宁容器云基于Kubernetes和Contiv的网络架构技术实现</h3><blockquote>
<p>Q：网络限速的对于系统级别是如何实现的？</p>
</blockquote>
<p>A：网络限速其实依然利用的操作系统的特性，比如tc，其实不管是OVS Ingress还是Netlink都是通过和内核通信，将限速规则加入到对应的port上。</p>
<blockquote>
<p>Q：上面提到的Kubernetes资源，对于实现Pod-IP固定是有限制的吗？</p>
</blockquote>
<p>A：是的，当前仅仅支持Deployment、ReplicaSet、StatefulSet，因为随着对不同资源类型的支持，我们发现处理越多的资源，对于实现IP固定的逻辑就越复杂，比如要判断这个资源是真正删除还是重新调度，在代码级别要处理的很细。所以，我们按照自身的业务特点，现在只实现三种。</p>
<blockquote>
<p>Q：RSF系统是什么系统？eBPF和XDP是什么？能简单介绍下吗？</p>
</blockquote>
<p>A：eBPF和XDF是Calico网络插件的概念，eBPF（extended Berkeley Packet Filter）起源于BPF，它提供了内核的数据包过滤机制。 BPF的基本思想是对用户提供两种SOCKET选项：SO_ATTACH_FILTER和SO_ATTACH_BPF，允许用户在sokcet上添加自定义的filter，只有满足该filter指定条件的数据包才会上发到用户空间。</p>
<blockquote>
<p>Q：您现在用的Contiv版本是多少，通过Pod的什么属性实现Pod IP？实现pod-ip固化目前代码改动量有多大，如果按人天算的话？</p>
</blockquote>
<p>A：现在用1.2.0版本，Pod的对应pause容器的IP、Mac。改动量需要30人/天，前提是对代码以及数据结构比较了解，也比较清楚Kubernetes的Pod创建逻辑。</p>
<blockquote>
<p>Q：你们做了大量定制化开发，是否提交社区了，如何保障与社区同步？</p>
</blockquote>
<p>A：没有提交社区，但是我们发现了一些重要的bug提交了，可能是因为很多代码涉及比较广，并且我们改动的有些并不是思科能够接受的，比如pod-ip固定，这个其实不符合Kubernetes开源思想。</p>
<hr>
<h3 id="2018-06-14：盘点Kubernetes网络问题的4种解决方案"><a href="#2018-06-14：盘点Kubernetes网络问题的4种解决方案" class="headerlink" title="2018-06-14：盘点Kubernetes网络问题的4种解决方案"></a>2018-06-14：盘点Kubernetes网络问题的4种解决方案</h3><blockquote>
<p>Q：今天讲了很多方法解决容器网络的问题，似乎可以从集群外部或集群内部可以直接访问容器的IP，但是在集群外部访问容器IP的场景有吗？我觉得容器的IP不应该暴露出来，从外部不能直接访问容器的IP，因为容器的IP可能是变化的。有的时候使用RC之类的。我的问题是能不能从集群外部通过clusterip或node-port ip来访问基于容器的业务呢？如果可以的话，今天介绍的Flanel或Calico的价值是什么呢，这两种方案，我感觉都是直接访问容器的IP地址，那么如果某个容器出问题，重启之后，肯定要换IP，那这个时候怎么办呢？另外，集群内容器到容器的访问，到底是直接访问对端容器的IP，还是访问cluster-ip，我这个有点晕，谢谢。</p>
</blockquote>
<p>A：集群内容器到容器的访问，可以直接通过localhost加端口即可。如果是同一主机上的Pod，由于它们在同一个docker0网桥上，地址段相同，可以直接通信。如果是不同主机上的Pod，则需要跨越物理机上的物理网卡，通过宿主机的IP转到docker0上再到对应的Pod里的某个容器。不管是Flanel或Calico，都有各自的应用场景。Flanel不是直接访问容器IP的，它还有自己的flanel0网桥，Calico节点组网可以直接利用数据中心的网络结构（支持L2或者 L3），可以直接通信。从外部可以直接访问容器的IP，需要做容器固定IP，针对某些特定应用比如数据库。</p>
<blockquote>
<p>Q：有没有碰到因为Pod数量大导致网络异常？</p>
</blockquote>
<p>A：暂时没有，Pod在大批量创建后有状态异常的，可以将其手工恢复到Running状态。</p>
<blockquote>
<p>Q：想问一下，我们实际项目中有没有使用Calico网络，有没有遇到典型的问题？Calico ipip生产环境应用有没有问题？</p>
</blockquote>
<p>A：数据中心环境有用Calico，问题是目前stable版本还无法很好的支持私有网络。</p>
<blockquote>
<p>Q：对于Kubernetes版本选择是否可以提供一些建议？</p>
</blockquote>
<p>A：建议使用1.8以上版本，在高可用、兼容性、稳定性上都更好一些。</p>
<hr>
<h3 id="2018-05-27：腾讯云TSF微服务平台及ServiceMesh技术实践"><a href="#2018-05-27：腾讯云TSF微服务平台及ServiceMesh技术实践" class="headerlink" title="2018-05-27：腾讯云TSF微服务平台及ServiceMesh技术实践"></a>2018-05-27：腾讯云TSF微服务平台及ServiceMesh技术实践</h3><blockquote>
<p>Q：感谢分享，请问目前TSF的集群规模大概是多大，ServiceMesh从选型到落地大概用了多少人月？</p>
</blockquote>
<p>A：公司内部万级的集群规模，ServiceMesh落地大概20人月。</p>
<blockquote>
<p>Q：请问你们微服务与Kubernetes的关系是怎么样的？下层跑的是Kubernetes容器吗？</p>
</blockquote>
<p>A：Kubernetes原则上是属于PaaS平台，PaaS平台是负责服务的生命周期管理以及伸缩运维等能力。而我们微服务框架本身实际上更多是针对服务调用以及治理方面，其架构是与PaaS解耦，并且可以对接不同的PaaS平台（包括Kubernetes），我们下层支持容器及虚拟机。</p>
<blockquote>
<p>Q：请问一下TSF如何融合Spring Cloud和ServiceMesh？</p>
</blockquote>
<p>A：TSF通过3种方式融合：一方面我们有一部分ServiceMesh方案基于Spring Cloud实现；二方面，是统一服务模型与配置模型；三方面，是体验统一，就是服务的部署/升级及运维的体验是一致。</p>
<blockquote>
<p>Q：引入Mesh之后，会额外多一跳，这多一跳带来的性能损失，TSF是如何找回来的？</p>
</blockquote>
<p>A：其实很多团队会纠结引入Mesh后多了的那1跳的性能损失，其实经过我们验证，一方面Envoy性能极高，媲美Nginx；二是这一跳的损耗，实际上与业务处理时延有比较大的关系，如果业务处理时延在30毫秒以上，那么这一跳带来的损耗实际上可以控制在可控范围内（具体要看机器性能）。</p>
<blockquote>
<p>Q：30ms时延算很大了。如果是2ms或者0.xms是不是必须考虑这个问题了？也就是说可能得看Envoy的性能与业务的性能是否接近？</p>
</blockquote>
<p>A：根据我们在公有云的测试结果来看是的，假如业务是属于那种对快速响应而且对时延特别敏感的业务，确实需要跟进实际的测试模型来评估下具体的性能损耗。</p>
<blockquote>
<p>Q：对于Spring Cloud与Spring Cloud Sidecar的区别是什么呢，对于从SOA转型到Spring Cloud有什么好的建议吗？谢谢。</p>
</blockquote>
<p>A：Spring Cloud Sidecar是以Sidecar方式支持非Java应用而提供的，和Spring Cloud没有太直接关系。具体从SOA到Spring Cloud转型这个不太好泛泛而谈，要结合实际情况分析。</p>
<blockquote>
<p>Q：集群外的服务是如何调用集群内的服务的？自己做的反向代理么？还是用的Zuul？</p>
</blockquote>
<p>A：TSF用的是自研的，性能更高，稳定性更好。对于小规模用户可以考虑用Zuul。</p>
<blockquote>
<p>Q：你好，根据你的介绍，你们使用Sidecar的部署模式，那在这种情况下，感觉开发人员在测试过程中也得了解如何通过配置服务本身及Envoy Sidecar实现服务的通讯，对于Envoy来说，开发人员来配置还是比较复杂的，你们是通过什么方式避免这种复杂的？</p>
</blockquote>
<p>A：如果没有一套自动化的管理部署工具，仅靠人肉支持还是不靠谱的，定位问题也不方遍，这也是TSF集成Envoy耗时比较久的一个原因。</p>
<blockquote>
<p>Q：Istio和Kubernetes结合使用时，服务注册和服务发现是怎么用的？</p>
</blockquote>
<p>A：Istio本身支持多种服务注册发现机制（包括Kubernetes、Consul、Digital Foundry、Ereuka等），在启动Istio时作为参数来配置即可。</p>
<blockquote>
<p>Q：请问是否有过使用gRPC通讯的相关案例或者需要注意的坑？目前是否能够在生产环境应用？</p>
</blockquote>
<p>A：暂时没有发现envoy-grpc的坑，不过Istio官方对于gRPC的feature状态是alpha，所以个人不建议在生产环境的使用Istio。</p>
<hr>
<h3 id="2018-05-23：全面学习Prometheus"><a href="#2018-05-23：全面学习Prometheus" class="headerlink" title="2018-05-23：全面学习Prometheus"></a>2018-05-23：全面学习Prometheus</h3><blockquote>
<p>Q：Prometheus的数据能否自动同步到InfluxDB中？</p>
</blockquote>
<p>A：可以，通过remote_write可以实现，可以参考：<a href="https://github.com/prometheus/prometheus/tree/master/documentation/examples/remote_storage/remote_storage_adapter" target="_blank" rel="noopener">github.com/prometheus/apter</a>。Prometheus通过将采集到的数据发送到Adaptor，再由Adaptor完成对数据格式的转换存储到InfluxDB即可。</p>
<blockquote>
<p>Q：请问数据采集的时间戳是Prometheus采集数据的时间，还是微服务产生数据的时间？</p>
</blockquote>
<p>A：采集时间，看node exporter里面返回的样本数据可以发现其中并不包含时间戳。</p>
<blockquote>
<p>Q：Prometheus做服务发现的时候Job是被自动分配到不同的Server节点的吗？具体分配策是？</p>
</blockquote>
<p>A：需要手动分配，然后再通过<a href="https://prometheus.io/docs/prometheus/latest/federation/" target="_blank" rel="noopener">Prometheus Fedreation</a>进行汇集。</p>
<blockquote>
<p>Q：Prometheus一个Server最多能运行多少个Job？</p>
</blockquote>
<p>A：这个没有做具体的试验，不过需要注意的是Job任务量（写操作），会直接影响Prometheus的性能，最好使用federation实现读写分离。</p>
<blockquote>
<p>Q：请问告警由Grafana实现比较好，还是Alertmanager，常用的metric列表有没有汇总的清单链接分享下，历史数据默认保留时间如何设置？</p>
</blockquote>
<p>A：Grafana自身是支持多数据源，Promethues只是其中之一。 如果只使用Promthues那用Alertmanager就好了，里面实现了很多告警去重和静默的机制，不然收到邮件轰炸也不太好。 如果需要基于Grafana中用到的多种数据源做告警的话，那就用Grafana。</p>
<blockquote>
<p>Q：Prometheus监控数据推荐存哪里是InfluxDB，或者ES里面，InfluxDB单节点免费，多节的似乎收费的？</p>
</blockquote>
<p>A：默认情况下，直接是保存到本地的。如果要把数据持久化到第三方存储只要实现remote_write接口就可以。理论上可以对接任意的第三方存储。 InfluxDB只是官方提供的一个示例之一。</p>
<blockquote>
<p>Q：请问告警规则文件可以动态配置吗？比如Prometheus已经启动，一个新的微服务上线，并需要配置新的告警规则，这时可以动态添加告警规则吗？</p>
</blockquote>
<p>A： 这个不能，不过你可以自己实现一个sideca在, 下发告警文件以后，让Prometheus Reload一次。</p>
<blockquote>
<p>Q：请问部署多套Prometheus Server，这些不同实例间的数据会重复吗？还是每个Prometheus只管理不同的服务的数据收集？</p>
</blockquote>
<p>A：如果在一个主机上运行几个Node Exporter那数据肯定会重复，这个应该从部署结构上去考虑。</p>
<blockquote>
<p>Q： 请问”再有上层Prometheus Server实现对数据的汇聚。”是表示该Prometheus会对下层Prometheus进行数据收集吗？使用什么接口？</p>
</blockquote>
<p>A： 请参考<a href="https://prometheus.io/docs/prometheus/latest/federation/" target="_blank" rel="noopener">Prometheus Fedreation</a>，这里主要是指由一部分Prometheus实例负责采集任务，然后Global的Prometheus汇集数据，并对外提供查询接口。 减少Global Prometheus的压力。</p>
<blockquote>
<p>Q：能否有集群方案分享一下？</p>
</blockquote>
<p>A： 请参考 <a href="https://github.com/yunlzheng/prometheus-book/blob/master/ha/READMD.md" target="_blank" rel="noopener">https://github.com/yunlzheng/prometheus-book</a>。</p>
<blockquote>
<p>Q：多个Prometheus监控方案数据能否共享？怎么持久化数据？</p>
</blockquote>
<p>A：同上，请参考 <a href="https://github.com/yunlzheng/prometheus-book/blob/master/ha/READMD.md" target="_blank" rel="noopener">https://github.com/yunlzheng/prometheus-book</a>。</p>
<blockquote>
<p>Q：Prometheus怎么做告警聚合？</p>
</blockquote>
<p>A： 不过如果是多个Prometheus的告警的数据的话，是可以都发送到一个Alertmanager（单实例或者集群）然后再统一处理。Alertmanager可以根据告警的标签，将多个告警合并成一个通知。</p>
<blockquote>
<p>Q：两台Prometheus server 可否用Keepalived？</p>
</blockquote>
<p>A： 直接负载均衡就可以了，对于Prometheus而言，实例之间本身并没有任何的直接关系。</p>
<blockquote>
<p>Q：告警通知支持脚本吗？</p>
</blockquote>
<p>A：Alertmanger对接webhook，通过这个可以自己扩展。</p>
<blockquote>
<p>Q：咨询下在传统服务器上安装node exporter后，怎么才能做到被Prometheus自动感知？每增加一台服务器安装node exporter后，再修改Prometheus配置文件，这样太不方便了。有什么自动注册方案吗？</p>
</blockquote>
<p>A：使用服务发现的能力，file_sd_config和consul_sd_config应该都能解决你的问题。</p>
<blockquote>
<p>Q：有个问题Prometheus是如何监控域名的？Zabbix可以监控域名，Prometheus不知道可不可以？</p>
</blockquote>
<p>A： 上面分享的Blackbox exporter就是做这个的。</p>
<hr>
<h3 id="2018-05-13：Kubernetes网络安全之访问控制技术实践"><a href="#2018-05-13：Kubernetes网络安全之访问控制技术实践" class="headerlink" title="2018-05-13：Kubernetes网络安全之访问控制技术实践"></a>2018-05-13：Kubernetes网络安全之访问控制技术实践</h3><blockquote>
<p>Q：根据<a href="http://cmgs.me/life/docker-network-cloud" target="_blank" rel="noopener">docker-network-cloud</a>的测试，Weave网络方案在性能上比其他方案差很多，这是真的吗？</p>
</blockquote>
<p>A：该文章测试的时候并未开启fast-data-path，经过我们的测试，在fast-data-path开启的情况下，还是很可观的。况且这个测试到今天已经过去了2年时间，Weave社区一直以来还是很活跃的，相信未来只会更好。</p>
<blockquote>
<p>Q：请问针对Azure和AWS在网络方面有没有遇到什么坑？好像前面只看到Aliyun的。</p>
</blockquote>
<p>A：AWS有个”源/目标地址检查”，华为云也有类似功能，如果在你的网络设计中云主机出来或进去的IP与注册的云主机IP不符，则需要把它关掉，另外如果不关”源/目标”地检查，也无法把目标主机设置成路由的next-hop；Azure主要就是默认动态公网IP，需要调整成固定IP。另外要特别注意主机间copy数据的流量费。 AWS上设置Kubernetes for Windows确实大费周折，我们当时和Kubernetes社区的Windows AIG的人一起搞了个方案，比较复杂。</p>
<blockquote>
<p>Q：有没有什么办法为每个命名空间设置一个全局的NetworkPolicy，还是说必须要先创建命名空间才能定义NetworkPolicy（希望是就像ClusterRoleBinding一样）？</p>
</blockquote>
<p>A：至少现在还不可以，一般来说这不应该是普遍的需求，因为每个应用在一个Namespace下，而每个应用的的访问控制策略不大可能是相同的。从另一个方面看，以Kubernetes社区的风格，任何普遍的需求最终都是会被实现的，而且速度很快。</p>
<hr>
<h3 id="2018-05-09：TalkingData的Spark-On-Kubernetes实践"><a href="#2018-05-09：TalkingData的Spark-On-Kubernetes实践" class="headerlink" title="2018-05-09：TalkingData的Spark On Kubernetes实践"></a>2018-05-09：TalkingData的Spark On Kubernetes实践</h3><blockquote>
<p>Q：我想问权限方面的问题，前面有看到一个提交作业的例子是spark－summit –files hdfs://host:port/path/to/file1，即用Spark处理HDFS上的数据，出于数据安全的考虑，HDFS一般会开启权限认证，用户在kerberos上做认证，用同一个身份信息访问Spark和HDFS。对于Spark on Kubernetes 这样一个方案，是如何认证并与HDFS结合的呢？</p>
</blockquote>
<p>A：老实说，我们原生的Spark集群也还是基于POSIX，并没有使用kerberos。不过我认为一个可行的结合方案是使用Kubernetes的webhook，在作业提交时，和kerberos交互换取身份验证信息。具体可参考：<a href="https://kubernetes.io/docs/admin/authorization/webhook/" target="_blank" rel="noopener">https://kubernetes.io/docs/hook/</a>。</p>
<blockquote>
<p>Q：为什么使用node label进行资源隔离，而不使用ResourceQuota对多租户进行资源隔离？</p>
</blockquote>
<p>A：由于我们很多大数据计算作业对SLA有很高的要求，并且Docker实际上对很多应用的资源限制都支持的不好。所以我们前期为了稳妥，还是对计算资源进行了物理隔离。</p>
<blockquote>
<p>Q：除了日志无法聚合外，每次查看Driver UI也是个问题。比如当我跑的程序较多时怎么有效地管理这些completed driver pod？</p>
</blockquote>
<p>A：是的，Spark On Kubernetes还缺少应用管理的功能。不过这个功能已经列在官方的todo list里。</p>
<blockquote>
<p>Q：比如flannel是把flannel参数传给Docker，一种用CNI插件，他们有何差别？</p>
</blockquote>
<p>A：实际上CNI是Kubernetes的标准网络接口，而flannel是实现Pod间通信的网络插件。CNI中有两类插件：一个是ipam，一个是network plugins。flannel属于后者，是可以纳入CNI管理的。</p>
<blockquote>
<p>Q：这里的多租户隔离，只提到任务执行过程的调度，那对于不同租户的任务提交，状态监控，结果呈现如何实现隔离的？</p>
</blockquote>
<p>A：不同的租户对应不同的Kubernetes namespace，所以自然实现了任务提交和状态监控的隔离。至于计算结果，我们以往是单纯用hdfs path做隔离。我们目前内部有大数据平台，那里真正实现了多租户。</p>
<blockquote>
<p>Q：Spark On Kubernetes这种方式为开发人员增加了难度，不像其他的集群方案，开发人员除了要会 Spark还要会Kubernetes，请问怎么推？</p>
</blockquote>
<p>A：实际上Spark On Kubernetes对大数据开发人员是透明的，任务的提交方式并没有改变，只是加了一些额外的option。并且我们上层是有统一的大数据平台，进行作业提交。</p>
<blockquote>
<p>Q：在使用HDFS存储资源下，如果不使用Spark的数据本地性，大量数据之间的传输，map和reduce操作是否会影响Spark的计算性能呢？</p>
</blockquote>
<p>A：个人认为肯定会有影响，因为每次从HDFS读取，会带来巨大的网络流量。但是我本身对Spark的数据本地性没有什么研究。后期我们计划将HDFS和Kubernetes混部，将数据尽量靠近计算节点，不知道这种方式能否缓解这个问题。同时，我们还可以使用Spark on Kubernetes的external-shuffle-service，从而使用hostpath volume将shuffle和executor pods打通。</p>
<blockquote>
<p>Q：Spark会作为哪种资源部署方式部署？Deployment还是StatefulSet？或者其他？Spark在生产环境上部署有需要什么资源配置？能否分享下TalkingData的生产环境是如何分配Spark资源的？</p>
</blockquote>
<p>A：Spark On Kubernetes实际就是创建了Spark driver headless service，然后创建Spark driver pod，最后由driver创建executors pods。上述分享中我也提到了，目前我们还是以物理机作为spark资源分配的单位。</p>
<blockquote>
<p>Q：Yarn vs Kubernetes优缺点?</p>
</blockquote>
<p>A：我们以前的Spark就是采用Spark On Yarn的方式，不过我对Yarn不是非常了解。之所以采用Kubernetes是因为，我们想统一底层的资源调度平台。但是Yarn目前还是和Hadoop生态强耦合的。</p>
<hr>
<h3 id="2018-04-24：Helm：强大的Kubernetes包管理工具"><a href="#2018-04-24：Helm：强大的Kubernetes包管理工具" class="headerlink" title="2018-04-24：Helm：强大的Kubernetes包管理工具"></a>2018-04-24：Helm：强大的Kubernetes包管理工具</h3><blockquote>
<p>Q：Helm结合CD有什么好的建议吗？</p>
</blockquote>
<p>A：采用Helm可以把零散的Kubernetes应用配置文件作为一个Chart管理，Chart源码可以和源代码一起放到Git库中管理。Helm还简了在CI/CD Pipeline的软件部署流程。通过把Chart参数化，可以在测试环境和生产环境可以采用不同的Chart参数配置。</p>
<blockquote>
<p>Q：请问下多环境（test、staging、production）的业务配置如何管理呢？通过Heml打包ConfigMap吗，比如配置文件更新，也要重新打Chart包吗？谢谢，这块我比较乱。</p>
</blockquote>
<p>A：Chart是支持参数替换的，可以把业务配置相关的参数设置为模板变量。使用Helm install Chart的时候可以指定一个参数值文件，这样就可以把业务参数从Chart中剥离了。例子：helm install –values=myvals.yaml wordpress。</p>
<blockquote>
<p>Q：Helm能解决服务依赖吗？</p>
</blockquote>
<p>A：可以的，在Chart可以通过requirements.yaml声明对其他Chart的依赖关系。如下面声明表明Chart依赖Apache和MySQL这两个第三方Chart。</p>
<blockquote>
<p>Q：Chart的reversion可以自定义吗，比如跟Git的tag？</p>
</blockquote>
<p>A：这位朋友应该是把Chart的version和Release的reversion搞混了，呵呵。 Chart是没有reversion的，Chart部署的一个实例（Release）才有Reversion，Reversion是Release被更新后自动生成的。</p>
<blockquote>
<p>Q：这个简单例子并没有看出Helm相比Kubectl有哪些优势，可以简要说一下吗？</p>
</blockquote>
<p>A：Helm将Kubernetes应用作为一个软件包整体管理，例如一个应用可能有前端服务器，后端服务器，数据库，这样会涉及多个Kubernetes部署配置文件，Helm就整体管理了。另外Helm还提供了软件包版本，一键安装、升级、回退。Kubectl和Helm就好比你手工下载安装一个应用 和使用apt-get安装一个应用的区别。</p>
<blockquote>
<p>Q：如何在Helm install时指定命名空间？</p>
</blockquote>
<p>A：<code>helm install local/testapi-chart --name testapi --namespace mynamespace</code>。</p>
<p>以上内容根据2018年4月24日晚微信群分享内容整理。</p>
<hr>
<h3 id="2018-04-17：DBaaS在金融生产环境的落地实践"><a href="#2018-04-17：DBaaS在金融生产环境的落地实践" class="headerlink" title="2018-04-17：DBaaS在金融生产环境的落地实践"></a>2018-04-17：DBaaS在金融生产环境的落地实践</h3><blockquote>
<p>Q：请问是采取什么策略升级这些数据库类型的服务？升级过程有宕机时间吗？如果没有，会有双写问题吗？</p>
</blockquote>
<p>A：在设计中是升级操作就是更新容器镜像。更新策略会根据数据库的高可用结构进行摇摆升级。</p>
<blockquote>
<p>Q：具体是实现方式是怎样，有没有用到StatefulSet，或者StatefulSet的区别？</p>
</blockquote>
<p>A：没有用到StatefulSet，目前我们构建了一个名为服务对象，来管理服务的。应该说我们服务对象比service更复杂，可以理解为是由多个不同类型的Pod组成的。</p>
<blockquote>
<p>Q：请问一下你们的binlog多长时间过期，有用什么持久化的方式存储吗？</p>
</blockquote>
<p>A：我们在封装容器镜像时，针对不同服务镜像有外围的配套脚本。类似于Kubernetes中sidecat的实现。然后通过定期调用方式备份binlog到备份存储。并且清理备份过的binlog。</p>
<blockquote>
<p>Q：还有关于中间件和高可用的选择，我们用MaxScale和MHA，但是并不是非常稳定？</p>
</blockquote>
<p>A：的确，我们在设计DBaaS也考虑到了，由于目前在MySQL中间件和高可用套件没有一个很好的开源产品，所以很难说你必须用哪个方案实现。所以我们在开发中就将这样的需求设计为灵活的服务架构定义，我们平台支持不同类型MySQL高可用方案和中间件方案。我们在中国银联是自己开发的高可用中间件方案，通过高可用组件发现故障进行隔离，使用Proxy组件进行数据路由，使用MySQL做数据复制。在我们设计中，可定制不同服务架构来进行服务的管理。</p>
<blockquote>
<p>Q：请问在这套平台里面支持比如说，前端可以让用户选择数据库运行的方式（单机）（还是读写分离、主从架构），这个是自动化配置的吗？这个过程是提前构建的容器镜像对吗？</p>
</blockquote>
<p>A：数据库容器镜像是相同的，单机、主从、读写分离等不同服务架构会生成相应的配置文件和启动项，管理逻辑。整体管理会使用定义服务架构配置信息进行自动解析产生相对应的管理操作。</p>
<blockquote>
<p>Q：单元、子服务、服务的理解还是比较抽象，有更易理解的例子吗？</p>
</blockquote>
<p>A：单元相当于一个我们自己构建的Pod，但不同于Pod。单元只会包换一个容器。子服务内是多个相同类型的单元，这样单元就可以部署在不同物理机上，并且完成数据库的复制关系。服务是多个类型的子服务的集合，服务内的子服务会有关联关系，比如一个完整的Redis可以有一组三个sentinel组成的子服务 + 一组多Redis Proxy的子服务 + 多组主从复制的Reids。同样的类型甚至可以映射到TiDB上，可以有一组三个TiDB + 一组三个PD + 一组五个TiKV。</p>
<blockquote>
<p>Q：如何理解数据库应用拆分和容器背道而驰？</p>
</blockquote>
<p>A：在容器开始阶段，大家会有共同的认识就是容器只适合运行无状态服务。直到大家对容器需求越来越多，有了Petset，有了StatefulSet，甚至有了MySQL Operater。但回归到容器本质还是为统一运维标准，快速灵活的管理资源。但是有状态服务天生就是重的，需要使用继承式的方式进行管理。但为了将有状态服务放到容器，享受容器的优势，就必须进行计算、存储、网络这些关键资源的分离。</p>
<blockquote>
<p>Q：请问你们的平台是用什么语言写的，有用到链路跟踪吗？</p>
</blockquote>
<p>A：我们平台全部组件都是用Golang写的。目前链路跟踪还没有，我们主要是通过我们的自研的监控平台，获取监控数据，监控物理机，容器，和容器内服务的信息，进行高可用的管理，也正在和人工智能公司合作，对运维数据进行分析，进行故障智能分析。</p>
<p>以上内容根据2018年4月17日晚微信群分享内容整理。</p>
<p>分享人<strong>鲍琳，富麦科技产品架构师，中国银联DBaaS项目架构师</strong>。</p>
<hr>
<h3 id="2018-04-16：Kubernetes-on-DC-OS最佳实践"><a href="#2018-04-16：Kubernetes-on-DC-OS最佳实践" class="headerlink" title="2018-04-16：Kubernetes on DC/OS最佳实践"></a>2018-04-16：Kubernetes on DC/OS最佳实践</h3><blockquote>
<p>Q：目前有公司落地这套方案上生产吗？ 在AWS是否实践过这个方案？</p>
</blockquote>
<p>A：Kubernetes on DC/OS是去年九月份官方由Mesosphere支持，经过半年的迭代开发，版本已经GA。目前国外的案例较多一些，国内的中国联通与中国石化正在尝试使用，国内的中国联通希望结合着Fabric8一起来使用，中石化希望用来运行微服务。目前AWS Marketplace支持DC/OS，国外很多用户也在用AWS构建混合云方案，Kubernetes on DC/OS屏蔽了底层，所以只要DC/OS运行在AWS上，Kubernetes就没有问题。</p>
<blockquote>
<p>Q：Kubelet、Kube-proxy、CoreDNS是一一个Pod中的三个容器运行在Agent节点上？还是以三个独立的UCR容器运行在Agent上？</p>
</blockquote>
<p>A：是通过三个UCR独立的容器运行在同一个Mesos Agent上。</p>
<blockquote>
<p>Q: 进来的晚了，那个图形管理控制台叫什么名字？</p>
</blockquote>
<p>A：Kube-dashboard，是Kubernetes的一个add-on组件。</p>
<blockquote>
<p>Q：DC/OS全称是什么？物理机跑虚拟机，虚拟机跑DC/OS，DC/OS又嵌套容器会不会无止境的架构，越来越复杂？</p>
</blockquote>
<p>A：全称就是DC/OS，也称Datacenter Operating System，数据中心操作系统。不会无止境的，UCR官方支持嵌套三十二层，但是我们容器层面一般只嵌套一层，而且容器与虚拟机最大的不同就是不会造成OS的开销，所以多几层嵌套问题也不大。</p>
<blockquote>
<p>Q：如果同一个集群内部的其他应用没有和Kubernetes在一个VXLAN里面，他们如何通讯，可以通过VIP吗？</p>
</blockquote>
<p>A：需要通过负载均衡、Node port或Ingress的方式，不久之后DC/OS的服务会和Kubernetes的服务全面融合。</p>
<blockquote>
<p>Q：很高兴能看到关于Mesos的分享，目前发现Mesos越来越被边缘化的趋势，比方说Cassandra Framework已经在GitHub上标记为过时了，我的问题是DC/OS以后会是Mesos主流的部署方式吗？用Mesos如果要使用Framework的话是不是要自己去封装？</p>
</blockquote>
<p>A：不能说被边缘化，很多大型互联网厂商都是低调的在使用，毕竟技术定位还是不同，而且Mesos确实在资源管理方面有其独特的优势。而且Cassandra虽然在GitHub上过时了，但是在Mesosphere内部从未过时，版本更新的很快，还可以无缝迁移。DC/OS的核心基于Mesos，这个不会变，但是支持Kubernetes是我们的重中之中，这个也不会变。DC/OS的Framework目前已经好几十种，Mesosphere也在不断地扩大生态，感兴趣可以到官方Universe上查看，那里详细地例举了Framework以及不同的版本号。</p>
<blockquote>
<p>Q：Server Agent的高可用，以及它们任务调度和Framework上的容器调度，任务调度有关系吗？</p>
</blockquote>
<p>A：Server Agent，您是指Mesos Agent吗？DC/OS 与VMware等虚拟化平台在某些方面有类似的功能，比如说，若Agent节点出现故障，DC/OS上的Framework会将task自动重启，或者在其他主机重启，对于有状态服务，建议使用共享存储方案。</p>
<blockquote>
<p>Q：如果同一个集群内的其他应用和Kubernetes不在一个VXLAN中，他们之间可以怎样通讯？有什么比较好的解决方案？</p>
</blockquote>
<p>A：若DC/OS的服务与Kubernetes不在同一个VXLAN上，目前就需要使用Kubernetes的 NODE IP，Ingress或则LB，这个和开源Kubernetes使用方式一致。当前的Kubernetes内的服务还只能处在一个flat network内，但是可以集成第三方Plugin，这个和DC/OS关系不大，用户可自行选择。</p>
<blockquote>
<p>Q：实际使用中Kafka、Elastic组件会出现集群不稳定情况，比如Kafka起三个broker，死活启动不了三个的情况，有好的解决办法吗？补充，因为是Framework的方式感觉不如Docker好管理。</p>
</blockquote>
<p>A：起不来的原因有很多，但是我很少遇见一直起不来，有可能是单节点资源不够，有可能是网络原因导致一些镜像或artifacts fetch不下来或者是节点数量不够，但是Framework与Docker的定位毕竟不同，也不属于一个技术。这个我们可以私下交流，我可以帮助您解决一些部署服务的问题。</p>
<blockquote>
<p>Q：刚才讲的节点规划，多区域管理是不是说的是企业版的功能？</p>
</blockquote>
<p>A：这个是DC/OS 1.11的新功能，多区域，同时Framework支持故障感知。但是是不是只有企业版支持，我需要查看一下，您也可以到DC/OS社区网站查看。</p>
<blockquote>
<p>Q：直接用Mesos可以部署DC/OS点Framework吗？</p>
</blockquote>
<p>A：可以，只不过操作起来没那么容易，需要一定的专业知识。毕竟Framework就是基于Mesos开发而成，很多互联网厂商也是仅用了Mesos，但是自己开发了很多Framework，既满足自己的业务需求，也为了操作简便。</p>
<blockquote>
<p>Q：DC/OS社区版跟企业版有多大的差异？</p>
</blockquote>
<p>A：当前的差异主要体现在安全、多租户、Edge-LB等几个方面，其它方面差异不大。</p>
<blockquote>
<p>Q：既然Marathon有容器编排功能，为何要弃Marathon，而用Kubernetes，增加体系复杂性，我的问题是，这只是为了满足用户偏好还是确实有设计或性能优势？</p>
</blockquote>
<p>A：没有嫌弃不用，Kubernetes的Framework不就是Marathon创建的吗？而且Marathon与Kubernetes的运行机制也不太一样，各有各的优势。只是因为Kubemetes在容器编排方面确实很优秀，而且生态很好，因此为客户提供更多的选择。这个绝对不是为了满足用户偏好，不然公司不会投入这么多，大家每天都在群里面讨论如何优化性能，提供差异化的服务。从发布到现在仅仅六个月，但是方便的话可以体验一下，确实在管理和运维上有很多优势。而且从Roadmap上看未来在性能和安全上会有很多新的提升。</p>
<blockquote>
<p>Q：为什么不直接用Kubernetes就好了呢？引入Mesos一套技术栈，投入和产出相比如何？</p>
</blockquote>
<p>A：还是分享时说的，Mesos在管理分布式系统上有独特的优势，您可以体验一下，在DC/OS安装Spark、HDFS、Cassandra、Kafka等，再试着用Kubernetes上安装一下，就解释的通了。</p>
<hr>
<h3 id="2018-04-10：扇贝网微服务编排和治理实践"><a href="#2018-04-10：扇贝网微服务编排和治理实践" class="headerlink" title="2018-04-10：扇贝网微服务编排和治理实践"></a>2018-04-10：扇贝网微服务编排和治理实践</h3><blockquote>
<p>Q：Prometheus 只采集 Kubernetes 集群的指标数据，那非 Kubernetes 的指标数据用什么采集？</p>
</blockquote>
<p>A：都是 Prometheus，应用是可以装 Prometheus 的client，暴露自己的metrics的，然后 Redis 什么的也都有exporter。</p>
<blockquote>
<p>Q：请问下日志如果都落到 stdout的话，会不会造成格式不一致，从而导致收集和归档困难？比如说业务日志和中间件日志都打到stdout，在 Filebeat 或者 Logstash内是怎么处理的？另外容器日志定期删除的策略是什么？</p>
</blockquote>
<p>A：这是个好问题，需要分拣的日志会在 message 的开头做特定的标记。例如[DATABEAT] 表示打点数据。ES 有很多工具可以做定期 archive 的，策略比如保留多少天，多少月，根据不同的数据的策略不同。</p>
<blockquote>
<p>Q：Envoy 对性能的损耗有多大，自身的性能消耗有多大？</p>
</blockquote>
<p>A：Envoy 是有性能损耗的，因为 API 的平均响应时间差不多在 100-150 ms，同时相比其带来的好处，我们认为这些损耗是值得的，所以我们具体并没有测算。</p>
<blockquote>
<p>Q：gRPC 做了服务注册吗，gRPC 新增减少字段兼容性如何处理的？</p>
</blockquote>
<p>A：服务注册/发现是基于 Kubernetes 和我们写的 Kubernetes Endpoint 到Envoy eds 的转化服务做的。</p>
<blockquote>
<p>Q：Istio 和 Envoy 什么关系？</p>
</blockquote>
<p>A：Istio 包括一个控制面 + 数据面，Envoy 可以作为 Istio 的数据面的一个实现。</p>
<p>以上内容根据2018年4月10日晚微信群分享内容整理。</p>
<hr>
<h3 id="2018-03-27：Kubernetes官方集群部署工具kubeadm原理解析"><a href="#2018-03-27：Kubernetes官方集群部署工具kubeadm原理解析" class="headerlink" title="2018-03-27：Kubernetes官方集群部署工具kubeadm原理解析"></a>2018-03-27：Kubernetes官方集群部署工具kubeadm原理解析</h3><blockquote>
<p>Q：etcd的升级是怎么处理？</p>
</blockquote>
<p>A：etcd也可以由kubeadm进行管理，这种情况下，etcd的升级也就可以由kubeadm来进行了。可以参考分享中kubeadm upgrade plan中的提示。如果kubeadm配置为使用外部etcd，则需要自行进行etcd的升级。</p>
<blockquote>
<p>Q：你们使用的网络插件是？</p>
</blockquote>
<p>A：我们使用的是中兴通讯自研的网络插件Knitter，该插件可以原生支持多网络平面，适合NFV的场景。</p>
<blockquote>
<p>Q：kubeadm可以指定仓库地址，不然在国内就得先注入镜像，你可以试试。</p>
</blockquote>
<p>A：对的，在分享中关于雷区的说明中有提到可以为kubeadm指定可用的第三方镜像库，需要在启动参数中进行设置。</p>
<blockquote>
<p>Q：Dashboard、网络组件、日志这些组件是不是都需要自己再安装？这些安装过程有没有介绍文档？有没有办法通过kubeadm导出每个版本的镜像名字，这样可以通过GitHub和Docker Hub关联导出镜像。</p>
</blockquote>
<p>A：对于您提到的其他组件，都是需要自己再安装的，直接按各个组件官方的安装文档进行安装即可。kubeadm使用的master组件镜像名字一般为类似这样的名称：gcr.io/google_containers/kube-apiserver-amd64:v1.9.6。</p>
<blockquote>
<p>Q：一定要使用etcd吗，可以用其他的数据库代替吗？</p>
</blockquote>
<p>A：目前Kubernetes只支持使用etcd，在大约两年前，社区有关于支持Consul的讨论，不过后来不了了之。</p>
<blockquote>
<p>Q：etcd默认有做故障恢复吗，如果没有，有没有好的方案？</p>
</blockquote>
<p>A：由kubeadm启动的etcd应该是没有做故障恢复，个人理解可以通过建立外部etcd高可用集群的方式达到目的。</p>
<blockquote>
<p>Q：knitter能描述一下吗，跟Calico、Flannel有什么区别呢？你们有测试过多高的负载？</p>
</blockquote>
<p>A：knitter已经开源，可以在其项目地址查看其说明：<a href="https://github.com/ZTE/Knitter" target="_blank" rel="noopener">ZTE/Knitter</a>。不过由于刚刚开源不久，上面的文档还不是特别完善，敬请保持关注。</p>
<blockquote>
<p>Q：CA证书过期怎么处理？</p>
</blockquote>
<p>A：kubeadm创建的CA证书默认的有效期是10年，一般情况下不需要考虑CA证书过期问题。不过apiserver的证书有效期默认的是1年，这个需要考虑过期问题。我在1.9中提过一个PR，在升级集群的时候，如果发现apiserver的证书到期时间小于180天，会重新生成其证书。</p>
<blockquote>
<p>Q：我看过kubelet默认有主动注册的选项，如果提供证书密钥应该就不需要使用kubeadm join？</p>
</blockquote>
<p>A：是的，不过这个前提就是像你所提到的，需要它已经有相应的证书密钥，如果不使用kubeadm join的话，就需要手动去为它创建证书和密钥，可能还需要一些其他配置，过程比较繁琐。所以如果集群是由kubeadm来管理的话，还是建议使用kubeadm join来加入。</p>
<blockquote>
<p>Q：kubeadm join使用的token是不是有时效的？</p>
</blockquote>
<p>A：对，我记得这个时效应该是24小时，如果超过时效，可以使用kubeadm token create来重新生成一个token。</p>
<blockquote>
<p>Q：<code>kubectl get daemonset -o wide --all-namespaces</code>可以查到kube-apiserver-master的是self-hosting模式吗？</p>
</blockquote>
<p>A：如果通过该命令可以查到，那应该就是了。kubeadm在这些DaemonSet的名字中统一加了”self-hosted-“前缀。</p>
<p>以上内容根据2018年3月27日晚微信群分享内容整理。</p>
<hr>
<h3 id="2018-03-24：新东方利用容器技术在用户自服务方面的探索"><a href="#2018-03-24：新东方利用容器技术在用户自服务方面的探索" class="headerlink" title="2018-03-24：新东方利用容器技术在用户自服务方面的探索"></a>2018-03-24：新东方利用容器技术在用户自服务方面的探索</h3><blockquote>
<p>Q：为什么不直接使用Kubernetes提供的编排方式？</p>
</blockquote>
<p>A：新东方的IT人员与业务人员比值是比较低的，因此在小团队下直接搞Kubernetes是个不现实的事情，小团队，项目时间紧 ，先解决”有”的问题，综合起来看最后选择了Rancher，我们的二期项目将基于Kubernetes。</p>
<blockquote>
<p>Q：混合云的话，网络组件用的哪个？</p>
</blockquote>
<p>A：用的Rancher 内置的VXLAN，现在部署的环境完全在私有云部分部署。</p>
<blockquote>
<p>Q：监控方案是什么？</p>
</blockquote>
<p>A：监控暂时使用的是Rancher社区内置的普罗米修斯，宿主机层面沿用了Zabbix，我们目前Zabbix监控非常完善了。普罗米修斯还在研究中。</p>
<blockquote>
<p>Q：请问为什么不直接用Helm？ 相关的包管理功能更加强大。</p>
</blockquote>
<p>A：确实Kubernetes和Helm更强大。 但是对于一个刚刚接触容器的团队直接搞Kubernetes的成本还是有些大。我们不可能让所有人等我们一年半年埋头搞，因此我们选择了Rancher，大家都会Docker，都知道docker-compose，稍微学一下就上手了。</p>
<blockquote>
<p>Q：请问Rancher在CI/CD方面是如何做的？</p>
</blockquote>
<p>A：CI/CD这部分，之前我们自己搞过Jenkins，后来Rancher出了Pipeline工具。Rancher Pipeline也是基于Jenkins，集成了GitLab和GitHub，并配置了UI，用户体验还不错。我们自己的镜像打包现在都切换到Pipeline了。Jenkins部分准备直接交给测试部门来搞，我们配合他们，因为他们搞Jenkins更专业。</p>
<hr>
<h3 id="2018-03-11：聊聊Docker监控那点事儿"><a href="#2018-03-11：聊聊Docker监控那点事儿" class="headerlink" title="2018-03-11：聊聊Docker监控那点事儿"></a>2018-03-11：聊聊Docker监控那点事儿</h3><blockquote>
<p>Q：既然当前已经存在很多指标监控方案，你们是基于什么考虑要自己写的？</p>
</blockquote>
<p>A：因为现有的方案都是独立的系统，我们的监控对象可不止容器，而且排查问题的时候可能还需要看宿主机的监控、网络设备的监控等等，我们需要把容器的集成进来；另外用开源的方案不好做定制化。</p>
<blockquote>
<p>Q：容器发生OOM时，计算的内存是包括Cache+RSS吗？生产环境经常会发生业务容器OOM，可以从那几个方面排查问题，并解决？</p>
</blockquote>
<p>A：是的，排查问题当然要基于监控，看是否是使用内存一直不释放，我们遇到的OOM一大部分都是应用本身有内存泄漏；这在使用虚拟机的时候没有暴露出来，在用Docker时候资源给得更少了就暴露出来了。</p>
<blockquote>
<p>Q：是否可以将Pod下所有容器汇总的指标作为Pod的性能指标呢？</p>
</blockquote>
<p>A：对于Kubernetes来说就更容易一些了，可以通过kubelet API server直接来获取的。</p>
<blockquote>
<p>Q：当遇到偶发的CPU throttled情况，是否意味着已经开始出现性能瓶颈？</p>
</blockquote>
<p>A：不是，CPU throttled是在一个period里面CPU的时间片到了限制触发的，如果是job类型的应用，是会偶发cpu throttled，这时候可能不需要关心。</p>
<blockquote>
<p>Q：现在针对容器的监控方案特别多，也基本上很完善。比如Telegraf采集、普罗米修斯采集等。想问下，你们那边现在的告警是怎么做的？</p>
</blockquote>
<p>A：告警现在我们更多地配置在应用上，这样反应地最直观。如果要在容器层面做的话，建议对持续的CPU throttling和mem failcnt做告警。</p>
<blockquote>
<p>Q：请问指标的存储用的是什么数据库？</p>
</blockquote>
<p>A：之前用的Elasticsearch，现在用的InfluxDB，自己包装实现了一套集群。</p>
<blockquote>
<p>Q：对于无状态的Java微服务容器，是否有必要进行监控？</p>
</blockquote>
<p>A：这个最好在应用层去监控，但是在排查问题的时候还是需要容器层面的指标数据。</p>
<blockquote>
<p>Q：其实监控本身并不是最终目的，监控是为了发现问题然后解决问题，对于Docker容器问题的定界定位有什么好的方案？以OOM为例，监控可能会触发一个内存高的告警，那么下一步该如何定界定问题根因呢？</p>
</blockquote>
<p>A：是的，这一般是开发者和Docker运维经常扯皮的地方；这个时候需要结构应用的监控来看，例如OOM来说，如果是Java应用就是看到heap的使用一直上升，那肯定是应用方去查问题了。</p>
<hr>
<h3 id="2018-02-03：基于Kubernetes的DevOps实践之路"><a href="#2018-02-03：基于Kubernetes的DevOps实践之路" class="headerlink" title="2018-02-03：基于Kubernetes的DevOps实践之路"></a>2018-02-03：基于Kubernetes的DevOps实践之路</h3><blockquote>
<p>Q：iSCSI挂载rbd到Windows Server的性能如何？是用tgt来实现吗？</p>
</blockquote>
<p>A：是的， 您可以查看这个文档<a href="https://github.com/Statemood/documents/blob/master/ceph/use-iscsi-to-windows.md" target="_blank" rel="noopener">use-iscsi-to-windows</a>。至于性能，目前存放了几TB的数据，只有网络是瓶颈（千兆）。</p>
<blockquote>
<p>Q：多套环境通过Kubernetes如何分割开的？</p>
</blockquote>
<p>A： 通过不同的namespace，前端Nginx代理通过不同环境监听不同IP实现。</p>
<hr>
<h3 id="2018-01-26：TensorFlow-on-Kubernetes的架构与实践"><a href="#2018-01-26：TensorFlow-on-Kubernetes的架构与实践" class="headerlink" title="2018-01-26：TensorFlow on Kubernetes的架构与实践"></a>2018-01-26：TensorFlow on Kubernetes的架构与实践</h3><blockquote>
<p>Q：Worker为什么不直接用Pod，而用的 Job？</p>
</blockquote>
<p>A：Kubernetes中是不建议直接使用Pod的，建议通过一个控制器（RS、RC、Deploy、StatefulSets、Job等）来创建和管理Pod。</p>
<blockquote>
<p>Q：我看训练的时候并没有指定数据集和训练参数等，是都放到训练脚本内了吗，还有训练集是放到Gluster，挂载到容器内吗，还是换存到本地？</p>
</blockquote>
<p>A：目前训练数据和参数都是在脚本里用户自己搞定，正在把这些放到Portal，提供”命令行参数自定义”的能力。目前我们的训练数据是从HDFS集群直接走网络读取，Kubernetes本身也没有HDFS的Volume Plugin。</p>
<blockquote>
<p>Q：请问PS的个数是用户指定还是根据Worker的数量来指派？</p>
</blockquote>
<p>A：PS和Worker数都是通过用户指定，但实际上都是用户根据自己的训练数据大小来计算的。</p>
<blockquote>
<p>Q：分布式训练的时候，Training data是如何分发到各个Worker节点的？Tensorflow API可以做到按节点数自动分发吗？</p>
</blockquote>
<p>A：各个Worker都是从HDFS集群读取训练数据加载到内存的。数据的分配都是用户自己在脚本种实现的。</p>
<hr>
<h3 id="2018-01-17：Kubernetes存储系统介绍及机制实现"><a href="#2018-01-17：Kubernetes存储系统介绍及机制实现" class="headerlink" title="2018-01-17：Kubernetes存储系统介绍及机制实现"></a>2018-01-17：Kubernetes存储系统介绍及机制实现</h3><blockquote>
<p>Q：Kubernetes和Cloud Foundry有什么区别，优势在什么地方？</p>
</blockquote>
<p>A：Cloud Foundry更像是Application PaaS，Kubernetes主要是Container PaaS。CF不会直接把container层暴露给用户，Kubernetes则不然，你可以直接访问container。个人觉得kubernetes的部署和使用更简单，更直接，操作起来也更方便。</p>
<blockquote>
<p>Q：请问对于Galera Cluster的集群存储如何设计存储方案，CSI有考虑有状态储存的解决方案吗？</p>
</blockquote>
<p>A：对于有状态服务，请使用StatefulSet来部署你的应用。Volume只是一个存储的地方。StatefulSet会负责给Pod设置顺序等等，保证是有序的，优雅的删除停止和扩展。</p>
<blockquote>
<p>Q：有没有对象存储，比如CephRGW，在Kubernetes集群中的使用案例，比如用户通过客户端上传、下载PVC中的数据之类的？</p>
</blockquote>
<p>A：有试过RGW来存储数据，但是性能不是很好，速度要慢很多。在Kubernetes集群中可以使用RGW来存储一些静态的文件，比如配置文件，Nginx静态html文件之类，用户也可以下载PV中的数据。不建议对RGW中的数据进行频繁的更改。</p>
<blockquote>
<p>Q：能否详细说下CSI？</p>
</blockquote>
<p>A：CSI在kubernetes v1.9才引入。这部分内容比较多，可以去看看<a href="https://github.com/container-storage-interface/spec" target="_blank" rel="noopener">CSI文档</a>，以及<a href="http://blog.kubernetes.io/2018/01/introducing-container-storage-interface.html" target="_blank" rel="noopener">Kubernetes官方的介绍</a>，以及 <a href="https://github.com/kubernetes/kubernetes/pull/54529" target="_blank" rel="noopener">这个feature实现代码</a>。</p>
<blockquote>
<p>Q：RBD用什么插件，有没有什么坑？</p>
</blockquote>
<p>A：需要在kubelet节点上安装<code>ceph-common</code>{.prettyprint}这个包，在volume mount的时候，会调用相关的命令。基本上没什么坑，RBD提供的volume还是很好使的。</p>
<blockquote>
<p>Q：存储这块IO性能下降大概多少呢，有实测过吗？</p>
</blockquote>
<p>A：存储的性能与Cluster的能力、存储的类型有很大关系。实测过RBD的IO性能，当然case by case，当时测出来的结果还是很不错的，相比较与CephFS、GlusterFS。</p>
<blockquote>
<p>Q：多个Pod共享一个 Nas，是否可行，需要注意什么？</p>
</blockquote>
<p>A：可行，但是需要注意Volume的读写权限，这个可以通过mount时候的PV的access mode进行设置，比如ReadWrite、ReadWriteOnce等等。</p>
<blockquote>
<p>Q：CSI和社区孵化的volume provisioner有什么区别？</p>
</blockquote>
<p>A：CSI的主要目的还是为了给容器存储定义一个统一的接口，方便进行定制化，以及新功能添加。社区孵化的volume provisioner，你指的应该是<a href="https://github.com/kubernetes-incubator/external-storage" target="_blank" rel="noopener">external-storage</a>这个项目吧，这个项目的主要目的是为了方便对in-tree的那些Plugin进行修改和定制，这样可以独立地进行更新。</p>
<blockquote>
<p>Q：请问你现在有把MySQL可以放进PV里面么？求介绍这方面的经验。</p>
</blockquote>
<p>A：如果只是单节点的MySQL，直接放进PV就好了，跟其它正常服务一样。对于多节点的MySQL Cluster，在部署的时候就需要注意了，建议部署成StatefulSet，有状态的服务。之前有试过用Galera Cluster For MySQL来部署集群，发现效果不是很好，尤其是在随意启停Pod的时候，Cluster的没办法自组成新的集群，新节点也无法加入集群。你可以再次试验下，确认一下。 后来使用MySQL Cluster CGE，效果很好，Cluster能够及时回复并重新组织起来。</p>
<p>以上内容根据2018年1月16日晚微信群分享内容整理。</p>
<p>分享人<strong>徐迪，Kubernetes社区Member，毕业于上海交通大学，有着四年的开源软件开发经验。曾任职于IBM从事Openstack的开发，对Kubernetes，Docker以及微服务架构有丰富的经验。目前在Arm主要从事开源社区的相关研发工作</strong>。</p>
<hr>
<h3 id="2018-01-10：一个可供参考的企业应用容器化实践案例"><a href="#2018-01-10：一个可供参考的企业应用容器化实践案例" class="headerlink" title="2018-01-10：一个可供参考的企业应用容器化实践案例"></a>2018-01-10：一个可供参考的企业应用容器化实践案例</h3><blockquote>
<p>Q：所有开发人员都是用一套OpenShift集群测试吗？CI/CD也是同一套环境吗？</p>
</blockquote>
<p>A：我们是按业务分的，原则上，一套业务线（一个业务部门）用一套系统，这样成本上也好分摊。</p>
<blockquote>
<p>Q：OpenShift也是用Go编写的？</p>
</blockquote>
<p>A：是的，OpenShift用的是源码级别的和Kubernetes的集成，不是通过client-go或者REST API的方式，所以我们可以看到，Kubernetes发型的版本总是比OpenShift的快1 到2个版本。</p>
<blockquote>
<p>Q：对于OpenShift比较适合多大规模的团队？</p>
</blockquote>
<p>A：这个怎么说呢，其实引入DevOps或者CI/CD的流程就是为了给企业减少人员成本，让有些能够自动化的东西通过计算机运行起来。所以因该是人员越少越好，但是人员如果少，就要求每个人的技术能里比较强，开源的东西往往用起来不难，但是真到出了问题的时候就需要看代码去解决了。所以如果人少的话，可能每个人就要求懂得就比较多一些。</p>
<blockquote>
<p>Q：router本身是否具备HAProxy？</p>
</blockquote>
<p>A：OpenShift的Router就是用HAProxy实现的，当然我现在用的是3.6.1的版本，我不知道以后会不会支持Nginx或者其他别的LB，因为我看到代码里已经有关于Nginx的相关配置了，但是没有激活。OpenShift使用HAProxy的大致流程就是通过一个Yaml或者jason文件，配置一条route信息，然后通过api-server持久化到etcd中，router的代码启动一个goroutine，去通过api-server watch etcd，然后根据配置信息和环境变量，通过haproxy-template模版，去生成 haproxy.conf，然后去动态reload。</p>
<blockquote>
<p>Q：OpenShift的project和Kubernetes的namespace是一对一的关系么？project可以设置资源配额么？怎么设的？</p>
</blockquote>
<p>A：是一对一关系，当然有一些namespace 是有一些特殊意义的，不建议在里面跑应用。project可以设置资源配额，具体怎么设置就比较复杂了，建议参考一下官方文档，简单的说就是可以根据CPU内存做资源的限定，这个和Kubernetes是一样的。</p>
<blockquote>
<p>Q：OpenShift中原生性能指标监控服务的Pod总挂有没有相应的解决办法？</p>
</blockquote>
<p>A：解决Pod总挂的问题就得具体问题具体分析了，我记得它做性能监控的那个Pod比较吃资源，其实可以对他进行一下限定，比如：oc env rc hawkular-cassandra-1 MAX_HEAP_SIZE=1024M -n openshift-infra。</p>
<blockquote>
<p>Q：OpenShift中的router默认情况下是跑在Pod里的，那么当service特别多，route规则也特别多的时候，如何解决router服务的性能问题的？</p>
</blockquote>
<p>A：这是一个好问题，但其实我觉得这个和HAProxy有很大的关系，跟在不在Pod中关系不大，因为router这个容器其实用的是主机网络，那么这个问题其实就转化成了如何提升HAProxy的性能，这种情况其实有很多可以参考的方案，比如前面在加一层LVS负载，或者用DNS做域名解析的时候进行一定的负载功能。</p>
<hr>
<h3 id="2017-12-26：分布式配置中心架构与实战"><a href="#2017-12-26：分布式配置中心架构与实战" class="headerlink" title="2017-12-26：分布式配置中心架构与实战"></a>2017-12-26：分布式配置中心架构与实战</h3><blockquote>
<p>Q：请问配置中心存储的是配置文件还是key-value?像数据库连接串之类的信息如何管理的？跟数据连接池怎么配合？</p>
</blockquote>
<p>A：是key-value的，存储在etcd集群上，服务可通过hawk-client拉取配置到服务本地生成本地的配置或直接导入到本地环境变量，这些配置随着服务启动就会生效。</p>
<blockquote>
<p>Q：为什么要自己开发一个配置中心，而不是直接使用Spring Cloud Config？</p>
</blockquote>
<p>A：其实很很简单，单纯的Spring Cloud Config没有办法充分地切合企业系统的生产需要。我这里有一个功能对比图，大家可以参考一下：</p>
<blockquote>
<p>Q：请问这个配置中心只能应用于Java语音吗？</p>
</blockquote>
<p>A：配置中心的代码是Java编写的，但是配置中心的使用方，即拉取配置的一方是不限制语言，因为配置拉取是基于http协议。</p>
<blockquote>
<p>Q：请问CI/CD流程控制是自己研发的还是用的开源方案？</p>
</blockquote>
<p>A：CI/CD持续集成，持续交互其实是一个很大的概念，我理解你想问的是Hawk的操作流程以及所使用的技术栈的问题，最初我们参考过其他的一些开源比如携程的Appolo，百度的Disconf等，结合他们的一些理念，我们又自己总结思考了自己的需求，对CI/CD的业务做出归纳，以达到简单直接的目标，技术方面，我们主要用到Spring Boot， Spring Cloud以及etcd等技术，其中Spring Cloud主要适用于服务注册发现，服务治理等方面。</p>
<blockquote>
<p>Q：我想问下，关于配置中心部署问题，第一个，不同环境或者不同集群，你们配置中心是怎么部署的，还有，一些基础组件配置和应用配置放在一个配置中心吗？</p>
</blockquote>
<p>A： 配置中心通过不同的存储集群，可以实现一个配置中心服务多个环境，但是原则上，建议测试，开发公用一个不熟而生产独立部署，配置中心的中心概念是基于微服务，所以从概念上说，我们的配置是生效于一个服务下的实例级别，而不是组件级别，每个实例下又分为不同的命名空间，命名空间可划分为：应用层，环境变量和自定义的组件，可由客户自定义，所以原则上涵盖了组件与服务的概念。</p>
<hr>
<h3 id="2017-12-25：在项目实践中，如何进行容器化改造和DevOps建设？"><a href="#2017-12-25：在项目实践中，如何进行容器化改造和DevOps建设？" class="headerlink" title="2017-12-25：在项目实践中，如何进行容器化改造和DevOps建设？"></a>2017-12-25：在项目实践中，如何进行容器化改造和DevOps建设？</h3><blockquote>
<p>Q：您确定你们是FTP做文件管理？</p>
</blockquote>
<p>A：FTP只有用于存放活动宣传的图片，在容器环境中，需要把这些图片同步到stN容器中。</p>
<blockquote>
<p>Q：用Jenkins测试完了以后如何发布到生产环境的？</p>
</blockquote>
<p>A：由于这个项目的客户是开发和测试环境中一个容器管理平台，生产环境一个容器管理平台，开发测试写成，生成生产环境的镜像tag；由于生产环境的应用stack更新，需要通过手动触发，进行更新。</p>
<blockquote>
<p>Q：请问，日志的话，是不是每个服务都有规定格式？</p>
</blockquote>
<p>A：做应用容器化改造，需要进行应用日志的收集，这样需要规定应用日志输出的格式和目录。这样方便进行统一的日志收集与管理。</p>
<blockquote>
<p>Q：这个环境支持应用一键部署到公有云嘛？</p>
</blockquote>
<p>A：如果使用PaaS云混合云部署，是可以支持一键部署到公有云环境中。</p>
<blockquote>
<p>Q： 哪些类型的应用和系统，不适合容器化呢？</p>
</blockquote>
<p>A：有一些对IO要求太高的应用或系统，不太适合容器化。</p>
<blockquote>
<p>Q：请问数据库是怎样部署的，有进行容器化吗？</p>
</blockquote>
<p>A：此客户项目实施中，使用MySQL和MongoDB两种数据库。其中MongoDB集群部署，做了容器化改造；另外，MySQL数据库使用阿里云的RDS数据库，没有容器化。阿里云平台提供服务库服务和备份，快照。</p>
<blockquote>
<p>Q：AKF原则可以详细介绍嘛？</p>
</blockquote>
<p>A：AKF扩展立方体（参考《The Art of Scalability》）技术专家抽象总结的应用扩展的三个维度： Y 轴 ：是功能分解，将不同职能的模块分成不同的服务。从y轴这个方向扩展，才能将巨型应用分解为一组不同的服务，例如订单管理中心、客户信息管理中心、商品管理中心、支付系统等等。 详细请参考《The Art of Scalability》</p>
<blockquote>
<p>Q：如何切换开发、测试、生产环境的参数配置？</p>
</blockquote>
<p>A： 如果您有三个Environment环境，开发、测试、生产环境需求；我们可以创建三个环境分别如下：DEV（开发环境）、TEST（测试环境）、PRO（生产环境），每个环境下面的应用栈与其它环境想到隔离，互不影响；如果需要切换管理，只需要在管理平台中进行ENV环境的切换，即可对相应的环境与应用栈进行管理。</p>
<blockquote>
<p>Q：请问目前监控使用的是什么方案？</p>
</blockquote>
<p>A：容器管理平台本身是基于cAdvisor可以监控实时容器指标CPU、Menory、I/O、网络资源资源。同时，它也可以部署使用其它监控应用栈。例如：Prometheus、Grafana、Datadog等。</p>
<blockquote>
<p>Q：代码怎么部署到容器中，是通过外部硬盘挂载吗，是不是每次都重新生成新的镜像？</p>
</blockquote>
<p>A：容器本身是生命周期比较短暂，而且会根据策略自动迁移。一般不会把代码代码通过外部挂载到容器。通常做法如果代码变动或更新，重新build镜像。可以根据自己定义是时间段进行build镜像。</p>
<blockquote>
<p>Q：对于数据库集群，现阶段是怎么运维的，有案例？同时对于数据安全是怎么保证的？数据的备份采用什么方式？</p>
</blockquote>
<p>A：针对数据库集群的运维，这个是一个针对性很强的专业问题；数据库的备份/还原、监控、故障处理、性能优化、升级/迁移、健康检查，用户反馈数据库问题等等，这些都需要专门的DBA处理。数据库运维总原则：第一：能不给数据库做的事情不要给数据库，数据库只做数据容器；第二：对于数据库的变更必须有记录，可以回滚。 数据库的安全至关重要，有相应的权限管理，以最低粒度的控制权限。所有开发人员权限粒度到表一级，数据库管理员和系统管理员权限粒度到库一级等等。不同的数据库以及部署方式不一样，要求的备份也有差别。以MySQL为例，如果搭建主从架构，就要通过binlog文件同步复制主库的数据。另外，通过系统计划任务执行mysqldump做周期性全备份；还有，物理备份，直接拷贝数据文件、参数文件、日志文件。最后，专门的备份工具如：mysqlhotcopy、ibbackup等。</p>
<hr>
<h3 id="2017-12-22：JDOS-2-0：Kubernetes的工业级实践"><a href="#2017-12-22：JDOS-2-0：Kubernetes的工业级实践" class="headerlink" title="2017-12-22：JDOS 2.0：Kubernetes的工业级实践"></a>2017-12-22：JDOS 2.0：Kubernetes的工业级实践</h3><blockquote>
<p>Q：请问Skynet网络基于OpenStack Neutron吗？</p>
</blockquote>
<p>A：我们的Kubernetes的网络是分为两套。最开始我们使用的是Neutron，因为我们的JDOS 1.0已经稳定运行了多年。今年开始，我们很多数据中心采用的是BGP的网络。可以参考Calico的实现。</p>
<blockquote>
<p>Q：LVM的磁盘IO限制是怎么做的？</p>
</blockquote>
<p>A：这是通过改造kube-apiserver以及kubelet，把磁盘限制的指标也作为一种资源，底层最终使用Cgroup实现的。</p>
<blockquote>
<p>Q：巡检工具是只检查不修复吗？</p>
</blockquote>
<p>A：是的，巡检的目的就只是检查并通知，一般有问题会找运维修复。</p>
<blockquote>
<p>Q：使用的什么Docker storage driver？</p>
</blockquote>
<p>A：我们JDOS 1.0是使用的自研的Vdisk，2.0使用的是DM。</p>
<blockquote>
<p>Q：为了提升Pod更新速度，我们对容器删除的流程进行了优化，将CNI接口的调用提前到了stop容器，没太明白这里。</p>
</blockquote>
<p>A：删除容器的流程原本是stop app容器-&gt;调用CNI-&gt;stop sandbox容器。因为在实际中，stop app容器时间会较长。因此我们将其调整为调用CNI-&gt;stop app容器-&gt;stop sandbox容器。这样可以更快释放IP。</p>
<blockquote>
<p>Q：有用PV PVC吗？底层存储多的什么技术？</p>
</blockquote>
<p>A：有用到PV PVC，底层存储使用的是我们自研的ContainerFS。目前已经开源在GitHub上，欢迎使用。</p>
<blockquote>
<p>Q：请问相同Service的不同Pod上的log，fm，pm怎么做汇总的？</p>
</blockquote>
<p>A：Pod的日志是在每个节点上，启动有daemonset的一个容器，负责收集该节点上的日志，并发送到消息队列予以汇总的。</p>
<blockquote>
<p>Q：能详细描述一下”gRPC的问题导致了apiserver的性能瓶颈”的具体内容吗？</p>
</blockquote>
<p>A：在1.6我们原来使用的单个apiserver在服务大概300个节点时，就会大量拒绝请求，出现409错误。后来我们查阅了社区的相关资料，发现是gRPC的问题，通过升级gRPC包，可以实现600以上节点无压力。</p>
<blockquote>
<p>Q：请问多IDC的场景你们是如何管理的？</p>
</blockquote>
<p>A：目前是分多个数据中心，每个数据中心再划分多个集群。控制单个集群规模，这样方便管理。但是镜像、配置、调度可以在不同数据中心、不同集群间通用。这样集群和数据中心对用户透明。</p>
<blockquote>
<p>Q：加固环节（包括etcd故障、apiserver全部失联、apiserver拒绝服务等等极端情况）上面列举的几种情况发生时会造成灾难性后果吗，Kubernetes集群的行为会怎样，有进行演练过不，这块可以细说一下吗？</p>
</blockquote>
<p>A：当然，如果未经过加固或者不能正常恢复etcd数据，还可能导致pod大量迁移或销毁，甚至整个集群节点压力增大，发生雪崩效应，最终整个集群崩溃。</p>
<blockquote>
<p>Q：Pod固定IP的使用场景是什么？有什么实际意义？</p>
</blockquote>
<p>A：呃，这个实际很多业务，特别是一些老业务，是无法做到完全无状态的。如果不能提供固定IP，那么他们的配置上线都会很麻烦。</p>
<blockquote>
<p>Q：请问有使用SR-IOV 或者DPDK的技术吗？如果目前没有，是有哪方面的考量，将来会考虑吗？**</p>
</blockquote>
<p>A： 有啊，可以参见我们的团队的分享：<a href="http://mp.weixin.qq.com/s/ZPDU66B_Cr1Zgb-k6t1zUA" target="_blank" rel="noopener">mp.weixin.qq.com/s/ZPDU66B_Cr1Zgb-k6t1zUA</a>。</p>
<blockquote>
<p>Q：请问系统开发完毕后，下一步有什么计划？进入维护优化阶段，优秀的设计开发人员下一步怎么玩？</p>
</blockquote>
<p>A：容器化，自动化这才是万里长征的第一步啊。我们已经在调度方面做了很多的工作，可以参看我们团队关于阿基米德的一些分享。集群自治与智能化，我们已经在路上了。欢迎大家一道来实践。未来我们也会同大家分享这其中的经验。</p>
<blockquote>
<p>Q：应用滚动升级，有无定制？还是采用Kubernetes默认机制？</p>
</blockquote>
<p>A：是我们自己定制的deployment，进行了适当的改造，可以支持暂停状态，比如说更新时，可以指定两个版本的Pod个数比例，中止在这个中间状态。</p>
<blockquote>
<p>Q：能否介绍一下对GPU支持这块？</p>
</blockquote>
<p>A：GPU我们的玩法其实很简单，就是一个容器一块卡，每个卡只分给一个容器。这样的好处是安全，分配效率高，利用率也比较高。</p>
<hr>
<h3 id="2017-12-16：东方国信基于Kubernetes构建容器云平台的实践和思考"><a href="#2017-12-16：东方国信基于Kubernetes构建容器云平台的实践和思考" class="headerlink" title="2017-12-16：东方国信基于Kubernetes构建容器云平台的实践和思考"></a>2017-12-16：东方国信基于Kubernetes构建容器云平台的实践和思考</h3><blockquote>
<p>Q：请问不用Jenkins，开发shera基于什么考虑？</p>
</blockquote>
<p>A：刚开时，我们也用了Jenkins，但是很难跟我们的多租户结合，所以我们就干脆自己开发一套了。</p>
<blockquote>
<p>Q：请问灰度发布如何实现的？</p>
</blockquote>
<p>A：灰度发布时通过一个service对应两个rc来实现，一个rc管理老的应用，一个rc管理新的应用。</p>
<blockquote>
<p>Q：Pinpoint是Tomcat启动时候加载的，不重启应用的情况下，如何控制Pinpoint开关？</p>
</blockquote>
<p>A：我们增加了环境变量，通过脚本判断环境变量，然后控制Tomcat启动。</p>
<blockquote>
<p>Q：请问挂在的Ceph存储的方式是什么，块还是文件系统？</p>
</blockquote>
<p>A：块和文件系统我们都有用，需要多实例的就用文件系统，MySQL、Redis等，就用的块。</p>
<blockquote>
<p>Q：有没有把MySQL或者Redis之类的中间件放入容器中运行，如果是如何调试，如果没有，如何实现弹性扩容？</p>
</blockquote>
<p>A：放到容器里面了，我们会把日志存储到块存储里面，我们也提供了shell，可以登录到容器内部进行调试，有日志，又有命令行，运维基本没问题。我们暂时没有做MySQL和Redis的扩容和缩容，主要是MySQL用于测试使用，单机版就够了，等我们使用本地存储来存储MySQL数据时，我们会考虑做主被、双主、扩容等；Redis我们提供单机版和8节点的集群版本，只是内存可以扩容，节点个数是不能变化的，8个节点每个节点最大16G，我们所有的业务都能满足了。</p>
<blockquote>
<p>Q：请问Ceph是如何管理的，申请和开通挂载都是自动的吗？用的CephRBD吗？</p>
</blockquote>
<p>A：有自动的也有不是自动的，我们有界面可以申请存储和进行快照管理，这就不是自动的，MySQL、Redis这些应用我们是用的PVC自动管理的。RBD跟CephFS都有用。</p>
<blockquote>
<p>Q：使用Ceph承载有状态服务的数据持久化有遇到什么坑吗？</p>
</blockquote>
<p>A：没有太多坑，就是Scheduler镜像里面没有Ceph的RBD可执行程序，需要自己重新做一下镜像，把RBD放进去。</p>
<blockquote>
<p>Q：请问这个系统用了多少人多久完成的？</p>
</blockquote>
<p>A：2年前我们开始做容器，整套系统用了20多人开发调试了1年多，后面我们又做的升级，然后把MySQL、Redis、Kafka、ZooKeeper、ActiveMQ、TensorFlow等弄了进来，现在还在做Hadoop的容器化。</p>
<blockquote>
<p>Q：请问这套架构，从规划到实施到推广完成用了多久？</p>
</blockquote>
<p>A：推广周期很长，去年下半年推广上线了一匹业务，今年公司全部的产品都开始推广使用这套系统，所以说推广完用多久，不好说，现在也是边开发边推广。</p>
<p>以上内容根据2017年12月12日晚微信群分享内容整理。 分享人崔东：东方国信容器云技术负责人，主要负责国信容器云平台的架构和实现，支持公司各产品线的云化。</p>
<hr>
<h3 id="2017-12-13：Docker在测试中的应用"><a href="#2017-12-13：Docker在测试中的应用" class="headerlink" title="2017-12-13：Docker在测试中的应用"></a>2017-12-13：Docker在测试中的应用</h3><blockquote>
<p>Q：你好，我是Docker初学者同时对测试工作不是特别了解，我能简单的理解你们是根据Web界面填写的压测需求然后生成很多的Docker容器充当客户端去大量请求你们服务，然后达到压测效果的吗？</p>
</blockquote>
<p>A：您理解的对，因为在传统的压测需求中，多台压测端的部署是个麻烦事，并且一台主机如果重复利用，环境管理是个很麻烦的事情，所以我们才有使用Docker的想法。</p>
<blockquote>
<p>Q：想请问一下压力测试，都会对服务做那些方面的测试，比如有没有是高并发等？</p>
</blockquote>
<p>A：一般来说，性能压测就是模拟多用户，一般是阶段性的压测，并发。我们关心的结果，业务的返回码，平响，平响分布时间等。</p>
<blockquote>
<p>Q：Flannel端口暴露和接口封装是怎么实现的，还有Web界面用的是什么？</p>
</blockquote>
<p>A：Flannel的IP暴露问题，您查询一下Flannel官网，这个网络插件可以达到暴露IP、端口的目的。接口封装，我们主要是将Docker的原生接口进行了封装，达到可以控制多台Node的功能，主要封装了创建网络、service，容器等接口。Web是采用Python的Django框架。</p>
<blockquote>
<p>Q：非常感谢分享，我也是从事性能工作的。我有两个问题希望能解答下。第一个问题，对压测本身而言，关注的不仅仅是应用层面的性能，更多是为了明确的测试目标而设定的特定场景，我想问的是，Docker在这方面如何定位性能瓶颈出现在哪个层级？第二个问题，如何利用Docker模拟生产环境的压力，比如全链路压测，JMeter是否还适合这样的业务场景，有没有其他的解决方案？</p>
</blockquote>
<p>A：我们的Web是提供传参功能的，用户可以自定义参数或参数列表，达到多样型的测试。并且我们提供用户自定义流量包的功能。到目前为此，压测过程中的瓶颈会偶尔出现在计算过程中，因为数据量大的时候后端计算时，会占用大量的内存。第二个问题，模拟生产环境，我们使用的是国产开源的TCPCopy，您可以查询一下，原理就是Dump线上的流量，进行线下回访。或在特定时间回访到线上，不知道是否回答了您的问题。</p>
<hr>
<h3 id="2017-12-06：小型公司DevOps落地实践案例"><a href="#2017-12-06：小型公司DevOps落地实践案例" class="headerlink" title="2017-12-06：小型公司DevOps落地实践案例"></a>2017-12-06：小型公司DevOps落地实践案例</h3><blockquote>
<p>Q：请问Portainer仅用于测试环境还是在生产也用这一套？</p>
</blockquote>
<p>A：因为Portainer是直接通过docker api执行的，并没有在服务器上装有什么客户端（也就是无侵入，这也是我们选用他的原因），我们只是在Docker里面配置了个http的TLS证书，加上我们对它做了一些改造，所以我们使用了Portainer应用生产环境。</p>
<blockquote>
<p>Q：请问下测试的时候接口模拟您这边是如何处理的？</p>
</blockquote>
<p>A：Ostman默认录入了几个多种情况下的出参，其次，我们前端每个人都有一套独立环境，通过Web端管理部署（数据库和测试人员共用），不会受后台开发人员对接口修改而中断服务。其次我们有少量前端页面使用了mock.js。</p>
<blockquote>
<p>Q：请问Docker里跑Java应用性能怎么调优，默认是共享资源池，对Java来说CPU切换很费性能，除了绑定CPU，但这样就没有弹性之说，麻烦说下？</p>
</blockquote>
<p>A：这个性能，我们对Java项目进行多次内存优化，通过ide的内存管理，线程查看等多重方法进行调优，单从war包体积上我们就缩小了60%，内存也下调很多。我们并不能自动伸缩，目前是通过Nginx配置多容器来实现负载均衡。</p>
<blockquote>
<p>Q：如何实现分布式事务？如何保证数据一致性？</p>
</blockquote>
<p>A：我们在Nginx层通过策略保证同一个机器请求只会分布到一台机器上，用最少代价解决这个问题，其次我们项目中，大部分都使用全局uuid操作和插库。</p>
<blockquote>
<p>Q：贵司的业务模式跟我们很像，感觉很受用。想问下，多客户、多版本共存的情况下，版本升级这块儿是怎么做的？</p>
</blockquote>
<p>A：我们使用的是Git分支化管理，由Jenkins定义版本号，SQL分为公共和私有的部分，比如某个客户升级2.0.0版本，会自动检测上个版本到此时的SQL语句，提示项目经理点击，自动执行。（我们现在回滚项目版本，不支持SQL回滚，所以我们SQL一般只增不减、不改），我们可以随时查看某客户线上版本和SQL执行到什么地方。</p>
<blockquote>
<p>Q：日志如何存储和分析？用什么工具？系统异常如何监控？</p>
</blockquote>
<p>A：先说说异常如何检测吧，我们做了一套http监控框架，以任务的形式添加，然后会对已配置的线上环境、多容器进行监控，比如任务为<code>http://xx.com/..../messages?token=&gt;{token}</code>，在配置任务执行时间及频率，然后配置项目列表，其中项目编辑的信息有host，可理解为<code>http://xx.com/</code>这块，还有变量列表，支持随意定义，比如token 11111111 用户token信息，这种k、v、说明文字，执行任务的时候，自动替换host和占位符。系统只记录变更，我们项目接口统一了出参，当状态码异常时显示，此方案可实现监控各种容器、各种测试、生产环境。</p>
<hr>
<h3 id="2017-11-15：Kubernetes调度详解"><a href="#2017-11-15：Kubernetes调度详解" class="headerlink" title="2017-11-15：Kubernetes调度详解"></a>2017-11-15：Kubernetes调度详解</h3><blockquote>
<p>Q：普通用户有自定义Pod优先级的权限吗？</p>
</blockquote>
<p>A：可以，Pod优先级定义与创建普通Pod类似，并没有特别权限控制。定义Pod优先级，需要先定义kind为PriorityClass类型的资源对象，然后通过在Pod的spec. priorityClassName中指定已定义的PriorityClass名称即可。</p>
<blockquote>
<p>Q：Kubernetes scheduler extender能介绍一下么？</p>
</blockquote>
<p>A：extender可理解为Kubernetes调度策略和算法的扩展，属于自定义调度器的一种方式，与Kubernetes默认调度器的过程类似，主要是针对一些不算受集群本身控制的资源（比如网络），需要通过外部调用来进行调度的情况。</p>
<blockquote>
<p>Q：用户使用了NodeSelector指定了Pod调度的node节点后，如果node不可用，那么scheduler会采用别的策略吗？</p>
</blockquote>
<p>A：nodeSelector是目前最为简单的一种pod运行时调度限制，目前在Kubernetes 1.7.x及以下版本可用。Pod.spec.nodeSelector通过kubernetes的label-selector机制选择节点，由调度器调度策略匹配label，而后调度Pod到目标节点，该匹配规则属于强制约束，如果node不可用，Pod会一直处于pending状态。nodeAffinity具备nodeSelector的全部功能，所以未来Kubernetes会将nodeSelector废除。</p>
<hr>
<h3 id="2017-11-08：Kubernetes的多集群管理实践"><a href="#2017-11-08：Kubernetes的多集群管理实践" class="headerlink" title="2017-11-08：Kubernetes的多集群管理实践"></a>2017-11-08：Kubernetes的多集群管理实践</h3><blockquote>
<p>Q：Node机器推荐命名规则与生成使用经验？</p>
</blockquote>
<p>A：推荐使用”地理位置+机房编号+机柜号+应用名称”的缩写字母来命名，这样便于运维人员后续的管理和维护。</p>
<blockquote>
<p>Q：为什么要修改etcd与apiserver的监听端口？</p>
</blockquote>
<p>A：修改etcd监听IP为0.0.0.0是为了防止出现监听了lo网卡的127.0.0.1的IP，出现不能连接的情况。apiserver则是开启8080端口用于接收http请求，这样是为了测试时方便不用使用CA证书认证。</p>
<blockquote>
<p>Q：请问Docker源怎么弄，国内一般不好连接，下载不了？另外还有1.6要升级到1.7怎么做？</p>
</blockquote>
<p>A：建议使用科学上网方式，这样就不需要改动配置。1.6升级到1.7，先停止Kubelet服务，然后下载1.7版本的kubernetes-server-linux-amd64.tar.gz包，解压替换/usr/bin目录下的同名文件，然后再把Kubelet服务启动。</p>
<blockquote>
<p>Q：在联邦集群中部署服务，可以将服务只部署在一个集群中么？</p>
</blockquote>
<p>A：可以只部署服务在一个集群中，通过编排文件中federation.kubernetes.io/replica-set-preference来控制副本分布在哪个集群。</p>
<blockquote>
<p>Q：联邦集群的几个组件现在有支持高可用么？没有的话，我们应该怎么避免联邦组件的bug导致的服务不可用？</p>
</blockquote>
<p>A ：联邦集群的Federation组目录没有支持高可用，但联邦功能主要是为了调度管理Kubernetes集群的，所以联邦集群Federation组件出现故障时并不会直接影响到下面各个集群自身的已经在运行的服务。</p>
<blockquote>
<p>Q：根据应用地理区域需求，调度工作负载到不同的Kubernetes集群中，对于不同的终端用户，提供更高的带宽和更低的延迟.这个调度到不同的集群，是Kubernetes根据地理位置调度吗？是Kubernetes自己调度吗？</p>
</blockquote>
<p>A：工作负载Kubernetes可以自己调度到比较空闲的集群上，地理位置调度这个需要通过编排文件控制应用的容器分配到更合适的区域机房。</p>
<blockquote>
<p>Q：是先建立3个Kubernetes集群，然后在1个集群的master上kubefed init fellowship是吗？</p>
</blockquote>
<p>A：是的，在其中1个集群的master上安装Federation组件，然后把3个Kubernetes集群加进来管理。</p>
<blockquote>
<p>Q：添加联邦集群文件时，里面的serverAddress是什么地址？</p>
</blockquote>
<p>A：serverAddress就是Kubernetes集群的API server的IP和端口，c1.yaml里面的serverAddress就是集群01的API server的IP和端口，c2.yaml里面的serverAddress就是集群02的API server的IP和端口。</p>
<hr>
<h3 id="2017-10-31：瓜子云的任务调度系统"><a href="#2017-10-31：瓜子云的任务调度系统" class="headerlink" title="2017-10-31：瓜子云的任务调度系统"></a>2017-10-31：瓜子云的任务调度系统</h3><blockquote>
<p>Q：请问下自动触发med-sdk构建Docker镜像，med-sdk是什么开源项目，能介绍下么？</p>
</blockquote>
<p>A：med-sdk是瓜子自行开发的一个工具，用于把代码打成Docker镜像包。每个Git里面只需要添加一个med.yml就可以实现。</p>
<blockquote>
<p>Q：请问为什么要集成Kubernetes？</p>
</blockquote>
<p>A：Airflow的Worker需要手动搭建，可扩展性不好；Job代码更新之后，需要手动部署到Worker上，非常繁琐；Airflow Worker的环境太多，由各个团队自行维护，维护成本太高；云平台搭建之后，所有机器都会被回收，各业务线拥有的机器将会很少，Worker将会没有地方部署。</p>
<blockquote>
<p>Q：Airflow处理的调度量是什么规模，也就是批量任务会不会阻塞，一次并发有多少Pod，多少容器实例，一套Kubernetes Master能否扛得住，方便给个数据量进行参考吗？</p>
</blockquote>
<p>A：目前瓜子每天有2000个任务。任务的执行地点都是在Kubernetes上的，不会阻塞。并发的Pod个数是由同时处理的Job数定的，Airflow的Worker有设置一个Worker可以同时跑几个Job。我们并发Pod有20个。一套Kubernetes可以抗住我们的规模。数据量不好给，因为任务的计算量不好估算，有的大有的小。</p>
<blockquote>
<p>Q：为什么不考虑Celery之类的任务队列？</p>
</blockquote>
<p>A：首先是我们之前选用的是Airflow，用Python写的DAG，非常符合我们的需求，我们的DAG需求很大，比如数据仓库，所以选择了Airflow。</p>
<blockquote>
<p>Q: 有做过类似软件的对比么，差异在哪？</p>
</blockquote>
<p>A：Kubernetes目前被Docker官方支持。Mesos用C写的，不好运维。Rancher社区不够大。其实功能大家都支持，主要是社区。</p>
<blockquote>
<p>Q：并发的容器数量是多少，实际的Docker实例个数量级，20个Pod可大可小。方便给个参考吗？谢谢！</p>
</blockquote>
<p>A：我们测过每台机的上限在100个，我们的机器是128G，24cores。我们Airflow的Worker有20个Pod。</p>
<p>以上内容根据2017年10月31日晚微信群分享内容整理。</p>
<hr>
<h3 id="2017-10-10：乐高式微服务化改造"><a href="#2017-10-10：乐高式微服务化改造" class="headerlink" title="2017-10-10：乐高式微服务化改造"></a>2017-10-10：乐高式微服务化改造</h3><blockquote>
<p>Q：配置中心使用Consul的配置共享，有没有考虑过？</p>
</blockquote>
<p>A：我们的配置中心里面除了键值对形式的配置项，更多的是存储了文件形式的配置文件，而Consul一般存储的是键值对信息。另外，除了存储、读取配置的能力，我们还需要一些上层的能力，比如环境隔离、版本匹配、版本管理等，这些Consul也无法直接提供。</p>
<blockquote>
<p>Q：今天讲的这些Spring Cloud、Spring Boot、配置中心、授权中心等等，有没有好的入门书籍推荐下？</p>
</blockquote>
<p>A：可以关注一下我的博客，里面提供了很多参考资源。<a href="http://emacoo.cn/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1" target="_blank" rel="noopener">emacoo.cn</a></p>
<blockquote>
<p>Q：服务边界的划分，有没有什么好的建议？</p>
</blockquote>
<p>A：这是一个好问题，也是一个见仁见智的问题。按照我目前的理解，边界至少意味着：1. 单数据库，保证数据独享；2. 各个服务层次清晰，无循环依赖。另外，很重要的一点是，随着业务复杂度的上升，一个微服务可能会需要进一步拆分，也就是说边界是跟复杂度挂钩的。</p>
<blockquote>
<p>Q：微服务多大程度应该独享数据库还是共享数据库资源？</p>
</blockquote>
<p>A：建议独享数据库，数据通过接口暴露给其他服务。</p>
<blockquote>
<p>Q：请问下如果有一个Spring Boot服务挂了，能自动发现然后重启么？有没有什么方案推荐？</p>
</blockquote>
<p>A：要实现这一点有很多方案。我们所有的服务都是跑在容器里面，借助Marathon的测活机制实现了服务意外宕机后的自动恢复。如果是非容器环境，可以通过监控平台（比如Zabbix、Open-Falcon）实时监控服务并尝试恢复。</p>
<blockquote>
<p>Q：看贵公司的架构，微服务是做了容器化部署的，微服务容器化之后采取什么样的网络方式暴露服务？</p>
</blockquote>
<p>A：没错，我们所有微服务都是跑在容器里面的。测试环境通过Marathon LB暴露服务，生产环境通过Consul Registrator自动发现服务，然后由Consul Template定时刷新LB配置，LB前面还有一层内网DNS，最终服务调用方通过内网域名访问服务。</p>
<blockquote>
<p>Q：集成Nginx实现负载均衡这个是怎么能实现的，能讲一下吗？</p>
</blockquote>
<p>A：非常简单，利用Nginx自带的upstream特性，相当于一个虚拟主机挂多个服务地址。</p>
<blockquote>
<p>Q：对一个系统做微服务改造时，什么样的功能或者应用不适合采用微服务模式，而是应该保留单体应用架构？</p>
</blockquote>
<p>A：这也是一个很好的问题。在我看来，关键看两点，第一，业务复杂度以及团队对领域模型的熟悉程度；第二，团队技术实力，尤其是DevOps水平，看能不能Hold住微服务本身所需的技术框架，以及支撑微服务的各类中间件、运维平台。</p>
<blockquote>
<p>Q：贵公司在进行微服务改造的时候，应该很难一下子全部改造成微服务同时上线，改造应用的顺序是横向还是纵向的？</p>
</blockquote>
<p>A：对，我们采取的是改良式路线，基本的思路是，首先通过重构将原本单体应用中的某个模块的边界进行纵向划分，然后新建数据库、迁移老数据、双写新老数据库，最后等新服务开发完上线之后，再将原本同一应用里的代码调用切换为外部服务调用。</p>
<hr>
<h3 id="2017-09-26：BizCloud：基于Kubernetes的私有云实践"><a href="#2017-09-26：BizCloud：基于Kubernetes的私有云实践" class="headerlink" title="2017-09-26：BizCloud：基于Kubernetes的私有云实践"></a>2017-09-26：BizCloud：基于Kubernetes的私有云实践</h3><blockquote>
<p>Q：有状态服务和无状态服务的主要区别是哪些？</p>
</blockquote>
<p>A：有状态服务，是指服务器端具备上下文关系，如Redis服务，当服务挂掉之后，Redis的内存数据丢失，我们不能简单地在另一个机器上拉起服务来恢复服务，必须同时恢复数据（状态），而无状态服务没有状态（数据）依赖。</p>
<blockquote>
<p>Q：通过模板的方式，会不会影响灵活性啊？因为大多数配置都是基本固定的。</p>
</blockquote>
<p>A：这个会牺牲一定的灵活性，但是会提升发布的安全性，并且达到对上层应用无感知。目前我们也会针对不同的应用类型定制不同的模板，如无状态服务、有状态服务的模板是不一样的。通过模板可以满足支持绝大多数服务需求，对于特定服务，我们也预留了特殊配置接口。后续我们也会尝试引入Helm Chart单元化模板。</p>
<blockquote>
<p>Q：event存在丢失的现象，请问如何处理？我觉得过度依靠event会造成很紧的偶合。</p>
</blockquote>
<p>A：我们watch event 的时候使用了ResourceVersion，不会出现丢事件的情况，如果watch提示ResourceVersion过早，我们会先List Pod，和服务管理模块做一次同步，清理脏数据。 出现过收到不完整event的情况，因为最初给Kubernetes加上Nginx代理时，Nginx默认开启了proxy_buffering，会收到不完整事件情况，关闭proxy_buffering解决这个问题。</p>
<blockquote>
<p>Q：请问k8s-monitor是通过Kubernetes的哪个API监控到Pods的状态事件ADD、MODIFY、DELETE？</p>
</blockquote>
<p>A：<a href="https://github.com/kubernetes/client-go" target="_blank" rel="noopener">kubernetes/client-go</a> 的 watch API。</p>
<blockquote>
<p>Q：能否讲下”Nginx会实时从服务管理中心获取服务对应关系”的原理是什么？</p>
</blockquote>
<p>A：我们在OpenResty基础上，通过Lua脚本从\”服务管理中心\”处查询和订阅服务对应关系，实时修改Nginx配置，进行负载均衡、服务发现。</p>
<blockquote>
<p>Q：请问你们Docker是安装在物理机还是？</p>
</blockquote>
<p>A：Docker是安装在物理机上，而且Docker安装启动是需要root权限的。</p>
<blockquote>
<p>Q：网络问题是如何处理的？没有使用自带的service吗？</p>
</blockquote>
<p>A：网络问题是指我们的网络模式么？我们的容器分配的是一个内网IP，对外部服务是可见的，如果发生了节点网络问题，在服务化这层本身会自动摘除这个节点，在调度层面一定超时后也会自动重新调度到另外一个节点上。我们没有采用Kubernetes的service，原因是因为在早期Kubernetes的调研中，service存在iptables条数过多导致性能下降问题，也担心service不稳定造成服务访问问题。</p>
<blockquote>
<p>Q：请问下你们服务动态扩容是全自动化的么？</p>
</blockquote>
<p>A：目前服务动态扩容是一键化的，不过我们也预留了一些API，来实现全自动化，大致的方案是：云平台会对接一个统一监控中心，通过统一监控中心的实时监控数据（系统数据，流量数据），分析服务的访问压力，来实时扩缩容。</p>
<blockquote>
<p>Q：问下你们程序包分发如何实现的，程序包放镜像内还是镜像外？</p>
</blockquote>
<p>A：我们开发了自己的CI模块，可以一键从SVN中生程序包，然后成镜像，编译生成镜像的时候会从统一服务管理模块中获取必要的服务信息。程序包放在镜像内。</p>
<blockquote>
<p>Q：请问你们Docker是基于CentOS制作的镜像吗？有什么优化地方？</p>
</blockquote>
<p>A：是基于CentOS 7.2制作的镜像，我们在镜像中做了一些严格的权限控制，限制了应用的一些行为。</p>
<blockquote>
<p>Q：WebShell的话，是每个节点都有Agent的吧，还是通过Kubernetes原生提供的功能呢？</p>
</blockquote>
<p>A：不需要每个节点都有Agent，我们只要实现Docker Controller 即可，Docker Controller 会去Docker Daemon上获取容器的具体信息。</p>
<blockquote>
<p>Q：你们数据库集群是用的哪种方案呢，能介绍下吗？</p>
</blockquote>
<p>A：无状态服务的话，就是使用hostPath本地挂载，日志数据我们会有实时采集的服务。有状态服务如数据库，我们目前还没有在生产环境进行大规模的数据库容器化。我们的基本思路是定制化CRD + Ceph分布式存储。也希望后面随着数据库容器化工作不断推进，能够和大家有更深入的交流。</p>
<hr>
<h3 id="2017-09-23：FreeWheel基于Kubernetes容器云构建与实践：应用编排与服务质量保证"><a href="#2017-09-23：FreeWheel基于Kubernetes容器云构建与实践：应用编排与服务质量保证" class="headerlink" title="2017-09-23：FreeWheel基于Kubernetes容器云构建与实践：应用编排与服务质量保证"></a>2017-09-23：FreeWheel基于Kubernetes容器云构建与实践：应用编排与服务质量保证</h3><blockquote>
<p>Q：这个东西的本质，是不是类似把kubectl的那一套指令做了封装呢，使操作简化？</p>
</blockquote>
<p>A：不是的，Helm的定位是Kubernetes应用的包管理工具，是对Kubernetes的补充而不是代替。Helm对Release提供了非常强大的版本管理、配置以及Hook等功能，这些都是原生Kubernetes不具备的。</p>
<blockquote>
<p>Q：Helm是一个cli client对吧？tiller有没有API可以调用？</p>
</blockquote>
<p>A：是的。tiller目前暂时不提供API调用，以Pod形式安装的Tiller service，采用的是clusterIP，然后helm client使用kubectl proxy连接。</p>
<blockquote>
<p>Q：请问生产环境负载均衡和服务发现有什么好的方案？</p>
</blockquote>
<p>A：对于生产环境负载均衡，可以采用HAProxy/Nginx等负载均衡器代替kube-proxy以求更好的转发性能。 对于Kubernetes服务发现：有2种方式，第一种是环境变量，第二种Kubernetes DNS。推荐用Kubernetes DNS，因为环境变量方式对Pod启动顺序有非常强的依赖，即先启动的Pod看不到在其之后启动Pod服务的环境注入信息。</p>
<blockquote>
<p>Q：Kubernetes的三种健康检查类型exec，tcp，http能在一个容器中同时使用吗？它们分别的应用场景是什么？</p>
</blockquote>
<p>A：可以的，Kubernetes并没有对此限制。但一般情况下，一个容器服务不会同时提供TCP和HTTP服务。 HTTPGetAction：适用于HTTP服务的健康检查，但使用前提是服务本身需要提供健康检查路径。</p>
<blockquote>
<p>Q：使用Helm是否可以不用kubectl了？另外是否支持Windows，支持的话如何配置呢？</p>
</blockquote>
<p>A：不是的。Helm是Kubernetes应用的包管理工具，对Kubernetes来说，Helm是对其Release版本管理、配置等功能的补充。</p>
<hr>
<h3 id="2017-09-21：容器云在万达的落地经验"><a href="#2017-09-21：容器云在万达的落地经验" class="headerlink" title="2017-09-21：容器云在万达的落地经验"></a>2017-09-21：容器云在万达的落地经验</h3><blockquote>
<p>Q：Grafana 是实时显示数据的，请问他如何能做到告警？就是 grafana 达到一定告警阈值时做告警？</p>
</blockquote>
<p>A：Grafana 新版本中添加了简单的告警功能，在 Notification Channels 页面有个新建通道，在里面设置一下，具体可以看下官方的文档。</p>
<blockquote>
<p>Q：请问如何实现容器限速的？</p>
</blockquote>
<p>A：你是说容器的网络限速吗？流量限制功能我们是通过在 pod 的 annotations 字段设置 <code>kubernetes.io/ingress-bandwidth</code> （设置输入流量带宽）和 <code>kubernetes.io/egress-bandwidth</code> （设置输出流量带宽）来实现。</p>
<blockquote>
<p>Q：请问使用什么操作系统部署 Kubernetes，有什么考虑？</p>
</blockquote>
<p>A：用的 CentOS 7，企业一般的用法，还有就是它稳定，不容易出问题，Kubernetes 和 Docker 的支持比较好。</p>
<blockquote>
<p>Q：如何把所有告警信息全部递给 Zabbix，Zabbix 自身是否也获取了监控值信息了？</p>
</blockquote>
<p>A：全部推送压力大，先将 APIserver、Heapster 中相关的信息放 MySQL，中间做个数据库。</p>
<blockquote>
<p>Q：etcd 3 的容灾和安全做了吗？</p>
</blockquote>
<p>A：etcd 非常关键，我们会在升级和定期用 etcdctl 做 backup。升级时需将 –initial-cluster-state 改为 existing ，安全方面还没有。</p>
<blockquote>
<p>Q：做灰度发布或 HPA 自动扩容时，实现了不影响正在提供服务的服务吗？</p>
</blockquote>
<p>A：灰度发布不会影响服务，我们使用了 Ingress + Nginx 来保证 Pod 的变化不受影响。HPA 这块我们不敢上线，功能完成了，但没有经过大量测试。</p>
<blockquote>
<p>Q：使用 rbd 作为后端存储，当 pod 发生迁移到另外一个节点后如何再次挂载这个 rbd？</p>
</blockquote>
<p>A：将 PVC 的 volume.beta.kubernetes.io/storage-class 和 StorageClass 的 name 名字一样就可。不需要管后面 Pod。</p>
<blockquote>
<p>Q：etcd 3 在哪些方面不如 etcd 2？</p>
</blockquote>
<p>A：没有去做对比，etcd 3 是通过搜集了 etcd 2 用户的反馈和实际扩展 etcd 2 的经验基础上全新设计了 API 的产品。etcd 3 在效率，可靠性和并发控制上改进比较多。etcd 2 支持多语言客户端驱动，etcd 3 由于采用 gRPC，很多需要自己实现驱动。</p>
<blockquote>
<p>Q：请问有状态的 pod 迁移，使用 ceph pv 是怎么保证分到同一个 volume？</p>
</blockquote>
<p>A：我们用的是 StorageClass，在 PVC 时指定和 StorageClass 名字一样就可。通过 volume.beta.kubernetes.io/storage-class 来指定该名字。</p>
<blockquote>
<p>Q：请问运行在不同的 Node 上面的 Pod 如何共享 Volume 存储，比如要共享一份代码？</p>
</blockquote>
<p>A：不同 Node 间的 Pod 卷共享方式比较多，但一般需要网络存储，比如：NFS，GlusterFS，CephFS，Ceph rbd，当然还包括很多大厂如：GCE 的 pd，AWS 的 ebs 等。甚至可以使用 ConfigMap 来共享，然后 mount 到相应的目录即可。</p>
<blockquote>
<p>Q：请问有没有对比过共有的容器云和私有的容器云的优缺点？</p>
</blockquote>
<p>A：公有云比较难做，我们之前是做私有云（物理资源隔离，用户数据更安全可控；独占资源，不受干扰；自行规划灵活调整资源复用比例，成本更优），公有云（公有云弹性，自如应对业务变化；具备跨机房、跨地区的容灾能力）我们也在做，正在和 IBM 合作。</p>
<blockquote>
<p>Q：请教多 Master 下，当某个 Master down 掉，default/kubernetes endpoints 中的 IP 没更新的问题，你们是如何处理的？</p>
</blockquote>
<p>A：这个主要是 Endpoints 控制器负责 Endpoints 对象的创建，更新。新 leader master 掌管后，Kubernetes 会用 checkLeftoverEndpoints 来删除 没有响应的服务的 endpoints，重启一下 kube-controller-manager 试试。</p>
<blockquote>
<p>Q：做过集群联盟吗？</p>
</blockquote>
<p>A：有测试过，但目前 Kubernetes 可以支持达 1000 节点了，能满足我们目前的需求，所以还没有上。</p>
<blockquote>
<p>Q：HPA不是Kubernetes支持的吗？你们对其做了哪些二次开发？支持蓝绿部署吗？</p>
</blockquote>
<p>A：对的，目前是支持 CPU 还有一些应用程序提供的 metrics 了，之前在社区还没有的时候，我们有自己开发，主要是通过 heapster 监控 qps 还提供自定义的一些度量来完成 HPA。但 HPA 这个一旦出问题会不可控，所以暂时还不敢上线。蓝绿部署比较耗硬件资源，相当于要多一新版本备份，目前我们还不支持蓝绿部署。</p>
<blockquote>
<p>Q：如果想看日志文件有没有好的办法，感觉在ES重被切割了不友好？</p>
</blockquote>
<p>A：日志文件可以通过在启动的时候新建一个以应用名字命名的目录挂载到本地或者网络存储中，然后应用的标准或错误输出会直接输出到 docker daemon 的日志目录下，如果应用有自己的专门的文件输出方式，则可以用 tail -f 方式进行转发与 docker daemon 对接。</p>
<blockquote>
<p>Q：还有就是基础容器是用的CentOS镜像吗？它默认就接近200m。开发语言用的Go的话有啥优化容器的地方？</p>
</blockquote>
<p>A：基础容器一般 CentOS 的多些，有些会直接采用 docker hub 提供的原始镜像，然后做些自定义组件添加并重打包。一般的会比较大一些，镜像可以对 Dockerfile 进行优化来变小。可以用 pprof 来分析 Go 代码性能，容器的优化还主要在 Dockerfile。</p>
<blockquote>
<p>Q：请问你们对于用户体验方面是如何监控的？比如每个点击在不同服务层面上的延时各是多少，超时报警等？</p>
</blockquote>
<p>A：这是个不错的想法，我们还没有做这块，不过可以通过应用提供的url，对其监控HTTP get 的 response 时间来控制。</p>
<blockquote>
<p>Q：前端基于 Opads和后端 Pluto实现CI，有具体的文档可以参考吗？</p>
</blockquote>
<p>A：这两个都是自己内部开发的模块，一个基于 PHP，一个基于 Python，文档不方便分享。</p>
<blockquote>
<p>Q：目前大规模落地云平台是建议上容器云吗？</p>
</blockquote>
<p>A：建议上。</p>
<blockquote>
<p>Q：服务启动依赖和应用版本控制如何做的？</p>
</blockquote>
<p>A：这块我们做的不大好，一般可以将每个服务注册到发现服务，然后记录它们的依赖，在启动时进行服务发现及启动，这个在微服务框架中有些。我们在应用程序版本控制方面有自己的约束规范，但后面会有 helm 来试试。</p>
<blockquote>
<p>Q：etcd 集群为什么不直接用Compose启动？</p>
</blockquote>
<p>A：这个我们为了ansible部署方便</p>
<blockquote>
<p>Q：Node 节点采用虚拟机还是物理机部署的？</p>
</blockquote>
<p>A：物理机。</p>
<p>以上内容根据2017年09月21日晚微信群分享内容整理。</p>
<p>分享人<strong>陈强，万达网络资深工程师，毕业于华东师范大学。目前在万达网络科技集团云公司基础架构部负责Kubernetes与Docker的落地与实践工作。曾先后就职于Intel、IBM和爱奇艺。在云计算领域长年搬砖，对Mesos/Kubernetes/Docker等有较深入的研究</strong>。</p>
<hr>
<h3 id="2017-09-16：Serverless云函数架构精解"><a href="#2017-09-16：Serverless云函数架构精解" class="headerlink" title="2017-09-16：Serverless云函数架构精解"></a>2017-09-16：Serverless云函数架构精解</h3><blockquote>
<p>Q：请问代码怎么部署到Docker中？</p>
</blockquote>
<p>A：直接将代码下载至母机，再将代码目录挂载至Docker。</p>
<blockquote>
<p>Q：云函数是通用的还是只能在云平台运行？</p>
</blockquote>
<p>A：云提供了云函数服务，自己也可搭建，目前GitHub上有不少开源云函数平台，比如OpenLambda，Iron.io等，建议直接使用云的服务，因为可以和多个云产品打通，单靠云函数自身难以构建完整服务。</p>
<blockquote>
<p>Q：事件传递使用的是队列吗？</p>
</blockquote>
<p>A：异步事件用了CMQ消息队列持久化存储，同步事件未使用。</p>
<blockquote>
<p>Q：请问云函数对开发语言有限制否？如果有，目前对Go语言的支持如何？</p>
</blockquote>
<p>A：目前支持Python 2.7/3.6，Node.js 4.3/6.10，Java 8，如果有通用的用户需求，可以支持其它语言，比如PHP、Go等。</p>
<blockquote>
<p>Q：有系统函数调用吗？自定义函数的颗粒度有何建议？</p>
</blockquote>
<p>A：绝大部分的系统调用都可调用，除了一些危险操作，比如关机，重启，网络服务监听等，函数颗粒度可参考微服务的设计原则，将功能尽量拆细。</p>
<blockquote>
<p>Q：能介绍下将请求调度到函数实例的实现吗？</p>
</blockquote>
<p>A：这里有个Invoker模块对每个函数维持有一个请求队列，目前没设置优先级，按照先来先到的顺序依次调度，调度时会从函数所有可用的函数实例中，选择一个下发。函数实例里有个循环接受请求，收到时传递参数调用用户函数。</p>
<blockquote>
<p>Q：代码可以下云落地吗？</p>
</blockquote>
<p>A：代码里一般会涉及其它云产品的调用，所以一般对云平台有一些依赖，可以关注下开源的Serverless框架，在公有云云函数上封装了一层，用来解除依赖，实现在各个云平台的平滑迁移。</p>
<blockquote>
<p>Q：云函数的代码有哪些限制？比如什么样的函数不可以调用，什么样的库不能import？</p>
</blockquote>
<p>A：可以基本认为无限制，但会禁止恶意行为，比如关机，重启，端口扫描等；也会禁止端口监听，因为常驻进程不符合云函数按需启用的原则。如果预装库不符合要求，可以自行将依赖库打包至zip里上传。</p>
<hr>
<h3 id="2017-08-25：基于Kubernetes的应用编排实践"><a href="#2017-08-25：基于Kubernetes的应用编排实践" class="headerlink" title="2017-08-25：基于Kubernetes的应用编排实践"></a>2017-08-25：基于Kubernetes的应用编排实践</h3><blockquote>
<p>Q：腾讯云Kubernetes网络用的是哪个组件呢？</p>
</blockquote>
<p>A：我们用的是全局路由的方式，直接和我们腾讯云的VPC网络打通。</p>
<blockquote>
<p>Q：使用ConfigMap的时候，在配置修改完，需要重启服务。腾讯云容器服务配置文件的变更如何触发服务的重新启动？</p>
</blockquote>
<p>A：通过触发器的模式，可以在修改配置时触发服务的更新。</p>
<blockquote>
<p>Q：应用配置如何实现版本控制的？</p>
</blockquote>
<p>A：对于每一个配置文件，我们支持每一次修改默认创建一个新的版本，具有唯一的版本号。</p>
<blockquote>
<p>Q：应用里的服务具体要怎么更新呢？</p>
</blockquote>
<p>A：一般建议的更新方法是，先修改配置，会生成配置的一个新的版本，这样这次修改在配置中是可以记录的。然后更新应用汇总配置文件的版本。触发或者手动更新对应的服务。在修改配置文件的版本后，我们会比较出哪些服务有变化，需要更新。</p>
<blockquote>
<p>Q：外部访问集群是通过Nginx转发到Pod还是通过Kubernetes本来都DNS服务来转发，两者优缺点是什么？</p>
</blockquote>
<p>A：外部访问，支持两种方式。一种是通过服务的LB直接转发到对应的Pod，但需要在创建服务时指定访问方式为外部访问（对应于Kubernetes中的LoadBanace方式）。另外一种是通过ingress的方式。这种方式会有一个统一的LB作为入口。然后配置对应的后端域名转发规则。可以将外部的访问按照配置的规则转发后端的服务。</p>
<blockquote>
<p>Q：应用的扩容缩容通过什么监控，有什么指标可以参考？</p>
</blockquote>
<p>A：自动扩容和缩容我们参考的是社区HPA的方案。指标目前考虑的是CPU和内存。</p>
<blockquote>
<p>Q：状态化的容器怎么做的？</p>
</blockquote>
<p>A：目前看到的有三种方式：一种是社区推荐的Stateful资源+headles service，另外一种是将服务的每一个实例拆分成独立的headless service ，第三种是采用CoreOS提出的operater方式。存储部分一般推荐使用PVC的方式，但有其他的存储方式也可以。</p>
<hr>
<h3 id="2017-08-22：白话Kubernetes网络"><a href="#2017-08-22：白话Kubernetes网络" class="headerlink" title="2017-08-22：白话Kubernetes网络"></a>2017-08-22：白话Kubernetes网络</h3><blockquote>
<p>Q：Kubernetes的网络策略采用了比较严格的单向流控制，即假如允许服务A访问服务B，反过来服务B并不一定能访问服务A。为什么要设计成严格单向流呢？</p>
</blockquote>
<p>A：主要是安全性的原因，这是一种更精细的权限控制策略，除了方向，Kuberetes还允许对可访问的端口进行控制。</p>
<blockquote>
<p>Q：Open vSwitch有测过么？</p>
</blockquote>
<p>A：没有测试，Open vSwitch同样可以配置成Overlay网络或者Macvlan网络等不同的通信模式，速度也会落到相应的档位上。那个测试例子只是为了说明网络速度与采用的通信原理有关，同时引出几种主流的通信模式原理，测试数据是不准确的，建议以在自己的实际环境中测试结果为准。</p>
<blockquote>
<p>Q：Calico怎么做网段间的隔离？</p>
</blockquote>
<p>A：各种网络工具的网络策略基本上都是基于内核的Iptables模块实现的。比如Calico只是根据用户配置，自动管理各个节点上的Iptables规则。其他有些改进的，比如Romana设计了一种基于”租户”的规则管理机制，可以用更少的Iptables规则实现网络隔离。</p>
<blockquote>
<p>Q：如果在Kubernetes里面需要做到平行网络，让每一个Pod获取一个业务IP，除了Bridge+Vlan的方式，还有更好的建议么？</p>
</blockquote>
<p>A：这次讲的这些CNI插件都会让每一个Pod获得一个独立业务IP。可以根据实际网络情况和对速度的需求选择。</p>
<blockquote>
<p>Q：Calico BGP IPIP NAT三种模式分别怎么配置？原理是怎样的？其中IPIP还有两种模式，区别在哪？</p>
</blockquote>
<p>A：在Calico的配置中设置<code>spec.ipip.enabled: ture</code> {.prettyprint}就会开启IPIP模式，否则默认是纯BGP模式。IPIP的两种模式其实是指纯IPIP（ipip always模式）或者混合IPIP和BGP（ipip cross-subnet），后者指的是”同子网内路由采用BGP，跨子网路由采用IPIP”，主要用于即想在内网获得高速，又想在跨公网时能保持联通的情况。这种模式需要每个节点启动时用<code>--ip</code> {.prettyprint}参数预先配置节点的子网，并且所有节点版本都在v2.1以上。</p>
<blockquote>
<p>Q：能麻烦具体介绍一下kube-proxy这种网络模式的优缺点吗，在测试过程中发现很不稳定，但是又没发现足够的证据。</p>
</blockquote>
<p>A：kube-proxy是Kubernetes的一个组件，提供通过Service到Pod的路由，并不是一种网络模式，不同的网络插件都会使用到这个组件。</p>
<hr>
<h3 id="2017-08-17：Kubernetes主机和容器的监控方案"><a href="#2017-08-17：Kubernetes主机和容器的监控方案" class="headerlink" title="2017-08-17：Kubernetes主机和容器的监控方案"></a>2017-08-17：Kubernetes主机和容器的监控方案</h3><blockquote>
<p>Q：容器监控和主机监控为何不能用同一套方案，比如Prometheus？</p>
</blockquote>
<p>A：可以，主要考虑到Prometheus的组件比较多，它将DB、Graph、Statistic、Alert都集于一体，但是它的扩展性不好，内存占用率大，在SSD盘下IO占用比较高，同时可能会有大量数据堆积内存，维护成本比较大，但是也可以避免，其实还是要看具体的业务场景和需求，如果是针对大规模的主机和容器监控，并且对DB、Graph、Statistic、Alert的要求都比较高，那么Prometheus肯定是比较好的选择，另外还可以使用cAdvisor + Prometheus + Grafana的组合方案，将这几个工具的有点结合起来使用。</p>
<blockquote>
<p>Q：有没有能集成邮件或短信告警工具的呢？</p>
</blockquote>
<p>A：比如Prometheus和Zabbix都有采集，展示，告警的功能。</p>
<blockquote>
<p>Q：Prometheus的数据存储在哪儿，用的文件系统是什么？</p>
</blockquote>
<p>A：Prometheus本身是用的LevelDB数据库，数据存储分两部分：内存和本地磁盘中。</p>
<blockquote>
<p>Q：kubelet和cAdvisor整合后，监控如果出问题岂不是会影响服务稳定性？这个如何解决？</p>
</blockquote>
<p>A：在Kubernetes的新版本中已经集成了cAdvisor，cAdvisor作为一个daemon跑在Kubernetes上面，即使cAdvisor出现问题，对Kubernetes并没有影响，而且Kubernetes本身也有一套管理机制。</p>
<blockquote>
<p>Q：想问一下对于Pod的生命周期的监控有没有好的解决方案，想监控一些pod不明原因频繁删除和新建？</p>
</blockquote>
<p>A：cAdvisor可以对Pod进行监控，如果想查原因，可以对日志进行监控和分析。</p>
<p>A：可以使用Prometheus、Icinga、Zabbix的告警功能。</p>
<blockquote>
<p>Q：cAdvisor的采集粒度是多长时间？当需要采集秒级的性能数据时cAdvisor是否能满足要求？</p>
</blockquote>
<p>A：cAdvisor采集了最近接近两分钟内的8组数据, 可以满足，这里主要是要考虑下存储问题，因为到采集到秒级别后，数据会很大。</p>
<blockquote>
<p>Q：容器中使用像JVM这种都会怎么来进行监控呢？</p>
</blockquote>
<p>A：ELK stack应该适合这种场景，另外Datadog也是SaaS监测工具，Datadog比较灵活，需要植入自己的代码，可能没有前者用起来简单。</p>
<blockquote>
<p>Q：对于群集环境，能不能简单比较一下各数据采集软件的好坏？或者分享一下用过的工具和坑。</p>
</blockquote>
<p>A：这几个采集工具不好说哪个好那个坏，还是要看具体应用场景和需求，适合自己的才是最好的（嘿嘿）。例如：功能全的工具可能会很臃肿，占用资源也多，而且并不一定使用所有场景，功能少的扩展性可能很好。</p>
<blockquote>
<p>Q：容器监控应该是为了容器能更好的运行。那么当容器出现一些异常情况，比如IO占用过高，带宽占用很多时，该怎么处理呢。</p>
</blockquote>
<p>A：这是监控系统中自动化处理的那部分，针对容器出现的异常到底是要采取什么自动化操作还是要看具体情况，一般如果容器异常挂掉，可能会选择自动拉起，但如果像IO占用过高这中问题，因为导致的原因太多了，可能是主机的问题，也可能是程序本身的问题，所以还是需要人为去排查才行。</p>
<blockquote>
<p>Q：cAdvisor 是定时采集数据，但是有时候时间点采集不到数据，是为什么？</p>
</blockquote>
<p>A：可以看下cAdvisor有没有异常重启过，然后可以手动区主机的文件下查看数据，然后跟cAdvisor取到的数据进行比较，有可能是是在采集数据的时候有问题。</p>
<blockquote>
<p>Q：数据采集中，您提到主动输出到文件，那么涉及到日志文件的读取采集，那这块怎么做呢？</p>
</blockquote>
<p>A：如果是传统的日志汇总收集有开源的软件ELK和Facebook开源的Scribe，容器的日志管理可以参考Fluentd。</p>
<blockquote>
<p>Q：这些监控方案中从资源占用数据准确性角度来看，哪个更好用？</p>
</blockquote>
<p>A：准确性都不会差，他们采集的源数据都是一样的，在资源占用这块，cAdvisor是占用资源最少的，Prometheus占用资源比较多。</p>
<blockquote>
<p>Q16：有一处我不是很确定是否讲错了，我实践发现即便为容器设置了MEM、CPU限制，所监控到的依然是主机的总MEM和CPU。</p>
</blockquote>
<p>A：我测试了，在启动容器的时候设置MEM和CPU限制后，通过docker stats命令监控的是设置的值。</p>
<blockquote>
<p>Q：如果要监控某个容器内正在跑的进程，你们现在的方案是如何的，能介绍下吗？</p>
</blockquote>
<p>A：可以参考Kubernetes中Pod健康部分：<a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">kubernetes.io/docs</a>，利用探针的方式监控进程。</p>
<p>以上内容根据2017年07月27日晚微信群分享内容整理。分享人<strong>李强，有容云后端开发工程师。有着多年的服务器、网络、容器、虚拟化等云计算技术相关工作经验，现主要负责Kubernetes安装、集群、监控等相关的后台研发工作</strong>。</p>
<hr>
<h3 id="2017-08-09：Kubernetes健康检查策略"><a href="#2017-08-09：Kubernetes健康检查策略" class="headerlink" title="2017-08-09：Kubernetes健康检查策略"></a>2017-08-09：Kubernetes健康检查策略</h3><blockquote>
<p>Q：请问Pod的状态是crashbackoff 除了下载镜像失败有哪些可能？下载的镜像能否指定registry？ pod如果有一个容器是exit 0，那是否就是您之前提到的succeed?使用livenessProbe检测失败的是failed还是crashbackoff？</p>
</blockquote>
<p>A：Crashbackoff大部分情况下是容器的启动命令失败，比如tomcat启动失败了，初学者比较容器犯的错误是CMD的命令是一个非阻塞命令，这样容器一运行就马上退出了。下载的镜像可以指定registry，根据镜像的命令来的，比如 test.registry.com/image:version。容器exit 0了，得根据重启策略来判断。而livenessProbe检测是业务层面的检测。</p>
<blockquote>
<p>Q：请问readinessProbe检测失败后，是手动Scale添加Pod确保业务稳定还是可以在ReplicationController的yaml里面定义？</p>
</blockquote>
<p>A：这部分 Kubernetes并不支持，是我们自己准备开发的功能。就是发现Pod NotReady后，一来保留问题容器，二来新增一个Pod顶替。</p>
<blockquote>
<p>Q：请问Supervisord是手动在Pod里面的容器里面添加么？还是有专门的镜像已经自带？谢谢！容器出错后收集的现场信息都保存在哪里？</p>
</blockquote>
<p>A：Supervisord就安装到容器里面就行了，比如我们是CentOS基础镜像，然后yum install即可。当进程异常的时候，Supervisord可以重启进程并且保证容器不会退出，这样一来就可以登录到容器里面排查问题，信息的话根据组件的情况来定了。</p>
<blockquote>
<p>Q：请问，如果一个deployment有三个副本，分别部署再三个Node上，当其中一个Node宕机了，这时候对应的service中的endpoint更新需要一定的时间，用户在这个时间段访问就会有1/3的错误可能，这种情况怎么办？</p>
</blockquote>
<p>A：当Pod异常的时候，比如是NotReady，Service的endpoint了马上就会剔除这个Pod了。Kubernetes的实现都是实时watch的。</p>
<blockquote>
<p>Q：保留容器现场如果造成多个僵尸容器怎么办？</p>
</blockquote>
<p>A：当Pod NotReady的时候，新建Pod顶替，新建的Pod也异常的话，就不能一直重建。然后定位完成后，只能手动去清理Pod了。</p>
<blockquote>
<p>Q：用Supervisor来启动服务，应用的日志是打到指定的目录的还是直接std输出然后再处理的啊？</p>
</blockquote>
<p>A：应用的日志打印到文件处理。Stdout被Supervisor占用了</p>
<blockquote>
<p>Q:一个容器里面推荐只跑一个进程，对于遇到一个项目要跑多个服务的情况，是每个服务都单独生成一个容器吗？如果是这样的话代码是怎么管理的？每个服务一个分支吗？而且往往开发、测试、生产是不同的分支，这样服务多了的话对于代码管理很麻烦，如果一个容器里面用Supervisor来跑多个进程的话理论上可以，但是显然做法不好。</p>
</blockquote>
<p>A：每个服务可以做成一个容器。那这个是管理的成本了，可以通过一些工具和脚本来自动化。至于要不要跑多进程，看实际场景，都是可以的，其实只要保证Pod提供的业务是正常的即可，所以我们用Probe来对业务检查，</p>
<blockquote>
<p>Q：请问Kubernetes的应用的日志是怎么管理的，用的网络文件系统还是其他的方式？</p>
</blockquote>
<p>A：我们是要求应用的日志全部输出到指定目录，比如/var/log。然后我们针对容器里面的日志目录统一挂载到Ceph存储。</p>
<blockquote>
<p>Q：是否可以通过preStop元素在pod failed被移除前执行一些收集现场信息的命令？</p>
</blockquote>
<p>A：也是可以的。但是大部分人定位问题还是希望能够登录到容器里面定位，这样是最快最方便的方式。</p>
<blockquote>
<p>Q：Supervisor的方式打乱了Kubernetes原来的容器重启方式，可能会带来更大的问题。不如考虑在Kubernetes的基础上修改增强。</p>
</blockquote>
<p>A：是个问题。可以说Supervisor就覆盖了Kubernetes的重启方式，但是一方面Supervisor的重启方式更加灵活，另一方面修改Kubernetes的话侵入性比较大。所以我们选择用Supervisor。</p>
<blockquote>
<p>Q：你们的应用日志统一挂载存储的话，存储上是为每个容器新建一个目录吗？</p>
</blockquote>
<p>A：这部门我们是修改了Kubernetes的代码，为每个pod在宿主机创建一个目录，然后宿主机的这个目录是挂载Cephfs的。</p>
<blockquote>
<p>Q：假如APP不能正常进行业务处理（连不上数据等原因），而health check依然正常返回。怎么办？你们会强制要求开发对APP的状态进行管理，在health check里返回吗？</p>
</blockquote>
<p>A：这是个好问题。我们会尽量要求应用提供的health接口尽量准确，但是这也很难保证100%的业务正常，所以目前就是需要权衡，这部门我们也在细化中。</p>
<p>以上内容根据2017年08月08日晚微信群分享内容整理。分享人<strong>吴龙辉，网宿科技云计算架构师，负责设计开发PaaS平台，《Kubernetes实战》作者</strong>。</p>
<hr>
<h3 id="2017-08-06：求取一份极致的简单：海量应用容器化改造之路"><a href="#2017-08-06：求取一份极致的简单：海量应用容器化改造之路" class="headerlink" title="2017-08-06：求取一份极致的简单：海量应用容器化改造之路"></a>2017-08-06：求取一份极致的简单：海量应用容器化改造之路</h3><blockquote>
<p>Q：构建镜像用的什么技术？</p>
</blockquote>
<p>A：我们使用的是Docker自身提供的docker build命令进行镜像构建的。</p>
<blockquote>
<p>Q：Config Center能否详细说一下？</p>
</blockquote>
<p>A：我们使用Config Center主要来管理应用自身的配置文件，应该在启动前首先拽下自己的配置文件；还有就是对应用进行Leader控制，因为应用可能会跑多个实例的，像定时任务类的功能，在同一个时间点只能其中一个实例生效。</p>
<blockquote>
<p>Q： 如何动态生成Dockerfile，如何在Docker镜像里配置JVM参数？</p>
</blockquote>
<p>A：Dockerfile文件：我们是使用sh脚本生成的，将内容 &gt;&gt; Dockerfile中；JVM参数是在应用中配置的，发送构建消息时，作为消息内容送过去。</p>
<blockquote>
<p>Q： Deployment 滚动更新如何设置间隔时间呢？</p>
</blockquote>
<p>A：Deployment对象有个minReadySeconds属性就是来解决这个问题的。</p>
<blockquote>
<p>Q： Logstash的日志为啥是发送到HDFS而不是ES？有什么考虑么？</p>
</blockquote>
<p>A：我们将Logstash采集到的日志输出到两个地方：ES、HDFS，输出到ES直接在Kibana上搜索到，而输出到HDFS便于在Kibana上面将日志文件进行下载下来。</p>
<blockquote>
<p>Q：Docker Registry的在garbage collect时怎么保证高可用？</p>
</blockquote>
<p>A：我们使用的由VMware公司中国团队开源的Harbor，无论安全、效率、可用性方面都提供了很强的保障了。</p>
<blockquote>
<p>Q：kubectl set image的时候 能不能限制每变更一个容器，再保证http访问正常的前提下，再变更下一个容器。毕竟有的服务启动时间超过30秒，对外的服务忍受不了信么久的不可访问时间的？</p>
</blockquote>
<p>A：这个可以直接借助Kubernetes的RollingUpdate功能就可以做了。</p>
<blockquote>
<p>Q：Dockerfile动态生成怎么做的，用的是什么生成工具？</p>
</blockquote>
<p>A：使用sh脚本生成,将内容 &gt;&gt; Dockerfile中去可以了。</p>
<blockquote>
<p>Q：统一的流程给实际的生产带来了怎样的好处能否介绍一下？</p>
</blockquote>
<p>A：流程统一后，像源码管理、日志采集及搜索、应用发布，应用滚动升级等就不需要应用本身来管了，这样各业务系统本身就会更加专注于自身的业务功能了。</p>
<hr>
<h3 id="2017-08-02：国内某大型酒店管理集团基于Kubernetes的实践"><a href="#2017-08-02：国内某大型酒店管理集团基于Kubernetes的实践" class="headerlink" title="2017-08-02：国内某大型酒店管理集团基于Kubernetes的实践"></a>2017-08-02：国内某大型酒店管理集团基于Kubernetes的实践</h3><blockquote>
<p>Q：容器的日志怎么管理呢？不同应用的日志怎么管理？</p>
</blockquote>
<p>A：我们在容器化之前已经开始使用ELK的解决方案，所以我们整个容器化平台的改造中也整合了ELK的方案。 1.  Docker启动的时候mount一个共享存储，日志都写在这个共享存储里，然后配置Logstach采集，最后吐到ES里，用kibana展示，缺点是挂共享存储，性能略差。优点是日志可以根据应用来分到不同的ELK上，并且日志做归档比较容易，我们有场景要查一年前的日志。 2.  我们在Kubernetes节点上安装fluentd组件，采集Kubernetes     node上的日志，应用部分只需要在log4j的配置里将日志输出打到标准输出上系统即可采集，缺点是这个集群的日志会全部聚合到一套ELK上。优点是应用几乎无需做什么改造。</p>
<blockquote>
<p>Q：容器中需要持久化的数据怎么处理？</p>
</blockquote>
<p>A：原则上我们不建议在容器化平台上的应用有持久化数据 ，如果互联网应用的背景，应用无状态化设计对于应用有横向扩展需求是更加适合的，应用在上容器云平台前要完成这部分改造。但是我们的确有做过数据持久化的研究，当时主要考虑ES集群会有持久化数据，我们的方案是Kubernetes+GlusterFS的方案。但是由于ES集群本身很稳定，也不会有发布，容器化意义并不大，所以暂时我们这部分仍保留在VM上。</p>
<blockquote>
<p>Q：请教下，如果开发机在本地，如何连到测试环境（联调环境）上去，你们的网络如何打通？</p>
</blockquote>
<p>A：我们不建议开发使用本地资源进行开发，我们提供整套的QA环境（都在Kubernetes上）。 如果实在要登录到Node上看一些东西，我们有堡垒机。</p>
<blockquote>
<p>Q：Docker网络用的什么方案？</p>
</blockquote>
<p>A：Flannel，能用，性能不太好，准备迭代掉它。这是坑！大家不要踩。</p>
<blockquote>
<p>Q：服务对外暴露是用什么实现的？</p>
</blockquote>
<p>A：集群内部访问之前说了，服务名的方式，集群外的访问，Kubernetes每个节点都可以提供服务。但是如果所有请求都落在一个Kubernetes节点上，这个节点就是一个单点。 所以我们提供对外服务时仍然会在node前面加一层loadbalance，LB后面将5-10个Kubernetes的节点作为backend添加上去。另外这部分节点最好不要调度任务在上面跑。</p>
<blockquote>
<p>Q：你们的Docker容器在Windows上是怎么解决IP通信的？</p>
</blockquote>
<p>A：我们不用Windows的Docker，Docker是进程共享的虚拟化技术，Windows和Linux共享哪门子进程？感觉不太靠谱，所以不用。（比较主观） 微软自己也在搞类似Docker+Kubernetes的架构的一套东西，大家可以关注一下，如果要上Windows的Docker那还是用MS的解决方案比较靠谱。</p>
<blockquote>
<p>Q：你们的宿主机、容器、服务的监控告警系统架构是怎样的，能简单介绍下吗？</p>
</blockquote>
<p>A：宿主机我们还是用Zabbix，服务的可用性我们也用Zabbix（这是容器化之前就保留下来的）但是只有当所有pod都挂掉才会报警，容器的监控我们是使用Prometheus和Grafana。</p>
<blockquote>
<p>Q：四个环境的发布权限你们怎么去合理配置呢？</p>
</blockquote>
<p>A：原则上用户登录所有环境都需要通过堡垒机，4个环境的发布，都是通过Jenkins来实现的，所以我们会控制Jenkins上对应的Pipline的权限。（Git-&gt;Jenkins-&gt;Kubernetes）这一段是自动化的，开发人员能做的就是触发构建任务。 如有特殊的需求，需要让运维人员操作。</p>
<blockquote>
<p>Q：如果有开发人员需要上去看错误日志，假设这种错误日志是需要调试，不会被收集，是只能通过堡垒机去看吗？容器的日志怎么进行存储，如果挂到宿主机目录那好多容器怎么分文件夹呢？</p>
</blockquote>
<p>A：我们方案里fluentd可以收集node上几乎所有的日志，另外关于错误调试日志，如果是应用的，那开发人员按照需求调整输出路径就好了，用ELK采集就好了。如果是系统级别的，运维人员就把它作为一个Linux主机查日志拍错就好了。 另外容器的日志，解释起来有些长，你可以参考我之前的帖子《<a href="https://mp.weixin.qq.com/s?__biz=MzA4MjQ1NTgyOQ==&amp;mid=300723383&amp;idx=1&amp;sn=2c31770da35b429b74ef0264bfb17201&amp;chksm=0b9d70cd3ceaf9db43d7cb943533500a15ebe5463f8f06d3b13075b305c23dadfa725f91e19b&amp;mpshare=1&amp;scene=1&amp;srcid=0725JDmSrXiXVBDLGj4A4yRe#rd" target="_blank" rel="noopener">Docker日志那点事</a>》，容器日志的目录和格式都有写到。</p>
<blockquote>
<p>Q：用的Overlay网络，那你们用的NodePort暴露的服务，然后外部LB访问NodePort？那你们现在容器一个集群内有多少容器？kube-proxy的性能有做过压力测试吗？</p>
</blockquote>
<p>A：回答后面一部分，我们每个环境都是一个集群，例如QA是一个集群，UAT是一个集群，我们一个生产集群目前大概 1000+个容器。 另外我们应用上线前会做压力测试，目前我们没遇到过kube-proxy被压死的情况，多是我们的压力不够（我们使用JMeter，大多时候是JMeter死掉）。</p>
<blockquote>
<p>Q：各环境用的是同一个imagebuild用env区分？还是不同build？有比较过或遇到什么坑吗？</p>
</blockquote>
<p>A：开始的分享提到了，一个image build用env区分，就是坑。配置文件管理变成了env的管理。所以老老实实每个环境build一个镜像。</p>
<blockquote>
<p>Q：各环境的config是怎样和什么时候打到image里的？</p>
</blockquote>
<p>A：配置文件一起放在Git上，Jenkins拉完代码再把配置文件拉下来，简单点使用CP命令把对应的配置文件和war或者jar以及Dockerfile放到对应的目录下，进行build就好了。</p>
<hr>
<h3 id="2017-07-21：深入理解Kubernetes网络策略"><a href="#2017-07-21：深入理解Kubernetes网络策略" class="headerlink" title="2017-07-21：深入理解Kubernetes网络策略"></a>2017-07-21：深入理解Kubernetes网络策略</h3><blockquote>
<p>Q：Calico 和 Weave 从 Policy 处理性能来看，两者哪个更优？</p>
</blockquote>
<p>A：两者在 iptables 层面上的实现原理是一样的。都用了 -m state 和 ipset 优化，性能差别不大。</p>
<blockquote>
<p>Q：Calico 结合 Kubernetes 怎么实现多租户，比如网络隔离之类的？</p>
</blockquote>
<p>A：可以考虑用 namespace 来隔离。没有 Network Policy 的情况下当然是互通的。但是 Kubernetes 的 Network Policy 支持 namespaceSelector，可以轻松搞定。</p>
<blockquote>
<p>Q：Weave、Calico、Flannel 比较，适用场景和优缺点是什么，Flannel out了么？</p>
</blockquote>
<p>A：各有各的市场 :-)。 Flannel 比较简单，资源消耗也会小些。Flannel 不能算 out 了。Cannel 的出现将 Flannel 和 Calico 整合了起来。</p>
<blockquote>
<p>Q：NPC 必须用 iptables 实现吗？在某些情况下，Pod 出向流量并不会由主机协议栈，这样 iptables 就用不了，这种情况下 NPC 怎么实现呢 ？</p>
</blockquote>
<p>A：Calico、Weave、Romana 的 NPC 都是通过 iptables 实现的</p>
<hr>
<h3 id="2017-07-19：58-赶集基于-Docker-的自动化部署实践"><a href="#2017-07-19：58-赶集基于-Docker-的自动化部署实践" class="headerlink" title="2017-07-19：58 赶集基于 Docker 的自动化部署实践"></a>2017-07-19：58 赶集基于 Docker 的自动化部署实践</h3><blockquote>
<p>Q：如何更新 nginx upstream？</p>
</blockquote>
<p>A：Nginx 机器上部署有 Agent，Web 类的业务有统一的框架，服务启动时会向 Consul 注册。Agent 订阅 Consul 中的节点数据，然后配合 nginx dyups 模块，动态修改 nginx upstream。</p>
<blockquote>
<p>Q：打包好镜像后，使用镜像还用再进行配置吗，就是说还用手动配置吗？</p>
</blockquote>
<p>A：不用配置，不同环境之间流转的是同一个镜像，包含了各个环境的所有配置，通过启动容器的环境变量来识别切换。</p>
<blockquote>
<p>Q：Docker 的正确的使用姿势，在本地环境已经构建了企业私有 Registry Harbor，那么我要构建基于业务的应用时，是先从 Linux 系列的像 Ubuntu 或 CentOS 的 Base 的 Docker 镜像开始，然后通过 Dockerfile 定制业务需求，来使用吗？</p>
</blockquote>
<p>A：我们基础镜像统一采用 CentOS 6.8，不同的业务有不同的 Dockerfile 模板，生成镜像的过程业务对 Dockerfile 是透明的。</p>
<blockquote>
<p>Q：这里实现灰度发布了吗？能否不停交易更新？</p>
</blockquote>
<p>A：实现了 PV 灰度，暂时没实现 UV 灰度，对于无状态的业务已经能满足需求了，对于有状态的业务，比如交易类型的主要还是需要程序架构来实现。</p>
<blockquote>
<p>Q：请问如何保证 NGINX 的高可用？</p>
</blockquote>
<p>A：域名-&gt;CNAME（快速切换IP解析）-&gt;LVS（多个rip）-&gt;多个 NGINX 实例（平行实例）；NGINX 同时和 LVS 保持心跳来自动踢掉故障的实例。</p>
<hr>
<h3 id="2017-07-13：Juice—一种基于MesosFramework的任务云框架"><a href="#2017-07-13：Juice—一种基于MesosFramework的任务云框架" class="headerlink" title="2017-07-13：Juice—一种基于MesosFramework的任务云框架"></a>2017-07-13：Juice—一种基于MesosFramework的任务云框架</h3><blockquote>
<p>Q：Juice与Elastic-Job有哪些差异？</p>
</blockquote>
<p>A：我本身对于Elastic-Job并不算太熟悉，就随便说几点，如果有错还请各位纠正： Juice目前版本并不支持作业分片。</p>
<blockquote>
<p>Q：能详细介绍下任务资源分配这一块的算法吗？</p>
</blockquote>
<p>A：之前已经简单介绍过了，通过接收\’OFFERS\’事件触发相关任务－资源分配的代码块。 由于得到的Offer对象实际为一个列表，处理逻辑会循环为每一个Offer分配具体的任务，而每个Offer的任务列表总资源（CPU、Memory等）必需小于Offer resources * RESOURCES_USE_THRESHOLD（资源使用阀值，可通过配置文件resources.use.threshold设置，默认0.8），每分配完一个Offer的task_infos后，便生成Accept Call由发送线程池进行发送处理，整个过程都是异步非阻塞的。</p>
<blockquote>
<p>Q：所有的任务都存档在Docker里面对于一些临时的任务如何处理?</p>
</blockquote>
<p>A：临时的任务确实会产生一些垃圾的镜像，需要定期对Docker仓库进行清理，一般设置清理周期为1个月。</p>
<blockquote>
<p>Q：任务系统是是否有帮助用户完成Docker封装的操作？</p>
</blockquote>
<p>A：目前没有，所以使用者必需会一些Docker的基本操作，至少要会打镜像，提交镜像等。当然，像一些Docker的设置，比如挂载Volume，网络（bridge、host）等可以在提交任务时通过参数设置。</p>
<blockquote>
<p>Q：Mesos和Kubernetes的优劣势是什么？</p>
</blockquote>
<p>A：其实我主要使用Mesos，Mesos相对Kubernetes应该是一套更重的系统，Mesos更像是个分布式操作系统，而Kubernetes在容器编排方面更有优势（Pod之类）。</p>
<p>以上内容根据2017年07月13日晚微信群分享内容整理。分享人<strong>徐佳，沪江Java工程师，开源框架Juice作者，10多年开发经验</strong>。</p>
<hr>
<h3 id="2017-07-12：探究PaaS网络模型设计"><a href="#2017-07-12：探究PaaS网络模型设计" class="headerlink" title="2017-07-12：探究PaaS网络模型设计"></a>2017-07-12：探究PaaS网络模型设计</h3><blockquote>
<p>Q：有这么多虚拟网络，覆盖网络，会不会有网络延迟？</p>
</blockquote>
<p>A：网络虚拟会带来性能损耗，比如Flannel需要将报文封装到UDP包中传输，这中间的封包解包就会带来损耗。所以网络虚拟化的部分，软件的实现还有待优化，其实更好的方式是硬件支持，比如现在提的很多的SDN网络。</p>
<blockquote>
<p>Q：Pod为什么要有个网络容器？</p>
</blockquote>
<p>A： 一方面这是解耦，通过网络容器来负责网络配置，这样对于业务容器来说稳定性会更高，比如在多个业务容器中，某一个业务容器断了，这样就不会导致网络中断。</p>
<blockquote>
<p>Q：Calico默认全网是打通的，怎么做基于网段之间的隔离？</p>
</blockquote>
<p>A：目前来说要做网段隔离，可能偏向安全性比较高的场景，我们目前是做私有云场景，对隔离的要求没那么高。所以如果要做隔离的话，可以参考OpenStack的OVS方案。</p>
<blockquote>
<p>Q：在某些应用场景下，Pod的IP需要固定，而不是重启之后IP可能会变化，请问如何满足这种场景的需求？</p>
</blockquote>
<p>A：Pod的IP需要固定的话，一种方式是修改Docker的代码，据我所知腾讯有实现过。另外的方案就是做L3的代理，给Pod一个浮动IP，有点像OpenStack的实现。</p>
<blockquote>
<p>Q：Ingress的流量默认是先走Service然后到Pod，还是直接到Pod？</p>
</blockquote>
<p>A：取决你的实现，官方的实现是先走Sevice再到Pod，我们是直接到Pod。</p>
<blockquote>
<p>Q：Ingress-Controller实现除了使用LVS和Nginx外，能否采用商用负载设备来实现？实现是否取决于和Kubernetes API的对接？</p>
</blockquote>
<p>A：可以，只要有接口都可以实现，通过实现Ingress-Controller，比如对接F5的硬件设备，只要F5支持相关的API。</p>
<blockquote>
<p>Q：代理入口上有哪些方法解决单点失效的问题呢？</p>
</blockquote>
<p>A：这个比较传统了，软件实现就Keepalived之类的。</p>
<blockquote>
<p>Q：Igress-Cntroller比较好的库都有哪些，分别基于Nginx Haproxy LVS的？</p>
</blockquote>
<p>A：GitHub有蛮多实现的，其实还是比较简单的，像go语言的话，直接套用官方提供的demo即可，其他语言可以对接Kubernetes的API实现。</p>
<blockquote>
<p>Q：这么多层的网络，多层转发后网络性能怎么样？有没有办法实现高速数据转发解决方案？</p>
</blockquote>
<p>A：代理层，虚拟层都会有损耗，这个就是要考虑管理成本和性能的权衡了。如何要实现高性能的话，就是要往SDN网络研究，通过硬件层的支持来实现虚。</p>
<p>以上内容根据2017年07月11日晚微信群分享内容整理。分享人<strong>吴龙辉，网宿科技云计算架构师，负责设计开发PaaS平台，《Kubernetes实战》作者</strong>。</p>
<hr>
<h3 id="2017-07-14：聊聊Service-Mesh：linkerd"><a href="#2017-07-14：聊聊Service-Mesh：linkerd" class="headerlink" title="2017-07-14：聊聊Service Mesh：linkerd"></a>2017-07-14：聊聊Service Mesh：linkerd</h3><blockquote>
<p>Q：具体的测试性能有么，对比LVS、Nginx？</p>
</blockquote>
<p>A：linkerd虽然是网络代理，但跟LVS、Nginx还是有不同的，所解决的问题也不同，比如linkerd常用的部署方式以sidecar模式部署。 对于性能数据，单个linkerd是可以可以处理20K/sec请求，p99延迟在10ms以内，但是超过20K，在我的测试环境，提高不大。而跟Nginx和LVS的对比，还没做过。</p>
<blockquote>
<p>Q：能否说说 “熔断机制（circuit-breaking） “怎么理解？</p>
</blockquote>
<p>A：linkerd支持2种方式进行熔断，一种是基于会话或者链接，另一种是基于请求的熔断。对于会话层的熔断，linkerd在转发请求到后端应用实例时，如果发现其中一个链接出现问题，linkerd会将它从维护的一个池子里移除，不会有真实请求发送到该实例，而在后台，linkerd会尝试连接，一旦连接成功，linkerd再次将它加入池子继续提供服务。 而对基于请求的熔断，linkerd会根据linkerd的配置进行处理，比如配置为io.l5d.consecutiveFailures， linkerd观察到指定数量的连续错误，则熔断，其他的方式可以查看<a href="https://linkerd.io/config/1.1.0/linkerd/index.html#failure-accrual" target="_blank" rel="noopener">linkerd.io/config/1.1.</a>。</p>
<blockquote>
<p>Q：linkerd如何实现水平扩展的？集群对linkerd计算节点数量有限制吗？</p>
</blockquote>
<p>A：linkerd本身是无状态的，所以水平扩展非常容易，集群对linkerd的数量取决于你是怎么部署linkerd的，<a href="https://linkerd.io/in-depth/deployment/" target="_blank" rel="noopener">https://linkerd.io/in-depth/deployment/</a>这个地方列出各种部署方式优势及缺点。</p>
<blockquote>
<p>Q：看最后的表格好像能实现展示服务调用链，展示上下游关系？能不能借此发现具体服务压力瓶颈在哪一环，是否有性能监控？</p>
</blockquote>
<p>A：linkerd提供详细的metric, 这些metric会告诉你性能出现在哪个地方，还有linkerd原生跟zipkin集成，所以你能trace到服务的访问流，会展示每一环节的性能情况。</p>
<blockquote>
<p>Q：可否对比一下Istio？</p>
</blockquote>
<p>A：对应Istio的底层Envoy和linkerd本质上实现了差不多类似的功能，linkerd支持Kubernetes、DC/OS，并且跟多种服务发现工具集成，而Istio，就我了解，目前支持Kubernetes，具体Istio的使用，没有使用过，不太清楚。</p>
<blockquote>
<p>Q：如果linkd是无状态，那怎么维护内部的熔断池？</p>
</blockquote>
<p>A：这里的无状态是指linkerd工作时各个实例之间不需要信息的同步，即使一个实例出现问题，对个整个环境的正常工作无关痛痒，只需重新启动即可，所有服务发现的信息都是存储在外部，比如Consul、ZK等，本地只会有缓存，没有持久化的数据，而熔断池的信息就是来自于服务发现系统。</p>
<p>以上内容根据2017年07月04日晚微信群分享内容整理。分享人<strong>杨章显，思科高级系统工程师。主要关注云计算，容器，微服务等领域，目前在思科负责内部PaaS平台的构建相关工作</strong>。</p>
<hr>
<h3 id="2017-07-04：容器化部署OpenStack的正确姿势"><a href="#2017-07-04：容器化部署OpenStack的正确姿势" class="headerlink" title="2017-07-04：容器化部署OpenStack的正确姿势"></a>2017-07-04：容器化部署OpenStack的正确姿势</h3><blockquote>
<p>Q：容器虚拟CPU支持虚拟化吗？</p>
</blockquote>
<p>A：容器只是一个进程服务，依赖于CPU虚拟化。</p>
<blockquote>
<p>Q：Kolla-Ansible部署的OpenStack是否满足生产环境？</p>
</blockquote>
<p>A：完全满足，已有客户上生产环境跑重要业务。</p>
<blockquote>
<p>Q：OpenStack服务的可靠性，主被仲裁，配置变更等，可以怎么管理呢：</p>
</blockquote>
<p>A：OpenStack服务的可靠性，主被仲裁，Kolla和Ansible均支持包括HAproxy等在内的OpenStack服务和Mariadb数据库的高可用性，社区推荐DB使用主主方式；至于管理，使用Ansible。</p>
<blockquote>
<p>Q： OpenStack容器化部署后数据持久化的问题如何解决？</p>
</blockquote>
<p>A：默认情况下，配置文件数据存放在主机的/etc/kolla目录下，数据库数据则在容器中，对于持久化等，可以考虑docker volume等相关方案，多种多样。</p>
<blockquote>
<p>Q：通过Kolla-Ansible部署之后的OpenStack对网络是否有要求，或者需要单独配置网络这块？</p>
</blockquote>
<p>A：使用Kolla-Ansible部署的OpenStack环境，和使用其他方式部署的网络环境一样，管理网、业务网和外网等。</p>
<blockquote>
<p>Q：可否对Kolla-Ansible项目做Socker化，目的是通过这个镜像去部署OpenStack，减少重复配置Kolla-Ansible的运行环境？</p>
</blockquote>
<p>A：Kolla-Ansible只是一个部署工具，做配置管理。可以把Kolla、Ansible和Docker镜像都放在一个部署模板上，通过这个部署模板去任意 部署OpenStack环境，这类似于Fuel ISO。</p>
<hr>
<h3 id="2017-06-30：容器如何监控？"><a href="#2017-06-30：容器如何监控？" class="headerlink" title="2017-06-30：容器如何监控？"></a>2017-06-30：容器如何监控？</h3><blockquote>
<p>Q：有对Docker本身做什么监控么？</p>
</blockquote>
<p>A：可以认为 Docker 监控是类主机监控，只不过是缩小版，基本上分为4部分 CPU、内存、磁盘、网络。</p>
<blockquote>
<p>Q：使用的整套监控工具是哪些？容器CPU 内存网络如何监控？容器事件比如起停如何监控。</p>
</blockquote>
<p>A：整套工具我们使用的是 Cadvisor + Prometheus + Grafana ,当然中间的组件是可以替换的，但基本上围绕着 采集、存储计算、展现来做。采集也可以使用自己的，比如文章说的自己写代理去拿。容器的监控数据当然靠采集程序了。起停这个一般通过监控Docker的事件来实现，采集工具也能收。</p>
<blockquote>
<p>Q：分享的监控图片，有数据的，是使用什么监控工具达成的？</p>
</blockquote>
<p>A：这个分两种，一种是靠底层的绘图引擎，将数据从存储里读出来自己绘制，一种就是用类Grafana的程序。</p>
<blockquote>
<p>Q：如果用Zabbix监控，是否需要定义容器的的历史数据保留时间和趋势数据存储周期，我设定的时历史数据保留7天，趋势数据14天，这样是否合理？</p>
</blockquote>
<p>A：我认为Zabbix 是上一代监控体系，或者以主机为中心的监控体系，如果是容器监控，我建议还是考虑时序类的监控体系，比如Influxdb\Prometheus等，继续刚才的，Zabbix 还可以沿用作为主机的，只是Docker单独分离出来，这样基础建设可以复用。</p>
<blockquote>
<p>Q：建不建议通过Pod中放一个监控容器来监控应用容器，比如Zabbix客户端的监控容器在Pod中，如果这么做优缺点哪些？</p>
</blockquote>
<p>A：Pod 应该是Kubernetes的概念，和容器其实关系不大，这个Kubernetes自己应该会提供数据，具体我不是很清楚。但是 Abbix 还是建议保留在主机层面使用，除非大改，否则即使靠拆分数据库什么的解决，未来维护和性能也是运维大坑。</p>
<blockquote>
<p>Q：做容器监控和JVM监控是否有什么工具可以推荐，感谢。</p>
</blockquote>
<p>A：容器监控现在自己玩套路都是跟着开源走，可以考虑刚才我们的套路，不过可以中间组件任意换，比如存储InfluxDB，JVM，我已知道没有什么好的套路，基本上走跟实例的路子，就是做个小程序跟着程序走，然后提供统一接口用软件抓。</p>
<blockquote>
<p>Q：Cadvisor Heapster 和 Prometheus 哪种好用一些，各自优缺点有哪些。</p>
</blockquote>
<p>A： Heapster 不熟悉， Prometheus 很好，Google 个人的开源项目，都是Google套路，唯独存储是个问题，这块还需要看他们未来如何处理，现在单机存储虽然性能上还可以，但是扩展能力比较差。</p>
<blockquote>
<p>Q：请问如何监控网络带宽，并对带宽进行限制？</p>
</blockquote>
<p>A：带宽监控可以按照容器提供的数据走，还是很准的，具体限制这个是另一个纬度了，属于容器网络，这个坑比较大不适合今天讨论。</p>
<blockquote>
<p>Q：Docker多套环境使用的域名要相同还是不同？如果相同的话如何隔离，如果不同的话如何维护配置？</p>
</blockquote>
<p>A：这个设计到容器服务的网络规划问题，看网络选择。隔离也看网络选型。和之前说的一样这个属于容器网络。坑大。</p>
<blockquote>
<p>Q：监控工具推荐那个？对于容器生命周期短，有何策略应对？容器快速后，如何实现快速监控策略？</p>
</blockquote>
<p>A：监控工具推荐刚才已经说了，可以参考我们的方案然后自己摸索出适合自己的。至于容器生命周期短的问题，这个不就是容器设计嘛，很正常，多起几个相同的服务顶上。容器快速后是什么?</p>
<blockquote>
<p>Q：容器的一大特点是IP或者ID信息变化频繁，这就会导致时间序列数据库存储的监控数据量增长和vm相比大上不少，这块有什么应对方案吗？尝试过固定ID的，但是效果不佳。</p>
</blockquote>
<p>A：这块确实没有什么好办法，不过可以换个角度，你可以将底层的实例抽象一个纬度，比如起了1个服务10个容器，你可以吧容器编号0-9，对应挂掉的容器，新启动继承这个编号。这样从时序上用这个作为标记，这样你就能看比较直观的显示了。这个功能我们SWAN实现了，可以考虑。</p>
<blockquote>
<p>Q：容器的安全如何做监控？</p>
</blockquote>
<p>A：这个问题问的好，现在比较通用的监控基本上走的是两条路，一个是监控性能，一个是监控业务，安全层面监控，到现在我觉得还是要靠网络层来监控比较靠谱。</p>
<blockquote>
<p>Q：Docker启动Kafka集群的问题，有没有控制内存方面的经验呢？</p>
</blockquote>
<p>A：Kafka 集群，性能监控的话，可以沿用原来的 Kafka 集群监控软件，这个我记得原来有一个什么来着，当然如果想做数据汇聚，也可以使用开源软件将数据汇聚到一个数据存储，然后在汇聚出来。关于Docker内存的超出被杀问题，这个主要是看你对于容器内存设置的容忍度问题，这里你大可以把容器当成一个机器，看到底给这个机器插多少内存合适。</p>
<blockquote>
<p>Q：Promethues有没有做高可用？</p>
</blockquote>
<p>A：如果存储高可用的话，可以考虑使用两台Prometheus同时抓，这样数据完全一样，也没啥压力。</p>
<hr>
<h3 id="2017-06-22：Docker的另类用法，就是这么简单粗暴"><a href="#2017-06-22：Docker的另类用法，就是这么简单粗暴" class="headerlink" title="2017-06-22：Docker的另类用法，就是这么简单粗暴"></a>2017-06-22：Docker的另类用法，就是这么简单粗暴</h3><blockquote>
<p>Q：请问从开始看Docker到完成环境搭建大概用了多长时间？</p>
</blockquote>
<p>A：前期的学习和选型用了2个月。后面基础搭建用了1个月，耗时最长的是旧服务的Docker化，这个到现在还没全部完成，因为技术债太多。</p>
<blockquote>
<p>Q：可以说明下为什么生产环境不用Docker吗，跟你们是金融公司属性有什么关系？</p>
</blockquote>
<p>A：因为金融公司对于稳定性有非常高的要求，同时对于生产服务器数量和空置率又不敏感。所以Docker这样的新技术应用还是需要不会那么快切入。同时运维团队也要去学习，技术储备等都是阻碍。所以现在很多银行也只是在周围不重要，变化频繁的系统开始尝试Docker。</p>
<blockquote>
<p>Q：主要想了解下你们集成的流程？</p>
</blockquote>
<p>A：CI的流程和普通的CI类似。代码变动后触发Jenkins，Jenkins会编译，打包，产生一个对应的发布单元的新容器版本。然后触发对应的脚本来停服务，取镜像，启动容器。</p>
<blockquote>
<p>Q：为什么不考虑在私有云平台上玩？</p>
</blockquote>
<p>A：因为资源限制，从硬件及人力上都不足。另外就几十台服务器，没必要。如果有几百台就要考虑资源调度等因素。</p>
<blockquote>
<p>Q：请问容器做编排管理，你们选用什么工具</p>
</blockquote>
<p>A：我们只用了原生的Swarm。这样不用考虑开源软件二次开发及工具间的版本兼容问题。</p>
<blockquote>
<p>Q：如何让宿主机挂载到存储之后，让容器全部跑在存储里面？</p>
</blockquote>
<p>A：容器本身还是在Docker主机的磁盘中，但其他数据：例如配置文件都是从SAN上挂载到容器中。这样保证如果Docker主机down了，容器可以在其他主机上重启恢复。</p>
<blockquote>
<p>Q：z387的ip如何分配？</p>
</blockquote>
<p>A：Contiv会帮你分配IP的，不用自己管理。</p>
<blockquote>
<p>Q：为什么把JIRA也Docker？</p>
</blockquote>
<p>A：因为资源不足，没有强大的主机来跑JIRA，也没有办法主备。所以干脆把这些重要系统都放到容器里。这样就可以用较少的主机来保证性能和可用性。</p>
<blockquote>
<p>Q：镜像带环境变量属性吗？</p>
</blockquote>
<p>A：看情况，我们跑自动化测试的镜像有环境变量属性，因为有很多可变参数。</p>
<blockquote>
<p>Q：如果服务挂了，重启服务。重新修改DNS和Nginx，问题1：服务挂了，Swarm可以负责重启吧？问题2：为什么重启后需要改DNS Nginx。Swarm的ingress网络可以从任何一台node路由到对应的Container吧。</p>
</blockquote>
<p>A：如果镜像down了，Swarm会管理的。但如果是服务不可用，Swarm是不知道的。这时候就需要在服务监控那里触发重启。由于服务还有端口的问题，所以是在Nginx上转发到真实的服务端口上。DNS基本都是配置到Nginx上，如果Nginx挂了，就要把DNS重新指向。</p>
<blockquote>
<p>Q：应用是Java的吗，根据环境不同的配置文件如何处理？</p>
</blockquote>
<p>A：大部分是Java的，也有Python等。我们自己开发了一套配置文件管理的系统，同时对配置文件里的配置项进行命名规范，这样从一套环境到另一套大部分情况是直接自动进行修改的。</p>
<blockquote>
<p>Q：如何做多版本环境隔离测试？</p>
</blockquote>
<p>A：目前我们没有这样的需求。测试环境基本上都是和生产对齐。特殊情况是在Jenkins上来选择特定的代码版本来进行部署。所以在不同的环境里可以部署不同的代码。</p>
<blockquote>
<p>Q：请问Ngin配置的是Container的IP还是物理机IP？</p>
</blockquote>
<p>A：Nginx是暴露出80端口在容器宿主机上的。</p>
<blockquote>
<p>Q：不同环境的配置文件是在镜像层面替换进去还是在容器层面替换进去</p>
</blockquote>
<p>A：是在容器层面的。每个容器上有个Agent，负责去拉取配置文件。</p>
<hr>
<h3 id="2017-06-11：深信服容器云的负载均衡实现"><a href="#2017-06-11：深信服容器云的负载均衡实现" class="headerlink" title="2017-06-11：深信服容器云的负载均衡实现"></a>2017-06-11：深信服容器云的负载均衡实现</h3><blockquote>
<p>Q：HAProxy是在Kubernetes内部对pod互通，是如何实现pod的发现的？</p>
</blockquote>
<p>A：Kubernetes有一个开源机制，叫做ingress模块，提供了pod基于service的发现。</p>
<blockquote>
<p>Q：Haproxy是通过配置模版生成的吗？更新然后重载吗？</p>
</blockquote>
<p>A：是通过配置模板来生成负载均衡的分发规则，我们时刻动态刷新配置，我们重载配置，链接达到0丢失。</p>
<blockquote>
<p>Q：如果你们的HAProxy的lb和ingress一样仅支持四，七层的lb，那么对于Nginx或者traefik的优势在于哪里呢？</p>
</blockquote>
<p>A：各有优缺点，HAProxy更加适用于我们的平台。对于Nginx等，我们更加轻量，更加简单 ，迭代快。</p>
<blockquote>
<p>Q：HAProxy经常reload有性能消耗，怎么做对单个发布的应用进行动态更新？之前新浪有Consul + Nginx？</p>
</blockquote>
<p>A：不存在性能消耗，我们针对于单个应用的动态更新与多个的性能差异很小，因为都是配置 重载。</p>
<blockquote>
<p>Q：如何做到HAProxy重载配置链接0丢失的？</p>
</blockquote>
<p>A：首先重载之前的iptable规则，丢弃握手包，重启之后，去掉规则，达到重载时间内新请求不丢失，原有链接，haproxy提供机制支持，接管原来的链接。</p>
<blockquote>
<p>Q：HAProxy是怎么调用service的？ 直接调用service的群集ip？</p>
</blockquote>
<p>A：基于Kubernetes的listwatch资源监听，通过service对应的endpoint获取到pod的ip。</p>
<hr>
<h3 id="2017-06-10：轻松筹监控系统实现方案"><a href="#2017-06-10：轻松筹监控系统实现方案" class="headerlink" title="2017-06-10：轻松筹监控系统实现方案"></a>2017-06-10：轻松筹监控系统实现方案</h3><blockquote>
<p>Q：针对Grafana不支持的报警，你们自己实现的报警引擎是直接在grafana的基础上修改的么，还是独立于Grafana呢？</p>
</blockquote>
<p>A：我们用Go自己实现的一个报警引擎，独立于Grafana。</p>
<blockquote>
<p>Q：Logstash你们遇到过收集慢和丢日志的情况吗？现在你们Logstash收集日志到什么规模了？</p>
</blockquote>
<p>A：我们目前的日质量大概每天2亿条，高峰时候每小时2000万条左右。Logstash运行的还可以，如果后期遇到手机慢，做简单的方式是扩机器，先解决问题，再想更好的优化策略。</p>
<blockquote>
<p>Q：如果类似于Nginx、MySQL这种日志，类型增加需要解析每增加一个就要去改Logstash的grok吗？</p>
</blockquote>
<p>A：针对常用的服务，grok已经提供了一些正则的pattern，例如你提到的Nginx、MySQL。目前是每增加一个就需要修改grok，后期可以实现一个UI来提高修改效率。</p>
<blockquote>
<p>Q：这个lostash日志格式转换怎么学习？</p>
</blockquote>
<p>A：Logstash有很完善的文档，感兴趣的话可以参考<a href="https://www.elastic.co/guide/en/logstash/current/index.html" target="_blank" rel="noopener">www.elastic.co/guide/</a></p>
<blockquote>
<p>Q：据说Logstash比较吃内存，fluentd作为EFK组合也经常出现，请问你们有没有做过选型呢？</p>
</blockquote>
<p>A：当时选择了ELK，就没有做太多的选型了，Logstash吃内存的问题现在还不是太突出。</p>
<blockquote>
<p>Q：日志的完整性怎么保证的？怎么知道没丢日志，或丢失了多少日志？</p>
</blockquote>
<p>A：Filebeat和Logstash的输出插件都有一些重试的策略，但是也免不了日志丢失。日志的完整性确实和保证日志不丢也是我们目前在尝试解决的问题。</p>
<blockquote>
<p>Q：请问监控系统需要考虑高可用吗？</p>
</blockquote>
<p>A：肯定是要考虑高可用，当后期更多的业务依赖监控系统后，就要保证监控系统不挂，查询要快，实时监控，报警准确等。</p>
<hr>
<h3 id="2017-06-04：如何扩展Kubernetes管理的资源对象"><a href="#2017-06-04：如何扩展Kubernetes管理的资源对象" class="headerlink" title="2017-06-04：如何扩展Kubernetes管理的资源对象"></a>2017-06-04：如何扩展Kubernetes管理的资源对象</h3><blockquote>
<p>Q：需要扩展管理资源对象的场景是什么？能否举个例子说明一下？</p>
</blockquote>
<p>A：举个例子，假如有这样一个场景，Nginx作为反向代理，我们需要非常详细的管理具体配置，并且Nginx的upstream不单单是容器还有许多部署在物理机和虚拟机上的应用，这就要求我们需要具体定义专门管理Nginx的资源对象；由于企业应用场景是十分具体的，也就需要对于资源做具体描述。</p>
<blockquote>
<p>Q：能否讲下具体应用场景和联邦后的用法？</p>
</blockquote>
<p>A：场景上个问题讲过了，关于联邦我目前的方案是在自定义的Controller里做相关联系和操作。</p>
<blockquote>
<p>Q：扩展API Server和通过third party resource +controller的方式相比有哪些优点？支持和多个集群的联邦吗？Kubernetes社区对这两种扩展模式的态度是怎么样的？</p>
</blockquote>
<p>A：首先third party resource在Kubernetes里一直不是很稳定，再者third party resource和原生资源有很多不同（可以参考官方文档），满足一些小的场景可以，但是对于深度定制化（资源之间关联、权限限制等），我还是会选择扩展API Server。</p>
<hr>
<h3 id="2017-06-02：探索Kubernetes的网络原理及方案"><a href="#2017-06-02：探索Kubernetes的网络原理及方案" class="headerlink" title="2017-06-02：探索Kubernetes的网络原理及方案"></a>2017-06-02：探索Kubernetes的网络原理及方案</h3><blockquote>
<p>Q：A的Pod如何连接B的Pod？ kube-dns起到什么作用？kube-dns如果调用kube-proxy？</p>
</blockquote>
<p>A：这里说的A和B应当是指Service，A Service中Pod与B Service Pod之间的通信，可以在其容器的环境变量中定义Service IP或是Service Name来实现；由于Service IP提前不知道，使用引入kube-dns做服务发现，它的作用就是监听Service变化并更新DNS，即Pod通过服务名称可以查询DNS；kube-proxy是一个简单的网络代理和负载均衡器，它的作用主要是负责service的实现，具体来说，就是实现了内部从Pod到Service和外部的从NodePort向Service的访问，可以说kube-dns和kube-proxy都是为Service服务的。</p>
<blockquote>
<p>Q：网络问题docker default是网桥模式（NAT）如果用路由的模式，所以Pod的网关都会是docker 0 IP ？ 那Pod 1与Pod2之间也走路由 ，这会使路由表很大？ Flannel 网络是不是可以把所有的Node上，相当于一个分布式交换机？</p>
</blockquote>
<p>A：Docker实现跨主机通信可以通过桥接和路由的方式，桥接的方式是将docker0桥接在主机的网卡上，而路由直接通过主机网口转发出去；Kubernetes网络有Pod和Server，Pod网络实现的方式很多，可以参考CNI网络模型，Flannel实质上是一种”覆盖网络（Overlay Network）”，也就是将TCP数据包装在另一种网络包里面进行路由转发和通信。</p>
<blockquote>
<p>Q：大规模容器集群如何保证安全? 主要从几个方面考虑？</p>
</blockquote>
<p>A：一个大规模容器集群从安全性考虑来讲，可以分为几个方面：1、集群安全，包括集群高可用；2、访问安全，包括认证、授权、访问控制等；3、资源隔离，包括多租户等；4、网络安全，包括网络隔离、流量控制等；5、镜像安全，包括容器漏洞等；6、容器安全，包括端口暴露、privileged权限等。</p>
<blockquote>
<p>Q：SVC如何进行客户端分流，A网段的访问Pod1，B网段的访问Pod2，C网段的访问Pod3，3个Pod都在SVC的Endpoint中？</p>
</blockquote>
<p>A：内部从Pod到Service的实现是由kube-proxy（简单的网络代理和负载均衡器）来完成，kube-proxy默认采用轮询方法进行分配，也可以通过将service.spec.sessionAffinity设置为”ClientIP”（默认为”无”）来选择基于客户端IP的会话关联，目前还不能进行网段的指定。</p>
<blockquote>
<p>Q：对于Ingress+HAProxy这种实现Service负载均衡的方式，Ingresscontroller轮询Service后面的Pods状态，并重新生成HAProxy配置文件，然后重启HAProxy，从而达到服务发现的目的。这种原理对于HAProxy来讲是不是服务会暂时间断。有没有好的替代方案？之前看到Golang实现的Træfik，可无缝对接Kubernetes，同时不需要Ingress了。方案可行么？</p>
</blockquote>
<p>A：由于微服务架构以及Docker技术和Kubernetes编排工具最近几年才开始逐渐流行，所以一开始的反向代理服务器比如Nginx/HAProxy并未提供其支持，毕竟他们也不是先知，所以才会出现IngressController这种东西来做Kubernetes和前端负载均衡器如Nginx/HAProxy之间做衔接，即Ingress Controller的存在就是为了能跟Kubernetes交互，又能写 Nginx/HAProxy配置，还能 reload 它，这是一种折中方案；而最近开始出现的Traefik天生就是提供了对Kubernetes的支持，也就是说Traefik本身就能跟Kubernetes API交互，感知后端变化，因此在使用Traefik时就不需要Ingress Controller，此方案当然可行。</p>
<blockquote>
<p>Q：1、一个POD里面的多个Container是同一个Service的？还是由不同的Service的组成？是啥样的分配逻辑？ 2、Flannel是实现多个宿主机上的N多的Service以及Pod里面的各个Container的IP的唯一性么？3、Kubernetes具备负载均衡的效果 。那是否就不用在考虑Nigix？</p>
</blockquote>
<p>A：Pod是Kubernetes的基本操作单元，Pod包含一个或者多个相关的容器，Pod可以认为是容器的一种延伸扩展，一个Pod也是一个隔离体，而Pod内部包含的一组容器又是共享的（包括PID、Network、IPC、UTS）；Service是Pod的路由代理抽象，能解决Pod之间的服务发现问题；Flannel的设计目的就是为集群中的所有节点重新规划IP地址的使用规则，从而使得不同节点上的容器能够获得”同属一个内网”且”不重复的”IP地址，并让属于不同节点上的容器能够直接通过内网IP通信；Kubernetes kube-proxy实现的是内部L4层轮询机制的负载均衡，要支持L4、L7负载均衡，Kubernetes也提供了Ingress组件，通过反向代理负载均衡器（Nginx/HAProxy）+Ingress Controller+Ingress可以实现对外服务暴露，另外使用Traefik方案来实现Service的负载均衡也是一种不错的选择。</p>
<blockquote>
<p>Q：kube-proxy是怎样进行负载？ Service虚拟IP存在哪里？</p>
</blockquote>
<p>A：kube-proxy有2个模式实现负载均衡，一种是userspace，通过Iptables重定向到kube-proxy对应的端口上，然后由kube-proxy进一步把数据发送到其中的一个Pod上，另一种是Iptables，纯采用Iptables来实现负载均衡，kube-proxy默认采用轮询方法进行分配，也可以通过将service.spec.sessionAffinity设置为”ClientIP”（默认为”无”）来选择基于客户端IP的会话关联；Service Cluster IP它是一个虚拟IP，是由kube-proxy使用Iptables规则重新定向到其本地端口，再均衡到后端Pod的，通过 apiserver的启动参数--service-cluster-ip-range来设置，由kubernetes集群内部维护。</p>
<blockquote>
<p>Q：Kubernetes网络复杂，如果要实现远程调试，该怎么做，端口映射的方式会有什么样的隐患？</p>
</blockquote>
<p>A：Kubernetes网络这块采用的是CNI规范，网络插件化，非常灵活，不同的网络插件调试的方法也是不一样的；端口映射方式的最大隐患就是很容易造成端口冲突。</p>
<blockquote>
<p>Q：RPC的服务注册，把本机IP注册到注册中心，如果在容器里面会注册那个虚拟IP，集群外面没法调用，有什么好的解决方案吗？</p>
</blockquote>
<p>A：Kubernetes Service到Pod的通信是由kube-proxy代理分发，而Pod中容器的通信是通过端口，不同Service间通信可以通过DNS，不一定要使用虚拟IP。</p>
<blockquote>
<p>Q：我现在才用的是CoreOS作为底层，所以网络采用的是Flannel但是上层用Calico作为NetworkPolicy，最近有一个Canal的结构和这个比较类似，能介绍一下么，可以的话，能详细介绍一下CNI原理和Callico的Policy实现么？</p>
</blockquote>
<p>A：Canal不是很了解；CNI并不是网络实现，它是网络规范和网络体系，从研发的角度它就是一堆接口，关心的是网络管理的问题，CNI的实现依赖于两种Plugin，一种是CNI Plugin负责将容器connect/disconnect到host中的vbridge/vswitch，另一种是IPAM Plugin负责配置容器Namespace中的网络参数；Calico 的policy是基于Iptables，保证通过各个节点上的 ACLs 来提供workload 的多租户隔离、安全组以及其他可达性限制等功能。</p>
<blockquote>
<p>Q：CNI是怎么管理网络的？或者说它跟网络方案之间是怎么配合的？</p>
</blockquote>
<p>A：CNI并不是网络实现，它是网络规范和网络体系，从研发的角度它就是一堆接口，你底层是用Flannel也好、用Calico也好，它并不关心，它关心的是网络管理的问题，CNI的实现依赖于两种plugin，一种是CNI Plugin负责将容器connect/disconnect到host中的vbridge/vswitch，另一种是IPAM Plugin负责配置容器Namespace中的网络参数。</p>
<blockquote>
<p>Q：Service是个实体组件么？那些个Service配置文件，什么部件来执行呢？</p>
</blockquote>
<p>A：Services是Kubernetes的基本操作单元，是真实应用服务的抽象，Service IP范围在配置kube-apiserver服务的时候通过–service-cluster-ip-range参数指定，由Kubernetes集群自身维护。</p>
<hr>
<h3 id="2017-05-24：喜马拉雅FM测试环境的Docker化实践案例"><a href="#2017-05-24：喜马拉雅FM测试环境的Docker化实践案例" class="headerlink" title="2017-05-24：喜马拉雅FM测试环境的Docker化实践案例"></a>2017-05-24：喜马拉雅FM测试环境的Docker化实践案例</h3><blockquote>
<p>Q：镜像精炼影响很大吗？Docker相同层不是只下载一次吗？</p>
</blockquote>
<p>A：我们绝大部分是Java项目，通常一个war包五六十M，更大的也有，占用一个layer。频繁的发布和部署，仅仅是下载这一个layer，时间上还是有一点耗时的。</p>
<blockquote>
<p>Q：网络对于Kubernetes出来容易，进去很难。不知道你们说的物理机和Docker网络是怎么互通的？希望能详细说下。</p>
</blockquote>
<p>A：首先通过docker ipam driver我们为每个容器分配一个IP，Docker本身也支持MacVLAN，不准确的说，相当于每个容器有一个物理网卡，只是和物理机网段不同。我们通过交换机连通两个网段。</p>
<blockquote>
<p>Q：问一下，配置的统一管理是怎么做的？哪些配置信息做了统一管理，数据库的链接信息也是放到配置信息里吗？</p>
</blockquote>
<p>A：可能我文中用配置一词不太对，文中的配置更多指的是，Tomcat的安装目录，Tomcat的Web端口、debug端口号，日志目录命名等约定。这个是做镜像时便已经确定的。</p>
<blockquote>
<p>Q：容器有了固定IP那么就不需要NAT了，那么在原Mesos下的服务发现就不适用了，能详细介绍下这块怎么搞么？</p>
</blockquote>
<p>A：从根本上，不管容器IP变不变，因为以后做扩容缩容，我们认为服务的IP总是会变得。因此我们写了Nginx插件等额外组件来屏蔽IP的变化，而不是尝试让IP不变。</p>
<blockquote>
<p>Q：怎么收集Tomcat启动时的log？ 有没有想过用WebSocket？</p>
</blockquote>
<p>A：我们公司有自己的日志采集系统，可以采集并分析业务日志。至于Tomcat日志，我们业务上暂时还不需要采集。我们有自己的手段来采集Tomcat运行状态。这里顺便说下，很多方案我们的选择，是基于公司目前已有的一些框架工具，大家要按照自己的情况因地制宜。</p>
<blockquote>
<p>Q：将容器的应用端口映射到主机端口，能不能解决IP变化问题？</p>
</blockquote>
<p>A：因为容器会在主机之间漂移，我们通过”物理机IP：物理机port”来访问容器时，容器对应的物理机IP在deploy后，还是会变得。</p>
<hr>
<h3 id="2017-05-19：基于Kubernetes的私有容器云建设实践"><a href="#2017-05-19：基于Kubernetes的私有容器云建设实践" class="headerlink" title="2017-05-19：基于Kubernetes的私有容器云建设实践"></a>2017-05-19：基于Kubernetes的私有容器云建设实践</h3><blockquote>
<p>Q：请教一下处理CI时，比如集群自动化部署方面的粒度是怎样的？比如修复一个bug改了一个class文件，然后本地测试完之后需要到线上部署进AB测试，那么就直接通过CI自动部署到集群服务器吗？</p>
</blockquote>
<p>A：我们的做法是只要有修改就触发重新构建，这只适合我们公司的情况，您可以根据自己的情况做出粒度选择。</p>
<blockquote>
<p>Q：能详细说说Dubbo应用迁移遇到的问题及解决办法吗？</p>
</blockquote>
<p>A：解决方案比较粗暴，对于Flannel，Container可以往出去，但是外面的请求进不到Container，因为我们物理机规模有限，我们就配置静态路由，只要让到达Node的能找到Container就行了。</p>
<blockquote>
<p>Q：自动生成Dockerfile的目的是什么？这样做有什么优势？</p>
</blockquote>
<p>A：这个问题有两个方面，第一个是标准化规范化的问题，我们的应用大多是Java Web，相似度很高，所以可以自动生成，没有什么特殊需要开发自己写的；另外，我们在CI平台里，留出了编辑Docker的口子，也可以针对特殊的情况自己编写，但是这种是非常少数的情况。CI跟每个企业的业务情况紧密相关，还是具体情况具体分析吧。</p>
<blockquote>
<p>Q：我起了一些Pod，对外有Service，然后我想让Pod实现单任务，但问题是，Service对Pod选择机制是随机的，也就是说有可能会出现多个任务请求到一个Pod上，达不到我的要求，怎么解决？</p>
</blockquote>
<p>A：这个问题我个人的理解，您要解决的问题跟一个Service对应多个Pod的场景不太吻合，我建议您考虑其他的方式实现，比如多个sevice-pod的组合等等，或者考虑其他的方式。</p>
<blockquote>
<p>Q：「Kubernetes master高可用」如何设计？多个数据中间是stand-by关系？</p>
</blockquote>
<p>A：API Server是无状态的，可以部署多个，前端负载均衡，Scheduler/ControllerManager有状态可以做成主备。Kubernetes还算稳定（当然我们的量小）。</p>
<blockquote>
<p>Q：贵司使用的Kubernetes版本是？RBD锁死的问题只能通过手动解锁来解决吗？有其他方案吗？</p>
</blockquote>
<p>A：我们上线比较早，生产系统还是1.2版本，我们正在升级1.6版本。RBD我只尝试了手动解锁的方法，别的方法没有尝试。</p>
<blockquote>
<p>Q：想问下关于你们Kubernetes分布式存储的选择，以及在使用当中遇到了那些问题？</p>
</blockquote>
<p>A：我们应用不挂盘，所以使用Ceph的场景不多。使用RBD没遇到什么问题，有些场景我们需要共享存储（Filesystem)，因为我们人手有限，没精力尝试Ceph FS或者其他方式，这算个问题吧。</p>
<blockquote>
<p>Q：在EFK的架构中有Kafka的存在，目的何在？是保证日志不丢失，还是提高吞吐量？</p>
</blockquote>
<p>A：主要是做Buffering缓冲，我们这个里还有个别日志需要中间处理的过程，从Kafka取出加工，再放入Kafka，最后到Elasticsearch。</p>
<blockquote>
<p>Q：能否详细介绍下CI系统考核的重要标准:对常用技术栈和配置进行标准化。具体对哪些指标做了标准化？技术方面如何实现的？</p>
</blockquote>
<p>A：对于Java应用，我们只提供JDK 7和JDK 8，规定日志目录的位置，提供标准的Log4j，配置与代码分离，war包与环境不管等等强制的要求。</p>
<blockquote>
<p>Q：Docker Registry的镜像复制是如何实现的？</p>
</blockquote>
<p>A：跑脚本、docker save、scp、docker load，这种做法比较low，建议直接用Harbor做吧。</p>
<blockquote>
<p>Q：请问Dockerfile自动生成是如何实现的？</p>
</blockquote>
<p>A：根据模板生成了，比如对于Java Web，在规定好日志输出目录等情况系，可变的只是工程名称等很少部分，名称CI系统知道，所以就可以自动生成了。</p>
<blockquote>
<p>Q：kube-proxy 那边性能怎么样？还有一个问题就是一些特定的容器的固定IP是怎么做的？</p>
</blockquote>
<p>A：我们量比较小，没有性能瓶颈，1.2（具体记不清了）以后kube-proxy是纯iptables实现，没那么差吧，业内也有用HAProxy等代替的，个人觉得没必要。特定的容器固定IP我们没有实现，我们没有这种场景。你可以折中一下，给个NodePort，固定IP我个人觉得尽量少用为好。</p>
<blockquote>
<p>Q：镜像的自描述能否展开讲讲呢？</p>
</blockquote>
<p>A：就是每个镜像里都有描述它构建过程的Dockerfile</p>
<blockquote>
<p>Q：对于你们现在使用的这套容器云平台，服务之间的依赖是怎么实现的？怎么区分的环境？另外应用健康检查和追踪用的是什么方案？</p>
</blockquote>
<p>A：服务之间的依赖指什么？如果是应用，他们还是通过Dubbo走，如果是非Java得应用，就通过Service调用。我们在不同的环境部署了Kubernetes集群，每个集群也部署了管理系统，这样就知道每个系统对应哪个环境了。健康检查就是通过Kubernetes的健康检查机制实现的，livenessprobe。</p>
<blockquote>
<p>Q：多数据中心灾备能具体讲一下吗，是在多个dc有多套一样的集群，全部是冷备状态吗？</p>
</blockquote>
<p>A：我们生产有三个数据中心，每次发布，我们都会向每个数据中心发请求，不是冷备，是多活。</p>
<blockquote>
<p>Q：监控体系搭建得细节和监控内容都是哪些，比如CPU内存，Pod事件等，包括告警体系？</p>
</blockquote>
<p>A：这个问题很好，我们这方面做得非常不足，监控的标准我们刚刚拿出细节方案。我们现在的方案是把CPU这些指标输出到日志中心（包含监控报警部分），由日志中心来完成。Pod事件等还没有监控报警。</p>
<blockquote>
<p>Q：日志如何让组件方方便查看同时可以排查问题，比如启动时的日志？</p>
</blockquote>
<p>A：应用日志通过日志中心（ELK）查看；启动日志通过容器云界面查看，通过Kubernetes的API接口实现。</p>
<blockquote>
<p>Q：很多组件有IP白名单的问题，而Kubernetes集群IP经常变换 ，如何解决？</p>
</blockquote>
<p>A：要么改组件，要么在网络层做限制（比如Calico或者其他的），尽量别在Kubernetes层解决。</p>
<blockquote>
<p>Q：容器管理平台是自研的吗？使用何种语言开发的？是全部基于API接口吗？</p>
</blockquote>
<p>A：是自研的，前台AngularJS，后台Golang，全部基于Kubernetes的API，开发过程比较简单，Kubernetes的API设计的非常完善，推荐尝试。</p>
<hr>
<h3 id="2017-05-14：容器技术在企业级服务里的实践"><a href="#2017-05-14：容器技术在企业级服务里的实践" class="headerlink" title="2017-05-14：容器技术在企业级服务里的实践"></a>2017-05-14：容器技术在企业级服务里的实践</h3><blockquote>
<p>Q：请问在容器和虚拟机之间访问网络有什么经验，通过Calico使跨主机之间容器互访，容器外的虚拟机如何访问容器，特别是在公有云环境下PaaS服务如何与容器之间进行访问？</p>
</blockquote>
<p>A：我们现在公有云PaaS每个用户是一个虚拟机的方式，虚拟机内部的通讯采用的默认的网络方式Overlay，在不是大并发情况下这种问题并不明显。</p>
<blockquote>
<p>Q：容器是否裸机部署、容器编排和调度工具？</p>
</blockquote>
<p>A：我们私有云产品是裸机部署，容器编排和调度工具目前有版Kubernetes。</p>
<blockquote>
<p>Q：请问你们的私有云建设主要用了什么软件？</p>
</blockquote>
<p>A：私有云就是裸机+容器+编排工具+基础能力容器（比如消息、SDN等）。</p>
<blockquote>
<p>Q：Auto Scaling是垂直的，还是水平的？</p>
</blockquote>
<p>A：是水平扩展的，就是在另外设备里面重新启动一组容器，并且将数据库容器加入到ge节点中取。</p>
<blockquote>
<p>Q：微服务注册，服务发现是怎么做到的？</p>
</blockquote>
<p>A：微服务注册分成2部分：1. 微服务是否经过了云审核，是否能通过LOTE网关验证；2. 在内部是通过etcd一整套来实现的（健康检查）。</p>
<hr>
<h3 id="2017-05-09：沪江容器化运维实践"><a href="#2017-05-09：沪江容器化运维实践" class="headerlink" title="2017-05-09：沪江容器化运维实践"></a>2017-05-09：沪江容器化运维实践</h3><blockquote>
<p>Q：请问Prometheus具体怎么玩的呢？比如，冷热存储Metrics数据有做什么处理吗？告警只用了Grafana4.0的吗？</p>
</blockquote>
<p>A：可以自己私下看看先关文档，这里一时半会也说不清；Metrics数据时以时序方式持久化在Prometheus中，不做任何处理，基于类SQL方式查询；查询语句中可以设置过滤，或者条件查询；Grafana 4.0及以后才支持报警，同时传统的监控报警也有Zabbix。</p>
<blockquote>
<p>Q：请问不同应用的QoS怎么实现的？容器的租户管理和粒度是怎样的？</p>
</blockquote>
<p>A：流量控制这块可以考虑在HAProxy、或者Nginx这块来做API Gateway；目前我们容器就自己使用，租户管理这块没有细分。</p>
<blockquote>
<p>Q：请问Marathon部署的流程是怎么样的，新版本是替换老版本是创建新的APP，删除老的，还是怎么样的，APP命名规范有没有什么建议。容器部署后如何注册到Nginx上，容器的IP如何与上游Upstream域名进行关联呢？</p>
</blockquote>
<p>A：先按照一定比例（2个）发布新的实例，然后删除老的实例，最终实现实例数目一致；命名最好有规范，防止冲突；Nginx + Consul serve r + Agent + Template可以解决你的所有疑问。</p>
<blockquote>
<p>Q：在此网络环境中是否会出现网络问题导致系统异常？</p>
</blockquote>
<p>A：我们之前遇到过Docker 1.9.1低版本bug导致网络丢包，后来升级了Docker至12.5，问题解决；目前使用内核 4.4.18，Docker 1.13.0，没有任何网络问题。</p>
<blockquote>
<p>Q：问下普罗米修斯的集群这么做的？后端数据库没有没考虑过OpenTSDB呢？</p>
</blockquote>
<p>A：目前单机没有性能瓶颈，如果存在性能问题可以考虑分机房部署，最终的展示和报警统一放在Grafana上面；没有使用OpenTSDB。</p>
<p>以上内容根据2017年5月9日晚微信群分享内容整理。分享人<strong>耿旭东，沪江教育运维架构师。目前主要从事容器技术学习研究、Ceph分布式存储系统维护、沪江部分业务运维相关工作</strong>。</p>
<hr>
<h3 id="2017-05-04：某股份制商业银行定制化PaaS介绍"><a href="#2017-05-04：某股份制商业银行定制化PaaS介绍" class="headerlink" title="2017-05-04：某股份制商业银行定制化PaaS介绍"></a>2017-05-04：某股份制商业银行定制化PaaS介绍</h3><blockquote>
<p>Q：弹性这块，扩容好说，缩的话有个问题，就是还有用户请求在这个容器上，怎么办？</p>
</blockquote>
<p>A： 在该项目中我们并未对这种情况做特殊处理，但是在我们另外的产品中，已经考虑到了该问题。正确的方法应该是基于ingress设置一个销毁容器的宽限时间，即：在这段时间内，不允许新流量导入即将销毁的容器，这些容器在该宽限时间到期后，自动销毁。</p>
<blockquote>
<p>Q：感谢分享，对弹性伸缩部分请教一下:您分享的弹性伸缩的场景业务周期性很明显，所以基于时间区间触发采取不同的伸缩操作，如果业务周期性不明显，伸缩机制能处理吗？如何处理？</p>
</blockquote>
<p>A：在当前项目中，客户明确要求按照1天为周期。在我们自己的PaaS产品线中，弹性伸缩可以调整周期（比如：星期、月份等），另外，还可以不按照时间周期，直接基于CPU、内存或者某一个可监控项。你可以理解为只要能够被监控的监控项，都可以作为弹性伸缩的依据。</p>
<blockquote>
<p>Q：我目前关注的是日志这块，怎么才能把日志集中在一起，能不能说的具体点？</p>
</blockquote>
<p>A：我们是将日志收集后，统一发送到kafka集群，你可以理解为拷贝一份集中存储到kafka集群。这里的集中不是什么难点，难点在于对日志的收集，涉及三个层面：主机、容器、应用。我们的方式是在各台主机上部署容器化后的logstash，然后通过程序修改其配置模板，从而收集不同目录的日志。而这些目录就分别对应着主机日志、容器日志映射到主机的目录、以及应用日志映射到主机的目录。</p>
<blockquote>
<p>Q：根据日志标签获得应用日志目录，请问容器标签具体是什么格式的，采集日志信息中包含节点信息，容器信息，应用信息等跟平台、应用相关的元数据字段吗？</p>
</blockquote>
<p>A：这里的日志标签是可以自定义的，相当于主机上的daemon程序会监听该主机上容器的创建、销毁等event，一旦发现容器创建，就去check其标签，是否有自定义的”日志目录信息”，”日志文件扩展名信息”。这些日志目录都有对应的volume挂载到宿主机上，因此通过分析容器的inspect信息，就能够找到日志目录映射到宿主机的目录。而你提到的节点信息，这些是每个宿主机上的日志收集的服务容器在启动的时候就定义好的，所有由它收集并发送出去的日志，都会有该宿主机的标签。</p>
<blockquote>
<p>Q：关于日志收集的时间取值问题，是日志收集点的本地时间还是系统时间，具体如何保持一致？NTP？</p>
</blockquote>
<p>A：是日志收集点的本地时间，具体通过NTP，但是要注意，需要保障容器时间与宿主机时间（时区）要保持一致。</p>
<blockquote>
<p>Q：弹性伸缩另一个问题，如果不是周期性弹性伸缩是否考虑避免短期脉冲现象引起的不必要的弹性伸缩操作？</p>
</blockquote>
<p>A：所以在弹性伸缩的规则里面有一个参数为：”retrigger time” 也可以把它理解为一个安全的时间片，再一次伸缩动作之后，必须要等待这个时间片结束之后才会再次触发弹性伸缩行为。否则不予响应。</p>
<hr>
<h3 id="2017-04-20：基于Neutron的Kubernetes-SDN实践经验之谈"><a href="#2017-04-20：基于Neutron的Kubernetes-SDN实践经验之谈" class="headerlink" title="2017-04-20：基于Neutron的Kubernetes SDN实践经验之谈"></a>2017-04-20：基于Neutron的Kubernetes SDN实践经验之谈</h3><blockquote>
<p>Q：请问Skynet用到的neutron-linux-agent需要部署到所有kubelet节点上吗？另外有没有开源的demo版本学习下呢？</p>
</blockquote>
<p>A：需要部署，这个Agent不只是安全组，对VXLAN类型的网络，它还可以编写FDB规则实现VXLAN网络。代码开源正在筹划中，再测试一波，就会发布。</p>
<blockquote>
<p>Q：感谢分享，请问你们有没有在在一个虚机内的pod需要挂到不同网络的场景？如果有的话，pod之间跨二层网络的互通你们是怎么做到的？</p>
</blockquote>
<p>A：目前来看，单个POD挂接到不同网络里的场景还比较少，但逻辑上来说，跟设置单网络的方式区别不大，只是默认路由走哪张网卡的问题值得商榷。POD之间跨二层网络互通可以通过物理交换机配置两个VLAN互通或者直接通过Neutron的vRouter做网关。</p>
<blockquote>
<p>Q：还有个问题，当一个Docker物理机down了，上面的容器会自动迁移到另一个节点还是Kubernetes自动启动相关的容器！能否实现特定容器在不同的Kubernetes节点上自动迁移而且保持ip不变！</p>
</blockquote>
<p>A：除非POD指定的调度需求无法满足，Kubernetes会自动尝试迁移POD到其他主机上启动。POD IP的保持还支持通过注解的方式设置POD的IP，当然需要限制RC的副本数只能是1或者运行的是单POD，否则会出现IP冲突。</p>
<blockquote>
<p>Q：容器的port支持Neutron的一些QoS特性吗？例如限速。</p>
</blockquote>
<p>A：据我对OpenStack的调研，Neutron的网络限速使用的是tc规则定义的，在使用Linux bridge+VLAN网络的情况下，Skynet可以保证POD的网络配置与VM的配置一致，从而使QoS规则能够正常运作，实现限速。其他特性暂时还没有研究过，后期会继续调研。</p>
<blockquote>
<p>Q：Skynet目前支持Overlay的网络吗？如何解决内网和外部网络相互访问呢？</p>
</blockquote>
<p>A：目前Skynet支持使用Neutron的VXLAN网络实现Overlay，结合Neutron vRouter的外网网关功能，通过设置路由为vRouter的外网网关，使内外网能够互通。</p>
<blockquote>
<p>Q：请问Veth设备另一端连接的是什么设备？</p>
</blockquote>
<p>A：Veth pair是Linux网络的基础技术，Veth总是成对出现的，所以Veth的另一端还是一个Veth，可以连接到bridge上或者直接暴露在主机上。</p>
<blockquote>
<p>Q：目前OpenStack社区也有一个类似的项目Kuryr，你能简单介绍下你们的方案和Kuryr的差异吗？</p>
</blockquote>
<p>A：Kuryr是社区项目，考虑的不像我们Skynet这么简单，可以短平快地以实现功能为首要目标，而Kuryr需要考虑的就比较多，需要同时支持Docker的CNM和Kubernetes的CNI。我们的Skynet从去年11月份开始调研实现，当时Kuryr的Kubernetes支持还只是个空壳子。现在，根据Kuryr在的BP，我们的实现思路差别不大，只是Kuryr更多的考虑了租户对接等等问题。</p>
<blockquote>
<p>Q：pod的IP保持是怎么做到的能详细介绍一下吗？如果pod名字发生变化了，可以保持吗？</p>
</blockquote>
<p>A：如前面两个类似问题，POD的IP保持通过两种方式：如果POD名称不变（比如StatefulSet中的POD），则对应的port就不会变，因此根据port设置的POD IP、MAC、主机名都不会变。如果POD名称变化，在一定的约束下，通过注解保留POD的IP地址信息，强制使POD保持IP不变。</p>
<p>以上内容根据2017年04月18日晚微信群分享内容整理。分享人<strong>冯建建，天云软件ECP开发工程师，主要负责ECP容器管理平台的网络、存储等方面的功能实现。熟悉CloudStack、OpenStack等开源IaaS平台软件。最近专注于容器集群管理平台的技术实践，包括Kubernetes、Swarm，对它们的网络实现、存储实现都有比较深入的了解</strong>。</p>
<hr>
<h3 id="2017-04-06：从一个实际案例来谈容器落地的问题"><a href="#2017-04-06：从一个实际案例来谈容器落地的问题" class="headerlink" title="2017-04-06：从一个实际案例来谈容器落地的问题"></a>2017-04-06：从一个实际案例来谈容器落地的问题</h3><blockquote>
<p>Q：我想问一下，日志打两份的话具体是怎么实现的呢，用到了哪些技术或现有的工具呢？</p>
</blockquote>
<p>A：我们自己实现了一个log-agent, 然后log-agent 可以实现这个功能。</p>
<blockquote>
<p>Q：如果应用有自己的写的日志，如log4j的，输出不到标准输出，还怎么处理？</p>
</blockquote>
<p>A：log4j貌似是可通过配置输出到标准输出的，另外如果有些应用不能输出到标准输出的，可以配置日志文件路径，我们会去读文件。</p>
<blockquote>
<p>Q：缩容的产生条件是否有比较好的解决方案，比如根据CPU、内存甚至业务规则多维度的进行考察？</p>
</blockquote>
<p>A：缩容很容易，但是麻烦的是如何安全的缩容，我理解这个环节其实是跟应用的逻辑有直接关系的，如果应用是一个无状态的应用，那么缩容非常简单，只需要在前端控制流量，然后停止容器即可，但是如果是有状态的应用，那么就有可能对用户造成影响。</p>
<blockquote>
<p>Q：配置管理这块，不断的覆盖会增加镜像体积，如何最大化减少镜像大小呢？</p>
</blockquote>
<p>A：首先，一个镜像最多被覆盖2，3次，测试镜像一次，生产镜像一次，而且配置文件一般是很小的，几乎对镜像大小没有影响。</p>
<blockquote>
<p>Q：测试环境配置文件覆盖开发环境镜像，是只用测试环境的docket file 吗？如果每天打版，会很麻烦吗？</p>
</blockquote>
<p>A：通过覆盖测试文件来解决环境问题，只是一个思路，不一定非要使用开发测试环境的信息，这个可以具体情况具体分析。</p>
<blockquote>
<p>Q：log-agent具体实现呢，日志直接打给log-agent还是log-agent读取本地日志文件呢？或者说log-agent读取标准输出的内容呢？</p>
</blockquote>
<p>A：log-agent可以通过Docker的log-driver获取标准输出的日志，同时也可以直接读取日志文件的日志。</p>
<blockquote>
<p>Q：配置ENV化完全可以由运维来实现，容器的启动交由脚本来执行，然后在脚本中来读取所有的ENV并修改应用，完成后再启动应用，这样就只需要来维护脚本了。</p>
</blockquote>
<p>A：是个好主意，但是我们当时考虑配置文件覆盖这个方案的时候，是基于开发人员不对代码做任何修改的思路来考虑的。</p>
<blockquote>
<p>Q：容器生命周期很短？如何做到动态监控？你们具体监控了哪些重要指标？谢谢。</p>
</blockquote>
<p>A：我们监控用的是Prometheus方案，监控做了 主机，容器，中间件 几个大的范围。</p>
<hr>
<h3 id="2017-04-02：Flannel中vxlan-backend的原理和实现"><a href="#2017-04-02：Flannel中vxlan-backend的原理和实现" class="headerlink" title="2017-04-02：Flannel中vxlan backend的原理和实现"></a>2017-04-02：Flannel中vxlan backend的原理和实现</h3><blockquote>
<p>Q：Flannel 创建多个网络，并且实现网络之间隔离可以实现吗？</p>
</blockquote>
<p>A：是的，最新的Flannel中已经加入管理多个网络的能力，你可以在启动时制定多个网络，etcd中配置信息的的格式略有不同，启动flanneld时有参数可以制定初始化哪几个网络。&gt; Q：如果使用Flannel过程中发现，跨节点无法访问，该从哪些方便着手排错？</p>
<p>A：首先看一下你指定的虚拟网络是否和现有物理网路中的网段冲突了；然后检查节点之间的UDP端口是否可以连通，最后还需要考虑当前系统是否支持VXLAN，最低要求v3.7，建议v3.9+，CentOS7的默认内核已经可以满足要求。</p>
<blockquote>
<p>Q：过一组测试数据两台VM to VM (vlan): 7.74 GBits/sec，使用flannel vxlan，两个container之间 1.71 GBits/sec，请问这个数据正常吗，vxlan的带宽损耗发生哪, 有啥调优思路，谢谢。</p>
</blockquote>
<p>A：首先我想确认一下你测试的结果是TCP还是UDP，建议实际测试一下，这个是我在Digital Ocean上2台VPS间的测试结果，仅供参考：搞清楚原理以后，相信很容易判断瓶颈位置：节点之间是通过UDP来转发L2的数据包的，我认为这部分可能有比较大的嫌疑。</p>
<blockquote>
<p>Q：Flannel 在使用过程中，如果需要新增网段，如何让每个节点获取最新的路由表信息？需要更新所有节点的Flannel配置项，重启Flannel 吗？</p>
</blockquote>
<p>A：这个问题其实还不错，比较接近实战了；首先你确实可以重启flanneld来更新网络配置；然后Flannel每24h会自动重新分配集群内的网络，所以你就算不重启，每24h也会自动刷新本地网络的，如果发现本地网络配置不符合Flannel在etcd中配置的要求，会重新生成网络配置。</p>
<blockquote>
<p>Q：我在项目中用了flanne lvxlan backend。按照文中说法，转发由内核进行，Flannel挂掉并不影响通宵。但是实际使用中，Flannel挂掉确实导致外部其他访问不到Docker。请问这个可能是什么原因？</p>
</blockquote>
<p>A：首先要澄清一下，并不是说挂掉网络没影响，flanneld挂掉会导致本地的ARP entry无法自动更新，但是已经生成的网络环境还是可用的，具体可以看我前面手动搭建overlay network的过程，根本在于ARP table。</p>
<hr>
<h3 id="2017-03-19：Docker在沪江落地的实践"><a href="#2017-03-19：Docker在沪江落地的实践" class="headerlink" title="2017-03-19：Docker在沪江落地的实践"></a>2017-03-19：Docker在沪江落地的实践</h3><blockquote>
<p>Q：Ceph 集群在使用过程中有遇到过什么坑吗，能否分享一下？</p>
</blockquote>
<p>A：Ceph集群在产线环境上使用的确有很多问题要注意，但这和本次分享没有什么关系，下次我可以分享一些Ceph集群我们遇到的问题及解决方案。</p>
<blockquote>
<p>Q：日志如何进行搜集，出现业务故障时如何快速定位问题或者线上debug？</p>
</blockquote>
<p>A：日志是通过卷挂载Host的方式放在了统一的文件夹下，由Logstash收集后上报ES后通过Kibana展现出来。如果出现故障，运维系统会出现报警，我们根据ELK stack看到问题所在。</p>
<blockquote>
<p>Q：基础架构层的分布式存储是否使用的Ceph，存储集群的规模是多大？</p>
</blockquote>
<p>A：的确，我们使用的是Ceph作为分布式存储。主要使用的是它的file system与Object storage。规模上，OSD有20台，存储容量在900T。</p>
<blockquote>
<p>Q：存储方案为什么需要实现多种volume方案？</p>
</blockquote>
<p>A：由于业务的需要，Docker不但要把日志输出到HOST的磁盘上给ELK使用，还要挂载Ceph文件存储，两者对应的驱动是不一样的，HOST磁盘使用的是Direct-lvm，而Ceph分布式文件存储使用的是ceph-fuse。</p>
<blockquote>
<p>Q：Docker怎么跟现有的业务之间相互访问，网络层IP怎么解决的？</p>
</blockquote>
<p>A：正如刚才我分享的，我们使用Docker Network作为我们网络的解决方案。在Docker Network中，我们创建了一个Overlay网络，容器之间有内部网络，路由表存储在zk中，容器中有两个虚拟网卡，一个对在Overlay中同网段的容器，一个对HOST。Overlay的IP范围是可以设置，建议不要设置太大，容易引起网络风暴。</p>
<blockquote>
<p>Q：使用Docker Network跨主机的容器IP是否能互通？</p>
</blockquote>
<p>A：能，而且必须能，否则这种方案是无法使用的。补充一点，Docker Network还能通过访问控制，来隔离各个Overlay网络的互访。</p>
<blockquote>
<p>Q：网络存储是怎么和Ceph结合的呢，利用Ceph的rbd挂载到主机上吗？</p>
</blockquote>
<p>A：很多公司都是这么做的。不过我们没有这么干，因为rbd是块存储设备，相当于在Docker中挂载了一块裸盘，没有文件系统无法使用。我们还是使用ceph-fuse并使用驱动的形式挂载载Docker内。</p>
<blockquote>
<p>Q：转码是CPU和内存密集型操作，请问当初是基于怎样的考虑上Docker的？</p>
</blockquote>
<p>A：这个问题其实挺有意思，有人大概还不了解转码，其实就是音视频的码率、编码格式转换的处理。例如把一个mp4视屏，转换成HLS切片格式。这的确是消耗CPU和内存的操作。但是，我们有Mesos这个强大的资源管家。如果一个视频过长过大，一台服务器转码速度太慢，可以切成小份让多台服务器一起工作，再合并起来。Docker的优势就体现了，我们把转码称为worker，当每个work接收到任务后，让Mesos调度资源，工作完成后立刻回收资源。这样既不浪费服务器也更能体现微服务，有兴趣的同学可以阅读我的另一片文章：Juice任务调度系统。</p>
<blockquote>
<p>Q：能做到根据压力自动扩容么？</p>
</blockquote>
<p>A：可以的。我们开源一个自动扩容程序，它的主要思想是：定时检查Mesos的Metrics中CPU和内存的占用，如果达到一个阈值，便给Marathon发一个扩容请求，Marathon接收到请求后便可按一定的比例扩充服务。如图所示：</p>
<blockquote>
<p>Q：请教一下关于容器的资源分配和程序切分问题，我有很多服务容器，放的是Java Web Serive，每次启动就占了128m内存，4G内存的主机也就放20个服务，io wait达到 10%，希望能给一些建议，谢谢。</p>
</blockquote>
<p>A：这个问题我们曾经也遇到过。不光io wait高，连Swap区占用都很厉害。后来研究发现了，其实这是Docker CGroup内存隔离的锅。当我们的Docker容器分配过少的内存后，应用程序的内存不够用，Docker会认为物理内存已经占完，会使用交换区，也就是硬盘中的Buffer作为内存，这样就会导致频繁的io交互。在高并发的状态下，io wait就高了。解决方式是，扩大Docker的内存设置。</p>
<blockquote>
<p>Q：传统的Java Web型应用如何放到容器里，一个镜像都要600m左右？</p>
</blockquote>
<p>A：如果使用官方的Java基础镜像，它的操作系统选用的是Debian，自然很大。我们使用的java-jre:alpine镜像，Alpine是最小的Linux集合，只有 5m，加上使用jre，基础镜像只有140多m。Java框架使用Spring Boot，再加上微服务的拆分，一个典型的Web应用也就200m左右。</p>
<blockquote>
<p>Q：Mesos集群本身怎么鉴控？是否可以自动化排除集群故障，如网络异常导致的数据不一致？</p>
</blockquote>
<p>A：Mesos集群由Mesos的master监控着，我们也是用Zabbix等对上面的Mesos服务做着监控。但Mesos中任何Slave有问题，对线上业务不会受到影响，这得益于Marathon这个应用程序的保姆，会自动在可用集群内迁移应用程序。至于网络异常导致数据不一致的问题，我们还真没遇到过，我们大部分的服务是无状态的服务，对有状态的服务一般采用主、从、选主三服务的经典HA方案。</p>
<hr>
<h3 id="2017-03-09：中小型团队的容器化之路"><a href="#2017-03-09：中小型团队的容器化之路" class="headerlink" title="2017-03-09：中小型团队的容器化之路"></a>2017-03-09：中小型团队的容器化之路</h3><blockquote>
<p>Q：我有几个问题请教： 1.底层是否使用了虚拟化？2.技术选项时没考虑Rancher？ 3.健康检查i是否可以动态设置？</p>
</blockquote>
<p>A：底层使用了虚拟化，考虑过Rancher，但是当时太早Rancher非常不稳定，后来还是放弃了，前几天线下跟他们团队交流过貌似重写了，值得大家试试。健康检查的i是逻辑上的，健康检查本身没有这个配置项，i可以通过Scale功能随时调整。</p>
<blockquote>
<p>Q：请问你们是否使用了CI/CD工具？如何贯穿整个应用的周期的？</p>
</blockquote>
<p>A：这个问题太大了，可以另开一个头了。 我们使用Jenkins做CI，生产的CD还有达到，发布的时候都是手动发布人盯着。</p>
<blockquote>
<p>Q：我们目前在用你们的产品，只要用来统计安卓和IOS端的用户行为数据，我们也有自己的容器，并且编排工具是Kubernetes，目前其他还算稳定，就是偶尔出现资源分发时不同集群的状态不一致，请问能否用Marathon去替换解决，是不是代价有点大？</p>
</blockquote>
<p>A：我的建议是继续使用Kubernetes，Marathon并不是完全没有bug，使用过程中同样会有坑在里面，Kubernetes发展很好，只不过Marathon对我们而言更合适。</p>
<blockquote>
<p>Q：问题1. 数据库有用到容器吗？需要注意什么？问题2.生产环境镜像更新，镜像较大，然而每次只更新一个文件，有什么好的建议？</p>
</blockquote>
<p>A：问题1. 测试环境有用到数据库的容器，主要是部署比较方便。生产没有用到，还是性能问题吧。问题2. 基础镜像要选好，不要把容器当虚拟机用，JVM的语言打包出来算大了，也可以控制在200M左右。</p>
<blockquote>
<p>Q：你们是针对每个环境都打包不同的镜像？还是使用同一个镜像？配置管理怎么做的？可以做到配置动态加载吗？</p>
</blockquote>
<p>A：不是针对每个环境打不同的镜像，是把应用本身对环境有要求的选项做成动态的，通过环境变量注入。动态加载需要自己编写工具通过Consul实现。</p>
<blockquote>
<p>Q：你们研发的程序是怎么微服务化的呢？怎么用容器提高研发的效率？</p>
</blockquote>
<p>A：微服务的话题也很大，我们在拆分服务的时候都会再三思考有没有必要，拆分带来的好处是什么。比如说我们把认证这块单独拆分成一个服务，这是根据功能拆分。还有为了提升性能的拆分，不同资源倾斜的拆分。容器带来的最大好处就是打包环境，能做到快速部署。</p>
<p>以上内容根据2017年3月7日晚微信群分享内容整理。分享人<strong>林生生，GrowingIO服务端研发工程师。从事GrowingIO核心系统研发。奉行DevOps，对一切能提高研发效率的技术痴迷</strong>。</p>
<hr>
<h3 id="2017-03-01：基于Jenkins和Kubernetes的CI工作流"><a href="#2017-03-01：基于Jenkins和Kubernetes的CI工作流" class="headerlink" title="2017-03-01：基于Jenkins和Kubernetes的CI工作流"></a>2017-03-01：基于Jenkins和Kubernetes的CI工作流</h3><blockquote>
<p>Q：关于Jenkins和Docker集成的几个插件可以分享一下吗？</p>
</blockquote>
<p>A：Docker Pipeline、Docker Plugin、docker-build-step这几个插件。</p>
<blockquote>
<p>Q：请问有容云的镜像复制大体思路是什么？目前我们是测试、预发布、发布共享一个仓库。通过辅助模块标签实现的。</p>
</blockquote>
<p>A：镜像复制功能，简单来说实现了不同项目间的镜像克隆，根据我们镜像仓库的设计，对不同阶段（开发、测试、可上线）的镜像以不同项目分类，基于镜像复制功能即可快速实现不同阶段的产品发布，也就是镜像发布，此功能可下载AppHouse版本进行试用。</p>
<blockquote>
<p>Q：贵公司的内部仓库和外部仓库镜像是实时同步的吗？你们的配置文件是通过配置中心管理还是镜像间的环境变量实现的？</p>
</blockquote>
<p>A：不是实时同步的，而是通过了我们公司镜像库产品的镜像复制能力实现的。目前开发流程中的产品运行配置是通过自身增强的配置文件能力实现的，配置会用来修改应用部署的YAML文件，也会生成为ConfigMap。</p>
<blockquote>
<p>Q：有没有一个简单的sample，可以上手跟着练习一下？</p>
</blockquote>
<p>A：基于Kubernetes的CICD产品即将发布，会提供对应的demo演示平台，请及时关注，谢谢！</p>
<blockquote>
<p>Q：Kubernetes的YAML的部署文件的模板怎么去替换占位符？旧版本的容器怎么处理？</p>
</blockquote>
<p>A：使用了自身开发的一套文本模板引擎，其实类似Web框架中的模板引擎，完成模板和配置的合并，通过使用配置中的key-value，替换掉模板中key的占位符。另外由于是使用的Kubernetes deployment的rolling update，升级完成后旧版本的容器/pod会由Kubernetes自行删除。</p>
<blockquote>
<p>Q：传统单体应用如何容器化改造，可否分阶段实施？</p>
</blockquote>
<p>A：可以的，容器化改造或微服务化改造有很多实施方法，例如逐渐重构拆解，或新增模块进行微服务化和容器化，或开发新的模块替代原有应用的功能点，等等。各团队均可以选择合适自身的流程来进行改造。</p>
<blockquote>
<p>Q：数据库可以容器化吗？</p>
</blockquote>
<p>A：可通过将数据卷挂入容器的方式将数据库容器化，但是现在实际项目中还很少见。</p>
<blockquote>
<p>Q：有这样一个场景，两个服务有依赖关系，服务A依赖于服务B，如何保证服务A和B的启动顺序的？</p>
</blockquote>
<p>A：良好的设计是使得A服务启动后自行完成对B服务的检测发现和调用，而不是强依赖其启动顺序.</p>
<blockquote>
<p>Q：Kubernetes的服务的模板和配置，这个模板怎么来的，是用户自己编排？还是自己事先准备好的？配置数据是怎么存储的？</p>
</blockquote>
<p>A：因为当前模板和配置只用来启动我们自身开发的应用，因此这个模板是我们自己为我们的应用准备的。配置数据以文件的形式存储，但同时在使用文本引擎做模板和配置合并时，也可以接受参数作为配置。</p>
<blockquote>
<p>Q：什么是CI和CD，这个搞不懂？</p>
</blockquote>
<p>A：CI更多是偏向应用编译，代码检查，单元测试等动作，CD是偏向于应用部署，运行流程。我们的开发过程在编译打包完成后，实际也会将应用跑起来用于测试，也可以算是针对测试的CD。</p>
<blockquote>
<p>Q：使用容器打包Jenkins流程的主要收益是什么？</p>
</blockquote>
<p>A：由于不同程序对于编译环境的依赖各有不同，原有使用Jenkins方法是在Jenkins node上完成环境准备，现在可以利用容器完成环境准备，对于Jenkins node的依赖可以进一步降低。同时环境变更也可以由开发人员自行控制。</p>
<blockquote>
<p>Q：多编译环境是用的不同镜像么？如何处理Pipeline处理编译环境的问题？</p>
</blockquote>
<p>A：是的。由于我们本身产品开发各个模块有各个模块的开发语言和框架，因此各模块都要维护自身的编译环境镜像。使用Pipeline在进行编译时，是通过使用镜像运行容器然后在容器内编译的方式来使用编译环境的。</p>
<blockquote>
<p>Q：请问Jenkins也是部署在Docker里面的吗？如果Jenkins在Docker里面怎么样在Docker里面使用Docker执行CI？</p>
</blockquote>
<p>A：是的，我们也在摸索将Jenkins本身放到容器中运行。在这种情况下，Jenkins容器内使用root权限，挂载docker.sock和Docker数据目录到容器中就可以了。</p>
<blockquote>
<p>Q：使用Pipeline先构建编译环境镜像，再编译，是否会导致整个流程需要很长时间？是否有优化方案？</p>
</blockquote>
<p>A：编译镜像由于不会经常变动，因此这个镜像的构建通常使用cache就能直接完成，另外我们也把编译环境镜像打包这个步骤抽出来单独作为job执行了，这样在实际编译流程中就无需再进行编译环境构建。</p>
<blockquote>
<p>Q：Jenkins和Kubernetes的用户是怎么管理的？我的期望是用户只能看到自己得资源，别的用户是没有权限的。</p>
</blockquote>
<p>A：我们本身只是使用这两种工具，在开发环境中不对外，所有不存在用户管理的问题。在我们公司正在开发的CICD产品中，对这块有我们自身理解基础上的设计。</p>
<blockquote>
<p>Q：Jenkins的持续集成是怎么实现的？比如不同的源码仓库的提交触发，如GitHub、GitLab版本号怎么控制的？</p>
</blockquote>
<p>A：Jenkins的CI流程触发可以有很多种，代码提交触发，定时触发，手动触发。版本号的控制也可以有很多方案，比如使用job的编号，使用Git的commit号，使用时间戳等等。</p>
<blockquote>
<p>Q：容器化后发布也要通过Jenkins，感觉Docker的发布没有Jenkins方便，除了容器化的可移植，还有什么原因值得推进项目容器化？</p>
</blockquote>
<p>A：应用容器化，其实更多的是看重应用在容器管理平台上运行起来后所获得的能力，例如在Kubernetes上运行后的水平扩展，服务发现，滚动升级，等等。</p>
<blockquote>
<p>Q：Kubernetes update需要制定新的镜像才能做滚服更新（升级），如果只是更新了ConfigMap，有办法做滚服更新吗？</p>
</blockquote>
<p>A：我们的CI流程完成后，各模块的镜像tag会发生变化，我们利用具体生成的tag生成配置，然后部署的YAML文件写为模板，镜像的具体tag会根据每次CI流程生成的配置不同而组合为不同的YAML文件，然后使用组合后的yaml，即tag已经变更为最新版本的YAML文件进行应用的滚动升级。</p>
<blockquote>
<p>Q：Pipeline采用在镜像里构建的方案，是怎么实现的？用Jenkins现成的插件 or 用Groovy脚本实现？</p>
</blockquote>
<p>A：使用了Jenkins的Docker插件，同时使用方式是将相应命令写在Groovy脚本里，例如：<code>stage(&#39;Build&#39;){docker.image(&#39;golang:1.7&#39;).inside { sh &#39;./script/build.sh&#39;   }  }</code>{.prettyprint}。</p>
<p>以上内容根据2017年2月28日晚微信群分享内容整理。分享人**黄文俊，有容云资深系统架构师。主要负责容器云平台产品架构及设计，8年工作经验，有着企业级存储，云计算解决方案相关理解。关注于微服务设计思考，开发流程优化，Docker及Kubernetes技术在实际环境中的应用。</p>
<hr>
<h3 id="2017-02-22：SRE工程实践——基于时间序列存储数据的报警"><a href="#2017-02-22：SRE工程实践——基于时间序列存储数据的报警" class="headerlink" title="2017-02-22：SRE工程实践——基于时间序列存储数据的报警"></a>2017-02-22：SRE工程实践——基于时间序列存储数据的报警</h3><blockquote>
<p>Q：告警信息收到后，系统有没有能力自动解决告警报告的问题？还是需要人工解决问题？谢谢</p>
</blockquote>
<p>A：这个要分情况，好的机制是报警应该发出的是新的问题，然后通过反馈机制，让同类的问题不再发生，或者由监控系统自身解决。</p>
<blockquote>
<p>Q：InfluxDB系列方案是否有考虑，Grafana 最新版也有了很好的告警机制，是否有尝试？</p>
</blockquote>
<p>A：曾经考虑并实践过InfluxDB的TICK组合方案，非常方便可以实现数据收集存储处理展示的完整流程。通过对比，我们发现Prometheus更符合Google SRE对于监控的理念，自身社区也非常活跃，就转向Prometheus的方案了。Grafana实现了强大的可视化配置报警规则的功能，对于原本只做为展示的工具，是很好的增强，这个对我们的启发也很大，也在学习中。</p>
<blockquote>
<p>Q：报警规则配置是什么语法，是否可以可视化？</p>
</blockquote>
<p>A：Prometheus是在配置文件中描述报警规则。可以自己动手实现可视化。</p>
<blockquote>
<p>Q：数据量庞大的情况怎么解决，比如说万台机器，500个指标数据等一分钟一个点 60<em>2430</em>50010000 的数据量，如何保存，如何快速查询数据。需要什么样的架构和硬件？</p>
</blockquote>
<p>A：简单回答，Prometheus可以通过分组支持大规模的集群，但是达到某个确定的规模，那就需要实践给出答案了。</p>
<blockquote>
<p>Q：请问在监控报警方面有没有考虑或实践过智能预警，比如基于历史监控数据，通过机器学习，实现提前预警等？</p>
</blockquote>
<p>A：这个不是SRE推荐的方式，报警应该简单，高级的功能会模糊真实的意图。</p>
<blockquote>
<p>Q：请问基于此方案部署的主机和容器规模有多大，基于什么频率进行监控收集？</p>
</blockquote>
<p>A：本次分享的是测试环境，规模不大。Prometheus定时从cAdvisor收集数据，抓取频率5s。</p>
<blockquote>
<p>Q：cAdvisor采集数据的性能表现怎么样，占用主机的资源大嘛？</p>
</blockquote>
<p>A：性能表现优异，担心占用资源，可以在启动容器时进行资源限制。</p>
<blockquote>
<p>Q：APP自身业务逻辑需要监控的数据，比如Counter，Gauge等，传统用Zabbix等可以进行数据采集。我明白cAdvisor是对Container进行数据采集。但是有没有可能把APP自身的监控和Container的监控结合？</p>
</blockquote>
<p>A：后续话题，我们会实践有关应用的监控报警。Prometheus的逻辑是定时从exporter抓取数据，然后对存储的时序数据，通过PromQL进行查询和分析，所以是可以实现APP自身的监控和容器监控的结合的。</p>
<p>以上内容根据2017年2月21日晚微信群分享内容整理。分享人**窦中强，数人云研发工程师。多年运维开发经验，熟悉配置管理，持续集成等相关技术和实践，目前负责数人云平台监控报警组件的研发工作。</p>
<hr>
<h3 id="2017-02-15：乐视云基于Kubernetes的PaaS平台建设"><a href="#2017-02-15：乐视云基于Kubernetes的PaaS平台建设" class="headerlink" title="2017-02-15：乐视云基于Kubernetes的PaaS平台建设"></a>2017-02-15：乐视云基于Kubernetes的PaaS平台建设</h3><blockquote>
<p>Q：你们的IP管理应该做了很大的开发工作吧？能详细介绍一下？</p>
</blockquote>
<p>A：确实做了很多开发工作，其中很大的一个开发量是关于空闲IP获取这块。</p>
<blockquote>
<p>Q：还有你们的灰度发布是用的Kubernetes本身滚动更新功能？还是自己实现的？</p>
</blockquote>
<p>A：灰度发布没用Kubernetes 的滚动更新更能，而是用了不同的RC的相互切换。</p>
<blockquote>
<p>Q：多个Region的镜像管理，如何实现镜像同步与更新？</p>
</blockquote>
<p>A： 我们不需要实现镜像的同步。分享中已经提到过，各个Region有自己的镜像仓库。</p>
<blockquote>
<p>Q：你好请问你们大二层网络是用开源方案实现的还是自己根据OVS开发实现的？</p>
</blockquote>
<p>A：是我们自己实现的，我们CNI中调用了OVS，主要是使用了OVS的网桥功能。</p>
<blockquote>
<p>Q：应用跨机房部署，我理解也就是可以跨Kubernetes集群部署，Kubernetes里的调度是如何做的？</p>
</blockquote>
<p>A：应用的概念，是在Kubernetes集群之上的，应用可以部署在多个Kubernetes 集群中。</p>
<blockquote>
<p>Q：请问贵公司内部服务之间的互相调用是怎么控制的？容器到容器还是容器-Nginx-容器（等同外部）？</p>
</blockquote>
<p>A：1. 容器-&gt;容器 2. 外部服务-&gt;Nginx-&gt;容器 3. 容器-&gt;Nginx-&gt;容器 4. 容器-&gt;外部服务。 这种情况都有，主要看业务场景。</p>
<blockquote>
<p>Q：构建服务集群用到什么CI工具，还是自己开发的？etcd在其中有什么作用？</p>
</blockquote>
<p>A：自己开发的，etcd 相当于消息队列，控制层收到构建请求后，etcd中存放了现阶段集群下都有哪些构建机，当来到构建请求后，控制层会寻找一个构建机器，并向构建机器所在的etcd key中发送命令， 对应的构建机器在监控自己的key发生变化后，会执行相应的构建任务。</p>
<hr>
<h3 id="2017-01-18：度量驱动的DevOps转型"><a href="#2017-01-18：度量驱动的DevOps转型" class="headerlink" title="2017-01-18：度量驱动的DevOps转型"></a>2017-01-18：度量驱动的DevOps转型</h3><blockquote>
<p>Q：基于Jenkins的CI/CD不同用户是怎么管理的 ？权限怎么控制的？</p>
</blockquote>
<p>A：在DevOps实施里面提倡充分授权团队，所以在基础设施自服务的基础上让团队有自己独占的Jenkins Master能够有效的减少权限控制此类问题，同时可以避免不同团队之间构建任务的相互影响；如果是共用JenkinsMaster，Jenkins有权限控制的插件可以控制用户的权限。</p>
<blockquote>
<p>Q：刚才你介绍的CI整个交付流程，每个细节都需要花大量的时间和精力去开发和实施，如果公司团队很多，如果分配自己团队的时间，时间少了自然达不到效果。</p>
</blockquote>
<p>A：在实施DevOps转型过程里面，可以先尝试试点团队，通过试点团队去完成DevOps工具链相关的技术选型，在工具链成熟的情况下向其它团队推广。</p>
<blockquote>
<p>Q：请问你们有DevOps的自动化运维平台吗？可能是一个Web页面，把DevOps相关的流程和工具集成在上面，方便管理的同时也方便运维开发一体化操作。这个平台可能还包括全链路检测系统？</p>
</blockquote>
<p>A：目前我们公司做的基于容器持续交付平台主要就是解决此类问题，通过流水线来组织工具链，同时对相关的环节进行度量，为避免广告嫌疑就不便多说。</p>
<blockquote>
<p>Q：你们在这个过程中怎么做沟通管理，以防止因为这造成的对需求理解的偏差等问题？</p>
</blockquote>
<p>A：这块更多是团队的组织结构的问题，有兴趣可以尝试通过看板方法，团队的各个角色都会基于看板完成迭代的开发，通过看板可以帮助团队成员之间的沟通和需求确认。</p>
<blockquote>
<p>Q：因为很简单，持续集成持续交付，快速迭代，小步快跑，稳扎稳打，这些都有所有的理论最后都回归到代码，所有的变更都回归到本源代码的变更，如何保障所有的变更无遗漏，如何保证每一次任务都在正确的代码基准线上进行，如何出了问题快速反馈到研发第一线，及时终止问题的蔓延？</p>
</blockquote>
<p>A：这块其实主要的方式就是基于持续部署流水线的方式，上面分享的时候有提到。通过将流水线通过自动化流水线的方式进行控制，在任何阶段出现问题都应该让流水线失败（门禁），另外出问题不怕，快速解决问题是关键，对于流水线最好可以设置Webhook实时触发，可以确保当问题出现后，问题代码的域可以关联到最近的一次提交。</p>
<blockquote>
<p>Q：请问你们容器发布是如何自动区分开发、测试、正式等不同环境的，是否需要人工介入修改应用访问关系和启动环境变量？</p>
</blockquote>
<p>A：目前我们自己持续交付平台对接不同的容器运行环境（目前主要是Rancher），团队会对环境进行分类管理，流水线中进行容器部署的时候选择相应的环境即可；另外由于主要是基于容器在做，所以也对容器镜像的不同状态也进行了划分，并且在多个Registry实例之间进行了流转，物理隔离了开发，测试以及发布状态的容器镜像。人工介入的部分主要是控制镜像状态的变化这块。</p>
<blockquote>
<p>Q：Jenkins的Pipeline和普通的Project都可以支持流水线 ，2者有区别吗？</p>
</blockquote>
<p>A：主要解决的问题就是当构建出问题的时候如何快速定位问题，假如在流水线线中涉及8个阶段，如果只是在一个Project中实现，需要开发者花很多时间定位；如果是Build Pipeline的话，则可以很直观的知道问题是发生在什么阶段。</p>
<hr>
<h3 id="2017-01-17：艺龙部署体系的演进"><a href="#2017-01-17：艺龙部署体系的演进" class="headerlink" title="2017-01-17：艺龙部署体系的演进"></a>2017-01-17：艺龙部署体系的演进</h3><blockquote>
<p>Q：麻烦问一下，桥接的网络是给容器的分配一个物理网络的IP吗？另外依据什么来确定每台主机运行多少容器？</p>
</blockquote>
<p>A：是的，我们给每个容器分配了一个物理网络的IP，我们根据目前我们物理机的规格去制定的容器数量，目前每台物理机分配上限是64个。</p>
<blockquote>
<p>Q：Docker存储考虑过Overlay当时吗？据说这种构建镜像比较快。</p>
</blockquote>
<p>A：考虑过，当时也做过各个方面的测试，这种增量式的构建，肯定最快，但是我们需要有专人从源码级别对其进行维护，成本对于我们还是有点高，我们后期打算采用环境和代码分离的方式，即环境部署一次，代码多次部署来提升效率。</p>
<blockquote>
<p>Q：.net不是也可以跑到Linux上了吗？有.net镜像吧？</p>
</blockquote>
<p>A：我们调研过，但是这个技术太新了，稳定是我们使用一个新技术的前提，而且我们的.net服务大多已经是很多年前的老服务，折腾起来比较费力，暂时.net方面我们只能搁置，但是也会继续跟进。</p>
<blockquote>
<p>Q：请问没有采用ZooKeeper和etcd而选择自研的原因是什么？是否如何进行技术对比的？</p>
</blockquote>
<p>A：就是我刚才说的，对于ZooKeeper来说，ZooKeeper基于Java编写，在GC层面存在一定的问题，数据量过大时候会导致服务可用性降低，我们希望用他做配置管理，我们甚至有一些上M的配置文件，最终的配置无论是配置项，还是最终大小，都会是一个比较大的量级。二是我们阅读了它的源码，它的Recovery在检测不一致时处理也比较暴力，同时ZAB协议较复杂，这个从它的论文上就可以看出来，因此运维起来成本较高。</p>
<hr>
<h3 id="2017-01-15：Kubernetes-有状态集群服务部署与管理"><a href="#2017-01-15：Kubernetes-有状态集群服务部署与管理" class="headerlink" title="2017-01-15：Kubernetes 有状态集群服务部署与管理"></a>2017-01-15：Kubernetes 有状态集群服务部署与管理</h3><blockquote>
<p>Q： 前面提到Init Container，Kubernetes里Pod初始化是基于GCR的pause，这个初始化镜像是自定义的吗？</p>
</blockquote>
<p>A：Init Container和GCR的Pause是不同的概念，一个是初始化容器（运行完就结束），一个是基础容器（一直运行）。</p>
<blockquote>
<p>Q：你介绍的Kubernetes存储技术都是比较新的，能否适应企业生产大规模使用，有没有什么性能和稳定性问题？</p>
</blockquote>
<p>A： 性能和稳定性上我们也在不断尝试，先使用起来看看效果，目前创建过几百个集群，暂时没有碰到太多稳定性问题。</p>
<blockquote>
<p>Q：存储系统如何动态创建StorageClass，如果 Headless Service没有Cluster IP，服务如何调用？</p>
</blockquote>
<p>A：Kubernetes通过StorageClass 让存储系统动态创建PV，不是动态创建StorageClass。Headless Service 用于集群内部通信，外部调用，再建普通Service，二者并存。</p>
<blockquote>
<p>Q：有状态集群还有其他的实现方式吗？</p>
</blockquote>
<p>A： 在容器云里比较好的方式是用PetSet，当然也能自己做，相当于自己实现PetSet的一些功能。</p>
<blockquote>
<p>Q：同步到整个集群才算写入成功，是不是意味着不适合高负载的项目使用？有可能增加其它策略供选择吗？</p>
</blockquote>
<p>A：由于采用多主方式，对外只写入一个，内部扩散同步可以并行，而且每个节点都能对外提供服务，相当于增加了服务带宽，所以性能不是问题。</p>
<blockquote>
<p>Q：您好，你们是采用什么分布式存储的，io性能如何？好像一些开源分布式的存储写io的性能普遍比较低，能撑得住一些io高性能的应用吗？</p>
</blockquote>
<p>A： 性能上要等到支持host 模式后，才能满足一些IO要求比较高的场景</p>
<p>以上内容根据2017年01月10日晚微信群分享内容整理。分享人**张寿红，时速云架构师。从事软件研发工作十余年，目前从事基于Docker和Kubernetes的企业级容器云平台研发工作，主要包括容器服务、存储服务、CI/CD和镜像服务等。在加入时速云之前，先后在CATechnologies和Symantec担任Tech Lead和Principal Software Engineer。参与研发的软件产品有：企业数据保护软件、云平台上的服务管理系统、企业客户服务平台等。</p>
<hr>
<h3 id="2017-01-06：基于容器的日志管理实践"><a href="#2017-01-06：基于容器的日志管理实践" class="headerlink" title="2017-01-06：基于容器的日志管理实践"></a>2017-01-06：基于容器的日志管理实践</h3><blockquote>
<p>Q：Overlay 是没有实现 inotify 接口的，是咋获取文件日志增量数据的？</p>
</blockquote>
<p>A：通过循环读取文件的方式，记录文件offset。</p>
<blockquote>
<p>Q：既然主要框架是 ELK，采集端不直接用 Filebeat 是因为 Filebeat有局限性吗？</p>
</blockquote>
<p>A：Filebeat没有满足我们产品基于Docker的需求，等于上面加了Docker的逻辑。</p>
<blockquote>
<p>Q：自研的日志系统，打出来的每条日志格式都是规定好的吗？开发中每个人都要按这个规范来做吗？不管是什么级别的日志？</p>
</blockquote>
<p>A：其实并没有，但是如果是内部使用，能规约好当然更好，可以更方便的处理，而且可以做更细粒度的分析。</p>
<blockquote>
<p>Q：日志收集有做分析展示处理吗？用什么处理的。</p>
</blockquote>
<p>A：对于日志内容的分析还没做，例如Nginx请求日志还是有分析意义的。</p>
<blockquote>
<p>Q：采集方面有考虑直接使用系统的Syslog和Logrotate吗？</p>
</blockquote>
<p>A：用过Syslog后来因为容器内的文件日志需求重新开发的。</p>
<p>以上内容根据2017年1月5日晚微信群分享内容整理。分享人郭已钦，数人云研发工程师。早期从事Java&amp;JavaScript开发，爬虫大数据开发，之后开始写Go，参与开源容器管理工具Crane的研发与维护，目前在数人云做云平台研发工作。</p>
<hr>
<h3 id="2017-01-03：构建容器服务平台（CaaS）"><a href="#2017-01-03：构建容器服务平台（CaaS）" class="headerlink" title="2017-01-03：构建容器服务平台（CaaS）"></a>2017-01-03：构建容器服务平台（CaaS）</h3><blockquote>
<p>Q：跨区域的容器集群间是否能通信？</p>
</blockquote>
<p>A：目前跨区域机器不能通讯。跨区域之间机器是租户完全隔离。如果租户需要通讯，需要针对具体机器进行开墙。</p>
<blockquote>
<p>Q：请问使用DeviceMapper其中遇到了那些问题？</p>
</blockquote>
<p>A：最常遇到的是device busy。会导致容器无法删除。此时需要人工干预。</p>
<blockquote>
<p>Q：镜像管理如果只是基于distribution的话，权限与多租户管理是如何实现的？</p>
</blockquote>
<p>A：权限纳入平台管理，由我们自行实现。租户之间的镜像不可共享。租户内的可共享和私有。 租户间的镜像必须通过发布，由平台审核方能在各个区域和各个租户间共享。</p>
<blockquote>
<p>Q：监控是用什么语言开发的，是自主开发还是用开源的？</p>
</blockquote>
<p>A：监控，我这边针对镜像和容器这块做了一些监控数据的收集，然后提供给监控平台。监控平台由部门另外一组开发。目前基于Zabbix进行开发。</p>
<blockquote>
<p>Q：请问：1. DockerHUB只有一个实例吗？如何保证高可用？2. DockerServer间同步的是什么内容呢？Docker事件？</p>
</blockquote>
<p>A：所有区域，包括pub和mirror，都是keepalive+lvs搭建。目前使用双registry+共享nas。而这两个Registry所在的vm是跨az。也就是一个Registry宕完全不影响另外一个提供。而nas是双写nas，我们这边的存储组提供的DNAS服务。备份策略也是可以根据自己定义。</p>
<blockquote>
<p>Q：pub hub获取docker hub 镜像的方式，目前是自动维护吗？</p>
</blockquote>
<p>A：不是，从docker hub进入公司官方镜像仓库，都是人工维护同步。我们需要针对一些镜像做特殊处理。</p>
<blockquote>
<p>Q：IPsec的性能传说不是很好，你们有遇到过网络的问题吗？Rancher 的IPsec网络性能怎么样？容器有涉及到弹性伸缩吗？容器间采用Rancher 实现网络通信，为什么没有选择类似组件？</p>
</blockquote>
<p>A：这3个问题统一回答。目前是使用IPsec。由于当前每个Rancher对接的容器数目不是特别大，还没产生网络问题。另外对外网络走的是云主机网络。 有考虑过其他组件，由于之前起步阶段，所有直接采取rancher提供的。最近Rancher提供支持CNI的方案。目前正在研究对应的组件。</p>
<blockquote>
<p>Q：我能想到的一个方案是自己的用户体系加云平台的租户和云平台的用户体系，多对1的映射，当审核通过后，使用不同的云平台用户，这样权限就不一样了。是这样吗？</p>
</blockquote>
<p>A：目前容器服务只针对公司内部开放，直接兼容云平台租户。</p>
<blockquote>
<p>Q：请问内核版本是？用4.9的计划吗？平安云是OpenStack吗？用Magnum吗？</p>
</blockquote>
<p>A：使用CentOS 7.2，内核版本是3.10.xxx,平安云使用Cloud Foundry，平安云使用了多种虚拟机，VMware和KVM是主要。</p>
<blockquote>
<p>Q：容器是跑在物理机上还是虚拟机上，容器所在的操作系统归租户所有还是运营商所有？容器的分配规则由谁决定？一个宿主机跑多少个容器由谁决定？</p>
</blockquote>
<p>A：目前资源限制还是交给Rancher来管理，我们对Rancher的规划是：让Rancher管理资源，分配容器。在页面提供Docker目前支持的资源参数。 容器所在的操作系统归租户所有。租户可以任意添加自己的云主机到容器华环境中。</p>
<blockquote>
<p>Q：目前这个系统是内部用的吧？安全性有没有考虑？</p>
</blockquote>
<p>A：安全：目前针对公司内部，使用公司AD认证登录。而计算资源限制采用租户隔离。镜像这块安全采用主机互信。</p>
<blockquote>
<p>Q：很多业务日志是不直接输出到stdout的，这些业务日志如何搜集？容器日志的采集采用什么方式？容器规模大约有多大呢？当采集方出现采集中断的时候会有报警提示吗？打入到es后，做了哪些比较有效的报表数据呢？</p>
</blockquote>
<hr>
<h3 id="2016-12-18：海航生态科技舆情大数据平台容器化改造"><a href="#2016-12-18：海航生态科技舆情大数据平台容器化改造" class="headerlink" title="2016-12-18：海航生态科技舆情大数据平台容器化改造"></a>2016-12-18：海航生态科技舆情大数据平台容器化改造</h3><blockquote>
<p>Q：Spark直接运行在Mesos不是很方便么，容器化优势是否明显？主要考虑点在哪？</p>
</blockquote>
<p>A：容器化主要考虑两点:一 解决海量数据计算的资源编排问题 ，未来也会基于CaaS云提供服务 , 二 研发体系的敏捷化与标准化问题。我们正在考虑根据计算需要实现弹性伸缩，容器化是一个助力。</p>
<blockquote>
<p>Q：请问为什么Elasticsearch，而没有选择Solr呢？</p>
</blockquote>
<p>A：在有索引下，ES性能会要好一些，而且它原生分布式支持，安装配置也简单。</p>
<blockquote>
<p>Q：代码没有打包进镜像中是出于什么原因？</p>
</blockquote>
<p>A：这样部署运行会更灵活，我可以代码放到本地，也可以上传到实例中。代码提交比较频繁，执行环境变化却不大，只替换变换的部分部署会更快速。主要是为了适应目前这种部署方式。</p>
<blockquote>
<p>Q：爬虫容器如何调度，是分布式吗？</p>
</blockquote>
<p>A：是分布式的，这个是按时间定时运行的，Rancher提供的crontab，爬虫程序提供执行入口。</p>
<blockquote>
<p>Q：HBase主键设计依然没有解决热点问题？</p>
</blockquote>
<p>A：确实未完全解决，基于时间序列的暂时未找到更好的rowkey设计方法；把他分成24小段，加入时间，单独对每段来说，它是按时间排序的，也算是一种折中。</p>
<p>以上内容根据2016年12月13日晚微信群分享内容整理。分享人<strong>高颜，就职于海航生态科技技术研究院，任职大数据开发工程师，从事大数据平台应用开发年，负责大数据平台技术选型，架构设计及代码开发工作</strong>。</p>
<hr>
<h3 id="2016-11-23：爱油科技基于SpringCloud的微服务实践"><a href="#2016-11-23：爱油科技基于SpringCloud的微服务实践" class="headerlink" title="2016-11-23：爱油科技基于SpringCloud的微服务实践"></a>2016-11-23：爱油科技基于SpringCloud的微服务实践</h3><blockquote>
<p>Q：你们是部署在公有云，还是托管机房？</p>
</blockquote>
<p>A：我们部署在阿里云上，使用了很多阿里云服务作为基础设施，这一点是为了节约运维成本。</p>
<blockquote>
<p>Q：怎么解决服务过多依赖问题？开发也会有麻烦，因为要开发一个功能，为了把服务跑起来，可能要跑很多服务。</p>
</blockquote>
<p>A：在我们的实际开发过程中，也遇到了这个问题。主要的是通过部署几个不同的仿真环境，一组开发者可以共用这组环境。本地开发也很简单，只需要把Consul指向到这个集群的Consul上即可。</p>
<blockquote>
<p>Q：你们微服务业务调用最深有几层？restful接口调用链的效率如何？比单体结构慢多少？</p>
</blockquote>
<p>A：一般不超过3层，这是领域驱动设计给我们带来的优势，单个服务几乎自己就能完成职责范围内的任务，没有出现RPC灾难，一个业务我们也不倾向于拆分成若干个远程操作进行。</p>
<blockquote>
<p>Q：你好，我们单位从6月份开始实施微服务化（O2O业务），使用的是Dubbo，使用事务型消息来做最终一致性，请问CQRS+Event Sourcing相对于事务型消息队列来处理一致性问题 有什么优势么？</p>
</blockquote>
<p>A：其实CQRS+Event Sourcing是一种观念的转变，落地还是需要靠存储和消息队列，优势在于可以消除系统中的锁点，性能会更好。</p>
<blockquote>
<p>Q：关于领域事件，如果本地事务提交后，下游的服务报错，是否只能在业务层面再发起一个补偿的事件，让本地事务达到最终一致性呢？</p>
</blockquote>
<p>A：如果下游服务报错，那么事件不会被消费。会以退避重试的方式重发事件。</p>
<blockquote>
<p>Q：分享很棒，请问你们的Docker的部署是基于原生的Docker和Swarm，还是Kubernetes来做的？</p>
</blockquote>
<p>A：谢谢，我们使用Rancher来管理集群。没选Kubernetes的原因是因为团队资源有限，Swarm最初试过，调度不够完善。后来Docker 1.12以后的Swarmkit应该是更好的选择。</p>
<blockquote>
<p>Q：微服务开发测试用例相比于单体应用是不是更复杂一些？你们是怎样保证测试覆盖率的？</p>
</blockquote>
<p>A：事实上对于单元测试来讲，反而更容易进行了。因为系统拆分之后，把原来很难测试的一些节点给疏通了。</p>
<blockquote>
<p>Q：你好请教一下，当微服务之间的依赖关系比较多，且层次比较深时，服务的启动，停止，以及升级之间的关系如何处理？</p>
</blockquote>
<p>A：目前还几乎没出现过需要彻底冷启动的情况。而且启动服务时并不需要依赖服务也启动，只需要发生业务时，依赖服务启动即可。</p>
<p>以上内容根据2016年11月15日晚微信群分享内容整理。分享人<strong>刘思贤（微博<a href="http://weibo.com/starlight36" target="_blank" rel="noopener">\@starlight36</a>），爱油科技架构师、PMP。主要负责业务平台架构设计，DevOps实施和研发过程持续改进等，关注领域驱动设计与微服务、建设高效团队和工程师文化培养</strong>。</p>
<hr>
<h3 id="2016-11-16：树莓派上的Docker集群管理"><a href="#2016-11-16：树莓派上的Docker集群管理" class="headerlink" title="2016-11-16：树莓派上的Docker集群管理"></a>2016-11-16：树莓派上的Docker集群管理</h3><blockquote>
<p>Q：先问一个问题，您家里的树莓集群用来做什么？有哪些场景会用到树莓Docker？</p>
</blockquote>
<p>A：这个需求点来自 MBH树莓派社区的朋友，他们提出希望能够简化多个树莓派上部署程序，同时我对未来Docker在arm服务器上的运行抱有很大期望，我只是对这块进行了一些探索。目前还没有找到真实的需求点，还需要更深入的落地。</p>
<blockquote>
<p>Q：您对CoreOS和RancherOS的区别或优劣势上，您是怎么看的？多谢！</p>
</blockquote>
<p>A：实际上使用了CoreOS和RancherOS后，会发现这两个在思路和理念上确实很像。RancherOS比CoreOS的容器化做的更加深入，CoreOS的稳定性会更好。RancherOS设计面向Rancher，CoreOS更多会考虑Kubernetes。CoreOS应该会持续深耕服务器端，而RancherOS也许会在IOT端发力一下。</p>
<blockquote>
<p>Q：树莓派的内存不大，单个主机上容器数会有很大限制吧？</p>
</blockquote>
<p>A：树莓派上跑是为了只是为了单纯简化程序部署，当然不会追求计算密度。计算密度那是服务器关注的事，另外，树莓派的内存不大只是暂时的。</p>
<blockquote>
<p>Q：请问在arm架构里partition是怎么做的?</p>
</blockquote>
<p>A：dd写完镜像后，默认又一个根分区，可以再建一个分区，把docker的目录挂上去，这样能充分利用整个sd卡。</p>
<blockquote>
<p>Q：RancherOS上使用Docker，应用能在容器中通过GPU执行浮点运算吗？需要装驱动吗？在哪装？</p>
</blockquote>
<p>A： RancherOS是一个完全可以定制的操作系统。只要有对应的module，都可以初始化到RancherOS中。</p>
<p>以上内容根据2016年11月15日晚微信群分享内容整理。分享人<strong>张智博（niusmallnan），初出茅庐在阿里巴巴口碑网，参与本地搜索业务研发工作，后与朋友联合创办美食点评社区”美食行”，之后在各种公司从事云计算研发工作。Rancher中国社区布道师，MBH树莓派社区成员，OpenStack中国社区长期作者。热爱coding，热爱技术分享，技术宅&amp;科幻粉，树莓派热血青年</strong>。</p>
<hr>
<h3 id="2016-11-09：唯品会基于Kubernetes的网络方案演进"><a href="#2016-11-09：唯品会基于Kubernetes的网络方案演进" class="headerlink" title="2016-11-09：唯品会基于Kubernetes的网络方案演进"></a>2016-11-09：唯品会基于Kubernetes的网络方案演进</h3><blockquote>
<p>Q：想问下这个IP外网可以直接访问吗？</p>
</blockquote>
<p>A：在Flannel网络下不可以直接访问Pod，在Contiv网络下，Pod所分配的网段是在交换机端打了tag的，默认办公网络是可以直接访问的。</p>
<blockquote>
<p>Q：贵司花了相当大的精力去做容器互通并显著提高了复杂度，如果直接用Kubernetes的host network方式是否可以直接绕过这些复杂点？</p>
</blockquote>
<p>A：首先是公司业务的需求。公司有1k+的业务域，运行在不同的Docker容器里，每个业务域的配置基本是固定的，比如Tomcat或Nginx使用的端口，如果使用host network的话，端口冲突是面临的首要问题，整个服务化的管理方式也要改变了。</p>
<blockquote>
<p>Q：文中提到一个应用的运行态对应Kubernetes的一个RC和Service，RS是否好过RC？</p>
</blockquote>
<p>A：我们的Kubernetes版本是1.2，Kubernetes 1.2里面RS这个东西还处于一个非常早期的版本，后面才有的，RS也是推荐的下一代RC。</p>
<blockquote>
<p>Q：什么样的应用必须要固定IP，是否有其他办法可以避开？</p>
</blockquote>
<p>A：业务域之间相互调用，有些业务域要求提供调用方白名单。还有些业务域会需要线上的数据访问，要加入相应的防火墙权限等。</p>
<blockquote>
<p>Q：固定ip的情况下：容器的IP是通过桥接到宿主机的网桥连接到宿主机网络的吗？</p>
</blockquote>
<p>A：固定IP的情况下，仍然是基于Contiv 的网络工作方式，只是在Docker运行时由IPAllocator负责分配好IP，Docker启动时使用--ip的方式绑定该IP。当前OVS的工作方式也是通过ovsbridge连接到宿主机的物理网卡的。</p>
<blockquote>
<p>Q：固定IP，分配的IP需要和宿主机同网段吗？</p>
</blockquote>
<p>A： Kubernetes node主机网段和pod网段是不同的。原则上可以相同也可以不同。</p>
<blockquote>
<p>Q：Kubernetes支持Docker启动加参数吗，例如 –ip？</p>
</blockquote>
<p>A：默认不支持，我们对kubelet做了一些修改: 例如通过参数传入vlan id以及根据PodSpec中所分配IP指定docker run的 --ip。</p>
<blockquote>
<p>Q：据我了解Contiv现在更多的是对CNM的支持， 对Kubernetes的话你们定制开发的多吗？</p>
</blockquote>
<p>A：Kubernetes用的CNI，我们用的是CNM。更多是适应当前的Contiv对相关组件做修改，以及后面的固定IP（把IPAM集成到了Kubernetes APIServer）。</p>
<p>以上内容根据2016年11月8日晚微信群分享内容整理。分享人<strong>王成昌，唯品会PaaS平台高级开发工程师，主要工作内容包括：平台DevOps方案流程优化，持续部署，平台日志收集，Docker以及Kubernetes研究</strong>。</p>
<hr>
<h3 id="2016-11-05：魅族云Docker实践"><a href="#2016-11-05：魅族云Docker实践" class="headerlink" title="2016-11-05：魅族云Docker实践"></a>2016-11-05：魅族云Docker实践</h3><blockquote>
<p>Q：请问下负载均衡LVS是怎么和容器结合的？</p>
</blockquote>
<p>A：现阶段我们的容器是当虚机来用，有固定IP，所以LVS按照传统方式使用即可，在容器里面配上VIP，如果是FullNAT方式则不需要。</p>
<blockquote>
<p>Q：魅族云的编排工具优选哪个，有混合云的计划吗？</p>
</blockquote>
<p>A：现阶段我们是原来的平台上做适配。今天的内容我们讲的都是对内的私有云，公有云正在开发测试阶段。</p>
<blockquote>
<p>Q：你们的缩容，具体是怎么做的？</p>
</blockquote>
<p>A：CPU、内存是修改CGroup配置，磁盘则通过LVM进行缩容。</p>
<blockquote>
<p>Q：请问，日志集中存储与日志查看怎么实现的？</p>
</blockquote>
<p>A：我们有基于ELK实现的统一日志管理中心，日志都发往日志中心存储，可在管理平台上进行查看。</p>
<blockquote>
<p>Q：”默认情况下，容器内部的proc显示的是宿主机的信息，我们通过获取CGroup中的统计信息来覆盖掉这部分proc信息” 这个Agent是你们自研的？ 方便说下细节吗？谢谢！</p>
</blockquote>
<p>A：简单点说就是通过拦截系统和程序读取proc目录下cpuinfo、meminfo等资源文件，让它去读取我们通过CGroup算好的文件，从而得到正确的容器资源使用情况。</p>
<blockquote>
<p>Q：容器式虚拟机和虚拟机式容器之间，在业务上落地方案是怎么样的，倾向于哪个？</p>
</blockquote>
<p>A：因为我们有虚拟机的历史包袱，所以落地方案上会选择虚拟机式容器， 如果没有历史包袱，直接可以上容器。</p>
<blockquote>
<p>Q：容器有分有状态和无状态么，容器如果是有状态的容器分布式存储是怎么处理的呢？</p>
</blockquote>
<p>A：有状态的容器存储有两种方式：一种是将本地目录挂载到容器，一种是在容器里面挂载分布式存储。</p>
<blockquote>
<p>Q：请问一下容量系统主要用来监控哪些设备？有没有容量不足会提前预知的功能？</p>
</blockquote>
<p>A：监控业务资源是使用情况。业务容量不足或者容量浪费都会有预警。</p>
<p>以上内容根据2016年10月25日晚微信群分享内容整理。分享人<strong>林钟洪，2014年加入魅族研发中心，任运维架构师，负责魅族云平台虚拟化及魅族日志平台研发，主要包括：KVM虚拟化，Docker容器化、分布式存储、集中式日志系统</strong>。</p>
<hr>
<h3 id="2016-11-04：如何使用-Node-js-和-Docker-构建高质量的微服务"><a href="#2016-11-04：如何使用-Node-js-和-Docker-构建高质量的微服务" class="headerlink" title="2016-11-04：如何使用 Node.js 和 Docker 构建高质量的微服务"></a>2016-11-04：如何使用 Node.js 和 Docker 构建高质量的微服务</h3><blockquote>
<p>Q：请问 Kubernetes 的网络用的什么？</p>
</blockquote>
<p>A：这个要看具体业务场景，简单的 Flannel、iptables 就够了。</p>
<blockquote>
<p>Q：请问外部访问服务和内部访问微服务方式是一样的吗？都是通过API Gateway的话，是否有性能压力？另外，对外暴露的服务要分配外网地址，纯内部服务只要内网地址，怎么区分？</p>
</blockquote>
<p>A：内部用或者微服务之间访问可以通过 内网地址 访问，外部用绑定一个外网地址就可以了，考虑性能的话，可以通过 Nginx 等实现 Kong 的高可用。</p>
<blockquote>
<p>Q：感谢分享！我想问一下容器网络对微服务的影响，需要自定义网络吗？还是用 Kubernetes 就可以了？有更好的方案吗？</p>
</blockquote>
<p>A：在我们实践过程中，是没有自定义网络的，微服务之间通过 rest api 进行交互，对客户端通过 Kong 提供统一入口，然后用 Kubernetes 的负载均衡就差不多了。</p>
<blockquote>
<p>Q：Node.js和Vue.js如何选择？</p>
</blockquote>
<p>A：童鞋，这两个是完全不同的东西，Node.js 是后端，Vue.js 是一个前端库，如果你非要选择，我选择 react。</p>
<hr>
<h3 id="2016-11-01：打造百亿级数据处理量的弹性调度容器平台"><a href="#2016-11-01：打造百亿级数据处理量的弹性调度容器平台" class="headerlink" title="2016-11-01：打造百亿级数据处理量的弹性调度容器平台"></a>2016-11-01：打造百亿级数据处理量的弹性调度容器平台</h3><blockquote>
<p>Q：请问管理系统是基于什么开发的？这个系统会开源吗？</p>
</blockquote>
<p>A：Dora的调度框架是基本GO语言开发的。目前不会开源，但提供私有部署。</p>
<blockquote>
<p>Q：刚开始看Mesos框架实现，请问自定义的Scheduler中如何调用自定义的executor？</p>
</blockquote>
<p>A：Schesuler跟executor这个都是按照Mesos最新的v1版的HTTP API去做的，这个没有不兼容的问题，只是mesos go版本的SDK有些老旧，更新也比较缓慢，这个地方我们自己根据需要做了些更改。</p>
<blockquote>
<p>Q：请问目前Consul集群是多大规模呢？有没有考虑Consul扩展的性能瓶颈呢？</p>
</blockquote>
<p>A：Consul是在每个slave节点上会有一个Consul的Agent ，我们一个机房有200多台专门用于数据处理的机器，所以Consul的集群规模也就这么大，单机房。对我们当前来说不存在瓶颈，因为我们对Consul的使用的场景相对单一简单：作为Metadata的可靠存储，Metadata的更新其实并不是很频繁，这个我们参考过别人做过的一些性能测试和我们自己的一些测试，性能是满足需求的。另外一个功能就是服务发现与实例的健康检查，健康检查是由运行在每个机器上的Consul Agent负责的，均摊到每个机器上，其实单个机器上的实例数不会特别的多，所以这部分也没有太大的压力。当然了，这个也是跟业务规模相关的，假定哪天Consul的扩展性成我们的问题了，也说明我们的业务量特别特别的大了，我们也是很期望这一天到来的。</p>
<blockquote>
<p>Q：Dora是否可以支持MySQL的自动伸缩扩容？</p>
</blockquote>
<p>A：Dora系统的应用场景还是运行一些数据处理命令这类无状态的服务。MySQL这类系统不适合直接跑在Dora这个里面，如果期望MySQL跑在Mesos上面的话，需要自己实现一个专门针对MySQL的调度器，因为MySQL实例的扩缩容，实例故障的修复都有MySQL自身特定的需求。我们公司MySQL这类有状态服务的容器化是由公司另一个容器平台实现的。MySQL的用的是Percona XtraDB Cluster方案，我们利用另一个容器平台的API写了一个Percona XtraDB Cluster的调度器，把Percona XtraDB Cluster的大部分运维操作在容器平台上自动化了。</p>
<blockquote>
<p>Q：你们的Ansible host文件是动态生成的嘛？代码推送也是通过Ansible嘛？新增删除节点，以及回滚等操作是如何实现的？</p>
</blockquote>
<p>A：最开始实践的时候不是动态生成的，其实我们是可以从Consul中获取到当前集群里面的节点和节点的一些简单的配置信息，后面有考虑从Consul里面拿节点信息，动态生成用于Ansible灰度的host文件。代码推送也是使用的Ansible，如果能和外网连接的机器，也可以使用GitHub。因为我们的Playbook的角色是通过组件区分的，新增删除节点只需要修改Host文件，把相应的节点加入安装或删除相应的组件。如回滚操作： <code>`</code> {.prettyprint} $ ansible-playbook rollback.yml -i hosts -e “hosts_env=XXX app_env=XXX version_env=XXX”   hosts_env：表示要回滚的主机组，如Masterapp_env：表示要回滚的组件，如ZooKeeperxxx_version：表示要回滚组件的版本号，如v1.0.1.20160918</p>
<blockquote>
<p>Q：Dora的调度策略是怎么样的？可否简单介绍一下。</p>
</blockquote>
<p>A：首先保证同一种数据处理命令的实例尽量均匀分散在不同的机器上，然后再是保证均衡每个机器上的负载。</p>
<blockquote>
<p>Q：Prometheus目前是单机的，数据量大了怎么办？Prometheus 的监控数据是存在InfluxDB吗？</p>
</blockquote>
<p>A：目前我们是按业务拆分server，数据量可以支撑。我们没有使用InfluxDB，还是用的原生的LevelDB。</p>
<blockquote>
<p>Q：这么大文件量，你们在存储技术方面有什么特别的处理吗？怎么实现高性能和海量存储之间均衡？</p>
</blockquote>
<p>A：七牛云存储的设计目标是针对海量小文件的存储，所以它对文件系统的第一个改变也是去关系，也就是去目录结构（有目录意味着有父子关系）。所以七牛云存储不是文件系统，而是键值存储，或对象存储。我们每个大文件都是切割成小文件存储下来的，元信息单独存放在数据库中，用户请求的时候通过业务层合并处理后返回。因此理论上磁盘只存储小文件，大文件存储和读取的性能主要在于文件切割和合并。</p>
<p>以上内容根据2016年11月1日晚微信群分享内容整理。分享人陈爱珍，七牛云布道师，负责DevOps ，容器，微服务相关技术的落地研究与布道。多年企业级系统运维管理经验，对大型分布式系统架构设计及运维有丰富的经验。</p>
<hr>
<h3 id="2016-10-25：猎豹移动基于CoreOS在AWS上的项目实践"><a href="#2016-10-25：猎豹移动基于CoreOS在AWS上的项目实践" class="headerlink" title="2016-10-25：猎豹移动基于CoreOS在AWS上的项目实践"></a>2016-10-25：猎豹移动基于CoreOS在AWS上的项目实践</h3><blockquote>
<p>Q：没有用到Flannel，网络实现是什么，未来对CoreOS的容器管理工具rkt的计划？</p>
</blockquote>
<p>A：网络上我们直接使用的host的方式，容器主要是看中了CI和CD的便利好没有往高密度的场景设计的计划，rkt是个好东西，更有开源的感觉，看后期Docker社区发展情况是否越来越封闭。</p>
<blockquote>
<p>Q：registry怎么ha的，是在容器还是VM？</p>
</blockquote>
<p>A：这个问题之前也是一直困扰着我们，我们用AWS的ELB做负载均衡，后端放2台EC2，镜像存到S3，缓存写在Redis里，我们是使用官方的image，随时用随时上传和使用，挂了就再启动一个，不依赖长期有效的hub。</p>
<blockquote>
<p>Q：最近暴漏的安全问题需要内核升级才能解决，这正是CoreOS的优势、不必重启系统，猎豹是否在线上有这种经验？实际中CoreOS在升级内核时是否真那么方便？</p>
</blockquote>
<p>A：这个是我们非常喜欢的一个特性，自动升级内核，做过运维的同学都知道，做一次内核升级是多么痛苦，我们最开始用的是stable766.4，现在都不用我们去升级就自动帮我们升级到8xx的stable版本了。</p>
<blockquote>
<p>Q：集群中etcd节点数目是多少，奇数个etcd节点的优势具体怎么体现的，以及etcd的代理节点在业务中的价值？</p>
</blockquote>
<p>A：etcd很类似于ZooKeeper，leader节点必须是奇数个，我们一般是3个，最多5个，所有节点都会主动和leader节点通讯，leader节点可以运行在集群任何节点上，也可以通过API接口手动调整leader节点所在的底层服务器，很灵活，任何一台都可以选举成leader，不用部署任何额外配置，省心。</p>
<blockquote>
<p>Q：编排调度都是自己开发的系统吗，如何管理那么多的容器？</p>
</blockquote>
<p>A：用的CoreOS自带的模块，etcd+fleet+systemd，很底层，登陆任何一台机器做操作就可以管理整个集群，就像管理一台机器一样，我们把日常发布等操作基本都用Jenkins代劳了。</p>
<p>以上内容根据2016年10月25日晚微信群分享内容整理。分享人<strong>齐海澎（KumaQi），猎豹移动高级运维工程师。负责猎豹移动商业广告产品与大数据相关产品的运维团队管理，作为猎豹移动运维部的管理团队成员，负责商业广告业务和大数据计算在AWS服务上的稳定运行，并帮助公司开展容器技术的初步尝试。3年AWS服务使用与运维经验，运维全球8个region数以千计的计算服务资源，搭建并运维起跨5个地区的基于CoreOS的Docker集群</strong>。</p>
<hr>
<h3 id="2016-10-25：恒生金融交易系统的Docker化实践"><a href="#2016-10-25：恒生金融交易系统的Docker化实践" class="headerlink" title="2016-10-25：恒生金融交易系统的Docker化实践"></a>2016-10-25：恒生金融交易系统的Docker化实践</h3><blockquote>
<p>Q：请问下，你们现在这个系统容器规模多大？OverlayFS有遇到什么坑吗？</p>
</blockquote>
<p>A：现在系统容器是100多个。由于镜像数少，对文件inode占用少，所以OverlayFS基本满足需求。但是需要主机内核高一点，在3.18以上。</p>
<blockquote>
<p>Q：请教一下。咱们这个容器管理平台是用什么语言开发的？直接调用Docker Remote API吗，用的是最新的1.24么？</p>
</blockquote>
<p>A：Java语言开发，直接调用的Docker Remote API，版本是1.24.</p>
<blockquote>
<p>Q：MySQL服务也Docker化了吗，怎么保证存储安全？</p>
</blockquote>
<p>A：MySQL这块是我们实现了RDS，底层用MySQL的复制方案。</p>
<blockquote>
<p>Q：交易系统应该涉及很多运行组件。在决定哪些组件容器化时有哪些考虑？</p>
</blockquote>
<p>A：一般性能要求很高，延迟要求在微秒级的组件，比如高频交易等，基本不考虑Docker化。</p>
<blockquote>
<p>Q：核心架构是Swarm+Docker+Confd+Registrator，如何实现动态扩展？</p>
</blockquote>
<p>A：组件还包括了Etcd，利用Etcd+Confd+Registrator来做服务注册和发现及配置管理，利用Docker Compose的Scale做服务的扩展。</p>
<blockquote>
<p>Q：请问你们用的编排系统都是Docker 1.12的Swarm吗，如何实现容器都是夸主机冗余部署？</p>
</blockquote>
<p>A：1.12也在试用，现在主要是老模式的Swarm，利用容器的互斥性，相同集群的2个容器实例，不要部署到同一台主机上。</p>
<blockquote>
<p>Q：请教下业务组件的镜像有多大？如何实现跨平台迁移，不如从华为云部署到阿里云之类？</p>
</blockquote>
<p>A：镜像大小在几百M，利用镜像中心的远程复制功能，同步到生产环境的镜像中心，比如阿里云和华为云上。</p>
<blockquote>
<p>Q：镜像安全如何保证？</p>
</blockquote>
<p>A：目前基础镜像都是由我们自己制作，会检查安装的软件和版本。后续会引进镜像安全扫描，来定期检查镜像。</p>
<blockquote>
<p>Q：请问网络采用host模式，如果一台主机运行多个同一端口的容器怎么办？比如运行2个Tomcat项目？</p>
</blockquote>
<p>A：我们在容器管理工具中增加了端口的配置管理，不会出现这种情况。另外部分网络性能要求不高的应用，也会采用flannel host-gw的方案，这样端口就可以相同了。后续会调研MacVLAN模式，给每个容器分配一个物理IP地址。</p>
<p>以上内容根据2016年10月18日晚微信群分享内容整理。分享人<strong>柳正龙，恒生电子研发中心Docker技术负责人。8年来一直专注于金融行业高性能中间件、分布式消息分发系统架构和研发。对于网络通信、服务器性能调优、GDB调试等有丰富的经验。2015年开始研究Docker技术，现负责推进Docker技术在公司内的落地</strong>。</p>
<hr>
<h3 id="2016-10-24：PPTV聚力传媒的Docker与DevOps"><a href="#2016-10-24：PPTV聚力传媒的Docker与DevOps" class="headerlink" title="2016-10-24：PPTV聚力传媒的Docker与DevOps"></a>2016-10-24：PPTV聚力传媒的Docker与DevOps</h3><blockquote>
<p>Q：线上和线下环境不一致的问题，通过配置中心，比如文件或者安全变量，容器App启动读取文件或者变量，就能过去正确的配置，这样方式pptv实践为什么不采用这个方法呢？</p>
</blockquote>
<p>A：我们线上环境是有配置中心的，但是因为管理上的原因，配置中心主要是管理系统级别的配置，和业务相关的配置不放在配置中心里。而且我们想要做到的效果是使用相同的配置在线下线上环境跑，通过配置中心来做的话，只是把配置项做成了变量，配置实际上还是有差异的。</p>
<blockquote>
<p>Q：DB变更流程怎么控制的，PPTV的业务中是否涉及到分库分表，又采用了哪些手段来针对测试库与生产库的数据变更带来对业务的影响？</p>
</blockquote>
<p>A：DB变更主要通过流程去规范，比如分库分表、表结构变更，需要提前1天以上申请，由DBA评估审核，涉及数据库的更新必须避开业务高峰期，选择凌晨或者早上8点前。技术上，要求业务方在数据库变更应该有备份脚本，备份需要更新的数据。</p>
<blockquote>
<p>Q：如何解决发布的时候Nginx频繁reload问题？对容器的Swap有限制么？</p>
</blockquote>
<p>A：Marathon上有变更的时候不会立即触发reload，首先会将变更的信息记录到DB中，然后有间隔的批量同步触发reload，Swap目前没有做配置</p>
<blockquote>
<p>Q：1、Redis、MySQL、DB、ZooKeeper这些如果跑在容器，数据初始化持久化的方案是什么，2、linux bridge网络方案 有没有对比过Calico Contiv等？</p>
</blockquote>
<p>A：1. 挂载外部卷GlusterFS实现持久化存储 。 2.对比过Calico，可以参考之前的一篇文章《<a href="http://dockone.io/article/1673" target="_blank" rel="noopener">PPTV Docker集群的网络方案选型</a>》，Contiv没有做过对比。</p>
<blockquote>
<p>Q：持续组件ZooKeeper、MySQL之类的是怎么和应用集成的，是一个整体镜像还是单个镜像组合的？</p>
</blockquote>
<p>A：ZooKeeper、MySQL是不同镜像，运行在不同容器中。</p>
<blockquote>
<p>Q：请问服务自动发现怎么搞的?新手，不知如何将Node注册进HAProxy或Nginx？</p>
</blockquote>
<p>A：对Marathon的label属性进行约定，默认label属性是没有意义的，可以在程序中判断label是否符合约定条件，并触发注册、修改操作。</p>
<blockquote>
<p>Q：您好，请问你们的DNS是怎么做的，单点故障问题是如何解决的？</p>
</blockquote>
<p>A：DNS也运行在由Marathon调度的容器中，Marathon实现故障自愈，DNS重启的同时将触发服务发现的同步操作。</p>
<blockquote>
<p>Q：灰度发布回退是回退images还是直接回退Docker中的应用包呢，回退前如果改过Volume中数据库话，数据库也一起回退？遇到什么问题么？</p>
</blockquote>
<p>A：目前线上环境的容器化还在进行中，将来会是回退images。线上的数据库不会跑在容器中，回退的时候数据库也回退，和没有用容器的时候流程一样。</p>
<blockquote>
<p>Q：在生产环境，一个App ID会存在需要多个容器的情况，也就需要多个IP。按上述使用方式应该会有问题。这块是如何解决呢？</p>
</blockquote>
<p>A：在生产环境中在Marathon上层封装了一套发布系统，同一个项目创建多个容器，会在Marathon上创建多个App ID，Marathon上的信息对外不可见。</p>
<blockquote>
<p>Q：我想问，使用bridge，10.199.45.0/24，会不会IP耗尽？还有有没有测试过bridge的效率？</p>
</blockquote>
<p>A：10.199.45.0/24 只是举个例子，实际场景下会有多个IP段，或者使用一个大的网段。只做了简单的测试，bridge效率基本能达到原生网络的90%以上。</p>
<blockquote>
<p>Q：选择CentOS而不是Ubuntu或者CoreOS的原因是什么？DNS和IP地址池如何协调？</p>
</blockquote>
<p>A：技术栈原因，公司一直在用RedHat和CentOS。DNS和IP由DCOS管理平台进行管理。</p>
<blockquote>
<p>Q：Mesos和Marathon结合时，关闭容器后会产生stop状态的容器而不自动清理，只能脚本清理，这个请问你们有什么方案处理么？</p>
</blockquote>
<p>A：目前我们也是脚本。将来可能会和Mesos的hook做到一起，Mesos发现task结束时删除容器，或者通知管理平台，由管理平台定期批量处理。</p>
<p>以上内容根据2016年10月11日晚微信群分享内容整理。分享人<strong>李周，PPTV聚力传媒DCOS技术主要负责人，专注于Docker网络解决方案，容器监控，DevOps。之前在中小创业公司长期负责客户现场实施工作，积累了大量关于网络，监控，权限认证，大数据，Oracle，中间件等经验，同时喜欢研究各种新兴技术</strong>。</p>
<hr>
<h3 id="2016-10-20：基于Docker的开发云提高资源利用率的实践"><a href="#2016-10-20：基于Docker的开发云提高资源利用率的实践" class="headerlink" title="2016-10-20：基于Docker的开发云提高资源利用率的实践"></a>2016-10-20：基于Docker的开发云提高资源利用率的实践</h3><blockquote>
<p>Q：你好，你们有做不影响服务的升级和自动伸缩吗？</p>
</blockquote>
<p>A：是的，上边提到的”动态应用部署”组件就是能够实现应用的升级更新不受影响，自动伸缩通过Rancher的监控和应用多实例来实现，监控到应用容易的CPU、内存、网络等如果在一个时间段内一直处于较高的利用率，就增加应用实例，反之则减少，保证应用的连续性。</p>
<blockquote>
<p>Q：请问对Docker学习需要看Docker源码吗？</p>
</blockquote>
<p>还是用Docker等工具来解决问题就可以了？</p>
<p>A：这个得根据实际需要来了，如果是说需要从Docker容器层面上来定制开发，那Docker源码肯定是需要去研究的，若仅仅是将Docker作为工具使用，那关注点可以放在相关的工具如Rancher、Mesos、Kubernetes等，当然了，若时间允许，了解源码好处多多，可以从底层弄清楚Docker的各种机制，有利无弊。</p>
<blockquote>
<p>Q：感谢分享，请问在容器资源池部分提到的”运行状态的IDE容器，与开发者的访问域名绑定” 假设有两个用户,用户A和用户B，他们访问的域名分别是什么？</p>
</blockquote>
<p>A：这个是用户自定义的二级域名，假如基于顶级域名cloudx5.com，用户A创建一个IDE实例，这是他可以输入一个二级域名如a.cloudx5.com（或者我们自动生成一个），资源池组件就会将这个域名与获取的IDE容器绑定，用户A就可以访问了。</p>
<blockquote>
<p>Q：想问下Docker部署应用，应用配置参数怎么处理？改一个参数就要重新打一包吗？</p>
</blockquote>
<p>A：其实在我们这个结构中，用户并不需要关心打包及参数配置，他需要做的，就是把开发的代码上传，我们后端使用了Jenkins来做统一的打包，打包完成后会调用”动态应用部署”环节提到的Deployer容器，这个Deployer会去约定好的目录下载打包好的文件做部署配置。</p>
<blockquote>
<p>Q：实例收缩的时候能保证释放的容器没有业务访问？</p>
</blockquote>
<p>A：这个不需要保证，运行着的实例容器都是无状态的，实例之间的Session是共享的，需要持久化的数据也是存在别的容器中的如MySQL。</p>
<blockquote>
<p>Q：LB路由WebApp的时候是按照IP寻址的吗？这样如何保证WebApp重启时候IP不变化?</p>
</blockquote>
<p>A：LB路由的本质是一个带有服务发现功能的Haproxy，WebApp重启后IP变化了，LB会得知这个变化并修改配置和reload。</p>
<blockquote>
<p>Q：就是说配置文件还是打到Docker里的，比如这时开发要改个配置或加一配置，而代码都没变，这时只能在打一个新的包？</p>
</blockquote>
<p>A：关于这个我们做了一些约定，例如上边讲到的一个最基本的Wex5应用，我们将其分为Wex5 APP容器、MySQL容器与Deployer容器，APP应用容器访问MySQL容器都是通过Rancher的内部DNS解析MySQL容器在Rancher中的服务名称来访问，这个是相对固定的，例如在外卖APP应用中配置的MySQL的地址是：database.waimai，database是服务名称，waimai是Rancher的stack名称。</p>
<hr>
<h3 id="2016-10-04：深入解析DC-OS"><a href="#2016-10-04：深入解析DC-OS" class="headerlink" title="2016-10-04：深入解析DC/OS"></a>2016-10-04：深入解析DC/OS</h3><blockquote>
<p>Q：请问DC/OS目前测试的最大集群是多少节点的？</p>
</blockquote>
<p>A： Mesos的节点数Tweeter和Apple网上说的数目都万节点以上，我们公司现在的客户有千节点级别的。</p>
<blockquote>
<p>Q：DC/OS目前用在什么场景？</p>
</blockquote>
<p>A：DC/OS目前的应用场景主要还是微服务和大数据混合部署比较多，也是其设计核心所在。</p>
<blockquote>
<p>Q：请问有部署Stateful的应用，比如MySQL吗？</p>
</blockquote>
<p>A：是用DC/OS还是建议从无状态的服务开始，随着运维能力的提高，可以部署有状态的服务，但是有状态的服务不建议直接使用Marathon进行部署，一方面它无法区分多个instance之间的区别，另一方面需要配合统一存储来实现。对于有状态的服务，可以自己实现Framework，例如我们使用的数据库是MongoDB，也是写了自己的Framework的。</p>
<p>以上内容根据2016年10月4日晚微信群分享内容整理。分享人<strong>刘超，Linker Networks首席架构师，10年云计算领域研发及架构经验，OpenDC/OS贡献者。长期专注于OpenStack、Hadoop、Docker、Spark、Mesos等开源软件的企业级应用及产品化。<a href="http://blog.csdn.net/popsuper1982" target="_blank" rel="noopener">个人博客：</a></strong>。</p>
<hr>
<h3 id="2016-09-27：Docker在B站的实施之路"><a href="#2016-09-27：Docker在B站的实施之路" class="headerlink" title="2016-09-27：Docker在B站的实施之路"></a>2016-09-27：Docker在B站的实施之路</h3><blockquote>
<p>Q：你好 问下贵公司的自动扩容是针对应用的吧</p>
</blockquote>
<p>有没有针对Mesos资源池监控并做Mesos Agent的扩容？</p>
<p>A：目前的自动扩容是针对应用的。Mesos Agent扩容时，先把物理机信息录入PaaS平台，手动在PaaS平台点击扩容，后台会调用Ansible，分钟快速级扩Mesos Agent。</p>
<blockquote>
<p>Q：现在是确定Nginx+UpSync+Upsteam check是无法一起用的么？贵公司的Nginx版本是多少哇？</p>
</blockquote>
<p>A：测试过Nginx 1.8和1.10，确认无法一同编译。我们用的最多的Nginx（SLB）是Tengine 2.1.1，部署在Docker上。</p>
<blockquote>
<p>Q：既然是封装， 那底层用Mesos比Kubernets并没有太大的灵活性吧？</p>
</blockquote>
<p>A：对于PaaS平台，目前我们希望的只需要资源调度这个功能，其他功能我们还是希望可以自己实现，而Mesos是专注于调度资源，而且已经历经了大量级的考验。而Kubernetes目前提供的很多服务，我们并不需要，所以选择了Mesos。</p>
<blockquote>
<p>Q：容器是采用Monitor Agent监控，那容器内的呢？也还是内部埋点？还是EFK吗？监控是采用Prometheus吗？</p>
</blockquote>
<p>A：Prometheus没有使用，我们是用自己的监控Agent InfluxDB。容器内有多种监控方式。有用ELK，也有其他埋点，比如StatsD，基于Dapper论文实现的全链路追踪。</p>
<blockquote>
<p>Q：网络选型这块,还调研过其他网络方案吗？譬如Calico、Weave等，为什么会选用Macvlan？</p>
</blockquote>
<p>A：我们的选型第一步是先选择标准的，要从CoreOS主导的cni还是Docker官方主导cnm里面选择，目前由于我们容器方案还是走的Docker，所以选择了cnm，那从cnm的标准里面的选择基本是：1. 基于XVLAN的Overlay；2. 基于三层路由的Calico；3. 基于二层隔离的Macvlan，实际以上的方案我们都调研使用过，基于希望尽量简单的原则最终选型还是Macvlan。</p>
<p>Q：Bili PaaS平台，自动扩容和手动扩容，应用多的是哪种方式？自动扩容后，资源会重调度么？是否会中断已有业务呢？</p>
<p>A：用的更多的是根据制定好的策略，自动扩容。通过Nginx 动态Upstream对外提供服务，不会中断业务。</p>
<blockquote>
<p>Q：关于日志收集每个容器里都跑一个Logstash吗？好像ELK不能搜索展示上下文的啊？</p>
</blockquote>
<p>A：容器里面没有跑Logstash。目前是在远端的Logstash集群上监听一个UDP端口，应用直接把日志推送到Logstash的UDP端口，然后Logstash把日志推送到Kafka，Kafka的消费者有两个，一个是Elasticsearch，一个是HDFS。一般用ELK足以。需要详细日志时，由运维通过HDFS查询。</p>
<blockquote>
<p>Q：我想请教下Nginx的一些动态配置文件是封装在容器内部了？还是通过volume的方式挂载了？有没有配置中心类似的服务？这块想了解下是怎么实现的？</p>
</blockquote>
<p>A：Nginx的Upstream是从Consul动态获取生成在本地的，通过Volume挂载，持久化到宿主机。有配置中心。业务Docker化时，就会推动业务配置接配置中心，Docker中不在保存业务依赖的配置。</p>
<p>以上内容根据2016年9月27日晚微信群分享内容整理。分享人<strong>武安闯，Bilibili运维工程师，目前主要负责B站运维和业务Docker化的实施。一直关注于Docker的发展，Docker与Mesos结合的容器平台实施</strong></p>
<hr>
<h3 id="2016-09-20：-Acttao-开发、运维容器化实践"><a href="#2016-09-20：-Acttao-开发、运维容器化实践" class="headerlink" title="2016-09-20： Acttao 开发、运维容器化实践"></a>2016-09-20： Acttao 开发、运维容器化实践</h3><blockquote>
<p>Q：为什么不采用 Kubernetes 呢？</p>
</blockquote>
<p>A：我们在 2015年初做选型时，Kubernetes 还不是很成熟。当时我们评估 Mesos 和 Kubernetes 后，觉得 Kubernetes 太复杂，Mesos 的核心功能很简单，其他的功能都由 Framework 来实现。我们很容易就理解了 Mesos，于是就选择了 Mesos。</p>
<blockquote>
<p>Q：您对容器化 OpenStack 怎么看？</p>
</blockquote>
<p>A：OpenStack 在我们看来只是更方便的提供底层资源的平台，容器化后的 OpenStack 只是能使用 OpenStack 的方式管理容器了。但使用 Mesos 来管理容器的话它不关心底层到底是虚拟机还是物理机。 容器化 OpenStack 软件本身后部署升级 OpenStack 也较为方便。我们现在这个系统部署的软件除了 Mesos 外，能使用 Docker 运行的也尽量地采用了 Docker 进行运行。</p>
<blockquote>
<p>Q：关于 Weave 很多文章都说性能不行，就你们的项目和实际使用情况来看，能对 Weave 做更多的评价么？</p>
</blockquote>
<p>A：我们自己当时测试在 FastDb 模式下，Weave 的性能还在接受的范围里，大概比 OpenStack 中的 Neutron 网络损失了 10% ～ 20% 。就实际的使用情况看来，Weave 集群搭建起来非常容易，毕竟不依赖于任何外部存储。但是它出现任何问题时，调试不是很方便。</p>
<blockquote>
<p>Q：Container 网络中，Weave 有什么优点，为什么不采用 Flannel？</p>
</blockquote>
<p>A：Weave 的优点搭建方便，有 proxy、plugin、cni 模式，自带 DNS 做服务发现。在 Mesos 还没有原生的容器网络支持时，weave proxy 的方式能很容器的让使用 Marathon 创建的 Docker 容器拥有自己的网络。 我们是一个小的团队，优先考虑我们能容易理解的方案。</p>
<blockquote>
<p>Q：请问目前你们 Staging 和 Product 环境的发布频率如何？两套环境是用的同一套CI/CD系统吗？对于部署在客户的系统即网络不连通的，如何实现镜像或环境同步的？</p>
</blockquote>
<p>A：Staging 环境的发布频率很快，开发恨不得没 merge 一个 mr 就做一次发布。Product 环境在今天之前依然是运维人工去部署的，明天正式迁移到阿里云后，前期依然会采用人工调用我们的 PaaS 工具去做发布。等大家都接受容器化自动化的部署方式可能会考虑在生产环境也进行自动部署。 都是用的同一套 CI/CD 系统。 我们现在的 Registry 使用的阿里云的 OSS，每个网络的内部部署自己的 Registry。</p>
<blockquote>
<p>Q：为什么不直接用阿里云的容器服务而自己搭建呢？</p>
</blockquote>
<p>A：我们自己弄这套环境时，没有想过会使用阿里云。当计划迁移到阿里云时，自己的那套东西已经运行很稳定，和开发流程配合的很好。使用阿里云的容器服务可能现有的流程要调整，而且我也不确认公司还会不会从阿里云迁走。</p>
<blockquote>
<p>Q：如果现在选，会选 Kubernetes 吗？ 为什么？</p>
</blockquote>
<p>A：依然会选择 Mesos，因为除了容器编排，不排除我们后续会使用其他的服务，比如 Spark 。同时，Kubernetes 有的， Mesos 现在也有，cni、Docker Volume 等等。</p>
<blockquote>
<p>Q：你们的网络似乎经历了 Calico- Weave- Calico 的过程，why？</p>
</blockquote>
<p>A：我们从来没有在正式的环境中使用过 Calico。选用 Weave 的原因是 weave proxy 模式在当时能很好的 Mesos/Marathon 进行集成。 现在考虑 Calico 的原因是 Mesos 1.0 后支持 cni 了，Calico cni 能很好的集成进 Mesos，而且 Calico 的性能、稳定性、网络隔离较 Weave 好。</p>
<blockquote>
<p>Q：这么多应用，数据库分布是怎样的？数据是挂载进 Docker 的？</p>
</blockquote>
<p>A：使用的 REX-Ray 把 OpenStack 的块存储作为数据盘挂载到 VM 的，然后采用 docker volume plugin 的方式挂载到容器里的。一个 Volume 对应一个 Cinder 块设备。</p>
<blockquote>
<p>Q：从你说的把你们这套CI/CD移到阿里云上差不多用了接近两个月的时间，这也算比较长了，能说说在迁移过程中都做了哪些事情，有什么需要注意的地方？那一般一个普通的应用系统如果迁移到阿里云上（当然也包括其维护的CI/CD），需要多长时间，有哪些需要注意的地方？</p>
</blockquote>
<p>A：实际的迁移时间没有用到两个月，在阿里云上搭建这个系统大概花了 2 到 3 周的时间（大部分的时间都在编写 Aliyun 的 terraform provider），真正部署起来用了一天的时间，我记得是在 8月 13，那天我们采用包月的方式买了一批的阿里云资源。后续的时间大多是在做迁移后的测试工作，因为公司的运维对在阿里云中运行 Docker 持怀疑的态度，而且这个迁移后续是用业余时间来完成的，8月中旬我们又忙活了一阵子，这两天刚歇会而。迁移系统应用系统需要注意的事情就是尽量多测试。</p>
<p>以上内容根据2016年9月20日晚微信群分享内容整理。分享人<strong>何威威，Acttao技术总监，多年 Python 开发经验，使用 SaltStack、Ansible 倒腾过OpenStack的部署。从 2014年初开始使用 Docker，2015 年初接触 Mesos半年后使用 Ansible 在 OpenStack 中部署 Mesos 集群运行到今年8月初。现在管理维护公司IDC KVM中和阿里云中运行的 Mesos 集群</strong>。</p>
<hr>
<h3 id="2016-09-06：唯品会数据库备份恢复容器化项目实践经验总结"><a href="#2016-09-06：唯品会数据库备份恢复容器化项目实践经验总结" class="headerlink" title="2016-09-06：唯品会数据库备份恢复容器化项目实践经验总结"></a>2016-09-06：唯品会数据库备份恢复容器化项目实践经验总结</h3><blockquote>
<p>Q：发现现在很多采用桥接网桥的方式改善Docker网络 ，这个可有测试？</p>
</blockquote>
<p>A：桥接网桥的方式是个简单的方案，但IP地址分配只能在本机做IPAM，无法全局管理，存在地址资源浪费的问题。</p>
<blockquote>
<p>Q：请问改体系在实战中研发环境，测试环境和预发布环境的交付物是什么呢？</p>
</blockquote>
<p>A：MySQL数据的备份恢复能力。</p>
<blockquote>
<p>Q：”容器异常退出IP地址不能释放的问题，这都需要我们自己去解决。”可否提供一个大致的解决思路？</p>
</blockquote>
<p>A：计划通过libnetwork unix socket调一个叫ReleaseEndpoint的API，这样可以保证删除操作的完整性，包括ovs port、etcd ep信息、IP地址。</p>
<blockquote>
<p>Q：Docker 1.12内置Docker swarm mode，Overlay网络的性能相比其他开源方案的优劣势是什么？</p>
</blockquote>
<p>A：Overlay网络的优势在于对虚拟网络，多租户场景支持更好，没有4096个的限制， 然而没有支持VXLAN硬件的情况下无法直接访问，这对于开发，问题定位，监控都是个难题。性能的话对于容器来说不会是一个瓶颈。</p>
<blockquote>
<p>Q：做过Mesos 1.0测试吗？1.0已经不会依赖Docker daemon了？</p>
</blockquote>
<p>A：Mesos 1.0中仍然支持Docker作为Containerizer。实验环境验证过Mesos + Docker + Netplugin是可行的，理论上无论用哪个Mesos版本，只要它仍然支持Docker，那么就可以网络插件的形式来落地网络实现。</p>
<blockquote>
<p>Q：容器一般是即用即销毁，想问下，你们做的容器监控，是如何保证数据持久性的？</p>
</blockquote>
<p>A：MySQL备份出来的数据是保存在容器外部卷上，即宿主机上的，容器销毁外部卷并不会被删除，所以数据仍然能够保留下来。</p>
<blockquote>
<p>Q：请问你们的容器告警是基于什么做的，cAdvisor并不能提供告警吧？</p>
</blockquote>
<p>A：基于我司已有的监控体系，即Zabbix。</p>
<blockquote>
<p>Q：Devicemapper使用的是Direct LVM吗？设备空间用满的情况下如何扩容？</p>
</blockquote>
<p>A：是的。扩容可以通过添加物理磁盘设备，扩VG，再resize dm pool大小。</p>
<blockquote>
<p>Q：当您用到上百台机器的时候，镜像是提前下载好的吗？还是临时下载，有没有做镜像下载加速这块儿？</p>
</blockquote>
<p>A：镜像是保存在本地IDC的Registry里，所有机器访问Registry通过相近的网络，下载速度很快。好的做法是先全局Pull一次再Run吧。</p>
<blockquote>
<p>Q：我对容器中放数据库的性能比较担心，你们的性能这么高，主要做了什么配置？</p>
</blockquote>
<p>A： 因为害怕互相抢资源，我们严格限制单一主机的容器数量、CPU、内存、磁盘都不超配。在资源充足的情况下，MySQL跑在容器里跟跑在外面没有本质的区别，都是进程。</p>
<blockquote>
<p>Q：关于监控这块，上文提到了两个，能给我们介绍一下Zabbix和cAdvisor的分工吗？</p>
</blockquote>
<p>A：Zabbix通过自己写的脚本，向cAdvisor RESTful接口请求容器监控数据。</p>
<blockquote>
<p>Q：MySQL数据库容器化后，性能如何？故障恢复速度怎么样？</p>
</blockquote>
<p>A：从数据备份恢复的角度来说，基本与在物理机上跑相当。</p>
<p>以上内容根据2016年9月6日晚微信群分享内容整理。分享<strong>叶凯峰，唯品会云平台资深开发工程师。十年IT行业工作经验，开发老司机，成长在爱立信，测试界与开发界都打拼过。技术实现崇尚”Simple is the best”，”不以解决问题为目的的技术引进就是耍流氓”。现在专注OpenStack、Docker等云计算相关技术的设计与开发工作，负责Docker整体技术方案设计、容器网络、监控、日志、操作系统等方面，为公司云计算技术基础设施演进提供支持。</strong>。</p>
<hr>
<h3 id="2016-09-08：云计算应用技术发展与企业异构资源池统一管理案例分析"><a href="#2016-09-08：云计算应用技术发展与企业异构资源池统一管理案例分析" class="headerlink" title="2016-09-08：云计算应用技术发展与企业异构资源池统一管理案例分析"></a>2016-09-08：云计算应用技术发展与企业异构资源池统一管理案例分析</h3><blockquote>
<p>Q：CMP怎样实现易构多资源池管理，一个OpenStack，一个VMware？</p>
</blockquote>
<p>A：CMP针对每种类型的资源池提供特定的driver，当前4.0版本已经支持CloudStack、OpenStack、VMware，公有云支持阿里云、Amazon等。</p>
<blockquote>
<p>Q：CloudStack和OpenStack也属于云管平台 上层套SkyForm的定位也是云管平台这样做的原因是什么？会不会有些臃肿或是在功能会有冲突？</p>
</blockquote>
<p>A：对SkyForm CMP来说，OpenStack和CloudStack只是一个虚拟化资源池。SkyForm CMP是一个统一的管理平台，不仅能管理不同类型的虚拟化资源池，企业版CMP平台还能管理物理机资源池。</p>
<blockquote>
<p>Q：请问OpenStack的Keystone、Glance、Neutron分别与VMware如何结合的？</p>
</blockquote>
<p>A：这个项目的OpenStack 资源池中，我们只使用了KVM。VMware是最为一个和OpenStack平级的虚拟化资源池。SkyForm CMP 在上层管理网络和镜像。SkyForm CMP和OpenStack使用同一套Keystone。</p>
<blockquote>
<p>Q：看到图例里面SkyForm也支持Docker容器 开始也提到客户的VM生命周期很短为何不建议用户用容器取代一部分虚拟机的工作呢？</p>
</blockquote>
<p>A：是的，我们已经支持容器了。使用虚拟机主要是用户业务决定了，这个项目用户的程序都在虚拟机里面跑的，还没有容器化。</p>
<blockquote>
<p>Q：镜像可以跨平台，跨资源池使用吗？</p>
</blockquote>
<p>A：镜像是不能跨平台的，比如VMware的镜像是OVA，KVM的镜像是qcow2，是无法直接使用的。补充一个功能，CMP支持使用IOS创建虚拟机。</p>
<blockquote>
<p>Q：好多OpenStack版本中不支持克隆和快照，SkyForm CMP是否完善过这些功能呢？</p>
</blockquote>
<p>A：对于VMware资源池和CloudStack资源池，快照和克隆功能已经支持。OpenStack我们有修改过，支持Ceph存储的快照，对于san存储还需要看具体设备了。</p>
<blockquote>
<p>Q：这家的OpenStack使用的是什么版本的OpenStack，上到生产环境了么 ？</p>
</blockquote>
<p>A：先后有I版和K版上线。是生产环境。</p>
<blockquote>
<p>Q：VMware尚不具备SDN，OpenStack具备SDN这块是怎么补齐的呢？</p>
</blockquote>
<p>A：SkyForm CMP 支持VMware 分布式交换机，可以实现基本的网络隔离和控制需求。在这个项目中，用户虚拟机都在客户企业内网，虚拟机网关直接使用网络设备。</p>
<p>以上内容根据2016年9月8日晚微信群分享内容整理。分享人**高铭，天云软件高级实施架构师。从事SkyForm云管理平台的实施与技术支持工作。对VMware vSphere、Citrix XenServer、KVM、CloudStack、OpenStack有较多的实施部署与运维经验。</p>
<hr>
<h3 id="2016-08-28：基于容器技术构建企业级PaaS云平台实践"><a href="#2016-08-28：基于容器技术构建企业级PaaS云平台实践" class="headerlink" title="2016-08-28：基于容器技术构建企业级PaaS云平台实践"></a>2016-08-28：基于容器技术构建企业级PaaS云平台实践</h3><blockquote>
<p>Q：弹性扩容的时候怎么区分需要垂直扩容还是水平扩容？</p>
</blockquote>
<p>A：自动扩容是水平扩容，根据并发量、CPU、内存的实时数据分析来实现。</p>
<blockquote>
<p>Q：所有的扩容都是水平扩容吗？不太清楚自动化的垂直扩容应该怎么判断，有什么想法不？</p>
</blockquote>
<p>A：目前所有扩容都是水平扩展，要垂直扩展只能手动，原因是垂直扩展变更内存、CPU后有些情况下需要重新进行实例分布。</p>
<blockquote>
<p>Q：水平扩容只是增加实例就可以了，对吧。缩容呢，怎么判断呢？</p>
</blockquote>
<p>A：缩容也是一样的，根据最近10秒内的并发量决定需要多少个实例。</p>
<blockquote>
<p>Q：现在扩容的依据是基础监控数据和业务的监控数据同时考虑吗？</p>
</blockquote>
<p>A：目前平台主要基于基础监控数据来进行扩容，业务数据如果也是导致应用性能瓶颈的一个因素的话，纳入到扩容策略里面也是比较简单。</p>
<blockquote>
<p>Q：数据共享卷的解决方案是如何考虑的，基于cinder还是ceph，创建个数据共享卷要先格式化创建文件系统，如何实现和node节点挂载前的前格式化的，node节点故障，容器发生重生共享卷如何挂载到新节点上呢？</p>
</blockquote>
<p>A：共享卷是直接挂到容器上的，不是挂载到宿主机上，Glusterfs、Ceph、NFS等都支持。</p>
<blockquote>
<p>Q：灰度发布功能，目前我理解的是分为滚动升级和AB测试，这个目前实现的那种，AB测试具体如何理解呢？</p>
</blockquote>
<p>A：您说的是蓝绿发布吗？蓝绿发布应该是保证无宕机的前提下，将老版更新到新版。</p>
<blockquote>
<p>Ｑ：请问，Kubernetes中的A域名指向一个应用，B域名指向另外一个应用，都要用到80和443端口，这个该怎么做呢？</p>
</blockquote>
<hr>
<h3 id="2016-08-25：中英人寿保险有限公司基于容器技术的实践分享"><a href="#2016-08-25：中英人寿保险有限公司基于容器技术的实践分享" class="headerlink" title="2016-08-25：中英人寿保险有限公司基于容器技术的实践分享"></a>2016-08-25：中英人寿保险有限公司基于容器技术的实践分享</h3><blockquote>
<p>Q：您好，现在基于容器的解决方案也有很多，我想了解下部署后，你们是如何设置监控系统的，如果监控容器，可能会因为容器的生命周期不固定，导致部分监控数据会随着容器消失，变成无用数据；如果通过宿主机监控，那么你们是通过什么方式实现的，是通过自行开发，还是第三方开源程序，如何做到资源、应用数据的准确收集和合并？</p>
</blockquote>
<p>A：您提的问题也是实践中最担心一些问题，由于容器的技术变化很快，目前监控方面的问题我们更多使用第三方厂商提供的软件进行监控。 保险公司IT本身对容器相关技术，更多目前还是处在摸索和熟悉阶段。我们更多把容器作为一种灵活的工具，因此对于后台管理和监控，没有使用Docker自带的工具。</p>
<blockquote>
<p>Q：请问在Docker化过程中，遇到的最大的难题是什么，最后是怎么解决的？谢谢！</p>
</blockquote>
<p>A：最大困难还是对容器的理解问题，特别是管理层及运维开发实际操作人员如何理解容器。实际容器2015年下半年我们就想使用，但考虑到实际的推广困难，我们也是一直在找合适的机会，直到有合适机会才会真正开始应用和推广。我在分享中也提到了，谨慎原则，因为一旦第一步推广部顺利，那么后续困难就很大。所以我们第一步并没有给自己订立太高目标。</p>
<blockquote>
<p>Q：规模上去后，容器如何自动化的管理和容器配置文件如何自动化管理？谢谢！</p>
</blockquote>
<p>A：规模问题更多要看自身情况，目前更多介绍上都在强调容器在规模上的优势。但正如我开始提的，实际在业务场景中，规模本身是随着业务发展而增长的。我们目前考虑就是随着规模的增长，自身对容器的使用和经验积累也会随之增长。同时对于我们这样的寿险公司来说，更多采用商业解决方案。这样有比较持续可靠的长期支持，毕竟这个技术变化很快，我们更多关注灵活性和我们选定的优势的发挥。自动化管理和容器配制文件，只要项目部是很多，那么问题不大。如果普遍推广的话（这也是我们下一步计划）那么开发和运维人员自身的能力提高是解决自动化的关键，而不只是软件。</p>
<blockquote>
<p>Q：您好，能否介绍下微服务技术改造方面的经验，尤其是数据拆分方面，如何破除数据库之间的表依赖，比如在单体应用里很多功能都是直接通过数据库的关联查询实现的，如果进行微服务改造，怎么处理类似的关联查询？另外，能否介绍分布式事务管理的技术方案？</p>
</blockquote>
<p>A：数据部分我分段来回答一下。数据拆本身更多是IT对业务的理解问题，中英IT在这方面是比较擅长的，毕竟是自己的业务。这点首先我认为没有什么通用解决方案，必须根据实际自身情况来考虑。中英情况我接着介绍一下。\ 关联查询问题会很多，特别是性能。所以我也提到，这点光用技术解决方案很难解决，必须结合业务逻辑，考虑如何把数据前推。关于分布式事务管理，目前我们不建议采用分布式的事务管理，那样只会带来更复杂的逻辑关系。我们最多是考虑Redis的集群部署，但事务处理都是集中的。对于复杂问题，我们尽量去回避，本身项目就有很多挑战，不希望在这方面有更多不稳定因素。</p>
<blockquote>
<p>Q：数据库的数据前移到Redis， 增删改也是通过Redis？</p>
</blockquote>
<p>A：不是数据库前移，我们由于考虑信息安全和合规的要求，实际这次数据不落地。Redis都是缓存数据，而且不写文件系统。只用作查询，对后台数据的更新删除，还是采用远程调用服务的方式。根据业务分析，我们的应用绝大多数是查询，因此首先保证查询速度。</p>
<blockquote>
<p>Q：如果通过服务调用的方式</p>
</blockquote>
<p>更新后台数据的话，怎么做到事务的集中管理的呢？</p>
<p>A：由于寿险公司核心业务系统都是集中系统，事务处理一开始就根据业务模块和逻辑做了划分。因此在内部本身就是事务逻辑非常严格控制。这里首先是业务逻辑就有严格的前后逻辑顺序，什么前提下能做什么不能做什么有严格划分的。在DB层面的事务，我们DB本身就是集中DB，不是分布式的，因此DB本身控制事务，不存在控制不住的情况。但如果调用太多，的确会有严重锁的问题，这点反而是我们比较头疼的问题。同时首先业务时时交互频率不是那么高，因为不像电商，这个问题不突出。</p>
<blockquote>
<p>Q：规模上去后，有没有测试过性能方面的场景，比如某种配置的物理设备，可以负载多少容器，性能相关指标如何？谢谢！</p>
</blockquote>
<p>A：目前我们还没有这方面实际的经验。但在实施中考虑到规模的问题，因此这次实际选择的就是公用云，直接使用云的基础服务。另外关于性能和物理配制。这点，至少目前我们遇到的主要问题是内存不是CPU。合理分配内存是个经验积累的过程,我在分享里也提到了，我们遇到了因为配制不合理ELK性能非常差的情况，反而应用环境本身没什么问题。由于我们在规模上没有太多经验，因此不能给您更多的有用建议，这点互联网企业应该更有经验。</p>
<blockquote>
<p>Q：您好，请问你们公司是否存在一些Windows应用，针对这些应用如何使用容器统一部署管理？</p>
</blockquote>
<p>A：我们有Windows应用，至少目前我认为用Docker来统一部署Windows应用不太合适，我们内部如果有这个要求会选择VM，VBOX也是不错选择。</p>
<blockquote>
<p>Q：您提到不过分强调测试自动化，尽量不改变测试流程，那么对于自动构建和单元测试的自动化有没有考虑呢？毕竟这些是比较消耗人力的部分。</p>
</blockquote>
<p>A：自动构建我认为比较现实，单元测试有考虑。不过我们测试案例过于复杂，目前看短期实现不太现实。而且性能也是个问题，如果下一步要做我们会更多考虑一些特定场景。比如产品发布后的回归测试，这个有可能，但不会是普遍应用。</p>
<blockquote>
<p>Q：这次容器化改造后，对比原来的系统有哪些方面具体的提升呢？</p>
</blockquote>
<p>A：性能本身我认为和容器没什么关系，虽然这次性能有很大提升，但更多是因为用了公有云和Redis做缓存。容器改造后最大提升的我认为目前是部署和更新的效率。对运维工作效率有非常大的提升，毕竟大部分应用环境的更新都自动化了。这点本质性变化。</p>
<blockquote>
<p>Q：请问中英人寿应用更新的自动化流程能做些介绍吗，有没有将应用和配置分离做改造？</p>
</blockquote>
<p>A：我们这次是个全新项目，所以不涉及改造。自动化部分就是标准的持续集成Git+Jenkins的自动化管道。Git根据环境做了一些分支，部署直接采用Docker方式。这是一整套的。Docker相关配制目前是在cSphere里做管理，实际我们没太多操心这个部分。对于开发来说实际没什么太大变动。只是自动化构建做通了。</p>
<blockquote>
<p>Q：是否建议企业最佳实践是从新开发或重构应用开始容器化？</p>
</blockquote>
<p>A：这是个最保险方法，但我认为重点不是全新或者重构。而是是不是能带来实际效益，我说的是业务效果。对于用户来说实际并不了解和关心容器技术，想推广一个过用户关，一个过运维和开发协调的关。</p>
<p>以上内容根据2016年8月25日晚微信群分享内容整理。分享人<strong>张琦，中英人寿信息技术部总经理。中央财经大学保险专业毕业，具有15以上的寿险从业经验。长期从事寿险业务及信息技术相关工作</strong>。</p>
<hr>
<h3 id="2016-08-18：用Harbor实现容器镜像仓库的管理和运维"><a href="#2016-08-18：用Harbor实现容器镜像仓库的管理和运维" class="headerlink" title="2016-08-18：用Harbor实现容器镜像仓库的管理和运维"></a>2016-08-18：用Harbor实现容器镜像仓库的管理和运维</h3><blockquote>
<p>Q：Master-Slave的镜像架构中,如果Slave Registy中的镜像被删除了，会不会再次自动从Master Reg里面自动同步？</p>
</blockquote>
<p>A：如果停止后再重新启动复制策略，可以同步被删除的镜像。</p>
<blockquote>
<p>Q：对于多个投产地，多个仓库，哪种方式的高可用方案好么？第一种，共享存储存储可能会出现单点故障么？</p>
</blockquote>
<p>A：共享存储只适合同一数据中心，多个产地延时太大，不适合共享存储。</p>
<blockquote>
<p>Q：Registry之间同步是如何实现的？</p>
</blockquote>
<p>A：Registry API。</p>
<blockquote>
<p>Q：在存储这块考虑过提供插件方式可以调用外部模块，比如以插件方式支持s3这种对象存储？</p>
</blockquote>
<p>A：Harbor支持其他存储方式，参见<a href="https://github.com/vmware/harbor/blob/master/docs/installation_guide.md" target="_blank" rel="noopener">Harbor文档</a>。</p>
<p>以上内容根据2016年8月18日晚微信群分享内容整理。分享人**张海宁（HenryZhang），VMware中国研发中心云原生应用首席架构师，Harbor开源企业级容器Registry项目负责人，Cloud Foundry中国社区最早的技术布道师之一。在VMware中国研发中心先后负责开源平台Cloud Foundry、大数据虚拟化、软件定义存储等领域的技术布道和解决方案推广。目前着重关注云原生应用的研发工作，内容包括Container、PaaS、IaaS等方面。</p>
<hr>
<h3 id="2016-08-16：容器化ICT融合初体验"><a href="#2016-08-16：容器化ICT融合初体验" class="headerlink" title="2016-08-16：容器化ICT融合初体验"></a>2016-08-16：容器化ICT融合初体验</h3><blockquote>
<p>Q：网络转发有没有遇到瓶颈？有没有尝试一些加速技术，比如DPDK？</p>
</blockquote>
<p>A：因为是控制面网元，目前没有遇到瓶颈，没有用DPDK，我们之前测试过虚拟机的，因为网元特点，也是没有配置DPDK，目前的测试上看，性能上没有问题。</p>
<blockquote>
<p>Q：现在数据库也放在容器中吗？</p>
</blockquote>
<p>A：是的，但是也是数据库集群，我们正在做将数据库分离的工作。</p>
<blockquote>
<p>Q：你们实测的容器运行于虚拟机环境，性能如何，你们容器网络如何实现NFV互联？</p>
</blockquote>
<p>A：容器没有基于虚拟机环境，因为是控制面网元，性能没有遇到瓶颈。</p>
<blockquote>
<p>Q：容器不会包打天下，与虚机，物理机并存可能是一段时间内的一种常态，我们有没有分析哪些业务适合容器化，哪些业务不宜改变？并且在利用Kubernetes作为容器的编排调度工具时，如何实现容器与虚机应用的互通？</p>
</blockquote>
<p>A：其实业务不宜改变不仅仅是技术问题，也和业务厂商是否愿意改变有关，毕竟一些遗留的业务已经在现网运行很久了，很难短期内容器化。另外，我们确实碰到了需要内核优化的业务。我们系统中还没有做容器和虚拟机应用互通。</p>
<blockquote>
<p>Q：传统CT网络不仅仅是IMS吧，对于CS、PS，SDN/NFV化，你们有什么思路吗？</p>
</blockquote>
<p>A：IMS使我们容器化的第一个尝试，其他的网元也正在研究中，后续也会做相关的测试，如果有兴趣，也欢迎参加我们后面的测试。</p>
<blockquote>
<p>Q：你们的资源池，有路由器，安全组，负载均衡之类的功能嘛？路由器，负载均衡器可以被分配公网IP吗？</p>
</blockquote>
<p>A：指的是容器的资源池还是我们已有的私有云资源池，已有的私有云资源池是有的，但是容器这个原型系统还没有。</p>
<blockquote>
<p>Q：类似Clearwater的开源项目还有哪些？</p>
</blockquote>
<p>A：NFV方面的吗，如果是IMS，Clearwater业界用的比较多，NFV其他网元开源项目很多。</p>
<blockquote>
<p>Q：你们的虚拟机底层使用什么虚拟化技术支撑？</p>
</blockquote>
<p>A：这次演示，底层用的就是Docker，我们的私有云资源池有VMware、KVM也有Xen。</p>
<p>以上内容根据2016年8月16日晚微信群分享内容整理。分享人<strong>马轶慧，中国移动通信有限公司研究院私有云项目经理，之前曾任VMware研发中心研发工程师。一直关注并致力于虚拟化、容器、云计算等相关领域。</strong></p>
<hr>
<h3 id="2016-08-11：应用容器化之Kubernetes实践"><a href="#2016-08-11：应用容器化之Kubernetes实践" class="headerlink" title="2016-08-11：应用容器化之Kubernetes实践"></a>2016-08-11：应用容器化之Kubernetes实践</h3><blockquote>
<p>Q：请问在Kubernetes架构下 搭建分布式服务框架如Dubbo</p>
</blockquote>
<p>需要将主机地址和暴露端口注册到ZooKeeper上，这个主机地址和暴露的端口你们是怎么处理的，即容器内的应用如何获取Docker宿主机地址？</p>
<p>A：Dubbo服务不需要暴露主机的IP和地址，只需要知道容器地址即可。这些服务都是注册到ZooKeeper上面，通过ZooKeeper完成服务发现，Kubernetes能够根据暴露端口进行调度,当然有些应用要求容器能获取到宿主机的IP地址，这块我们对Kubernetes做了一些修改，可以动态注入诸如宿主机IP，宿主机主机名信息到容器的环境变量中。</p>
<blockquote>
<p>Q：ECP的定位和解决目标相比较目前大家在用传统的云平台解决方案来讲下？</p>
</blockquote>
<p>A：ECP产品定位是一套完整的容器解决方案，从容器生命周期管理，资源监控到日志分析处理，相比与云平台解决方案管理的对象不再是虚拟机，而是容器，面向的对象是服务。</p>
<blockquote>
<p>Q：关于容器本身的资源性能监控，是用的cAdvisor+Heapster吗，如何能保持pod重启（重启后pod名称变化）后的数据连续性，谢谢。</p>
</blockquote>
<p>A：资源监控用的不是Heapster，ECP的资源监控是用cAdvisor+我们自己研发的采集Agent+Ceilometer+MongoDB+HBase等技术。复用了我们在做CMP产品时的技术，rc中的pod重建后会重命名，这块对于单一pod数据的连续性还没有考虑，我们是把rc当做一个整体考虑的 。</p>
<blockquote>
<p>Q：你们对外服务的负载均衡如何做的？是直接用Kubernetes的service吗？</p>
</blockquote>
<p>A：对外负载均衡现阶段用的是Kubernetes的service，考虑到iptables带来的性能损耗，后续我们会考虑使用别的方案，在集群内部直接把流量转发到对于的pod上。</p>
<blockquote>
<p>Q：请问Kubernetes容器和在其中运行的应用程序监控是如何做的？能介绍下吗？谢谢！</p>
</blockquote>
<p>A：ECP的资源监控是用cAdvisor+我们自己研发的采集Agent+Ceilometer+MongoDB+HBase等技术。复用了我们在做CMP产品时的技术。简单来说就是用cAdvisor采集原始数据，然后通过Ceilometer持久化，提供实时数据查询、告警等功能。数据会定期转存到hbase做历史数据分析。</p>
<blockquote>
<p>Q：请问，有基于Kubernetes的多租户和用户配额开源实现嘛？</p>
</blockquote>
<hr>
<h3 id="2016-08-04：传统金融-IT-对混合云管理的一些思考"><a href="#2016-08-04：传统金融-IT-对混合云管理的一些思考" class="headerlink" title="2016-08-04：传统金融 IT 对混合云管理的一些思考"></a>2016-08-04：传统金融 IT 对混合云管理的一些思考</h3><blockquote>
<p>Q：传统金融行业很多关键系统架构比较简单都为集中式架构，不好做横向扩展，不适合放到私有云上，这个问题有什么好的解决思路？</p>
</blockquote>
<p>A：从数据面和业务场景来细分，关键系统涉及客户资料、资金动账系统，仍然保留在传统集中式的主机平台，但是会将查询类交易下移到基于 X86 的私有云上。</p>
<blockquote>
<p>Q：混合云如何解决多租户服务与金融行业监管要求物理隔离之间的矛盾？</p>
</blockquote>
<p>A：金融行业监管要求物理隔离在数据中心网络层面表现为”2 网分离”：办公网和业务网。 相对应的，混合云的多租户也细分出开发云、测试云和生产云租户。各租户的资源和操作严格进行隔离</p>
<blockquote>
<p>Q：您认为迁移到云的步骤应该如何，哪些适合迁移到云</p>
</blockquote>
<p>A：在实践中，先理清应用的家底。根据业务场景需要和云的能力、团队的技能成长、监管底线（上公有云的话）等维度进行评估，选择上云的应用。迁移步骤具体看是否要重构应用架构，相应迁移难度不一。</p>
<blockquote>
<p>Q：哪些业务适合使用云服务?云架构与传统架构肯定存在一个并行期，两套架构如何融合并存?</p>
</blockquote>
<p>A：在私有云，云服务不是像公有云服务一样完备，建设是有个过程，所以前期内部管理类、和客户交互的渠道类业务适用上云。</p>
<blockquote>
<p>Q：云架构与传统架构肯定存在一个并行期，两套架构如何融合并存?</p>
</blockquote>
<p>A：的确存在并行期，架构职能团队可以发挥较大作用，一个作用是架构管理团队各片区和开发团队设计角色管理好各产品的应用架构,另外一个作用组织人手开展云架构的设计、原型开发，引导产品的架构进行演进。</p>
<blockquote>
<p>Q：你指的混合云是以 Oracle、IBM、VMware 主导的商业软件公司提供的平台比如 O 记的数据库混合云，还是以开源软件为主的比如 OpenStack、KVM，上面跑基于开源的 Tomcat、MySQL ？</p>
</blockquote>
<p>A：我们理解的混合云是更广义，包括公有云和私有云领域，公有云例如 AWS、AZURE、阿里云等，私有云例如 vCloud、青云等。</p>
<blockquote>
<p>Q：传统金融的现有商业软件如何与开源平台结合？</p>
</blockquote>
<p>A：以选择云平台的技术栈建设云服务，现有商业软件不是强求结合，结合成本太高或技术架构不合适就该舍弃。例如小机 WEB 应用上云，就会从 Was 换成轻量级的WEB 应用服务器，例如 Tomcat、JBoss。</p>
<blockquote>
<p>Q：传统金融的 IT运维能否自己支撑开源平台构建自己的混合云，从你的视角看中小型城市商行依靠自己的 it运维构建自己的混合云当前阶段是否切实可行？</p>
</blockquote>
<p>A：这要看单位的大背景，如果业务部门没有传导市场压力到 IT 部门，那么面对 IT 开发团队，由 IT 运维主导建设基于开源的混合云平台作为起点，也是一种可行的选择。我们的大背景是业务压力的传导，以及自我变革的高层压力，所以是由架构职能团队牵头规划设计，新建的云平台团队实施落地。</p>
<blockquote>
<p>Q：请问在云化的过程中，是已自行研发开源技术为主呢，还是使用较为成熟的商用软件为主。如何平衡成本与效率的关系</p>
</blockquote>
<p>A：贴近应用的部分建议自研，例如开发框架、公共组件。基础设施部分需要稳定为主，例如虚拟化平台、对象存储服务、消息队列服务等，一般选择商用软件或开源软件企业版，有些加客户化定制。</p>
<blockquote>
<p>Q：如果是混合云的架构话不是应当考虑公有云和私有云一致性吗？，而刚才说的结合就变成了一种简单的去IOE，客户总不能生产跑 Was，公有云跑 Tomcat 吧，如果这样推动混合云那么是不是意味着先就要推动去IOE，改造应用？</p>
</blockquote>
<p>A：这个问题可以细分 2 种层次来看，混合云架构设计对基础设施（VM、容器、镜像、网络等）是要进行抽象，达成这个层次上看私有云和公有云是一致 的。 另外混合云架构设计上，管理的另一个高阶层次是对应用架构的抽象，理想能够做到应用在不同云上进行无痛迁移。传统上在 IOE 上的业务系统，如果有开发框架的支持，且框架的架构做的好，则开发框架改造上云后，应用代码改造量很少。</p>
<p>以上内容根据2016年8月4日晚微信群分享内容整理。分享人<strong>罗文江，某传统金融IT架构师，关注和IaaS、Docker和云管理关联的技术</strong>。</p>
<hr>
<h3 id="2016-07-28：SAP-Anywhere产品背后CD的实现"><a href="#2016-07-28：SAP-Anywhere产品背后CD的实现" class="headerlink" title="2016-07-28：SAP Anywhere产品背后CD的实现"></a>2016-07-28：SAP Anywhere产品背后CD的实现</h3><p>A：DaemonSet是Kubernetes的一种功能，用来把POD调度到所有满足条件的节点上。我们的使用场景是把看家狗程序调度到每一个集群里的节点，以起到监控作用。</p>
<blockquote>
<p>Q：你们主要跑的什么类型的应用？</p>
</blockquote>
<p>A：我们的业务是基于WEB-UI的ERP产品。</p>
<blockquote>
<p>Q：请问Kubernetes使用health check http请求的时候有没有遇到容器可能本身需要好久才能启动完毕那么这个人机制就会一直死循环…请问这个有没有好的方式解决？</p>
</blockquote>
<p>A：Kubernetes health check分成readinessProbe和livenessProbe。前者决定容器是否ready，后者当检查失败后直接暴力杀死容器。某些容器启动较慢，所以需要设定一个等待时间。我们的容器等待时间是readiness->15s, liveness->2min。</p>
<blockquote>
<p>Q：后来，我们按功能把原先的一个集群拆分成了多个，分别运维，如此一来，稳定性大为提升，这个怎么拆的呢？</p>
</blockquote>
<p>A：根据功能拆。比如一个集群专门跑Jenkins，另一个集群专门跑slow-test。BTW、slow-test是用来进一步验证当前提交是否存在bug的一种测试，由于跑的时间比较长，所以叫slow-test。</p>
<blockquote>
<p>Q：Kubernetes API server经常宕机?到规模上限了？API server可以起多个做负载均衡吧，API server宕机的时候Scheduler和controller-manager到瓶颈了么？</p>
</blockquote>
<p>A：早期的宕机可能是我们自己使用不当，比如把API server交给每一个开发人员（我们有200多人），然后大家都去玩kubectl各种命令，里面有几个命令比较吃资源，一种是port-forward，另一种是watch kubectl get pod。</p>
<blockquote>
<p>Q：对于应用的配置你们如何管理？</p>
</blockquote>
<p>A：这是个好问题。我们内部讨论的比较激烈。目前有两种极端，一类人倾向于每个服务自己管理配置；另一类人倾向提供一个专门的配置微服务。各有利弊吧。</p>
<blockquote>
<p>Q：一个DEMO系统是否包括依赖的服务？如果依赖，那假如DEMO系统中多个服务需要发布，要每个都起一套DEMO系统吗？</p>
</blockquote>
<p>A：前文提到我们有接近30个微服务，是的，每一套DEMO系统都包含那么多微服务，所以做一套DEMO系统挺”重”的。当然我们在搭建DEMO系统时，主要还是利用了Kubernetes的调度能力来并行处理任务的。</p>
<blockquote>
<p>Q：Web UI应用有没有涉及到负载均衡可以介绍一下的？</p>
</blockquote>
<p>A：我们使用Nginx作为反向代理，Kubernetes的deployment/rs作为负载均衡。nginx upstrea/server编写服务的内部域名，被SkyDNS解析成cluster IP，再被IP tables做round robin路由到真实pod。</p>
<blockquote>
<p>Q：『根据功能拆。比如一个集群专门跑Jenkins，另一个集群专门跑slow-test。BTW，slow-test是用来进一步验证当前提交是否存在bug的一种测试，由于跑的时间比较长，所以叫slow-test』，你们原来是混在一个集群里的啊？</p>
</blockquote>
<p>A：是的，早期我们是跑在一个集群里的。那时候我们膜拜Kubernetes，认为谷歌大师级的产品一定能很好的利用异构系统组成集群，并且良好的管理里面的应用的。事实比较令人遗憾，当然不排除我们自己代码的问题，总之跑在一起比较不稳定，而且遇到故障时比较难恢复（因为影响面比较大）。</p>
<blockquote>
<p>Q：您好，我想了解下你们开发的DaemonSet可不可以用Supervisor这样的去替代，如果可以需要注意些什么，之前监控Web遇到过Web服务200，实际Web服务已经挂起的情况，如何监控类似事件？</p>
</blockquote>
<p>A：补充一下第一个问题的答复：监控web服务，这个需要服务自己暴露（实现）一个特殊的API，通常可以是 /heath，然后服务自己在API里面完成健康扫描。那么k8s就知道服务是否处于僵尸状态了。</p>
<blockquote>
<p>Q：你们的Kubernetes API有没开启HTTPS？如果开启是否有在Pod访问API的案例介绍一下？</p>
</blockquote>
<p>A：事实上，我们开启了HTTPS，但是在大部分情况下，我们仍然使用HTTP端口连接API server。我们下一个目标就是全面启用授信的安全模式。至于Pod访问API server只要有service token即可。</p>
<blockquote>
<p>Q：你好，把Jenkins和Slow Tests拆分集群是按命名空间分了，还是再单独部署了另外一套Kubernetes？</p>
</blockquote>
<p>A：我说的拆分是指物理上的拆分，变成两个Kubernetes集群了。这方面我们仍然在摸索，到底是多个小集群容易管理还是一个大集群容易管理。</p>
<blockquote>
<p>Q：有考虑过使用Docker官方的Swarm吗？新手，不知道该选择哪个。</p>
</blockquote>
<p>A：Kubernetes和Docker Swarm天生就是两种教派，有点”正邪不两立”的味道。事实上，我们早期做原型的时候有考虑过Mesosphere。个人观点：从目前的发展来看Kubernetes和Swarm很难走到一起去，这意味着选择其中之一必然会放弃另一个。而Kubernetes是谷歌主推的，考虑到谷歌内部Borg系统是Kubernetes的原型，每天跑着百万级的应用，应该不会有错的。</p>
<p>以上内容根据2016年7月28日晚微信群分享内容整理。分享人<strong>陈贇喆（MilesChen），资深开发工程师、全栈工程师、系统架构师。从业十年有余，目前就职SAP中国研究院，担任架构师一职，负责SAPAnywhere产品的CI/CD工作</strong>。</p>
<hr>
<h3 id="2016-07-26：基于Docker的负载均衡和服务发现"><a href="#2016-07-26：基于Docker的负载均衡和服务发现" class="headerlink" title="2016-07-26：基于Docker的负载均衡和服务发现"></a>2016-07-26：基于Docker的负载均衡和服务发现</h3><blockquote>
<p>Q：同一个域名指向一台主机内的容器服务，部署了n个相同的容器，怎么根据他们的负载来分配到不同的容器中？</p>
</blockquote>
<p>A：7层负载均衡麻烦参考下<a href="http://nginx.org/en/docs/http/load_balancing.html" target="_blank" rel="noopener">Nginx</a>和<a href="http://cbonte.github.io/haproxy-dconv/intro-1.6.html#3.3.5" target="_blank" rel="noopener">HAProxy</a>的使用方法即可，注意，我们的HAProxy容器跟其他目标服务的容器是直接在同一个网络里面的。你说的根据负载分配，可以使用最小连接数算法，即<a href="http://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4.2-balance" target="_blank" rel="noopener">leastconn</a>算法，需要查看HAProxy帮助手册进行设置。</p>
<blockquote>
<p>Q：Docker 1.2 IPVS的方案，是否可以实现完全取代Keepalived+Nginx的效果？</p>
</blockquote>
<p>A：不能， IPVS是4层协议的，在很多场景下，需要7层协议的功能，例如共享同一个端口，提供7层协议解析，gzip压缩，cookie注入，session保持等功能。</p>
<blockquote>
<p>Q：有没有评估过Kubernetes在host上用iptables做lb的方案？为什么不用那种？</p>
</blockquote>
<p>A：因为我们希望提供7层的路由和负载均衡，iptables的方案是基于4层的，不能共享同一个端口，不能提供7层协议解析，压缩，cookie注入，session保持等功能。</p>
<blockquote>
<p>Q：问下灰度发布具体是怎么实现的？</p>
</blockquote>
<p>A：灰度发布的具体实现方式如下： 例如有服务的两个版本A 和 a，他们使用相同的路由，挂在同一个域名（例如<a href="http://www.example.com" target="_blank" rel="noopener">www.example.com</a>）的后端，但是A和a的权重不一样，通过调整权重来做到灰度发布，流量分配到不同的后端。</p>
<blockquote>
<p>Q：请问haproxy访问其它主机容器网络怎样通信？</p>
</blockquote>
<p>A：一个容器集群有多台机器，通过<a href="https://docs.docker.com/engine/userguide/networking/dockernetworks/#/an-overlay-network" target="_blank" rel="noopener">Overlay</a>网络，可以做到跨主机节点在同一个网络中。</p>
<p>以上内容根据2016年7月26日晚微信群分享内容整理。分享人<strong>谭林华，阿里巴巴高级工程师，多年以来一直关注系统接入层相关技术，包括DNS，负载均衡，服务路由和发现，热衷容器技术</strong>。</p>
<hr>
<h3 id="2016-07-19：浅谈Docker安全合规建设"><a href="#2016-07-19：浅谈Docker安全合规建设" class="headerlink" title="2016-07-19：浅谈Docker安全合规建设"></a>2016-07-19：浅谈Docker安全合规建设</h3><blockquote>
<p>Q：容器安全和虚拟机的安全有什么异同？</p>
</blockquote>
<p>A：容器可以在更细的颗粒度上来保护应用，比如说物理机好比大楼，虚拟机好比不同的房间，容器就是里面同房的租户，大楼及房间保障了外部的安全，如果你不相信同屋的租客，则需要用容器来更强的隔离，这是2个不同角度的问题。</p>
<blockquote>
<p>Q：镜像安全，Clair扫描靠谱么？</p>
</blockquote>
<p>A：Clair是CoreOS发布的一款开源容器漏洞扫描工具。该工具可以交叉检查Docker镜像的操作系统以及上面安装的任何包是否与任何已知不安全的包版本相匹配。漏洞是从特定操作系统的通用漏洞披露（CVE）数据库获取,它偏向于静态扫描，即镜像安全，国际上对容器运行时安全方案涉足较少，国内容器云对安全更是空白一片。</p>
<blockquote>
<p>Q：Docker有一个User Namespace的机制，这种隔离在正式的安全规范里有相应描述吗？有没有尝试过利用这种机制增加安全性？</p>
</blockquote>
<p>A：Docker的安全标准规范基本处于空白阶段，大家都在摸索，主要是实践累计。user namespace可以增强一定的隔离性，但是刚才也提到：用user namespace隔离后，其实太多用户不会用操作日志，用于后期追踪及审计。</p>
<blockquote>
<p>Q：能介绍下沙箱与容器的不同吗？</p>
</blockquote>
<p>A：沙箱和容器只是在工作的方式上比较类似，但是底层的技术实现和代码其实是完全不一样的。</p>
<blockquote>
<p>Q：如何才能有效的检测出下载的镜像是否含有木马等不安全的信息呢?挂载到容器中的目录，如何给只读权限，后续数据库一些信息想写入宿主机又如何实现？</p>
</blockquote>
<p>A：对镜像扫描目前世面上还是有一些产品的，比如说刚才某位同学提到的Clair。 挂载到容器的目录可以通过ro参数设定只读权限，但是需要写入的目录挂载只设只读权限程序是不能运行的，这样就涉及到宿主机的文件安全，相信宿主机的安全产品及方案，现在已经很多，就不复述了。</p>
<blockquote>
<p>Q：木马检测涉及到特征代码库，检测比较难吧？</p>
</blockquote>
<p>A：木马检测其实都是基于目前的技术， 只是容器的数量可以远远大于虚拟机，这样对检测的性能和时效有了更高的要求。</p>
<blockquote>
<p>Q：最近一直被人问到安全性的问题，但是只从单机角度考虑安全性是否已经无法满足分布式计算环境，我们是否更应该从分布式计算带给我们的规模效应和自愈机制来重新审视Docker的安全标准，请问嘉宾是如何看待分布式计算中的整体和部分，以及它们之间的安全关系，谢谢。</p>
</blockquote>
<p>A：分布式也是由节点组成的，单机安全是基础，如果单机安全性都无法满足，分布式的安全更无从说起。 当然，分布式存在大规模效应，节点更多需要关注的是数据的处理及储存安全；在满足了节点安全后，分布式更多的应该是考虑跨节点之间的数据传输安全，尤其是跨公网的数据传输（VPN 隧道也是属于跨公网的传输一种）。自愈机制其实应该算保障业务连续性的一种方式，当然也可以归纳为安全的一种。</p>
<blockquote>
<p>Q：请问Rancher 除了使用”环境”外，目前能完美实现租户隔离吗？</p>
</blockquote>
<p>A：可以使用主机标签+容器策略的方式，将不同用户用虚拟机或物理机进行隔离。 就目前Rancher来说，不同环境是比较好的隔离方案。</p>
<blockquote>
<p>Q：不知道嘉宾给的安全建议是否适用于CoreOS这种Docker化的OS，还是说这类OS会有更好的合规功能？</p>
</blockquote>
<p>A：CoreOS这种系统确实更适合容器，而且承载的功能也更加少，相应的需要合规的点也越少。 但是不排除某些合规要求强制的功能点无法满足，这需要根据实际情况来判断。</p>
<blockquote>
<p>Q：除了镜像扫描，还有哪些容器安全需要注意的地方，和哪些成熟方案呢？</p>
</blockquote>
<p>A：除了镜像扫描，还需要关注容器运行时安全，如网络安全，应用程序漏洞，防止被攻击，安全策略等； 相信接下来有容云发布的AppSafe产品不会让大家失望。</p>
<blockquote>
<p>Q：虚拟机的安全方案是否也同样适用于容器？</p>
</blockquote>
<p>A：应该是部分适合，刚才提到容器和虚拟机关注点是不一样的。 虚拟机更多是系统安全+应用安全， 容器的主要关注点还是应用安全，如代码漏洞，软件漏洞等等。</p>
<blockquote>
<p>Q：如何评价Docker 1.12中Swarm模式自带的TLS认证？</p>
</blockquote>
<p>A：大家都知道前段时间的心血漏洞，大家也知道目前互联网环境的情况， 其实TLS认证已经是很多环境的必备要求，甚至对TLS的版本号也是严格的要求，比如说某些行业必须使用TLS1.2以上的版本才能合规。Swarm模式自带的TLS认证相信也是基于此类要求。</p>
<p>以上内容根据2016年7月19日晚微信群分享内容整理。分享人<strong>蒋运龙，<a href="http://www.youruncloud.com/" target="_blank" rel="noopener">有容云</a>高级咨询顾问，一个IT的老兵，十年来混迹于存储、三网融合、多屏互动、智能穿戴、第三方支付、Docker等行业；经历过测试、运维、实施各岗位全方位的摧残，依然活跃在技术的风头浪尖上。之前分享过<a href="http://www.youruncloud.com/blog/78.html" target="_blank" rel="noopener">《老司机带路 使用Docker实现丝般顺滑的持续集成》</a></strong>。</p>
<hr>
<h3 id="2016-07-14：应用容器env化实战"><a href="#2016-07-14：应用容器env化实战" class="headerlink" title="2016-07-14：应用容器env化实战"></a>2016-07-14：应用容器env化实战</h3><blockquote>
<p>Q：Mesos运行一个任务，如果发现该任务运行过程中需要加大资源，Mesos如何做到对任务资源的弹性扩容？如果采用Docker的话，是新建更多的Docker容器还是直接扩大现有Docker的大小？</p>
</blockquote>
<p>A：一般是扩展更多的Docker容器个数，除非是某个任务有最小资源要求，才要扩大单个Docker的大小。</p>
<blockquote>
<p>Q：开发人员使用的本地环境变量如何管理？例如一个应用，有数据库，有搜索引擎，还有两个Java APP，不同开发可能需要嗯环境不同，例如我是搜索功能的开发，需要链接公共的数据库，而有些开发需要自己有数据库，搜索引擎却需要链接公共的。这种配置，如何管理？</p>
</blockquote>
<p>A：这种最好将数据库环境变了进行区分，配置两个或多个类似环境变量。</p>
<blockquote>
<p>Q：请问MySQL数据库怎么随Docker迁移?备份和恢复有什么好的建议吗？</p>
</blockquote>
<p>A：MySQL现在是固定主机主从同步，没有对MySQL做迁移，我们的数据现在备份是定时全备份，正在尝试使用MariaDB集群Galera Cluster ，但还没有上生产，当然有共享存储的话就最好不过啦。</p>
<blockquote>
<p>Q：请问线上服务更新war包，如何能使对外服务不间断吗？</p>
</blockquote>
<p>A：数人云目前采用代码版本和镜像版本统一，对外服务不间断，数人云目前的做法是对应用进行无状态改造，后通过marathon put更新容器。</p>
<blockquote>
<p>Q：请问 配置文件的话生产环境和开发环境怎么区分？</p>
</blockquote>
<p>A：生产环境和测试环境都是隔离的，配置文件配置不同的参数即可。</p>
<blockquote>
<p>Q：请问对类似Java应用jdbc、spring.xml等配置文件如何管理？</p>
</blockquote>
<p>A：XML配置 通过sed替换传入的环境变量。</p>
<blockquote>
<p>Q：生产上配置项变更怎么操作？</p>
</blockquote>
<p>A：生产配置的值需要修改时 ，在configcenter页面中修改，再触发Jenkins更新配置文件的job， 生产新的配置文件 ，再调用marathon API 更新task进行更新。</p>
<blockquote>
<p>Q：业务的配置是和环境配置放在一起的么？</p>
</blockquote>
<p>A：是的，都是通过envfile进行统一的。</p>
<blockquote>
<p>Q：请问你们针对应用弹性扩展是自感应的吗？如果是，请问是基于什么策略做的，监控报警还是什么？</p>
</blockquote>
<p>A：数人云是通过监控报警触发弹性扩展的，如监控接口返回的时间，容器内存使用率等。</p>
<blockquote>
<p>Q：请问你们对环境变量是采用什么样的管理方法？有相应的命名规范吗？环境变量多了，会出现管理方面的问题吧。</p>
</blockquote>
<p>A：环境变量键值由开发维护，运维需要提前了解新增环境变量，目前在配置中心里维护，容器环境变量变量命名规范很重要，我们目前采用服务名＋需连接的组件名＋属性 进行命名的，且环境变量全部大写。</p>
<p>以上内容根据2016年7月14日晚微信群分享内容整理。分享人<strong>方志浩，92年的程序猿，毕业之后一直在数人云，对Docker 和 Mesos有深入研究，目前做数人云平台打包部署以及部分客户项目实施工作，喜欢在实践中尝试新事物并总结</strong>。</p>
<hr>
<h3 id="2016-06-30：-Docker网络方案初探"><a href="#2016-06-30：-Docker网络方案初探" class="headerlink" title="2016-06-30： Docker网络方案初探"></a>2016-06-30： Docker网络方案初探</h3><blockquote>
<p>Q：从你发的Marathon json文件来看，你们是对Mesos底层的网络做了扩展吗？容器网络通过\”parameters\”传递下去的吗？</p>
</blockquote>
<p>A：就是利用Marathon支持的Docker parameters下发，等同于 <code>docker run ---net dataman xxx</code>。</p>
<blockquote>
<p>Q：Felix根据配置的pool地址段配置路由，BGP Client通告路由？请问bgp的邻居关系是怎么建立的？是依靠etcd里的信息？</p>
</blockquote>
<p>A：是的，Felix配置本地Kernel路由，BGP Client负责分发路由信息；BGP小规模部署采取mesh方式建立，所有节点互联n\^2的联系，大规模部署推荐 部署一个或多个BGP route reflector，专门负责路由信息分发。</p>
<blockquote>
<p>Q：请问在DataMan这个网络中路由信息是如何更新的？我们知道BGP是可以自己发现收敛网络的，那么在网络控制层面是如何设计的？</p>
</blockquote>
<p>A：随着使用DatMan这个网络的容器的添加或者删除，Felix负责更新本地路由，BGP client 负责向外分发；Calico的BGP和广域网的BGP还是有不同，它只是使用private AS num，相对自治，网络控制层面都是可以程序控制的。</p>
<blockquote>
<p>Q：请问Calico如何解决多租户里地址冲突的问题？</p>
</blockquote>
<p>A：多租户容器混部在同一主机上时，所使用的Network最好不要用同一个Pool里的就好，这样就不可能有冲突了。</p>
<blockquote>
<p>Q：如果集群的容器很多，那么相应的路由表的规则也会增多，这样会不会对网络性能造成影响？</p>
</blockquote>
<p>A：网络性能不会有太大影响，因为容器多流量多网络压力本来就大，倒是会增加系统负载，毕竟要配置路由规则，同步网络信息；这部分我们也很关心，但还没有具体的测试结果。</p>
<blockquote>
<p>Q：还有就是路由信息是存放在etcd中吗？如何保证路由表的读取性能和维护路由表的信息更新？</p>
</blockquote>
<p>A：生效的路由肯定是本地的，Endpoint等信息是在etcd的；这两个问题都是Calico自身要解决的问题，这部分我们也很关心，但还没有具体的测试结果；</p>
<blockquote>
<p>Q：Calico下跨多个路由hop的情况，中间路由不需要学习这么多的容器路由表吗？</p>
</blockquote>
<p>A：不需要，中间过程是依赖节点之间原有的网络建设的，只要两个节点互通，所有的hop都不需要知道Calico内部的容器路由信息。</p>
<blockquote>
<p>Q：还有一个问题，就是网络管理问题。目前从设备厂商网站看有几个支持VXLAN控制器的。这些控制器能不能与容器OVS协同？目前来看我们这里买国外产品还是比较困难的。</p>
</blockquote>
<p>A：这个肯定是问题，我觉得作为平台方，我们能做的很少，如果要改变，肯定是要SDN设备厂商发力，就像是各家都会去为OpenStack适配设备提供driver一样，但是也需要Docker或者说容器编排系统能做到如同OpenStack那样的行业标准级。</p>
<blockquote>
<p>Q：Calico能和Flannel整合么，CoreOS上Kubelet里同时出现了Calico和Flannel？</p>
</blockquote>
<p>A：Calico在DockerCon 2016应该是高调拥抱了Flannel，两个整合出了一个叫canal的项目，有兴趣可以去找找看。</p>
<blockquote>
<p>Q：我想问一下老师，你这VXLAN的标签是Calico打的对吧？</p>
</blockquote>
<p>A：Calico没有VXLAN，Calico的tag会对应到 ipset，iptables 用来 match filter规则。</p>
<blockquote>
<p>Q：Calico下跨多个路由hop的情况，中间路由不需要学习这么多的容器路由表吗？</p>
</blockquote>
<p>A：不需要，中间过程是依赖节点之间原有的网络建设的，只要两个节点互通，所有的hop都不需要知道Calico内部的容器路由信息。</p>
<hr>
<h3 id="2016-06-28：公有云上的容器实践分享"><a href="#2016-06-28：公有云上的容器实践分享" class="headerlink" title="2016-06-28：公有云上的容器实践分享"></a>2016-06-28：公有云上的容器实践分享</h3><blockquote>
<p>Q：请问你们是生产环境么，应用代码放容器里还是挂卷，镜像权限如何控制（比如测试和生产），代码测试后，上生产配置自动还是手动修改还是有配置中心呢？</p>
</blockquote>
<p>A：您指的是源码还是编译后的产物，我们是编译后的产物是镜像，容器直接运行，测试和生产是隔离的，相当于我们管理了四套环境（开发、测试、预发、生产），介质是通过跳板机同步的，有统一的SCM做不同环境的配管。</p>
<blockquote>
<p>Q：Kubernetes Master的高可用你们是怎么做的？</p>
</blockquote>
<p>A：Master我觉得没必要做，宕了重启就行，没有损失，我们就是这么做的，只要保证etcd等高可用就行。</p>
<blockquote>
<p>Q：从集群外部对Kubernetes的Service的访问是如何实现的？比如公网IP是怎么绑定给Service的？</p>
</blockquote>
<p>A：Kubernetes发布成Service，是可以给定publicip的，这个时候你可以用公网IP作为网络池，内部有一层端口映射。</p>
<blockquote>
<p>Q：Kubernetes现在自己还缺少可视化编排能力，那个UI也是以监控为主，你们实际使用中对Kubernetes可视化编排需求多吗，如果多的话目前怎么解决？</p>
</blockquote>
<p>A：我们自己做了部分编排，编排不一定非得是图形化的，我们以表单为主，主要用于部署编排。</p>
<blockquote>
<p>Q：阿里云上的容器能提供负载均衡嘛比如我有个宿主机挂了？</p>
</blockquote>
<p>A：这个不是阿里云做，而是Kubernetes做的，Kubernetes有Replication的能力。</p>
<blockquote>
<p>Q：这几天遇到个需求，用户想要通过VNC进入容器里安装他的应用，请问你们碰见过吗，网络方面怎么解决呢，需要将用户使用的容器配置上外网的IP，我们也用Flannel，但Flannel似乎不行吧？</p>
</blockquote>
<p>A：这不是个好方式，这是把容器当虚机用，如果真要这么做，那Flannel就不要用了，直接端口映射或者Pipework，但真不建议，会丧失容器的好特性。</p>
<hr>
<h3 id="2016-06-21：基于Docker实现DevOps的一些探索"><a href="#2016-06-21：基于Docker实现DevOps的一些探索" class="headerlink" title="2016-06-21：基于Docker实现DevOps的一些探索"></a>2016-06-21：基于Docker实现DevOps的一些探索</h3><blockquote>
<p>Q：对于一些中小互联网企业尤其DevOps二次开发能力不强的，在使用Docker集群方面有什么建议？</p>
</blockquote>
<p>A：一条DevOps流水线对集群环境的需求不高，我们更应该关心的是对每一个步骤的单个工具怎么去使用和管理，集群环境适用于都会用到大规模的容器部署中。还是那句话，技术不分好坏，选择最合适的就行。如果把容器当作虚拟机来跑，可以解决你的一些问题，那就这样跑又如何呢，技术或者工具是为需求服务的。</p>
<blockquote>
<p>Q：运维投拆开发应用消耗太大，为什么用了容器就能解决？只是开发和运行用了同一套环境，性能低下一样得靠优化，客器只是让大家在同一个平台上对话了。</p>
</blockquote>
<p>A：对的，如果应用本身的代码写得不好，不论在开发环境和运维环境都会造成应用消耗大的问题。使用DevOps这样的流水线，一个方面就是解决环境异构的问题。好比我是一个开发者，我在Windows里面开发，Java用的是1.5。但是在生产环境中，APP服务器用的是Linux，Java是1.6，那这样可能会引起功能性的问题。</p>
<blockquote>
<p>Q：您好，有些传统应用比较难拆分，上云的话难免会把容器做虚拟机用，请问在这一块有好的实践么？</p>
</blockquote>
<p>A：传统应用拆分确实是个难题，从可用性和性能方面考虑把传统应用放到容器当作虚拟机跑是可以的。这种场景实现了硬件的资源的高利用率，但是由于传统应用的紧耦合，很难以利用到容器的灵活迁移和弹性部署。而且需要关心的是，传统应用放到容器里面跑，数据保护这方面到底如何去做。目前我这边没有很好的实践方案，而且这种案例确实是国内整个Docker界需要面临的一个问题。</p>
<blockquote>
<p>Q：虚机或容器，传统双机节点模式部署，出问题通过双机切换主备应用还有意义么？</p>
</blockquote>
<p>A：有，双机热备或互备的方案是在传统IT环境中经历了时间的考验的。容器的出现并不是要颠覆以前的所有，而是让客户的应用场景拥有一个多的选择。</p>
<blockquote>
<p>Q：目前容器化的都是应用APP之类的，可以使用容器化一个类Unix系统么？比如容器化一个苹果系统能实现么？</p>
</blockquote>
<p>A：容器的定位就是在于APP的封装，就算有CentOS这样的镜像也只是为了拉取运行应用需要的Bin文件和Lib文件。你这个问题有点是想把容器当作虚拟机跑了，可以去了解一下RancherVM或HyperContainer，或许能够满足你的需求。</p>
<hr>
<h3 id="2016-06-14：传统企业PaaS平台功能设计与业务上云思考"><a href="#2016-06-14：传统企业PaaS平台功能设计与业务上云思考" class="headerlink" title="2016-06-14：传统企业PaaS平台功能设计与业务上云思考"></a>2016-06-14：传统企业PaaS平台功能设计与业务上云思考</h3><blockquote>
<p>Q：在你的新一代PaaS平台中，我怎么对公司的很多个不同的应用做不同的集群，有些集群偏向于大量的IO占用，有些集群偏向于大量的网络占用，有些集群偏向于大量的内存占用，并且启用的集群间还有通信和交互，针对这些不均衡现象该如何处理？</p>
</blockquote>
<p>A：所以PaaS平台硬件资源会针对不同应用去做区分，在企业私有云建设时，需要对应用进行梳理，将不同的应用分类，底层采取相应集群支撑，比如计算密集型、IO密集型等，同时综合考虑波峰波谷与业务特性进行配置。</p>
<blockquote>
<p>Q：公司有很多Web系统，每一个Web系统都有自己的存储、数据库，所以如果融入PaaS平台的话，首先第一点软硬件问题如何做到全部满足，其次就是就算把我的DB层整合迁徙到你的PaaS的DB层，我是不是还要做其它方面的投入，比如开发成本等等，还有就是DB的兼容性是不是会有问题？</p>
</blockquote>
<p>A：Web层我们推荐做无状态化，且要做应用与数据分离，session信息集中存放。DB迁移到PaaS层是一个比较慎重的过程，PaaS层优先考虑开源数据库。如果原先是MySQL基于PaaS平台也提供的MySQL数据库服务，那么开发成本基本比较小，只需考虑版本问题。</p>
<blockquote>
<p>Q：后面的OLAP主要的作用是数据整合和存储与分析，但是首先要解决的就是各个应用的数据不一致问题，还有就是数据中又分业务数据和非业务数据，这些问题是各个应用的团队自己解决吗？该怎么解决？</p>
</blockquote>
<p>A：数据仓库大数据平台中数据不一致的问题由ETL+数据建模来解决，应用团队要参与一起进行数据分析与建模。</p>
<blockquote>
<p>Q：请问MySQL部署数据应用能承载多大数据量，响应速度如何？</p>
</blockquote>
<p>A：我们一个项目中，采用读写分离的MySQL架构，几千万的数据表，及时查询没问题，这也要看硬件配置与数据索引的建立等。</p>
<blockquote>
<p>Q：有些传统公司，有些软件设备是以序列号安装使用的，所以这一块融入PaaS平台是不是不太可能？</p>
</blockquote>
<p>A：比较困难，另外还有一个问题是License限制的问题，在弹性架构中也比较难。</p>
<blockquote>
<p>Q：讲session集中到Redis，是需要做代码层面的修改吗？</p>
</blockquote>
<p>A：要修改，每次session的操作都要到Redis中增删改。</p>
<blockquote>
<p>Q：请问架构改造会不会导致应用要重新开发？</p>
</blockquote>
<p>A：会，从IOE架构到x86架构，从x86物理机到虚拟机到Docker，应用需要以越来越小的模块化分布式部署，也就是说逐步向微服务化过渡。</p>
<blockquote>
<p>Q：为什么Kubernetes和Mesos要一起用呢，考虑点在哪里？</p>
</blockquote>
<p>A：针对单个应用Docker化，我们开始的选型定位在Kubernetes，主要考虑了POD的应用场景更类似虚拟机，另外Kubernetes的模块比较丰富，像负载均衡、服务发现等已经成熟，后来用Mesos是因为需要把大数据之类的应用进行整合。需要Kubernetes/Spark on Mesos。</p>
<blockquote>
<p>Q：分处于不同子网的容器和虚拟机之间三层网络通信如何解决的？中间还走传统三层交换机？</p>
</blockquote>
<p>A：三层网络之间的互通还是走三层交换机。二层组网我们基于OVS+VXLAN。</p>
<blockquote>
<p>Q：开发周期过长或者客户开发能力弱会导致整个架构流产有配套的应用改造方案吗？</p>
</blockquote>
<p>A：对传统企业而言，一开始就搭建一个大而全PaaS方案是不现实的，我们推荐从某一个典型应用做起。我们针对交易性应用、分布式应用、批处理应用等应用都有配套改造方案。</p>
<blockquote>
<p>Q：另外大量采用开源工具 如何解决 版本升级及后期维护？</p>
</blockquote>
<p>A：一般会跟应用的代码配套做版本升级与维护。</p>
<blockquote>
<p>Q：Mesos使用集中式存储和分布式存储效率上有什么不同吗？</p>
</blockquote>
<p>A：这个看应用，集中式存储在集群中应用时，如果针对单一与应用划分Volume，性能会好一些，如果是分布式应用，比如MR类的应用，分布式存储反而会好。</p>
<blockquote>
<p>Q：容器弹性伸缩策略具体怎么考虑的，CPU？</p>
</blockquote>
<p>A：CPU、内存、IO、用户连接数等都可以作为弹性伸缩的策略依据。</p>
<p>以上内容根据2016年6月14日晚微信群分享内容整理。分享人**牛继宾，曾任VMware研发中心研发工程师，IBM实验室服务部高级技术专家，目前在天云软件（北京天云融创软件技术有限公司）担任技术总监。擅长云计算与大数据相关技术，除了底层平台技术，对云计算解决IT应用系统的实际问题、应用的分布式改造、业务支撑等也有丰富的经验。</p>
<hr>
<h3 id="2016-05-31：站在运维的角度讲如何打造一个Docker-Mesos平台"><a href="#2016-05-31：站在运维的角度讲如何打造一个Docker-Mesos平台" class="headerlink" title="2016-05-31：站在运维的角度讲如何打造一个Docker-Mesos平台"></a>2016-05-31：站在运维的角度讲如何打造一个Docker-Mesos平台</h3><blockquote>
<p>Q：您好，请问一下你们的监控采用的是什么方案？发现”变慢”后的动作是自动的还是需要人工介入的呢？</p>
</blockquote>
<p>A：1、我们PaaS上的SaaS业务的框架，由平台部统一提供，框架本身集成了健康检查（存活状态，响应时间）；2、运维开发小组会针对于这些有一套监控；3、另外针对于变慢，我们有Zabbix、日志收集、trace系统统一来做数据展示、分析、比对报警。</p>
<blockquote>
<p>Q：请问，你们环境的存储用的是本机存储还是分布式存储？</p>
</blockquote>
<p>A：由于我们的业务直接走的RDS，存在本地的只有日志，我们的日志是挂载本地，规范了存放的格式，统一收走来做日志分析、trace问题排查系统等。</p>
<blockquote>
<p>Q：请问Docker 你们是如何做鉴权的？即控制哪些人可以使用Docker Registry 哪些又可执行push等操作？怎么实现的？谢谢！</p>
</blockquote>
<p>A：1、首先鉴权分为业务层和PaaS层，业务层我们配套了框架及API GATEWAY/认证系统等来做业务上的鉴权；2、Docker层的我们这里做的比较简单：我们的Registry只做了简单的鉴权，由于我们只为内网服务，所以otheruser都具有pull权限，我们的push操作只有单独的几台机器、操作人员可以通过Jenkins操作（这里我们做了封装开发）。</p>
<blockquote>
<p>Q：可以讲讲在CentOS 7跑Java的时候，对JRE 和JDK做了哪些修改吗？跑Java应用按理说JRE就够用了么？</p>
</blockquote>
<p>A：理论上JRE就够了，但是不排除一些其他需要javac等的嘛 O(∩_∩)O~；另外修改的最重要的算是内存细分的限制了（看业务要求，我们对单个容器使用的内存严格限制），以及一些第三方的APM性能监控插件。</p>
<blockquote>
<p>Q：对于Java应用，如何设置DataSource？我的意思的测试环境和生产，如果用同一个image？</p>
</blockquote>
<p>A：针对于不同的环境，我们在用封装过的Jenkins来打相应的镜像，也就是不同环境的镜像在build的时候的操作，其实不一样。针对于环境信息的配置放在etcd中。</p>
<blockquote>
<p>Q：请问整个项目中的大概成本比例呢？如何定义各种成本？</p>
</blockquote>
<p>A：这点比较难说，看公司的态度吧，比如百度和腾讯对于新技术的投入比例就远远不同。</p>
<blockquote>
<p>Q：请问，使用host模式，你们目前怎么实现对端口的分配控制？</p>
</blockquote>
<p>A：端口是由Marathon随机分配的，不过可以针对端口段来做控制。一个机器可以开几千个端口，但是容器就开不了那么多啦。</p>
<p>以上内容根据2016年5月31日晚微信群分享内容整理。分享人**陈延宗，杭州数云运维工程师，工作内容比较多、杂：Docker/基础服务/SRE等等。</p>
<hr>
<h3 id="2016-05-30：虚拟化老兵介绍虚拟化技术"><a href="#2016-05-30：虚拟化老兵介绍虚拟化技术" class="headerlink" title="2016-05-30：虚拟化老兵介绍虚拟化技术"></a>2016-05-30：虚拟化老兵介绍虚拟化技术</h3><blockquote>
<p>Q：虚机迁移是否有涉及？不论是负载触发还是容灾触发或者业务逻辑触发。</p>
</blockquote>
<p>A：负载触发的有DRS，省电模式。基本考虑是负载高时往低负载上迁移，省电模式则正好相反，把虚拟机集中起来，关闭那些不需要的虚拟机。</p>
<blockquote>
<p>Q：KVM的Host内核参数开启IP转发作用是啥，如果使用的是桥接网络是否一样需要开启？</p>
</blockquote>
<p>A：一般情况下都是需要开启的，如果物理机需要给虚拟机网络通信的话。</p>
<blockquote>
<p>Q：容器化取代虚拟化真的只是时间问题吗？</p>
</blockquote>
<p>A：虚拟化技术源于以CPU为核心的硬件能力溢出，一虚多也绰绰有余。带来的结果：1.降低x86硬件平台的差异性，VM随便漂移；2.可统一管理池化后的资源，提高管理性和利用效率；3.不同guest os的vm可同时运行在同一个主机里；4.各层级，各种类软件近乎零成本往上迁移。 所以，短期未来更有可能的是：虚拟化与容器各负责自己擅长的部分，由于更容易与现有世界”兼容”，虚拟化占的市场份额可能会更大。长期未来，当统一的世界什么都提供时，哪里都可运行时，虚拟化，容器，你，我可能都已不存在。</p>
<blockquote>
<p>Q：后面讲到的Docker具体Ceph的高可用和迁移，是已经实现了，还是只是一个设想？</p>
</blockquote>
<p>A：设想，原计划这么去做，但有其他优先级的事情就没做了。</p>
<blockquote>
<p>Q：请问桌面虚拟化有什么痛点，或者难点么？</p>
</blockquote>
<p>A：业务上的疼点： 2）协议的分析，研究，以及改进。</p>
<blockquote>
<p>Q：KVM虚拟化中Linux内核的两个模块kvm和kvm_intel具体起到什么作用？</p>
</blockquote>
<p>A：我有段时间没有摸具体的代码了，kvm和kvm_intel组合在一起完成KVM内核相关的工作。</p>
<hr>
<h3 id="2016-05-19：容器的配置管理"><a href="#2016-05-19：容器的配置管理" class="headerlink" title="2016-05-19：容器的配置管理"></a>2016-05-19：容器的配置管理</h3><blockquote>
<p>Q：有两个问题，基础镜像的继承管理和如何处理多个技术栈的应用版本。举个例子，我们对于CentOS 7，做了公司级别的基础OS镜像A，基于这个镜像加入了JDK成为镜像B，基于B加入了JBOSS成为C，在C的基础上再构建项目的APP镜像D。问题来了1，有没有办法针对A镜像修改了，B，C和D去级连更新。2，由于是继承关系，各层软件的版本不同，导致镜像种类就特别多，例如JDK有3种，jboss有三种，那么镜像C就有九种，技术栈深了，命名又成为了问题。求指导解决思路？</p>
</blockquote>
<p>A：镜像如果涉及到继承，需要通过Jenkins之类的工具实现链式自动构建。 Jenkins中的任务可以设置触发条件，在某个任务完成后自动触发本任务。依赖关系可以在Jenkins的Jobs里面定义清楚。 镜像命名问题，可以用镜像名+tag的方式，如：tomcat:8-jre-7</p>
<blockquote>
<p>Q：我有个问题。现在这个平台只是Web服务级的PaaS平台么？</p>
</blockquote>
<p>A：cSphere目前除支持Web服务外，还支持任意复杂度的企业级应用。可以实现多个相互关联的服务的一键快速部署和环境Clone。</p>
<blockquote>
<p>Q：有没有打算开源你们这套容器的配置管理系统？</p>
</blockquote>
<p>A：目前我们有企业版和免费版。其中免费版可以根据我们官方网站上的文档自己安装部署。开源方面我们主要以向Docker的开源项目中贡献代码为主。</p>
<blockquote>
<p>Q：这里Agent能否理解成通过伙伴进程的方式来实现的配置管理？那是否连带有服务发现的功能？</p>
</blockquote>
<p>A：这里的Agent就是cSphere在每台主机上的Agent，该Agent与控制器协同处理所有管理工作，包括配置引擎。配置引擎本身支持应用、服务、容器、节点四种对象的发现，不仅仅是服务发现。</p>
<blockquote>
<p>Q：请问据你所知其他类似平台如何解决刚刚提到的配置问题呢？</p>
</blockquote>
<p>A：据我所知，包括Docker官方产品在内的一些产品还是主要以修改配置后重启容器或者通过-v参数映射配置文件的方法解决。这样做主要问题是配置文件的更新与容器的生命周期联动不起来</p>
<blockquote>
<p>Q：请问嘉宾，你们这个配置管理系统是自己完全独立开发的，还是借鉴了哪个开源项目？</p>
</blockquote>
<p>A：配置管理系统完全是我们自己独立开发的。配置管理的Agent除负责配置管理外，还负责控制器与各主机上的Docker Daemon的通信、监控数据采集等工作。</p>
<blockquote>
<p>Q：能否详细讲解下Agent如何装载配置文件的</p>
</blockquote>
<p>A：Docker 1.9为了支持所谓的”完全客户端镜像构建”能力，为docker cp命令添加了向容器传文件的API。我们通过这种机制把配置文件”装”到容器里</p>
<blockquote>
<p>Q：Create -> 下发配置 Start这样确保容器启动之前已经加载了正确的配置文件。这一步的下发配置是怎么做的，因为那个时候容器还没启动？</p>
</blockquote>
<p>A：向容器里copy文件并不需要容器处于运行状态，只要容器存在就能copy。</p>
<blockquote>
<p>Q：支持批量部署上百台服务吗？自定义部署到不同的环境。</p>
</blockquote>
<p>A：cSphere的配置引擎，支持批量下发，可以选择某个服务或多个服务，也可以针对个别容器做灰度下发，同时支持上千容器没有问题。另外针对不同环境部署，可以通过配置模版化能力，解决环境之间的微小差异，既可以通过用户定义变量，也可以通过类似发现的技术自动计算出对应参数，比如MySQL InnoDB的Buffer需要根据内存做一个公式计算。</p>
<blockquote>
<p>Q：请问Agent在发现新的配置后，针对不同容器是执行不同命令是怎么管理的？执行的命令和容器中应用运行状态有关系吗？</p>
</blockquote>
<p>A：在配置文件下发后执行的命令是与容器所属的应用关联的，要执行的命令并不是配置文件的一个属性。比如：某个配置文件同时在A应用和B应用里都用到，可以配置为在A应用下发后执行restart container，同时在B应用中下发后什么也不干</p>
<blockquote>
<p>Q：cSphere是企业PaaS平台，请问Agent程序是否开源？如果不是企业在自己的机器上安装闭源程序会不会有担忧。</p>
</blockquote>
<p>A：我们的客户没有过这方面担忧。首先客户基本都是内网。其次客户在过去大量使用vSphere，同样没有这样的担心。客户关心的是你的产品是否能解决自己的实际问题。</p>
<p>以上内容根据2016年5月19日晚微信群分享内容整理。分享人</p>
<p><strong>魏世江，云栈科技（希云cSphere）技术负责人，Docker代码贡献者，目前在Docker开源项目中代码贡献量全球排名50名左右。创业之前在新浪负责PasS平台（SAE）的各种基于Web的服务管理系统的设计及开发，全程参与了SAE从无到有、从3台虚拟机到后来支撑30多万应用和十几亿日PV（13年数据）的整个过程，在PaaS建设及DevOps方面积累了丰富的经验。2013年底离开新浪，与前SAE总监王利俊先生一起创立了云栈科技，主要做基于Docker的企业级私有PaaS产品（cSphere）及容器相关解决方案</strong>。</p>
<hr>
<h3 id="2016-05-10：基于Docker的分布式服务研发实践"><a href="#2016-05-10：基于Docker的分布式服务研发实践" class="headerlink" title="2016-05-10：基于Docker的分布式服务研发实践"></a>2016-05-10：基于Docker的分布式服务研发实践</h3><blockquote>
<p>Q：用Jenkins持续集成过程中，如何对项目进行测试？</p>
</blockquote>
<p>A：在jenkins中进行测试，一般主要是已unit test 为主，除此之外，可以自己写测试脚本进行测试。</p>
<blockquote>
<p>Q：研发采用IDE远程调试这个地方我不是很清楚细节可否详细讲讲？</p>
</blockquote>
<p>A：我们使用的Web容器为Tomcat，你只需在Tomcat中开启远程调试端口，在IDE中进行配置即可。</p>
<blockquote>
<p>Q：我们不采用Marathon和Swarm的原因是什么？</p>
</blockquote>
<p>A：Swarm目前还不成熟，还在发展中，功能相对弱一些。Marathon的话还是看使用场景，如果还要跑例如Hadoop的话可以选择。如果是纯容器，建议Kubernetes。</p>
<blockquote>
<p>Q：问下开发使用的目录挂载到容器是在宿主机还是共享存储上开辟存储空间，能否做到针对每个用户存储空间容量限制？</p>
</blockquote>
<p>A：开发使用的宿主机在办公云中，使用的存储是宿主机的本地存储。</p>
<blockquote>
<p>Q：测试和研发数据库用的是同样的一套吗？如果数据不一致，怎么处理呢？</p>
</blockquote>
<p>A：测试和研发使用的环境是一致的，包括使用的数据库脚本也一致，如果出现对同一个计算资源操作产生不同的数据，那就需要研发和测试一起来定位。采用同一套环境的一个好处是让研发不再有借口：”我的环境是好的，我本地无法复现”！</p>
<hr>
<h3 id="2016-05-03：基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系之大二层网络"><a href="#2016-05-03：基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系之大二层网络" class="headerlink" title="2016-05-03：基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系之大二层网络"></a>2016-05-03：基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系之大二层网络</h3><blockquote>
<p>Q：请教下Overlay性能和稳定性如何，适合大规模生产应用吗？你是全部的Overlay吗？</p>
</blockquote>
<p>A：我接触的思科ACI是可以实现在大规模生产应用的，在整个方案中使用的全部是Overlay网络。</p>
<blockquote>
<p>Q：请问，你所说的Swarm发布的网卡，是物理网卡还是虚拟网卡？</p>
</blockquote>
<p>A：不是Swarm发布的，是Docker1.9的一个新的网卡特性，在Docker 里面使用docker network -help可以看到。</p>
<blockquote>
<p>Q：请问Overlay使用的是物理交换机还是虚拟交换机？</p>
</blockquote>
<p>A：在本方案中使用的是物理交换机，VTEP是部署在leaf层的物理交换机上的。当然也可以使用OVS来作为VTEP，不过这样在性能和稳定性不如物理交换机。</p>
<blockquote>
<p>Q：请问通过Docker Network创建的网桥怎样可以让OVS发现并控制？</p>
</blockquote>
<p>A：当Docker Network为容器创建新的网卡接口后，通过脚本自动的挂载到OVS的网桥上。对网络的管理是是在更宏观的层面进行的，换句话说实在调度框架层面进行的，调度框架会根据自己的需求将需要的网络配置发给APIC，APIC会下发相应的网络配置策略。</p>
<p>以上内容根据2016年5月3日晚微信群分享内容整理。分享人赵英俊，来自城云科技企业云事业部，从事云计算大数据云存储的项目咨询和管理工作。</p>
<hr>
<h3 id="2016-04-28：Docker容器对存储的定义（Volume-与-Volume-Plugin）"><a href="#2016-04-28：Docker容器对存储的定义（Volume-与-Volume-Plugin）" class="headerlink" title="2016-04-28：Docker容器对存储的定义（Volume 与 Volume Plugin）"></a>2016-04-28：Docker容器对存储的定义（Volume 与 Volume Plugin）</h3><blockquote>
<p>Q：Kubernetes中是否有Volume的处理模块，或者说Volume的重要性，以及前面提到的各种操作，在Kubernetes中是怎么体现的？</p>
</blockquote>
<p>A：Kubernetes借助Docker Volume实现一套自己的volume管理机制。Kubernetes的相关问题下一次再详细说明。</p>
<blockquote>
<p>Q：请教下现在分布式存储很多，Ceph、CFS等，哪个性能更好，更稳定，适合上生产？</p>
</blockquote>
<p>A： Ceph、Glusterfs都有上生产环境成功的案例。 就运维成本来说Gluster更加简单点。Ceph的运维成本较高。稳定性上Gluster因为设计更简单，所以社区版本就已经稳定了。</p>
<blockquote>
<p>Q：Docker Volume 和Kubernetes volume/persistent volume比较，有什么异同？</p>
</blockquote>
<p>A：Kubernetes借助Docker Volume实现一套自己的Volume管理机制。</p>
<blockquote>
<p>Q：应用日志管理收集是否适用Volume？有没有什么注意的地方？推荐的共享方式？不同应用是否-v到不同的地方？</p>
</blockquote>
<p>A：容器如果需要持久的数据，使用Volume挂在到目标存储上。注意日志太多对系统资源的占用。</p>
<blockquote>
<p>Q：想问下有没有类似测试过，或者说你现在觉得性能比较好的一些方案？有没有测试用例级数据？</p>
</blockquote>
<p>A：存储的性能是与实际的应用是相关联的。我们开发适合容器的存储。</p>
<blockquote>
<p>Q：一个存储盘能共享挂载到多个容器吗？</p>
</blockquote>
<p>A：看后端存储类型，如NFS、Glusterfs是支持存储盘能共享挂载多个容器。</p>
<blockquote>
<p>Q：Rancher刚出，不知道它这个Convoy能单独用么，比如说安装在Ubuntu？</p>
</blockquote>
<p>A： Convoy与Rancher是独立的，可以独立安装在Ubuntu。</p>
<blockquote>
<p>Q：请问有什么静态资源共享数据的方案，例如Web图片？</p>
</blockquote>
<p>A：OpenStack Swift、GlusterFS都可以。</p>
<blockquote>
<p>Q：Convoy或Flocker能支持rbd么？</p>
</blockquote>
<p>A：原生的Convoy目前不支持rbd。现在我们做Convoy支持rbd的功能。</p>
<blockquote>
<p>Q：不同主机上的容器能同时挂到一个共享存储上吗，最多能支持多少个？</p>
</blockquote>
<p>A：共享存储支持就可以，NFS、Glusterfs都可以支持。</p>
<blockquote>
<p>Q：Kubernetes和Docker Swarm两个更看好谁，如果只能选一个的话？</p>
</blockquote>
<p>A：看具体的应用场景，Kubernetes会越来越稳定。Swarm对容器的支持会越来越好。</p>
<p>以上内容根据2016年4月28日晚微信群分享内容整理。分享人**江松，有容云联合创始人兼研发副总裁。拥有16年的国内外企业级软件基础架构研发经验，在企业级存储，云计算解决方案方面有很深的技术造诣和行业理解。曾任美国AITechLtd、爱尔兰Raidtec Ltd高级系统架构师，存锋科技Storwind创始人兼CEO。</p>
<hr>
<h3 id="2016-04-26：Kubernetes代码贡献者谈Kubernetes的发展动态"><a href="#2016-04-26：Kubernetes代码贡献者谈Kubernetes的发展动态" class="headerlink" title="2016-04-26：Kubernetes代码贡献者谈Kubernetes的发展动态"></a>2016-04-26：Kubernetes代码贡献者谈Kubernetes的发展动态</h3><blockquote>
<p>Q：谢谢分享Scheduler的演进，想问一下planning的问题，针对multiple scheduler和rescheduler，是谁在主导，有时间线吗？浙大会参与设计和开发吗？</p>
</blockquote>
<p>A：据我所知，目前design和implementation都是由Google主导，国内主要是华为的团队在参与开发，网易也有人力投入，当然极有可能存在一些我不知道的团队。Timeline上Multiple Scheduler已经完成了接口，但是有不少细节的工作还没有完成。Rescheduler还在design阶段。据我所知，浙大的确有感兴趣的同学在做相关的内容，但是我不确定有没有向社区贡献code的计划。</p>
<blockquote>
<p>Q：这些讨论一般都集中在哪些地方？是公开的吗？</p>
</blockquote>
<p>A：大多数在GitHub上可以trace到，当然也有weekly sig视频会议和offline discussion。如果是个人开发者的话，可以在GitHub上的issue/pr里comment或者直接提交pr参与开发。</p>
<blockquote>
<p>Q：Kubernetes目前表现的比较好的托管方式是容器安装吗？还有CoreOS官方给了这么多选择不知道选什么好。</p>
</blockquote>
<p>A：definitely not。容器安装是一个快速的solution，但是可能会有很多bug。CoreOS应该是一个支撑性非常高的平台。我本人是Ubuntu平台的 maintainer之一，如果希望play with ubuntu的同学，也可以尝试一下。</p>
<blockquote>
<p>Q：未来horizontal pod autoscaling将不仅仅是依据CPU，还会有更多的指标。请问如何处理可能的矛盾。如CPU超载指示扩容，而memory可能使用低而指示减少容器数量？</p>
</blockquote>
<p>A：这是一个策略问题。对应的解决方案无疑会牺牲其中一个，Kubernetes是否允许用户来指定这个priority也还值得讨论。但是就目前看来用户还不需要过分担心，毕竟它还没有实现。</p>
<blockquote>
<p>Q：还是那个老问题，在企业环境下Kubernetes和Mesos哪个更可取？</p>
</blockquote>
<p>A：如果一定用事实说话的话，当前Mesos在企业中的use case无疑比Kubernetes要多。作为一个两级调度框架，Mesos的完备性相当高。但是我个人并不认为Kubernetes就相对不适用于企业环境。毕竟在选取solution的时候，需要考量的实际因素很多。</p>
<blockquote>
<p>Q：其实去年开年的时候玩过Kubernetes，然后是因为网络部分的限制导致选择了Mesos，想问下容器网络这部分Kubernetes你觉得最成熟的方案是哪一种？</p>
</blockquote>
<p>A：我自己只玩过Flannel（包括UDP和VXLAN），但是它在效率上可能并不是非常好，VXLAN相对来说要好一些。我所知道的方案中，Calico应该做得还不错。您也可以尝试一下OpenVSwitch。</p>
<blockquote>
<p>Q：Rancher除支持自己的编排方案cattle以外，也支持Kubernetes和Docker Swarm。想听听你的建议，是否可以采用Rancher+Kubernetes这样的方案？谢谢</p>
</blockquote>
<p>A：非常抱歉没有使用Rancher的经历。但是就大多数我所知道的cross-platform solution而言，通常都出于生产环境中具体的需求。比如我现在实习的公司的AP组就自己写了docker-on-yarn。在solution的选取上很难脱离需求来进行评断。</p>
<blockquote>
<p>Q：现在所有调度规则都是集中在master控制分发，Kunernetes可不可以在node上面添加像mesos role的概念？</p>
</blockquote>
<p>A：调度器的演化经历了很长时间的发展，各有千秋。Kunernetes选用的单体调度器，而Mesos是两极调度框架，本质上还是有相当大的gap的。当然现在也有Kunernetes和Mesos的集成，有兴趣的同学也可以尝试一下。</p>
<p>以上内容根据2016年4月26日晚微信群分享内容整理。分享人<strong>何思玫，浙江大学SEL实验室研究生，Kubernetes、Docker等容器相关开源项目的代码贡献者。</strong></p>
<hr>
<h3 id="2016-04-19：阿里云容器服务设计实践"><a href="#2016-04-19：阿里云容器服务设计实践" class="headerlink" title="2016-04-19：阿里云容器服务设计实践"></a>2016-04-19：阿里云容器服务设计实践</h3><blockquote>
<p>Q：针对容器跨主机通讯采用vSwitch和vRouter，那么容器和VM应用通讯也是采用此方法吗？vRouter规模如何？</p>
</blockquote>
<p>A：在前面说的VPC实现中，容器和VM是可以直接通信的。VPC目前的vRouter支持50个条目，也就是最多50个网段。</p>
<blockquote>
<p>Q：各种扩展和Plugin有开源吗？</p>
</blockquote>
<p>A：未来我们会开源安装在用户机器上Agent和Plugin代码，目前还有一些知识产权工作需要解决。</p>
<blockquote>
<p>Q：Registry的HA方案能否介绍下？</p>
</blockquote>
<p>A：我们开发过Registry的OSS storage driver，已经提交到社区。后端使用OSS存储，直接启多台Registry，挂一个vip就好了。</p>
<blockquote>
<p>Q：想问下阿里的支持混合云吗？宿主机是不是要求一定是阿里的ECS？</p>
</blockquote>
<p>A：目前主要支持阿里云环境和专有云。对于宿主机在外面的，也可以通过VPC的方式接入。</p>
<blockquote>
<p>Q：跟Docker hub兼容有哪些方面，hook功能是怎么实现的？</p>
</blockquote>
<p>A：支持仓库管理、自动构建、加速器等功能。hook方面是通过Registry的Notify实现的。</p>
<blockquote>
<p>Q：镜像对分发到多个Registry吗？</p>
</blockquote>
<p>A：OSS本身可以保证数据的高可用。对于Registry，重点在于Pull/Push速度，我们在会每个Region都部署Registry，尽可能提供最好的用户体验。</p>
<blockquote>
<p>Q：Docker服务本身的升级，怎么解决的，需要用户停止线上容器吗？</p>
</blockquote>
<p>A：目前我们支持的社区版本1.10需要重启容器，用户可以自己选择合适的时间升级。对于阿里内部我们同事修改过的alidocker是无需重启的。当然，随着1.11的Docker重构，未来社区版本也不再是单点失效点。</p>
<p>以上内容根据2016年4月19日晚微信群分享内容整理。分享人<strong>姜继忠，花名戒空，阿里云技术专家，一直专注于云服务和PaaS平台相关的架构和开发工作，目前负责阿里云容器服务的架构和开发。</strong></p>
<hr>
<h3 id="2016-04-12：双模IT给你的企业装上双引擎"><a href="#2016-04-12：双模IT给你的企业装上双引擎" class="headerlink" title="2016-04-12：双模IT给你的企业装上双引擎"></a>2016-04-12：双模IT给你的企业装上双引擎</h3><blockquote>
<p>Q：双模模式和DevOps以及目前流行的Docker容器有什么关系吗？</p>
</blockquote>
<p>A：首先双模模式是一个管理理念，它指导IT部门采用的组织架构、制度、人员技能，以及技术。如前所说，DevOps和Docker技术优势可以更有效推动企业提升业务创新能力，因此在我见到的金融企业中普遍应用到了信用卡、互联网金融等2C端的业务。</p>
<blockquote>
<p>Q：这个双模模式和目前常用的敏捷开发，CMMI开发在操作上，产品质量保证上，开发迭代，效率上有哪些不同？或者说有哪些优势？以及如何和这些开发流程协作？</p>
</blockquote>
<p>A：大家可能以往比较关注技术，较少关注管理体系方面的内容。双模IT管理更多侧重在管理体系，它指导IT部门采用的组织架构、制度、人员技能，以及技术。CMMI采用了传统的瀑布模型，这种方式适合在明确需求的前提下稳步推进工作。但由于当前市场环境十分不确定，需求的不确定性是创新的最大挑战，因此演化出一种持续迭代的开发方法，这也是DevOps强调持续反馈的原因。</p>
<blockquote>
<p>Q：怎么理解ITIL V3的服务驱动？</p>
</blockquote>
<p>A：相比V2，ITIL V3尝试从服务战略、服务设计、服务转换、服务运行、服务持续改进五个方面阐述服务生命周期，一个比较明显的特点就是重点强化了服务目录，并从服务目录出发将服务交付、事件、问题、变更、容量管理等流程串联在一起。</p>
<blockquote>
<p>Q：客户在碰到类似的管理产品时，通常很畏惧，不仅收效甚微，还可能要改造现有流程，反而增加他们的工作量，后续更是增大管理成本，如何说服他们？</p>
</blockquote>
<p>A：双模IT首先是一个管理理念，然后基于这种理念演变成管理最佳实践、管理方法和管理标准。其次，管理重点要解决的是人、财、物，如何最大化协调三者，使得企业效益最大化，提升IT效率才是关键，所以我们在推进一个新方法的时候关键要说明白好处已经风险，让管理者有一个全面了解。在实际的推进过程中，最常用的方法是培训理念导入，让企业内部关键人员说一种语言，统一思想，但最近几年一个明显的变化是我们可以采用一种技术驱动的模式将管理理念通过平台落地。</p>
<p>以上内容根据2016年4月12日晚微信群分享内容整理。分享人**张亮，上海翰纬信息科技有限公司技术总监兼合伙人。IT从业经验14年以上，先后从事开发、架构、项目管理、技术管理等岗位，曾就职于IBM，在大型企业数据中心运维方面，积累了超过10年的架构和规划管理经验，先后为五大行、农商行等金融机构提供数据中心运维管理规划和管理平台落地咨询及实施服务。热爱开源技术，现专注于OpenStack、Docker、Cloudify、Apache Kylin等开源方案在传统企业的落地。</p>
<h3 id="2016-04-05：搜狐基于Docker-Kubernetes的一站式运维管理实践"><a href="#2016-04-05：搜狐基于Docker-Kubernetes的一站式运维管理实践" class="headerlink" title="2016-04-05：搜狐基于Docker+Kubernetes的一站式运维管理实践"></a>2016-04-05：搜狐基于Docker+Kubernetes的一站式运维管理实践</h3><blockquote>
<p>Q：”可以在Pod中配置一个或多个日志收集模块，该部分用Flume实现”这块能具体说下吗？</p>
</blockquote>
<p>A：我们把Flume做成了一个镜像，利用Kubernetes的Empty Directories来收集其他容器产生的日志。</p>
<blockquote>
<p>Q：我想问下容器内监控是怎么实现的？每个容器安装open-falcon的Agent吗？</p>
</blockquote>
<p>A：每个Node上会启动一个Agent，通过Agent收集主机和容器的信息，Agent集成了open-falcon的Agent和cAdvisor。</p>
<blockquote>
<p>Q：自动化构建过程中，对应用的测试是怎么实现的？</p>
</blockquote>
<p>A：单元测试可以在编译的时候完成，功能测试需要启动部署。</p>
<blockquote>
<p>Q：你们的部署环境是同时使用了overlay模式和host模式吗，对于预防潜在的冲突你们有什么好的建议？</p>
</blockquote>
<p>A：我们主要对端口冲突做了严格限制，host模式下提供了自动寻找20000~21000段可用端口的插件，overlay模式会根据数据库中配置检测冲突。</p>
<blockquote>
<p>Q：使用Kubernetes编排容器后，你们怎么做服务发现的？如何解决容器间互相调用问题，及容器外调容器内服务问题？</p>
</blockquote>
<p>A：我们用skyDNS做服务发现，容器间相互调用可以用内部域名，Kubernetes集群内的主机通过修改DNS服务器配置也可以通过内部域名访问容器。</p>
<blockquote>
<p>Q：项目有什么瓶颈吗？</p>
</blockquote>
<p>A：Kubernetes的部署比较复杂，我们做的是私有云下的管理，不同系统下部署会有各种各样的问题。</p>
<blockquote>
<p>Q：刚刚提到WebSSH在Agent里封装了docker exec，当在master执行某容器的命令时，具体是如何控制Node节点执行docker exec的，Agent封装是自己开发的吗，还是借用一些第三方工具，Kubernetes好像也有kubectl exec？</p>
</blockquote>
<p>A：WebSSH有Server端和Agent端，Agent在每个Node节点上，Server只要一个就够了。kubectl也可以exec，不过采用的是Kubernetes自定义的连接协议，性能也不如我们目前采用的方案。</p>
<p>以上内容由<strong>李世龙</strong>根据2016年4月5日晚微信群分享内容整理。分享人**刘菲，搜狐北京研发中心副研究员，主要负责DomeOS系统的设计研发工作。致力于研究Docker为代表的容器技术，为企业级用户打造持续交付和自动运维平台，解决用户从代码自动编译打包，到线上运行维护的全套需求。</p>
<hr>
<h3 id="2016-03-31：DCOS中监控和弹性伸缩方案经验分享"><a href="#2016-03-31：DCOS中监控和弹性伸缩方案经验分享" class="headerlink" title="2016-03-31：DCOS中监控和弹性伸缩方案经验分享"></a>2016-03-31：DCOS中监控和弹性伸缩方案经验分享</h3><blockquote>
<p>Q：CPU占用率，内存占用率这些指标为啥要改cAdvisor的代码实现？既然使用了Grafana的话，Grafana本身就有对数据二次加工的能力，比如CPU利用率可以直接通过cAdvisor发送的cpuacct，usage的数据做Derivatives就能取到CPU的利用率了。不知道这块你们是基于什么考虑在cadvisor里去提前算了？</p>
</blockquote>
<p>A：首先，我们并没有使用Grafana；其次你说的不错，CPU只是打了一个比方，其实我们计算更多的是网络传输的一些数据，比如收发报的数量，大小，这些都是在我们公司NFV的业务比较常见，这里给大家分享的主要目的是，可以通过cAdvisor 做一些定制化的开发。 我们用cAdvisor的目的主要是 统一信息的收集，并不想用多个监控工具，这样会有点复杂。</p>
<blockquote>
<p>Q：请问，每个Prmetheus会管理10个Mesos-Slave+cAdvisor的节点信息，抓取频率是1s，如何保证在规定时间间隔搜集完所有监控信息，即如何保证监控指标是实时有效的呢？</p>
</blockquote>
<p>A：这个结果其实是我们经过反复测量得出来的，是有前提，就是我说的每个Slave的大小其实是有限制的，我们的每个Slave 在8 CPU， 16G内存，这样保证了运行的容器数量是有限制的。我觉得如果容器过多，那么管理10个节点可能就不适合，抓取频率也需要调整。 目前官方没有给出Best Pactice，我们也是经验之谈。 测试下来，我们的配置 基本上没有出现丢失信息的情况。</p>
<blockquote>
<p>Q：想问下嘉宾：1、DCOS这套环境是用的社区版？2、方便透露下集群规模么？</p>
</blockquote>
<p>A：DCOS的这套环境是我们公司研发的， 但是我们公司和Mesosphere的Open DCOS是合作伙伴，这个消息近期就会宣布。目前我们环境规模是50个mesos-slave 左右。</p>
<blockquote>
<p>Q：请问这个系统本身消耗好资源多少？例如采集CPU用top命令，top本身是消耗很多资源。</p>
</blockquote>
<p>A：目前在我们的环境实测下来，cAdvisor的CPU占用率在1~5%； 如果容器非常拥挤的情况下，开销会在10% 一下，我们的cAdvisor是用Marathon启动的，配置的CPU是0.1。</p>
<blockquote>
<p>Q：请问每次新增监控纬度时，是否需要同时修改cAdvisor和Prometheus，如何保证通用化？是否考虑过其他的容器监控方案，比如通过FUSE在用户态统计，兼容历史的监控工具？</p>
</blockquote>
<p>A：是的， 是需要修改cAdvisor和Prometheus， 这一点也是相对来说比较头疼的部分，我们的主要是通过2方面来做的，第一方面是抽象服务模型来做的，让不同的服务模型的共同部分可以共享我们的监控指标和告警规则。第二是利用灰度升级的方式，对cAdvisor和Prometheus来进行升级，尽量保证服务监控的不中断。正如我说的，提前的规划非常重要。其他方案也有所考虑，但是使用下来还是觉得cAdvisor和Prometheus更加适合自动弹性伸缩。</p>
<hr>
<h3 id="2016-03-29：基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系"><a href="#2016-03-29：基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系" class="headerlink" title="2016-03-29：基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系"></a>2016-03-29：基于Docker、Mesos、Ceph全新技术栈的三地三中心容灾体系</h3><blockquote>
<p>Q：您这个框架中使用的PaaS执行框架具体是什么？</p>
</blockquote>
<p>A：这个是开放的，可以是马拉松也可以Kubernetes，这个都没有具体的限定的。因为我觉得这两个都是比较好的执行框架。</p>
<blockquote>
<p>Q：Docker的兴起是否会影响OpenStack云计算的地位会和OpenStack竞争，共存？OpenStack工程师如何面对Docker技术的兴起？Unikernel发展趋势能否取代Docker？</p>
</blockquote>
<p>A：竞争肯定是有的，但是共存也是存在的，我认为这是一个灰度的。我觉得OpenStack工程师要拥抱Docker，其实我的主要工作就是向客户设计基于OpenStack的私有云解决方案。Unikernel技术的对手不是Docker，是容器。具体是否会取代，我觉得不一定。</p>
<blockquote>
<p>Q：Vxlan具体怎么实现？是核心交换机旁挂大二层设备吗？另外超远距离，比如北京上海这么做会有什么问题？我们现在遇到延迟问题比较大。</p>
</blockquote>
<p>A：VxLan的实现在Vswitch中通过对每次TCP包的UDP封装，Vswitch是在每个宿主机上的。北京到上海的话，就需要通过光纤中继，这会损耗一定的传输带宽，这么远距离的传输只能等待光传输技术的发展以及在应用层面进行弥补。不过在应用层去弥补这不是很好的方案。</p>
<blockquote>
<p>Q：ZK集群的部署是怎样？有做哪些调优么？另外网络方面有做哪些监控么？</p>
</blockquote>
<p>A：主要是根据实际的请求时延对TIMEOUT进行修改，网络方面的监控是通过专业的安全设备进行。</p>
<blockquote>
<p>Q： 那个数据中心部署3机Mesosmaster，所有数据中心共享一个ZK集群，难道这个ZK集群如何在多数据中心部署，还有因为网络延时导致slave掉了后，或者executor挂了后怎么处理孤儿容器。</p>
</blockquote>
<p>A：ZK是每台Master节点上的，由于使用了大二层网络，所以所有的ZK就相当于在同一个局域网内部署的。对于孤儿容器，是Kill掉然后替换的。</p>
<blockquote>
<p>Q：请问在你们设计的方案中通常建议用户租用几条裸纤来实现三地三中心，同时考虑过租用长距离裸纤给用户带来的长期运维成本吗？</p>
</blockquote>
<p>A：恩，这是个好问题，我在准备这次分享的时候也在考虑这个问题。这个设计方案的前提是客户有这样的需求，需要支付这样的成本去实现。从技术的角度，双纤是性能与经济性的平衡点。</p>
<blockquote>
<p>Q：请问关于事务处理的负载轮询，如果使用长连接，如何保证每个连接负载是均匀的，同时这里的事务是指存储层的还是应用层的，如果是应用层是如何保证事务的？</p>
</blockquote>
<p>A：这个确实比较难，可以采用类似于一致性哈希环的思想，就是尽可能多的将轮询环进行分割，这样长连接就会尽可能的均衡分配。负载轮询是在应用层面进行轮询的。</p>
<blockquote>
<p>Q：你们这套架构上生产环境了吗？Ceph是强一致性的，6个副本延迟会不会大？六个副本是不是有点浪费存储空间？大规模写入的时候IO会不会是瓶颈（Ceph先写Journal，再写磁盘）？另外，你们是全SSD吗？</p>
</blockquote>
<p>A：这套架构没有上生产环境。这是我们公司做的一个前瞻性方案设计研究。在Ceph的副本配置中，有一个最小副本数，可以先设置一个最小副本数实现快速的写操作。之所以6副本，主要是防止避免过度频繁的数据读切换。在这种方案下，建议全部是SSD，当然也可以有选择性的使用SAS。</p>
<p>以上内容根据2016年3月29日晚微信群分享内容整理。分享人**赵英俊，来自城云科技企业云事业部，从事云计算大数据云存储的项目咨询和管理工作。</p>
<hr>
<h3 id="2016-03-22：太保DCOS平台——微信项目实践"><a href="#2016-03-22：太保DCOS平台——微信项目实践" class="headerlink" title="2016-03-22：太保DCOS平台——微信项目实践"></a>2016-03-22：太保DCOS平台——微信项目实践</h3><blockquote>
<p>Q：想问下嘉宾，资源调度层为啥选用了Mesos而不是Kubernetes？Mesos使用的是开源版本？从项目预研到落地投入的人力是多少（含开发、测试、运维）－方便透露的话？</p>
</blockquote>
<p>A：Kubernetes提供的集成功能较多，可以提供整体的解决方案，但我们有很多内部的应用间调用，最后选定了HAProxy+Mesos的方式，而且从前期的评测来看Mesos与Marathon集成更为稳定。</p>
<blockquote>
<p>Q：容器运行WebLogic的时候有没有遇到什么坑可以分享一下吗？</p>
</blockquote>
<p>A：容器运行WebLogic本身没有问题，但如果程序包过大，容器的自动恢复时间会较长，所以建议控制每一程序包的大小。</p>
<blockquote>
<p>Q：研究新的软件如Mesos这么重量级的产品也是需要很大的时间成本和人力成本的！如何权衡的？</p>
</blockquote>
<p>A：主要还是看面对的问题，在微信红包这样的应用场景中传统技术已遇到瓶颈，必须要引入新技术。不过我们很多新技术的研发是前期即进行，进行前期的技术储备。</p>
<blockquote>
<p>Q：我们发现，在Mesos中，如果主进程先退出，而子进程还在的话，会导致task直接返回，而我们的实际应用中有比较复杂的父子进程关系，除了重新梳理一下外，还有什么别的好的做法？</p>
</blockquote>
<p>A：应用之间的依赖关系，我们正在着手在Marathon调度之前，如B应用与A应用有依赖关系，则先判断A是否启动，A如果没启动则启动A再启动B，同时，需判断A应用启动后是否满足应用服务能力，比如一个容器是否能承受压力。</p>
<blockquote>
<p>Q：请问下Docker地址如何分配和管理跨主机通讯？</p>
</blockquote>
<p>A：地址是有容器平台动态分配，跨主机通讯通过HAProxy进行应用间调用。</p>
<blockquote>
<p>Q：你们如何做监控的？就是红包活动的时候如何监控当前的服务器性能或者是接口的访问量之类的？</p>
</blockquote>
<blockquote>
<p>Q：聊一聊为什么使用传统方法+APM监控而不使用cAdvisor、Prometheus、Docker API来实现？</p>
</blockquote>
<p>A：两个问题我一并回答，因为我们APM并不是仅使用在容器平台，目前在传统平台也使用，正好上容器平台发现传统监控遇到问题，当时我们做APM的poc有一段时间，发现APM正好可以解决此问题，所以就采用了这种方式。\ 容器平台本身是有性能和可用性监控工具。用APM是更好的进行应用的端到端监控。</p>
<blockquote>
<p>Q：传统行业转容器一般没那么容易，你们有什么过度方案吗？</p>
</blockquote>
<p>A：我们针对无状态的应用、传统应用的容器化都制定了对应的技术方案，帮助研发团队进行应用的容器化迁移。</p>
<p>以上内容根据2016年3月22日晚微信群分享内容整理。分享人**沈大斌，太平洋保险信息技术中心高级经理，目前主要负责Docker容器技术在太保集团的落地、推广及优化工作。18年保险行业IT从业经验，专注于应用运维领域。</p>
<hr>
<h3 id="2016-03-15：Kubernetes集成外部服务实践"><a href="#2016-03-15：Kubernetes集成外部服务实践" class="headerlink" title="2016-03-15：Kubernetes集成外部服务实践"></a>2016-03-15：Kubernetes集成外部服务实践</h3><blockquote>
<p>Q：请问在举的MySQL服务的例子中，讲到不是采用应用与MySQL一起打包成容器运行的方式，而是只需要把应用链接mysql服务的环境变量注册到PaaS平台上面就可以使用MySQL的服务了是吗？那么你们平台上面不是运行多个MySQL镜像吗？</p>
</blockquote>
<p>A：后端服务与PaaS在逻辑上是分开的，可能独立运行在平台集群外部，也可能运行在集群里，以service的形式服务。所以是否运行多个MySQL容器，取决于servicebroker的设计实现。每一种servicebroker的设计都不必相同。</p>
<blockquote>
<p>Q：如果我把MySQL环境变量注册到PaaS平台后，我应用链接你们平台上面的MySQL服务后，如果后期分库分表可以吗？还需要重新配置环境变量信息吗？</p>
</blockquote>
<p>A：这个取决于后端服务提供的套餐。不同套餐计划提供不同程度的服务。</p>
<blockquote>
<p>Q：1. Kubernetes自定义扩展具体怎么做的？2.后端服务你弹性伸缩直接用Kubernetes自带的，还是有什么改造？</p>
</blockquote>
<p>A：1. 扩展Kubernetes是我们参考Kubernetes的API server、Controller这种异步机制直接在Kubernetes中增加代码，Kubernetes在易扩展性上做的挺好。2. 后端服务可以运行在Kubernetes集群上，或独立运行，其弹性伸缩由后端服务自身的设计来决定。</p>
<blockquote>
<p>Q：请问容器里的环境变量是Kubernetes的BackingService自动生成的，还是OpenShift特有的？是不是可以说因为Backing Service会自动在容器里注册环境变量，所以某些场景下使用起来比起直接使用MongoDB地址来得方便？</p>
</blockquote>
<p>A：是实例在绑定的时候由我们的扩展生成，并更新到pod里，不是OpenShift特有的。第二个问题的话，确实是这样，多数情况下，用环境变量都会很方便。</p>
<blockquote>
<p>Q：Kubernetes的Volume，你们是如何使用的，当pod发生迁移后，如何保证Volume还挂在pod上？</p>
</blockquote>
<p>A：Kubernetes本身提供了persistent volume功能，并且支持多种存储机制。pod迁移时，Kubernetes会维护其对应的Volume，根据不同的存储，Kubernetes有不同的调度实现。</p>
<blockquote>
<p>Q：现在生产上用什么监控，监控有报警吗，什么粒度的？还有就是日志收集怎么处理有什么成熟的方案吗？</p>
</blockquote>
<p>A：我们采用了多种监控机制。主机、容器、和Kubernetes服务本身，我们都采取不同的监控策略/工具。至于粒度，也跟监控的对象有关。日志我们用ELK。</p>
<blockquote>
<p>Q：Kubernetes的部署可否做到跨数据中心吗？如何实现？谢谢。</p>
</blockquote>
<p>A：Kubernetes是分布式的异步系统，理论上是可以跨数据中心的。但考虑到网络环境的复杂性，我们当前还没有作这方面的尝试。</p>
<p>以上内容根据2016年3月15日晚微信群分享内容整理。分享人**柴宗三，资深架构师，10年的IT从业经验，在云计算、大数据方面及大型企业级应用拥有丰富技术架构经验。负责北京亚信智慧数据科技有限公司大数据云平台的架构设计及开发管理。</p>
<hr>
<h3 id="2016-03-04：Docker在乐视的实践之路"><a href="#2016-03-04：Docker在乐视的实践之路" class="headerlink" title="2016-03-04：Docker在乐视的实践之路"></a>2016-03-04：Docker在乐视的实践之路</h3><blockquote>
<p>Q：想请问一下这些Docker是部署在物理机上还是虚拟机上？在扩容的时候除了增加内存，能增加CPU吗？</p>
</blockquote>
<p>A：物理机和虚拟机都有，我们提供一键安装Docker和其他组件环境的脚本，业务部门单纯执行脚本即可。在扩容方面我们现在只做了内存扩容，CPU是共享的。</p>
<blockquote>
<p>Q：通过镜像的构建脚本是怎么生成镜像的？在基础镜像上执行相关脚本么？一些端口存储卷环境变量这些镜像中的信息是怎么解决的？</p>
</blockquote>
<p>A：我们对Dockerfile进行了封装，业务和开发人员不需要关心Dockerfile语法，直接写一个镜像构建脚本，最后根据一定的规则由Harbor生成Dockerfile，之后调用docker build去生成镜像。在这个过程中， 镜像的名称，版本都已经根据规则生成</p>
<blockquote>
<p>Q：资源共享的方式，不能是一个部门或者小组增加一个公用账号，把需要分享的资源，push到公用账号吗？</p>
</blockquote>
<p>A：我们没有使用公共账号的方式，我们使用的是镜像仓库的方式，镜像仓库可以有团队成员，达到的效果是一样的。</p>
<blockquote>
<p>Q：抛弃Jenkins那你们多语言怎么办 Java编译和Golang编译这些？</p>
</blockquote>
<p>A：我们不需要关心什么语言，我们现在提供了一个Java公用的基础镜像，编译什么的都可以在构建时候完成。 如果需要其他语言，比如go、Python，可以有业务部门自己创建自己的基础镜像。</p>
<blockquote>
<p>Q：Jenkins配置jdk和maven，是要在容器里自己安装吗？</p>
</blockquote>
<p>A：在构建时候，这些环境可以在业务部门基础镜像里，提前安装好。</p>
<blockquote>
<p>Q：在构建时候，这些环境可以提前安装好？</p>
</blockquote>
<p>A：应用里都有自己的版本概念，每个应用版本里有：镜像版本，环境变量、 export、Volmue等信息，所以在回退或者升级时候，最终的表现形式就是杀掉旧容器，根据版本的参数创建新容器。</p>
<blockquote>
<p>Q：Harbor和Jenkins比起来你们是不是基于后者的实现思路开发的精简版，解决问题的方法和思路变了吗？</p>
</blockquote>
<p>A：原因有多个，我们希望Harbor能从代码到构建到部署一气呵成，如果用Jenkins，会给用户已断片的感觉，业务部门一旦业务多的话，有可能会分不清哪个Git对应哪个Jenkins配置。学习成本也比较高。</p>
<blockquote>
<p>Q：你们这样，开发人员的本地环境是不是不需要使用容器了？</p>
</blockquote>
<p>A：本地环境一般不需要容器，但是如果开发人员想使用容器玩玩，可以通过我们提供的基础镜像创建一个容器即可。</p>
<blockquote>
<p>Q：最近在学习Magnum和Kubernetes。有一些疑问比如minionA/B上分别有serviceA的podA/B。那么访问minionA的kube-proxy是不是也会被导流到minionB上的podB上？service的重要部件proxy就是起到了个负载均衡和反向代理的作用。这个角色是不是直接可以用haproxy/nginx这样的软件代替呢？</p>
</blockquote>
<p>A：我们也在研究Kubernetes，不敢做过多的评价，据说proxy 这块性能有问题。 刚开始没用Kubernetes，是因为之前他还不是很稳定，变动也比较快。 负载均衡这块是我们自己写的，整个乐视网现在300多个域名都跑在上面。</p>
<blockquote>
<p>Q：请问构建一次平均要多长时间？</p>
</blockquote>
<p>A：现在Java、Dubbo、Python、go的多， 一般2分钟，而且有的镜像用户开启了自动构建后，在他们没意识的过程中，都已经构建完成。 到时候升级时候，选择对应的镜像版本即可。</p>
<blockquote>
<p>Q：使用了harbor之后，Dockerfile是不是不用写了？</p>
</blockquote>
<p>A：是的，用户和业务部门只需要关心基本的容器概念（export 和 Volume）就行， 不需要写Dockerfile。</p>
<blockquote>
<p>Q：App的每一次提交都是一个version吗，是不是每次构建完测试完成，就可以发布了？</p>
</blockquote>
<p>A：App 没有提交的概念，您说的应该是镜像，我们设计的是一个镜像对应一个Git仓库以及分支。当有push或者tag操作后，会自动触发构建，构建的行为是根据用户写的镜像构建shell脚本来决定的。 一般我们建议业务部门做出的镜像跟测试环境和生成环境没关系。 镜像就是镜像，只有应用有测试环境和生产环境。</p>
<blockquote>
<p>Q：提到”用公有云的思想去构建私有云”，请问您在构建公有云和私有云时，在技术上有什么区别？可以谈谈您的看法吗？</p>
</blockquote>
<p>A：我们主要是把我们内部用户也看成外部用户去对待，在产品设计上会考虑这一点。这也是我们一直摸索的方向。</p>
<blockquote>
<p>Q：您有物理机和虚机，请问根据什么场景选择运行在物理机还是虚机上？是性能的选择吗？</p>
</blockquote>
<p>A：这完全看业务方的需求，Harbor本身不关心。 它允许业务自己创建私有集群，把自己的虚拟机或者物理主机添加进去。</p>
<hr>
<h3 id="2016-02-23：一个关于不可变基础设施的实践案例"><a href="#2016-02-23：一个关于不可变基础设施的实践案例" class="headerlink" title="2016-02-23：一个关于不可变基础设施的实践案例"></a>2016-02-23：一个关于不可变基础设施的实践案例</h3><blockquote>
<p>Q：你们这套方案中遇到过哪些坑让你印象深刻，请举一两个具体实例说明？</p>
</blockquote>
<p>A：使用 Packer 在国内进行构建时，因为众所周知的网络原因，经常会有失败的问题，这一点可以通过其他方式避免。此外由于 Terraform 并非完全支持所有的 AWS 资源管理，如 Cloudfront、Route53 Geo DNS，仍然需要手工管理这些，不过未来 Terraform 会加入这些的支持。</p>
<blockquote>
<p>Q：每个vpc组是完全独立的提供服务？能说下这套技术应对的业务层是哪个方面的么？</p>
</blockquote>
<p>A：每个 VPC 组提供的是一个完整的应用功能实现，上面也提高了我们会有 prd-sg-master，prd-sg-slave，可用于灾容。业务层提供的主要是 HTTP 服务及内部依赖的微服务。</p>
<blockquote>
<p>Q：请问为什么选用Consul？很多类似方案用的etcd。</p>
</blockquote>
<p>A：Consul 对于 agent 的节点的失效更友好，此外 Vagrant、Consul、Terraform 都是由 HashiCorp 公司开发的，其文档和技术栈都很全面，值得应用实践。</p>
<blockquote>
<p>Q：如果我用了Kubernetes，对大数据Hadoop、Spark都没啥需求，是否还有用Mesos的必要呢？换句话说Mesos和Kubernetes结合针对纯容器平台有什么好处，使用场景是什么？</p>
</blockquote>
<p>A：Kubernetes 和 Mesos 都是容器管理调度的框架，Mesos 的优势是更具可开发扩展性。</p>
<blockquote>
<p>Q：请问对于PHP这种可以动态加载代码的服务，在这套系统里应该怎么应用呢？</p>
</blockquote>
<p>A：动态加载代码的代码源建议使用微服务的方式提供。</p>
<blockquote>
<p>Q：Vagrant在宿主机使用的是NAT模式还是bridge ？Packer相对于vagrant package 命令，优势是哪些？Vagrant 在宿主机使用 NAT 模式，这样可以减少 DNS 出问题的几率。</p>
</blockquote>
<p>A：Packer 可以从ISO镜像开始构建你的系统，相对于Vagrant更纯粹；实际上Vagrant的大多数 box 都是从Packer打包过来的。</p>
<blockquote>
<p>Q：我在<a href="http://dockone.io/article/996" target="_blank" rel="noopener">上期分享</a>时，介绍过类似的Packer+Terraform工具。在使用Terraform管理AWS资源时，你提到另外的脚本管理（thor exec:terraform apply)。请问，你为何不直接运行Terraform的命令，用thor的目的是什么，你的哪个repo了有用到thor，我可以参考一下？</p>
</blockquote>
<p>A：我们在运行Terraform时需要传递很多变量以及硬编码参数，同时我们使用了AWS国内区域和 AWS 国际区域，他们是分开的，对应的 AWS Access Key 及 SecretKey 不同，Thor 脚本的目的是讲这些内容通过配置文件和环境变量的的方式传递给 Terraform，使其能获取正确的参数和定位正确的执行环境。</p>
<blockquote>
<p>Q：请问持续集成采用的是Jenkins加插件的方式吗？持续集成的代码采用了什么样的分支管理策略？</p>
</blockquote>
<p>A：是的，持续集成采用Jenkins及插件，我们采用的分支是 Git Flow 的变种，基于pull的模型。</p>
<blockquote>
<p>Q：单纯的用于AWS的话，亚马逊自家的CloudFormation支持的基础设施应该更全面，如果不考虑跨平台的能力，还有什么理由选择Terraform吗？</p>
</blockquote>
<p>A：CloudFormation 的设计并不友好，基于 JSON 的语法非常晦涩且难于维护，不像 Terraform 一样一目了然。</p>
<blockquote>
<p>Q：跨主机网络是咋解决的啊？是结合了Kubernetes和Mesos、Docker功能吗？</p>
</blockquote>
<p>A：我们采用的方案是 Weave，没有使用Kubernetes。</p>
<hr>
<h3 id="2016-02-14：基于Docker搭建轻量的私有构建环境"><a href="#2016-02-14：基于Docker搭建轻量的私有构建环境" class="headerlink" title="2016-02-14：基于Docker搭建轻量的私有构建环境"></a>2016-02-14：基于Docker搭建轻量的私有构建环境</h3><blockquote>
<p>Q：是否Windows 2016原生支持Docker运行之后Virtualbox/Ubuntu这一层就可以跳过了？</p>
</blockquote>
<p>A：我们使用VB／Ubuntu的原因不是因为Windows原生不支持，实际上Boot2Docker在Win7上就可以用，主要原因是公司机器要装非认证的软件流程没权限，本地认证的虚拟机只有VB。。。</p>
<blockquote>
<p>Q：Oracle Express和Oracle企业版的区别是？能否开发测试环境用Oracle Express，生产环境用Oracle 企业版？</p>
</blockquote>
<p>A：Oracle Express 和Oracle Enterprise 区别还是比较多的，私有构建环境用Express是为了限制资源占用。但是集成和测试环境都是Enterprise。</p>
<blockquote>
<p>Q：选择的什么操作系统运行的Docker ？</p>
</blockquote>
<p>A：Ubuntu 14 LTS。</p>
<blockquote>
<p>Q：在Docker 用Oracle数据库存储如何做？</p>
</blockquote>
<p>A：通过Volume挂上去, 由于是较小的测试库，所以数据量不大。</p>
<blockquote>
<p>Q：请问你们一直是使用Virtual box吗，有没有尝试在VMware下部署？为什么考虑前者？谢谢！</p>
</blockquote>
<p>A：没有用过VMware，关键因为公司认证的是Virtual box，而且是特定版本的。VMware还是Virtual box，对于我们的部署区别不大。还有一个考虑是希望有一个松耦合（不强依赖于特定产品）的开发环境，并且VIRTUALBOX开源，免费，够用。</p>
<blockquote>
<p>Q：能分享下jenkins master与jenkins slave上与各个Docker容器是怎么调度的？</p>
</blockquote>
<p>A：Jenkins有个Docker的插件，可以做到这三者间的调度协调。但是我们没有用，由于我们的实践相对还是比较特殊的，所以都是自己写的shell 脚本。</p>
<blockquote>
<p>Q：Oracle对资源要求比较高，你们用Docker做性能如何，有对比数据吗？</p>
</blockquote>
<p>A：我们没有特意做过测试，但经过一段时间的实践，基于Docker的测试比基于Windows桌面的测试速度快。稍微量化一点来说，用VIRTUALBOX，起一套私有环境跑AT，16G内存，2核4线程的开发机器，内存和CPU的占用率将近80%。用Docker的话，跑一套私有环境做AT，内存和CPU占用率大概40%多一点，基本上能省一半的资源。</p>
<blockquote>
<p>Q：vagrant用于开发环境，Docker用于生产环境，这里面哪个坑最多，你们怎样解决的？</p>
</blockquote>
<p>A：现在Docker并没有用在生产环境，只是用来辅助开发和回归测试。技术本身的坑并不多，因为我们用的方式都很直接，基本上查docker docs加google一下都能解决了。</p>
<blockquote>
<p>Q：使用容器起一套AT环境，代码是通过Volume挂载到容器内部吗？运行的输出，如测试结果，编译出的binary是怎么交付的？</p>
</blockquote>
<p>A：对的，代码通过volume挂载。我们的输出结果是一个文本文件包含测试的结果，以及日志；文本文件我们会自动上传至一个共享的位置，而日志是通过logstash收集，发送至elasticsearch。关于binary，我们AT的产出不包括binary，我们也有构建的job会产生binary，这些我们会上传至中央共享位置。</p>
<blockquote>
<p>Q：开发测试环境下的数据库每次是全量构建还是增量构建？基准数据是如何管理和导入的？</p>
</blockquote>
<p>A：每次都是全量构建。基准数据是来自于生产环境，对敏感数据进行清洗后得到一个轻量的测试库，然后再应用最新的代码，就成了我们每天的测试库。这个测试库是在Oracle Enterprise版本上，通过Oracle 的export/import导入到私有构建环境，这样保证我们的所有测试环境都是一致的而且干净。基准数据不是每天导出的，大概一周到两周才会做一次。</p>
<hr>
<h3 id="2016-01-30：IT基础架构的自动化编排"><a href="#2016-01-30：IT基础架构的自动化编排" class="headerlink" title="2016-01-30：IT基础架构的自动化编排"></a>2016-01-30：IT基础架构的自动化编排</h3><blockquote>
<p>Q：Terraform 建立EC2时怎么用之前构建好的镜像？</p>
</blockquote>
<p>A：例子中， \”source_ami\”: \”ami-de0d9eb7\” 就是引入源镜像。</p>
<blockquote>
<p>Q：packers感觉就是镜像的封装，不知道描述是否贴切，它与kickstart有什么不同？</p>
</blockquote>
<p>A：可以理解为封装。kickstart 更像userdata。</p>
<blockquote>
<p>Q：这个Terraform构建基础架构是否可以理解为基础应用环境的搭建？</p>
</blockquote>
<p>A：是基础设施（Infrastructure) 的搭建。</p>
<blockquote>
<p>Q：請問如果在AWS主要服務運行在ECS ElasticBeanstalk 甚至API Gateway、Lambda這些stack，是否這些工具就不適用了？</p>
</blockquote>
<p>A：ElasticBeanstalk 本身已经是高度自动化了。 但是 lambda支持。 具体可以查看：<a href="https://www.terraform.io/docs/providers/aws/index.html" target="_blank" rel="noopener">terraform.io/docs</a>。</p>
<blockquote>
<p>Q：Windows系统也可以用packer制作镜像，底层需不需要虚拟化?</p>
</blockquote>
<p>A：可以在源镜像上扩展，也可以直接用操作系统的iso文件制作。</p>
<blockquote>
<p>Q：请问这里面介绍的模板与heat的模板通用么？</p>
</blockquote>
<p>A：我没有用过heat。 但是这里有个专门的比较：<a href="https://www.terraform.io/intro/vs/cloudformation.html" target="_blank" rel="noopener">www.terraform.io/cloudformation</a>。</p>
<blockquote>
<p>Q：我现在用的技术栈也是基于 vagrant+packer+terraform，上面讲到Terraform 不支持 AWS VPC Peering 这一点是不正确的，因为我现在已经在使用了，可能您使用的版本比较老。</p>
</blockquote>
<p>A：Terraform里的原话： <code>You still have to accept the peering with the AWS Console, aws-cli or aws-sdk-go</code>.（<a href="https://www.terraform.io/docs/providers/aws/r/vpc_peering.html" target="_blank" rel="noopener">www.terraform.io/docs/</a>）。</p>
<blockquote>
<p>Q：这个Terraform是否可用于管理CPU、内存等资源？</p>
</blockquote>
<p>A：可以定义和更新需要的资源类型 （instance type），不同的instance type 代表不同的CPU和内存。</p>
<blockquote>
<p>Q：用packer制作一次镜像能用于生产测试各环境运行吗，不同环境配置参数可能不同，packer如何支持一次打包到处运行的问题？</p>
</blockquote>
<p>A：你可以按需定制不同的模版文件和制作不同的镜像。</p>
<blockquote>
<p>Q：packer 和 vagrant 使用起来感觉很像呀，他们的主要区别是啥 ？</p>
</blockquote>
<p>A：你说的是vagrant box 吧， packer 是可以用来创建 vagrant box 的。具体参考 <a href="https://www.packer.io/intro/getting-started/vagrant.html" target="_blank" rel="noopener">www.packer.io/intro/</a> 。</p>
<blockquote>
<p>Q：可以简单介绍一下您认为最好用的服务层和应用层的自动化工具，以及原因。</p>
</blockquote>
<p>A：这个话题很大。 主流的话，就是Puppet、Ansbile、Chef、SaltStack。 我们公司用Puppet 来管理系统配置，用Ansible管理应用级别的配置。因为系统配置改变相对较少，我们是level 4 engineering team，用Puppet 统一管理不同的云服务（AWS和公司内部的私有云）的系统配置。 但是Puppet 相对来说，学习曲线要比ansbile困难很多。 对应用的管理，需要较多的修改，BAU（运维）团队比较容易支持。所以选用ansible 做自动配置管理。</p>
<blockquote>
<p>Q：自动化编程能实现0运维吗？</p>
</blockquote>
<p>A：还是需要DevOps（自动化运维）</p>
<blockquote>
<p>Q：基础设施可以理解为中间件？JVM对于Hadoop来说是基础设施？这样理解正确吗？</p>
</blockquote>
<p>A：对我来说，jvm 和hadoop都属于应用层的。</p>
<blockquote>
<p>Q：packer制作镜像，使用本地shell脚本文件来执行命令感觉调试困难，因为命令有错的话如何方便配合用户修改？不会是让用户看日志然后改脚本从头重试，再错再试，如此反复吧？很低效哦。</p>
</blockquote>
<p>A：有很多方法。但是写脚本是最直接的。 镜像的制作确实需要不断调试的过程。 这是DevOps工作的一部分。 通常你将制作好的镜像告诉开发人员即可。</p>
<blockquote>
<p>Q：脚本里直接使用apt-get，会不会导致不同时间创建的基础设施上软件版本出现不一致？你们考虑过自建软件源保证一致性吗？</p>
</blockquote>
<p>A：这就是用packer 的好处。 你可以阶段性的产生不同的镜像，不会覆盖以前的。 然后新镜像需要在dev／uat 环境下测试。过关后，才可以用于生产环境。 镜像制作完后，里面的内容不会改变了。</p>
<blockquote>
<p>Q：可以对创意的资源健康状况进行监控么？一旦有异常，会有自愈策略么？</p>
</blockquote>
<p>A：Terraform里有部分支持的。比如某个security group 的inbound 规则有改变，运行 terraform plan 是可以看到有资源被修改。 如果运行实施的话，会修复的。</p>
<blockquote>
<p>Q：编排的时候有没有把类似监控nagios sensu 之类agent的考虑在内？</p>
</blockquote>
<p>A：这个属于应用层的配置，归自动化配置管理工具，比如puppet／ansible 来管理。</p>
<blockquote>
<p>Q：按照您的回复，不同时间创建的镜像还是存在某些包版本不一致，您有针对性的测试方法推荐吗，还是在uat环境应用没问题就直接上生产使用了？</p>
</blockquote>
<p>A：我们暂时是这样使用的。dev/uat 环境下运行正常就推到生产环境。 如果出了问题，也可以快速回滚。公司允许我们承担这个风险的。</p>
<blockquote>
<p>Q： Terraform在AWS使用play apply等创建实例时候，只支持单个AMI镜像么？如果想要同时配置多个不同镜像的实例，该怎么办？</p>
</blockquote>
<p>A：不是的，可以创建任意多个。在创建不同的ec2实例时，指定不同的源镜像即可。</p>
<blockquote>
<p>Q：你们有没有类似cmdb将所有的资源包括虚拟机的信息放在一个统一的数据库里。另外，你们有用服务发现吗？用的什么软件做服务发现? 怎么做的集成？</p>
</blockquote>
<p>A：Terraform 的模版文件做的就是做这个事情啊。 针对第二个问题，服务发现属于应用层的。 当然你可以在定制terraform 实例资源里的userdata时，加一条 服务发现的命令即可，这样该实例启动后，发现服务自然就注册了这个新的实例了。</p>
<blockquote>
<p>Q：用模版文件管理是如何进行版本控制（version control）的？</p>
</blockquote>
<p>A：就是用Git 。 将Template 文件存到Git 里， 可以是内部的Git服务器，比如我们公司用的atlassian stash， 也可以用GitHub之类的 。</p>
<blockquote>
<p>Q：这个自动化部署的工具，嘉宾有实践过通过PaaS调用，并且部署成功吗？</p>
</blockquote>
<p>A：没有。 AWS属于IaaS。</p>
<hr>
<h3 id="2016-01-23：基于OVS的Docker多主机互联设计和实践"><a href="#2016-01-23：基于OVS的Docker多主机互联设计和实践" class="headerlink" title="2016-01-23：基于OVS的Docker多主机互联设计和实践"></a>2016-01-23：基于OVS的Docker多主机互联设计和实践</h3><blockquote>
<p>Q：我见你是一台主机创建了一个Vxlan，如果有上万台机器，岂不是要创建上万个Vxlan？</p>
</blockquote>
<p>A：创建网络是通过Swarm管理的，因此只需创建一次。</p>
<blockquote>
<p>Q：这个对网络硬件有要求么？</p>
</blockquote>
<p>A：没有具体的要求，倒是相应的内核版本要编译OVS的Kernel模块。</p>
<blockquote>
<p>Q：有没有试过Docker自带的Overlay网络，和OVS有什么区别？</p>
</blockquote>
<p>A：Docker自带的Overlway网络，通过Serf提供的邻居节点发现功能，如实的广播ARP，而我们OVS网络，ARP都被代理了。另外Overlay需要更高的内核支持，应该是3.19，OVS没有这个限制。另外我们还提供多租户内网络地址复用。</p>
<blockquote>
<p>Q：我以前OVS和Docker容器重启后，容器的IP变化了怎么办？</p>
</blockquote>
<p>A：在Vxlan网络里面，在容器的生命周期内，IP不变。</p>
<blockquote>
<p>Q：为什么不直接使用大二层，就像之前的IaaS，2个主机的容器在Vlan里面可以互通？</p>
</blockquote>
<p>A： 关于Vlan，我们也有自己的Vlan网络插件。Vlan和Vxlan场景不同，Vxlan的优势是可以节省IP地址资源。</p>
<hr>
<h3 id="2016-01-15：关于混合云的一点思考"><a href="#2016-01-15：关于混合云的一点思考" class="headerlink" title="2016-01-15：关于混合云的一点思考"></a>2016-01-15：关于混合云的一点思考</h3><blockquote>
<p>Q：我的感觉混合云是从私有云向公有云的过渡，之所有现在还存在私有云是由于一些DC的利旧和安全方面的考虑，这些考虑与成本和管理上便利就看孰轻孰重了。不知理解的对不对？</p>
</blockquote>
<p>A：公有云是私有云和公有云发展的结合。而不是过度。大型企业涉及到国家命脉的企业是不会抛弃私有云的。</p>
<blockquote>
<p>Q：您认为使用混合云面临的最大问题是什么？</p>
</blockquote>
<p>A：管理的复杂。每家接口不一样。很难抽象统一。</p>
<blockquote>
<p>Q：了解下目前支持混合云的开源方案有没有比较流行的解决方案？希望能提供一些指导性的建议或意见。</p>
</blockquote>
<p>A：混合云还没非常完善的开源方案（我的了解），如果只是从管理角度做混合云，那么只是调用API就行了。如果是资源角度，那么资源混用，目前还没方案（这个首先是网络上的问题，涉及SDN等）。</p>
<blockquote>
<p>Q：目前大多数企业都是为了云而云，在没有完善私有云CI/CD和微服务化前，企业如何将笨重的VM在混合云环境下部署？</p>
</blockquote>
<p>A：CI/CD，这个问题，在PaaS层，如果从PaaS层谈混合云，又是一种不同的做法。</p>
<blockquote>
<p>Q：混合云的安全性一般是怎么考虑的？</p>
</blockquote>
<p>A：安全这个问题比较大。管理角度做只能保证用户基本数据的安全。1.  如何确保企业的数据在网络传输中严格加密，保证数据即使获取也无法还原；2.  保证云计算服务商在得到数据时不将企业数据泄露出去。；3.  在云计算服务商处存储时，如何保证访问用户经过严格的权限认证并且是合法的数据访问，同时保证企业在任何时候都可以安全访问到自身数据。</p>
<blockquote>
<p>Q：如何看待目前国内一些CaaS厂商提供的自有主机管理功能？是否能为混合云的管理提供新的思路？</p>
</blockquote>
<p>A：个人看好CaaS，但目前还在发展阶段，估计成熟还需要一点时间积累，经过市场检验后。才能算成功。</p>
<blockquote>
<p>Q：公有云和私有云网络打通后如何解决安全问题，是否需要防火墙，IPS做一定的隔离？</p>
</blockquote>
<p>A：防火墙IPS我感觉在内部需要的，公有云这些我们也无法管理到，公有云的安全都是软件定义的。</p>
<hr>
<h3 id="2016-01-06：思源基于Docker和OpenStack的私有云平台实践"><a href="#2016-01-06：思源基于Docker和OpenStack的私有云平台实践" class="headerlink" title="2016-01-06：思源基于Docker和OpenStack的私有云平台实践"></a>2016-01-06：思源基于Docker和OpenStack的私有云平台实践</h3><blockquote>
<p>Q：Hostname DNS 贵方 用什么方案固定？</p>
</blockquote>
<p>A：首先Container创建之初，hostname和DNS都是通过Docker API来设置的。Hostname是nova instance的name，DNS是公司内部设置。如果想修改Container默认设置也是可以的，我们在内部镜像预留了一个目录，该目录下的hosts、hostname、DNS如果存在都会在Container启动后主动覆盖Container外部挂载的内容。</p>
<blockquote>
<p>Q：在使用Docker去封装novacompute模拟大规模集群测试时，运行一段时间后总出现部分使用Docker封装的nova compute服务出现down的状态，不知道你们是否遇到过这样的问题？</p>
</blockquote>
<p>A：我们这边没有遇到，有没有可能是模拟的nova compute进程数量过多消息有所积压。NOVA方面考虑增加NOVA时间戳超时设置。Docker方面建议Docker的网络使用host模式，并在NOVA配置文件中设置不同的host，以便成为不同的hypervisor node。</p>
<blockquote>
<p>Q：Sahara在使用Docker替代KVM创建Hadoop集群时，是直接使用heat创建Docker，还是使用nova-docker？Sahara相关的代码是否需要改动，遇到过哪些坑？</p>
</blockquote>
<p>A：我们是使用nova docker的driver创建docker container的，Sahara本身相关的代码有部分改动，但是不大，主要改动在使用container和虚机的差别，比如hostname、cloudinit的部分配置等等。</p>
<blockquote>
<p>Q：Docker 的网络模式中，中间添加一层linux bridge的原因是什么，这么做是否会有性能问题？</p>
</blockquote>
<p>A：这个还是为了安全组，实际上我们支持配置两种模式，linux bridge并不是默认配置的。OpenvSwitch 2.4以后可以根据流表设置安全组。</p>
<blockquote>
<p>Q：Container限速是如何实现的，是否有必要针对Container进行限速？</p>
</blockquote>
<p>A：我们的环境中使用的OpenvSwitch，通过veth pair的方式建立虚拟网络设备的关系。限速主要是使用tc，毕竟OpenvSwitch的限速也是使用tc做的。</p>
<blockquote>
<p>Q：NOVA组件中Docker的高级特性无法使用你怎么看，是否使用docker api来控制容器？</p>
</blockquote>
<p>A：上面已经说过这个问题了，其实通过flavor metadata的设置，nova docker driver 可以实现生成一组容器。nova docker这块过去确实是直接调用Docker API的，但是为了应对不断变化的API，我们使用了docker-py作为Client，并在nova 配置文件中增加了API版本的设置。从而尽可能拿到Docker本身升级带来的福利。</p>
<blockquote>
<p>Q：OPS已经有超分设置，你设置超分的意义是什么？</p>
</blockquote>
<p>A：我们Docker和KVM都在一个openstack平台中，而nova的超分实在NOVA Conductor中生效的。Nova compute Libvirt Driver是直接上报的服务器核数。而我们认为Docker在密度上存在比KVM密度更高的需求，所以在Compute上支持超分是有必要的。</p>
<blockquote>
<p>Q：使用CPU share是否会出现单个容器负载很高的场景，出现这种情况如何处理？</p>
</blockquote>
<p>A：还是会出现的，记得有个容器CPU占用1600%的场景（32核心）。通常这种情况还是应用出现了问题，最简单的方法是通过cgroup本身的命令进行限制。容器重启之后该限制就会丢失。限制方法例如： cgset -r cpuset.cpus=20-23 cpuset:/docker/91d943c55687630dd20775128e2ba70ad1a0c9145799025e403be6c2a7480cb2</p>
<blockquote>
<p>Q：Docker 的监控和scale-auto是如何实现的？</p>
</blockquote>
<p>A：监控方面目前主要是通docker stats api 和 部分脚本来实现，集成到Zabbix中，后面会考虑使用CAdvisor。\ 后者目前不支持，计划上会在Kubernetes平台中支持，而非heat或NOVA中。毕竟这是Kubernetes、Mesos它们的专长。</p>
<blockquote>
<p>Q：你的三层镜像中，第一层和第二层都是系统层，为什么不合并成为一层？</p>
</blockquote>
<p>A：首先我们的第一层镜像并不是通过dockerfile创建的，而是依据官方文档从0建立的最小的镜像，这一层是很少变动的。而第二层的设置是为上层设计的通用层，涉及到进程管理器、SSH设置、pam设置、入侵检测设置、开机初始化设置、还是有很大可能变动的，我们希望有关配置都应该放入dockerfile以便管理。</p>
<blockquote>
<p>Q：nova-docker如何支持cloudinit？</p>
</blockquote>
<p>A：因为在novadocker中就是完全模拟KVM的网络模式，所以cloudinit除了一些小幅配置变更之外没有什么特殊的。 +</p>
<blockquote>
<p>Q：能否详细介绍下ARP问题？</p>
</blockquote>
<p>A：由于建立的vm的ip之前分配给了已经删除的vm，导致mac被记录在交换机上。数据交换经过3层，3层交换机会将mac直接返回给ping的一方，导致无法ping通、 启动container后通过arping -c 3 -f -U -I eth0 172.28.19.243 -c 3开机发送免费arp来处理。</p>
<blockquote>
<p>Q：NOVA Docker实现了热迁移吗？如何做快照？</p>
</blockquote>
<p>A：热迁移目前还没有支持，nova docker快照就是将容器commit成一个镜像，然后使用glance的接口上传glance中。通过快照可以重新建立新的container。</p>
<blockquote>
<p>Q：nova-docker不是早在H版本就废弃了吗？你们自己维护的？</p>
</blockquote>
<p>A：确实废弃了，我们自己维护。不过GitHub上有了更新，我们刚刚merge机那里一些特性。可以再关注一下。</p>
<blockquote>
<p>Q：OpenStack如何对novadocker环境的container进行监控？在监控指标上是否与其他hypervisor driver有区别？</p>
</blockquote>
<p>A：监控方面目前主要是通docker stats api 和 部分脚本来实现，集成到Zabbix中，后面会考虑使用CAdvisor。监控上有一些区别。主要是pid_max、docker daemon存活，和Docker自身存储pool等Docker特有的，其他方面没有太大区别。</p>
<blockquote>
<p>Q：您好，贵公司只维护Git代码和镜像容器。请问假如同一个编译环境，能编译不同操作系统版本的库吗？或者镜像。因为同一套代码会部署到不同的系统上？</p>
</blockquote>
<p>A：我们这条编译环境只是用来编译OPS本身的，如果需要增加新的编译环境，我们会向Registry推送一个新的编译镜像。</p>
<blockquote>
<p>Q：glance管理镜像和快照时有没有能用到Docker的分层？如果有，如何利用的？</p>
</blockquote>
<p>A：没有，tar包形式，compute节点下载之后load到compute节点上。</p>
<blockquote>
<p>Q：生产环境相比测试环境有什么不同吗？</p>
</blockquote>
<p>A：Docker在CPU超分系数不同，系统pid_max等调优参数略有不同。</p>
<blockquote>
<p>Q：Nova Docker快照是如何实现的？</p>
</blockquote>
<p>A：将操作的Container commit成为一个镜像，并上传到glance中。</p>
<hr>
<h3 id="2015-12-29：用Docker和Git搭建在线开发环境"><a href="#2015-12-29：用Docker和Git搭建在线开发环境" class="headerlink" title="2015-12-29：用Docker和Git搭建在线开发环境"></a>2015-12-29：用Docker和Git搭建在线开发环境</h3><blockquote>
<p>Q：那么多的开发者，域名怎么分配？</p>
</blockquote>
<p>A：目前，我是通过Nginx的反向代理来分配不同的子域名给不同开发人员。</p>
<blockquote>
<p>Q：在这个体系中开发与测试是如何联系？</p>
</blockquote>
<p>A：这套体系主要专注于开发的部分，测试与开发的互动并没有在这套体系中体现出来，不过有很多成型的DevOps体系可以作为参考。</p>
<blockquote>
<p>Q：云端开发是不是开发环境放在云上，开发者SSH到自己的开发环境，提交代码后Compose是自动执行还是人为执行？</p>
</blockquote>
<p>A：理想状况下，是将一下三个部分都放倒云端，目前我只实现了运行环境在云端。 Compose现在也是手动之行的，但是可以通过脚本做到自动化功能完备的代码编辑器 一个应用运行环境 一个调试工具箱。</p>
<blockquote>
<p>Q：云端开发会不会减少开发者的工作量，让其更专注于代码上，而不是流程的应用上？</p>
</blockquote>
<p>A：云端开发会让开发人员更少的经历去学习了解中间件， 用更多的时间专注于业务功能的实现，从而做到让开发更关注需求本身，而不是技术本身。 另外在线开发环境可以提高协作性。因为运行环境和代码都在云端，开发人员可以很快的切换其他人的开发环境和代码。</p>
<blockquote>
<p>Q：在线IDE在实际使用中的体验，可被开发人员的接受程度如何，对各类语言的支持情况呢？</p>
</blockquote>
<p>A： 目前的尝试在线IDE受网络，和功能的制约，不能完全和本地的IDE相比较。 不过因为Git的解耦，开发人员可以选择使用本地的IDE编辑代码</p>
<blockquote>
<p>Q：Git还是比较复杂，有没有更简单的工具？</p>
</blockquote>
<p>A：除了Git之外还有一种sshfs的技术，可以直接映射远端代码到本地。 不过考虑到版本的回溯，甚至将来利用大数据来分析开发人员的开发行为。 Git会是一个比较好的选择。 Git现在的复杂是因为相应的自动化脚本没有建立，在建立之后，开发人员可以忽略Git同步的部分。</p>
<blockquote>
<p>Q：代码提交到云端后，容器中是怎么生效的，是把代码目录作为挂载点还是容器中有进程实时去拉？</p>
</blockquote>
<p>A：是的，现在代码作为卷挂载到容器中的。</p>
<blockquote>
<p>Q：但是如果是以挂载的方式，怎么能重现Commit镜像时保证代码的同步呢？</p>
</blockquote>
<p>A：我想这个问题回到了”这个体系关注的问题到底是什么”上。 我分享的这套体系专注于项目中的开发部分，并不专注版本控制，测试和部署。 通常情况下，项目应该有另外一个Git仓库来做版本控制，然后会有专门的build体系，来自动build指定的代码。</p>
<blockquote>
<p>Q：Commit镜像时的镜像里并没有代码啊？打算任何环境都是以挂载的方式吗？这样可移值性会不会很差？</p>
</blockquote>
<p>A：首先Container是通过项目路径下的dockerfile生成的， 只是在运行环境中又挂在了一次代码。 当开发结束后， 可以通过项目的dockerfile,整体build代码和环境，并部署。</p>
<blockquote>
<p>Q：例如采用git flow这样的多分支并行开发，每个分支都要有一套对应的docker container 吗？如何来关联分支和容器？</p>
</blockquote>
<p>A：这是个好问题，首先Docker只提供代码的运行环境，如果代码的不同分支使用的是不同的运行环境，docker container是应该是多套的，而且，不同的dockerfile是应该跟代码在一起的。 如果运行环境是相同的，可以使用同一套docker container。只需要把代码切换到Container里即可。</p>
<blockquote>
<p>Q：当先就目前来说，在云上部署确实很好，可是关于一些生产的私有性环境是不是在本地比云端更靠谱？</p>
</blockquote>
<p>A：我理解这个问题应该是问将云端开发环境部署到公有云，还是私有云。 我个人的理解是， 目前来看，应该部署在企业内部的私有云上，来避免代码的泄露。</p>
<blockquote>
<p>Q：当前来说搭建一个统一的环境使用Kubernetes or SHIPYARD 搭建起来会更方便，而且现在物理设备的价格也更便宜，可控程度更高，在云端真的比在内部控制好么？</p>
</blockquote>
<p>A：同第一个问题一样，云端指的可以是私有云，也可以是公有云。 我赞同提问者的考量，私有云会更好一些。</p>
<blockquote>
<p>Q：是不是先提交代码，触发hook，在容器里同步代码并编译和执行。这样效率会更高吗？</p>
</blockquote>
<p>A：将代码编辑环境和运行环境解藕， 使用Git来同步，效率受两个因素制约： -   I/O也就是网络速度和盘速度。     保证网络速度的前提下，这个因素是可以忽略的 -   Git本身的效率，因为每一次保存都会提交Git，Git本身是增量存储，所以效率也不会太低。</p>
<blockquote>
<p>Q：对私有仓库是否也能同样生效？对于容器不能被外部访问的话，hook机制还能同步代码吗？</p>
</blockquote>
<p>A： 目前这套体系建议整体部署在私有云中。</p>
<blockquote>
<p>Q：每位开发者都具有相同的开发环境，该开发环境是用Container么，网络是如何解决的？也就是说在开发者眼里使用的就是虚拟机，具有故定的IP。</p>
</blockquote>
<p>A：应该说每位开发者都有相同的代码运行环境，这部分是通过Container实现的。目前明没有对网络有太多的考量， 在规划中会有一个网络分配的组件，为开发人员分配不同的子域名，并自动将域名路由到container上，这样可以更灵活的分配主机资源，管理Container。</p>
<blockquote>
<p>Q：代码放在云端怎么保证安全，防止企业代码泄漏？</p>
</blockquote>
<p>A：部署在私有云上， 需要公网访问时，使用VPN。</p>
<blockquote>
<p>Q：我公司主要需要是C++研发电信行业，不通的省份，不同的机型都要搭理一套开发测试环境，你们讲的主要是Web开发，C++是否适合云端开发？</p>
</blockquote>
<p>A：我主要研究Web方向。 只能简单的说一下思路， C++的docker image是有的，主要是看你需要一个什么样的调试环境。如果可以通过Web查看结果。我觉得是可行的。</p>
<blockquote>
<p>Q：关于使用Git搭建持续集成环境有一个疑问，就是如何处理在开发环境和生产环境下，个别文件不同的情况应该如何处理？例如一些配置文件，Django中的settings.py，在生产和开发环境下，其内容是不同的。</p>
</blockquote>
<p>A：通常情况下，配置文件是要独立在代码之外的，用Django举例， 可以使用.env。 在开发环境，和生产环境使用不同的配置文件，而不是直接写在代码里面。 如何配置产品环境和开发环境，可以参考一些好的实践文章。 分离运行环境和代码的实践文章，业界比较认同的是”<a href="http://12factor.net/zh_cn/" target="_blank" rel="noopener">The 12-Factor App</a>“这个设计思路。</p>
<blockquote>
<p>Q：如果后端采用集群方式进行管理，请问您对后端容器资源使用的预估，以及对整个集群的负载能力的判断，是如何考虑的？项目不同，对后端资源影响挺大。</p>
</blockquote>
<p>A： 目前项目还处在概念验证阶段。 对于中型的Web项目，单个开发人员分配1CPU资源，1GB内存是完全可以满足需要的。</p>
<blockquote>
<p>Q：本地开发可以快速切换本地Git的不同代码版本查看，远程运行的话，想要查看之前代码的运行结果需要真的将代码在远程共享本库中回滚吗？</p>
</blockquote>
<p>A：是的，因为每个开发都自己的远程代码代码库。 所以，回滚并不会影响其他人，也不会丢失自己的代码。</p>
<hr>
<h3 id="2015-12-22：基于Docker和Git的持续集成工作流"><a href="#2015-12-22：基于Docker和Git的持续集成工作流" class="headerlink" title="2015-12-22：基于Docker和Git的持续集成工作流"></a>2015-12-22：基于Docker和Git的持续集成工作流</h3><blockquote>
<p>Q：开发每提交一个bugfix，都会触发jinkens去构建镜像，那么多的开发者，岂不是要构建很多镜像？</p>
</blockquote>
<p>A：没有错，我们是每次都触发构建 image，由于image是分层的，底层已经存在的父对象，是不用存储，只存储变化的部分所以再用的磁盘空间很低，在系统开始初，我做过统计，1000个 image 也不到 9G，这其中还有很多基础镜像。</p>
<blockquote>
<p>Q：想问一个集群相关的，像Docker部署这部是直接调用Docker部署容器，还是通过Ansible或其他工具？</p>
</blockquote>
<p>A：有了 Kubernetes 管理集群后，发布的工作就比较简单了，用不上 Ansible。但是 Ansible 还是有它的用处的，比如清理集群中过时的 image，和已经退出的 Container等。</p>
<blockquote>
<p>Q：你好，以前也做过类似的服务”第三步：Jenkins 会把相应的 image部署到服务器集群中，开发者就可以通过 iss001.kingdee这个域名访问刚刚对应分支的服务了”，单独一个分支解决了对应的bug，但实际生产中非常容易修改一个bug引起其他的bug，你们是怎么去把控整体的稳定性？如何提高这种单个bug分支单个测试环境的意义？</p>
</blockquote>
<p>A：这个 pull-request 的工作方式是应对功能开发的，如像长期开发某个 new feature，你刚刚说的一个 bug 产生另外一个bug，我们的做法是有回归测试，我们有一个 smoke 分支，持续不断的对其做功能回归测试，只有通过的才能 cherry pick 到release 上。</p>
<blockquote>
<p>Q：测试环境依赖的redis/MQ之类的外部服务如何做的隔离?每次测试单独拉起来一套外部依赖的服务吗？</p>
</blockquote>
<p>A：我们通过多个手段来实现共享数据：master、smoke、release 分支测试都有自己独立的中间件，要是不用访问共享的数据，可以部署如 MQ image，代码层面的，如 MQ key 的名称加上机器的 IP。</p>
<blockquote>
<p>Q：有没有用到Mesos？是否容易遇到问题？这方面的文档好像并不多。</p>
</blockquote>
<p>A：Mesos 是个二级调度，适用于像存在多套集群的情况，来均衡资源，如：部署了 Hadoop 和 storm ，一般会使用 storm 来处理实时的请求，Hadoop 做离线工作。晚上和白天就存在一种可能就是 Hadoop 闲置，但是 storm 可能很忙，这时 Mesos 这样的二级调度就可以平衡资源，节约成本，我们暂时没有这样的需求。至于文档方面我也没有深入研究，建议看官方文档。</p>
<hr>
<h3 id="2015-12-15：容器服务如何在企业客户落地？Rancher解决之道分享。"><a href="#2015-12-15：容器服务如何在企业客户落地？Rancher解决之道分享。" class="headerlink" title="2015-12-15：容器服务如何在企业客户落地？Rancher解决之道分享。"></a>2015-12-15：容器服务如何在企业客户落地？Rancher解决之道分享。</h3><blockquote>
<p>Q：rancher-compose 和 docker-compose 关系？</p>
</blockquote>
<p>A：rancher-compose是对docker-compose的扩展，docker-compose目前的能力太有限。</p>
<blockquote>
<p>Q：Rancher自己有持续集成的工具？</p>
</blockquote>
<p>A：我们本身产品中不带CI，但会在CATALOG里提供这样的工具让客户一键部署，我想这个比直接提供CI集成更COOL</p>
<blockquote>
<p>Q：Rancher产品是付费还是开源的呀？</p>
</blockquote>
<p>A： 我们是开源的，但也会有对应的企业版，像CentOS 和RHEL一样。</p>
<blockquote>
<p>Q：Rancher的网络是如何实现的？</p>
</blockquote>
<p>A：简单来说，我们目前是IPSEC VPN+基于DNS的服务发现。</p>
<blockquote>
<p>Q：我接触Rancher有两个月了，感觉是目前Docker管理平台里比较出色的。stack、service管理逻辑很好。不过目前还是0.4*版，迭代应该比较频繁。现在上业务的话，后期升级会有什么影响么？</p>
</blockquote>
<p>A：升级非常容易，且向后兼容，在这一点上秉承CloudStack的设计原则。</p>
<blockquote>
<p>Q：私有网络与公有云之间的数据安全是怎么控制的？</p>
</blockquote>
<p>A：通过ReverseNAT 下采用IPSec Tunnel，也就是数据是加密的，但要开在服务器间开两个UDP端口。</p>
<blockquote>
<p>Q：请问Rancher 在多租户隔离方面做了那些事，采用哪些安全手段？</p>
</blockquote>
<p>A：容器的隔离是和虚拟机不太一样，目前我们用”环境”的概念做多租户隔离，每个”环境”有自己的容器主机和容器。</p>
<blockquote>
<p>Q：相比于Kubernetes、Mesos和 Swarm、Rancher的优势在哪里？</p>
</blockquote>
<p>A：我们和上述容器编排不是竞争关系（虽然目前编排是我们自己写的），我们会根据用户的需求提供Swarm、Kubernates甚至是Mesos的编排方式。但容器编排不是全部企业容器服务内容。</p>
<blockquote>
<p>Q：请问Rancher是自己实现了一套容器管理工具吗，能介绍一下你们用到的技术栈吗？</p>
</blockquote>
<p>A：我们是完全自己实现的。借鉴了之前团队做的CloudStack的成功经验。</p>
<blockquote>
<p>Q：Rancher推荐运行在什么样的宿主机之上，Ubuntu or CentOS？</p>
</blockquote>
<p>A：都行，Rancher可以管理标准Docker 主机。</p>
<blockquote>
<p>Q: 我看新版本多了一个存储池storage pool这个是什么作用，可以添加集群存储来供容器使用么？<a href="http://rancher.com/how-rancher-storage-services-unleash-the-power-of-software-defined-storage/" target="_blank" rel="noopener">rancher.com/how-rancher/rage/</a>。</p>
</blockquote>
<blockquote>
<p>Q：请问catalog离线可以使用吗？</p>
</blockquote>
<p>A：很多企业都是没有互联网访问的，我们支持从本地镜像库Registry中拉images。</p>
<blockquote>
<p>Q：请问你们跟Docker公司是如何合作的？是什么一种关系？他们会推广你们的产品吗？</p>
</blockquote>
<p>A：都是硅谷公司，有深入的技术合作，很多Docker组件如libcompose都是我们贡献的。</p>
<hr>
<h3 id="2015-12-09：玩转Docker镜像和镜像构建"><a href="#2015-12-09：玩转Docker镜像和镜像构建" class="headerlink" title="2015-12-09：玩转Docker镜像和镜像构建"></a>2015-12-09：玩转Docker镜像和镜像构建</h3><blockquote>
<p>Q：京东私有云是基于OpenStack＋Docker吗，网络和存储的解决方案是什么？</p>
</blockquote>
<p>A：是的。私有云网络使用的是VLAN。并没有使用租户隔离，主要保证效率。存储使用的是京东自己的存储。</p>
<blockquote>
<p>Q：那个镜像压缩，有什么好处？</p>
</blockquote>
<p>A：镜像压缩或者说合并，主要是减少层数，减少担忧。其实目前看，好处并不明显。因为层数过多带来的更多的是担忧，但没有确凿证据表明会影响稳定。</p>
<blockquote>
<p>Q：在线编译应用广泛吗？我们一般可能更关注最后的结果。有很多代码都是先在本地编译，成功后，再发布到镜像中的。</p>
</blockquote>
<p>A：这个玩法应该说并不广泛。主要是我自己玩的时候，不想自己去拉镜像的全部层，只关注编译结果。所以这样玩</p>
<blockquote>
<p>Q：对于Docker镜像的存储京东是使用什么方式实现的分布式文件系统京东Docker上有使用吗能否介绍下？</p>
</blockquote>
<p>A：镜像存储使用的是官方的registry。v1版本。registry后端是京东自研的JFS存储。</p>
<blockquote>
<p>Q：你之前提到了”镜像的合并缩减了层数，但是弊端在于将生成镜像的Dockerfile信息也消除了（使用Dockerfile生成的镜像，可以通过dockerhistory进行回溯）。”那如果使用了Compress之后，应该如何进行回溯？还是说需要舍弃这部分功能？</p>
</blockquote>
<p>A：是的，确实没办法回溯了，所以要舍弃了。不过反过来想，其实如果Dockerfile的ADD和COPY之类的功能，就算能回溯，其实意义也不大。所以我认为保存Dockerfile更有意义。</p>
<blockquote>
<p>Q：为什么不采用将要执行的命令做成脚本，直接add进去执行这种，也能减少层数？</p>
</blockquote>
<p>A：这种方法也是可行的。只是Dockerfile更显式一些。同理，其实只要你做好镜像，直接export出去，就可以得到所有文件了。再配上配置文件。这样整个就只有一层了。</p>
<blockquote>
<p>Q：我平时在，测试的时候并没-有压缩过，也不知道，压缩会带来什么风险，但是，看你刚才说有可能会带来一定的风险。你们遇到过么？</p>
</blockquote>
<p>A：因为我们的镜像都做过合并层，所以层数并不多。不合并会带来什么风险，其实更多的是出于性能和稳定性上的担忧。这种担忧可能是多余的。但是我们宁愿选择谨慎一些。</p>
<blockquote>
<p>Q：镜像的合并方面怎么样能方便的减小镜像的大小，我做的镜像有些都在1G以上？</p>
</blockquote>
<p>A：减少镜像大小主要还是靠去除不必要的文件。合并只能减少冗余文件，如果每层的文件都不相同，合并并不会缩小镜像的大小。</p>
<blockquote>
<p>Q：网络这个使用VLAN能说详细一些吗，是每个容器都有一个和宿主机同网段的真实的物理IP吗？</p>
</blockquote>
<p>A：是的。每个容器都有一个真实的IP。跟宿主机网段不同。是单独的容器网络。这个可以参考neutron中的Vlan实现。</p>
<blockquote>
<p>Q：还有，把镜像压缩我也觉，但是像你那样把父镜像整个合并成新镜像这点我觉得有点问题，毕竟大家玩容器时都是在基础镜像上添加东西，你把常用的镜像为了压缩生成一个一次性的镜像，以后再使用基础镜像做其他业务时那不还得重新下载基础镜像？</p>
</blockquote>
<p>A：镜像合并其实主要还是为了获得一个基础镜像。然后大家在基础镜像上添加东西。基础镜像相对来说，不会轻易改变。</p>
<blockquote>
<p>Q：在你们的实践中，大规模部署容器时，每个节点都会从Registry节点下载镜像，给网络带来的压力大吗？</p>
</blockquote>
<p>A：我们做了一些优化。首先，大部分业务使用的镜像会提前推送到每个Docker节点上。即使节点没有，Registry后端接的是京东的JFS，通过优化，临时去下载的时候可以直接从JFS去拿镜像数据。所以网络压力并不大。</p>
<blockquote>
<p>Q：镜像压缩或者合并之后，镜像的层次减少了，但每层镜像不是变大了吗，这对于发布不是会占用带宽降低效率吗？</p>
</blockquote>
<p>A：这个问题跟上个差不多。合并主要是为基础镜像使用的。</p>
<blockquote>
<p>Q：你们怎么看待OpenStack和Docker的关系？在京东未来会长期两个并存吗？现在两个架构的发展速度和研发力量对比如何？</p>
</blockquote>
<p>A：OpenStack和Docker并不矛盾。私有云采用nova docker的结合更多的是迎合用户习于使用VM的习惯。Magnum也在快速发展中。所以我相信二者都有存在的价值和发展的必要。</p>
<blockquote>
<p>Q：关于dockfile的优化，你们有没有什么好的建议或者经验？</p>
</blockquote>
<p>A：似乎也没多少新的建议。参考DockOne的相关文章。<a href="http://dockone.io/article/255" target="_blank" rel="noopener">Dockerfile之优化经验浅谈</a>、<a href="http://dockone.io/question/683" target="_blank" rel="noopener">大家在写dockerfile时有啥最佳实践？希望得到大家的建议</a>。</p>
<blockquote>
<p>Q：比如创建一个rabbitmq镜像，需要安装很多依赖包，最后编译，最后生成的镜像1.3G，像这种情况，在创建镜像的时候能否减少镜像的大小呢？</p>
</blockquote>
<p>A：并没有什么好的办法来减少。可能需要一定的人工或者工具去分析不需要的文件，来减少镜像的大小。</p>
<blockquote>
<p>Q：Docker是如何进行自动更新的，自己搭建的镜像仓库，如何更新新版本的镜像？</p>
</blockquote>
<p>A：Docker我们固定了一个版本。如果没出大面积的严重问题，几乎不会更新。目前来看，运行稳定。所以也没有更新必要。新版本的Docker提供的如网络等，暂时我们还不会大面积跟进使用。自己的镜像仓库，如果要更新新版本镜像，push进去就可以了。</p>
<blockquote>
<p>Q：一个困扰我比较久的问题，如果镜像间存在依赖关系，基础镜像发生改变后其他镜像你们是跟着更新的呢？</p>
</blockquote>
<p>A：在内部私有云中，一般大家使用的都是一个做好的base镜像。这里面就有一个问题，一旦这个base镜像需要打补丁，影响面比较大。首先很多base的子镜像会受到影响。另一方面，就是要考虑已经在使用基于base或者base子镜像的节点。前者我的方案是直接在base镜像中的layer，把需要打补丁的文件加入进去，重新打包放回。对于后者，目前还没想到很好的方法解决。</p>
<blockquote>
<p>Q：在运行容器的时候，1、应用里面的日志或者配置文件，使用本地映射是不是好点，我是考虑到方便查看日志或者修改配置；2、创建的数据库镜像，在运行容器的时候把数据文件是不是映射到本地更好些呢？</p>
</blockquote>
<p>A：日志我们的确是使用的本地映射。而且有的业务方狂写日志不加约束。所以我们给本地映射做了个LVM，挂给容器。做了容量上的限制。配置的话，现在是有一个内部的部署系统会帮他们部署配置。数据库的话是一个道理，也是映射到本地。也有一部分接入了云硬盘。</p>
<blockquote>
<p>Q：Docker中，每层镜像打标签那我觉的很奇怪，当pull一个镜像或生成一个容器时，它如何找到你所命名的镜像层？</p>
</blockquote>
<p>A：并不是给每层都打标签，而是你根据你的需要来给某一层打标签。至于标签内容，需要自己来进行控制。</p>
<blockquote>
<p>Q：关于Compress的实现有些疑问，是不是在实现的过程中，只考虑最后的镜像和前一层的diff，还是说要逐层做diff？</p>
</blockquote>
<p>A：是只考虑最后的镜像和你要合并到的父层镜像做diff。这样只要做一次diff，就可以获得中间的所有文件变化了。</p>
<blockquote>
<p>Q：wrapdocker文件的工作原理是什么?</p>
</blockquote>
<p>A：这个工作原理主要是准备一些Docker启动必要的环境。比如在CentOS下，需要wrapdocker把cgroups等准备好等。你可以参考下wrapdocker里面的代码。</p>
<blockquote>
<p>Q：容器运行在物理机上，与OpenStack平台虚拟机是同一套管理系统？如何与容器的集群系统整合？</p>
</blockquote>
<p>A：是同一套系统，都是用nova。虚拟机KVM和容器主要是镜像类型不同。在nova调度的时候，会根据镜像类型调度到KVM或者Docker节点进行创建。</p>
<blockquote>
<p>Q：在一台物理机上运行Docker的数量是否有限定 还是看运行的应用来决定？</p>
</blockquote>
<p>A：没有特别做限定。主要还是业务方去申请的。业务方习惯用大内存，多CPU的。那这个物理机上创建的容器数就少些。大致这样。</p>
<blockquote>
<blockquote>
<p>Q：想了解一下，你们对镜像的tag是怎么管理的？根据什么来打的？对于旧的镜像你们是丢弃还是像Git保存代码一样一直保留在仓库呢？</p>
</blockquote>
</blockquote>
<p>A：tag由各个用户来定。不同的用户在不同的Repository里。镜像tag自己管理。不过我们更希望他们能够更加规范一些，比如用git的版本号来打tag。</p>
<hr>
<h3 id="2015-11-29：微服务架构云端应用"><a href="#2015-11-29：微服务架构云端应用" class="headerlink" title="2015-11-29：微服务架构云端应用"></a>2015-11-29：微服务架构云端应用</h3><blockquote>
<p>Q：请问你是基于Docker和Mesos吗?</p>
</blockquote>
<p>A：用了Docker。</p>
<blockquote>
<p>Q：是混合云架构吗?</p>
</blockquote>
<p>A：是的，也可用在私有云。</p>
<blockquote>
<p>Q：微服务是谁发布哪？</p>
</blockquote>
<p>A：只要有代码就可以发布微服务，一般由微服务的开发者发布。</p>
<blockquote>
<p>Q：业务系统日志是如何处理的？</p>
</blockquote>
<p>A：统一输出到标准输出和错误输出，按租户存储，实时显示到页面，可以按天下载。</p>
<blockquote>
<p>Q：请问你们的容器管理系统是基于开源平台还是自己开发的？有何优势？</p>
</blockquote>
<p>A：用了一部分开源。 4.持开源服务和用户贡献的服务，用户选择空间更大。</p>
<blockquote>
<p>Q：请问你们的服务「水平伸缩」和「垂直伸缩」分别面对哪类场景？如何实现？</p>
</blockquote>
<p>A：「垂直伸缩」对于所有场景都是可以使用的。「水平伸缩」用到无状态服务的场景，而且可以和「垂直伸缩」叠加使用的，有状态服务不支持水平伸缩。针对不同微服务类型，在管理后台配置就可以实现。</p>
<blockquote>
<p>Q：微服务跨平台如何解决网络延迟问题呢？</p>
</blockquote>
<p>A：在网络不稳定的场景，服务之前的调用一定要用断路器，另外只有优化物理网络链路了。</p>
<blockquote>
<p>Q：微服务怎么解决后端数据库的部署和依赖问题？</p>
</blockquote>
<p>A：在好雨云，数据库也算特殊一类微服务，同样有其他微服务的特性，一样可以通过微服务的特性部署和配置依赖关系。</p>
<blockquote>
<p>Q：介绍下服务间通信是如何实现的？</p>
</blockquote>
<p>A：在服务使用端实现了一个透明的代理，它根据服务注册的Endpoint，找到要使用的服务，如果是多个服务，自动实现负载均衡。</p>
<blockquote>
<p>Q：支持的语言有没有c语言？</p>
</blockquote>
<p>A：可以通过dockfile支持的。</p>
<blockquote>
<p>Q：请问一下docker选用的是哪个版本？有特殊原因么？</p>
</blockquote>
<p>A：我们比较保守，用的是比较稳定的，除非有个大特性吸引我们</p>
<blockquote>
<p>Q：请问代理模式是指类似于 API GATEWAY 吗？具体用什么实现的？</p>
</blockquote>
<p>A：是的。有很多种实现方式，可以自己写代码实现，也可以部署一个 Nginx。</p>
<blockquote>
<p>Q：从前面架构图看每个微服务的数据库是独立的，这是必须的吗？</p>
</blockquote>
<p>A：这样有很多优点，比如业务隔离，独立团队维护，业务分区，等等，不是必须，共享模式就是特例。</p>
<blockquote>
<p>Q：能否理解解决「服务伸缩」问题的重点是「服务发现」和「状态共享」？</p>
</blockquote>
<p>A：这块的核心依赖程序实现，如果程序实现的好，就可以做到非常好的水平伸缩，我们自己的有状态服务也是可以水平伸缩的。</p>
<blockquote>
<p>Q: 请问当每个服务都可能同时存在多个在线版本时，如何做ab testing？如何控制业务路由？</p>
</blockquote>
<p>A：ab testing我们当前没有实现，下一步会引入这个特性。我们的设计思路是实现一个控制用户访问路由的微服务，同时支持ab testing。</p>
<blockquote>
<p>Q：哪种服务模式用的最多？异步消息模式吗？</p>
</blockquote>
<p>A：用的最多的是聚合模式和异步消息模式。</p>
<blockquote>
<p>Q：微服务后端的数据库是弹性伸缩的怎么做的？MySQL，mongodb</p>
</blockquote>
<p>A：要支持水平伸缩，需要部署一个支持水平伸缩的数据库中间件做为微服务。 垂直伸缩，直接调整资源就可以了，受限于物理机的资源容量。</p>
<blockquote>
<p>Q：伸缩的时候对业务可以做到完全透明吗！</p>
</blockquote>
<p>A：是的。我们现在的实现是对业务完全透明。</p>
<blockquote>
<p>Q：服务发现用到什么，Consul、Dubbo？</p>
</blockquote>
<p>A：轻量级封装 etcd。</p>
<blockquote>
<p>Q：每个微服务对应一个数据库，怎么做到数据共享呢？</p>
</blockquote>
<p>A：每个微服务后面的数据库支持有状态数据的持久化，对外整体是一个业务服务，需要根据业务关系来梳理服务结构。如果有一致性要求比较高的场景，可以使用共享数据库或消息服务实现。</p>
<blockquote>
<p>Q：垂直伸缩，调整资源就可以了，资源需求超过一台物理机呢？拆库？</p>
</blockquote>
<p>A：三种方式：第一种，把业务拆的小，数据库分库。第二种，数据库sharding。第三种，使用CQRS模式，重新设计实现。</p>
<blockquote>
<p>Q：服务调用链的事务怎么保证的？</p>
</blockquote>
<p>A：可以通过共享数据库，使用数据库事务解决调用链事务问题。另外，还可以使用异步的消息服务，通过保证消息可靠消费来实现。</p>
<blockquote>
<p>Q：CQRS 模式的 维护成本很高啊 有评估过这种改造的成本吗？</p>
</blockquote>
<p>A：有框架重用的，比如AKKA，性能奇高，开发也很简单。只是学习曲线比较陡</p>
<blockquote>
<p>Q：能分享下如何把控提供微服务的细粒度，微服务的范围和边界怎么控制？</p>
</blockquote>
<p>A：一定要结合实际业务场景，还要看团队情况，我的经验是，微服务的粒度和内部人员管理关联。随着业务发展，粒度也需要不断调整的。边界要考虑业务抽象的合理性。</p>
<hr>
<h3 id="2015-11-25：搭建企业私有Docker-Registry实战分享"><a href="#2015-11-25：搭建企业私有Docker-Registry实战分享" class="headerlink" title="2015-11-25：搭建企业私有Docker Registry实战分享"></a>2015-11-25：搭建企业私有Docker Registry实战分享</h3><blockquote>
<p>Q：目前有没有尝到监控Register运行和使用情况的好处，或者在维护私有Register有没有遇到过什么问题？</p>
</blockquote>
<p>A：能够实时监控Registry，就能观察用户的行为，当我们在负载量很大的时候，能够有效保持Registry稳定运行。维护私有的Registry的问题，就是要跟进官方的更新，看看是否也需要同步。</p>
<blockquote>
<p>Q：Rancher实际上是基于Docker的开源PaaS，基于容器技术的开源PaaS很多，比如Deis、Flynn等，但是Rancher跟这些项目不同的地方是，它尽可能的和Docker生态圈工具兼容。请问当初为什么会选择Rancher，在你看来，Rancher最吸引你的地方是什么？</p>
</blockquote>
<p>A：Rancher的UI比较方便于上手和使用。而且Rancher的概念也更接近Docker compose，目前官方的文档也比较齐全。</p>
<blockquote>
<p>Q：Flowdock+Hubot这种方式下的监控是否必须用Sensu，是否支持采用zabbix作监控，Zabbix的远程脚本可以实现一些自动重启等等操作?</p>
</blockquote>
<p>A：Sensu不是必须的，你可以使用你熟悉的监控服务，比如Zabbix。</p>
<blockquote>
<p>Q：Flowdock+Hubot在一些安全性要求比较高的生产环境上是否可用，其发布的命令采用什么方式连接到容器\虚拟机或者主机上？要不要建立SSH免密码连接之类的操作？</p>
</blockquote>
<p>A：Hubot是拉取Flowdock的信息，所以Hubot可以部署在公司防火墙内。目前Hubot使用docker  remote API来控制虚拟机上的容器。</p>
<blockquote>
<p>Q：请教一下，Rancher可以理解为Compose的增强版吗，特别是可视化部分？</p>
</blockquote>
<p>A： Rancher自己有一套rancher-compose，提供load balance和auto scaling，可以算是Compose的增强版。可视化部分，是Rancher的一个Feature。</p>
<blockquote>
<p>Q：Rancher的lb是用的HAProxy么？</p>
</blockquote>
<p>A：是的。</p>
<blockquote>
<p>Q：有没有做过横向比较，Kubernetes和Swarm+Compose，Rancher+Compose，在这几种选择间做过比较，或者说为什么最终选择了Rancher？</p>
</blockquote>
<p>A：最初是选择Swarm+Compose，但是由于那个时候的Swarm不太稳定，有bug，集群管理工作不起来。Rancher部署方便，操作简单，所以就用了它。</p>
<blockquote>
<p>Q：Rancher的网络具体是怎么做的呢？</p>
</blockquote>
<p>A：据目前了解，是overlay模式。各主机之间采用IPsec Tunneling来实现通信，使用udp的500和4500端口。启动时在各个主机部署容器之前启动一个Network Agent管理容器网络。具体可以参看文档：docs.rancher.com</p>
<blockquote>
<p>Q：rancher master如何实现的高可用？之前看了文档搭建之后，cpu等监控图无法显示了</p>
</blockquote>
<p>A：通过rancher-compose提供load balance和auto scaling实现高可用。监控图无法显示也是我们遇到的问题，目前正在解决。</p>
<blockquote>
<p>Q：从描述看Rancher的网络类似于weave吧，给每个容器分配固定IP，对集群规模比较大的或者IP地址段受限的似乎不太够用？</p>
</blockquote>
<p>A：从我们目前的经验来看，的确有这样的限制，如果有大规模集群的需求下，需要重新评估Rancher来管理和部署。</p>
<blockquote>
<p>Q： Hubot是不是也支持非容器方式的部署，比如部署在虚拟机上？</p>
</blockquote>
<p>A：可以，可以参照<a href="https://hubot.github.com" target="_blank" rel="noopener">hubot.github.com</a>。</p>
<blockquote>
<p>Q：Hubot使用docker remote API是否采用了安全策略，另外Docker Registry采用了何种安全策略？</p>
</blockquote>
<p>A：Remote API使用了TLS验证。目前我们的private registry使用了LDAP+token作为安全认证。</p>
<blockquote>
<p>Q：在部署方面很重要的是动态伸缩和灰度发布，在这两方面你们是怎么考虑的？Rancher在这两个方面有支持吗？</p>
</blockquote>
<p>A：通过rancher-compose提供load balance和auto scaling实现动态伸缩。其他方面，还没有考虑过。</p>
<blockquote>
<p>Q：Rancher的管理数据是不是都放在了MySQL里面？MySQL需要搭建在物理机上吗？</p>
</blockquote>
<p>A：MySQL是rancher server自己提供的，无需手工部署。</p>
<blockquote>
<p>Q：Rancher能支持云存储吗？</p>
</blockquote>
<p>A：最新版本的Rancher对Docker volume插件有了支持，可以通过它来实现Container的数据存储管理。</p>
<blockquote>
<p>Q：请问你们实践或了解到的基于Rancher的集群规模有多大？</p>
</blockquote>
<p>A：目前我们的使用规模比较小，还没有这方面的准确数据。</p>
<blockquote>
<p>Q：从介绍看整个系统是搭建在OpenStack上的，采用Swift作为存储，那Docker的部署是不是采用的nova-docker呢？容器是部署在物理机上还是虚机上的，如果是虚拟机采用的是哪种hypervisor，性能方面如何，有没有做过相关的压测？</p>
</blockquote>
<p>A：Docker是部署在KVM的虚拟机上，使用的企业私有云平台，目前没有做过性能测试。</p>
<blockquote>
<p>Q：Rancher 实际应用中有哪些要特别注意的问题，麻烦分享下？</p>
</blockquote>
<p>A：Rancher版本更新快，较低的版本会有很多bug。</p>
<blockquote>
<p>Q：有考虑过升级问题么？比如Registry从v1升级到v2？或者docker升级到1.9？</p>
</blockquote>
<p>A：目前我们使用的就是v2，使用rancher upgrade来升级。 升级Docker的成本较大，目前还没有相关最佳实践。</p>
<blockquote>
<p>Q： Rancher中文资料多嘛，有推荐嘛？</p>
</blockquote>
<p>A：目前我们看的都是官方英文文档，这样能看到最新的信息，中文文档没有关注。</p>
<hr>
<h3 id="2015-11-17：-接触AWS近5年，谈谈我的运维经验"><a href="#2015-11-17：-接触AWS近5年，谈谈我的运维经验" class="headerlink" title="2015-11-17： 接触AWS近5年，谈谈我的运维经验"></a>2015-11-17： 接触AWS近5年，谈谈我的运维经验</h3><blockquote>
<p>Q：请问您觉得AWS和国内的云厂商相比，最大的优势是什么？</p>
</blockquote>
<p>A：从全球的角度来看，根据Gartner Report，是最领先的云服务。对于功能而言，AWS的服务多，质量上乘。对于业务需求在海外的，AWS更为重要。有些国内的云服务，基本上都是模仿着AWS起来的。</p>
<blockquote>
<p>Q： 防DDoS架构都需要自己搭建，AWS没有提供外层包装好的服务么？</p>
</blockquote>
<p>A：AWS内置的服务中已经提供了防范DDoS的能力，大多数情况下都够用，只是针对应用层的攻击，需要额外的服务。另外有很多安全厂商和AWS有合作，在AWS Market可以得到相应的安全服务。</p>
<blockquote>
<p>Q：你们用过ECS服务吗，功能上能否满足你们的应用需求？</p>
</blockquote>
<p>A：我们目前正在尝试采用ECS的方式来部署我们的服务，10月份的reInvent大会发布了Private  Registry还有ecs-cli等一些工具，会使ECS更易使用。</p>
<blockquote>
<p>Q：前端放不同az还好说，后端数据库不同az怎么搞？</p>
</blockquote>
<p>A：数据库如果是自己在EC2上部署的话，比如我们使用的Cassandra，多台同样可以采用不同AZ，至于AWS本身的数据库服务RDS、Aurora、DynamoDB，里面有一个multi-AZ的功能。</p>
<blockquote>
<p>Q：另外目前很多公司都采用了云服务，很多运维同学比较关注的一个问题是会对运维成员带来了一定的影响，因为很多工作使用云服务就可以解决。一种观点是，上云，是运维人员的一个机会，因为使用云服务在某个方面来说，对运维人员的要求又提高了。目前熟悉AWS的运维人员并不好招。请问，您是怎么想的？</p>
</blockquote>
<p>A：这个问题，我自己也深有体会，Docker会这么火，里面也有这一层关系。</p>
<blockquote>
<p>Q：自动伸缩服务对于用户这边需要做哪些准备，如何保证代码持续更新，自动伸缩也是可用的，就是我怎样信任自动扩容出的机器？</p>
</blockquote>
<p>A：主要还得要求机器中的服务实现无状态，信任是建立在测试和监控的基础上。代码持续更新是另一个问题，持续发布的问题，这个现有的解决方案也蛮多的，可以线下讨论。</p>
<blockquote>
<p>Q：亚马逊云的故障率大概有多少，企业级应用的价格是否可以接受？</p>
</blockquote>
<p>A：目前根据我们使用的服务来看，故障率不高，稳定性和质量都蛮高的，剩下的都是一些小问题，2012年的时候曾有5个大问题（AWS专门解释原因的）。对于价格可能要具体问题具体看，对于我们而言，也做企业级应用，7个地区的部署，还是能接受的。</p>
<blockquote>
<p>Q：请问有没有部署将企业自己数据中心和AWS上服务互联，推荐方式是？</p>
</blockquote>
<p>A：公司里其他部门是有的，通过VPN的方式更安全。</p>
<blockquote>
<p>Q：请问ECS是否只有提供CD、CO、CI部分是否只能是用户自己定制和对接，还有预计ECS什么时候会在中国站点发布呢？</p>
</blockquote>
<p>A：AWS本身有提供code deploy、code pipeline、code commit持续发布的服务，可以和ECS一起使用，新发布的Private  Registry也会对ECS的CI/CD带来帮助。中国站点的情况，不了解。</p>
<blockquote>
<p>Q：请问老师是否知道目前亚马逊在国内数据中心部署进展怎样？</p>
</blockquote>
<p>A：我们没有使用，所以具体的细节不太了解。似乎是有限开放，之前去reInvent开会，有一个中国专场，很多国内的公司都在使用了。</p>
<blockquote>
<p>Q：你们有考虑过灰度发布吗，AWS上对此是否有相应支持？</p>
</blockquote>
<p>A：有在使用，粒度现在还比较粗一点。一方面需要依靠应用程序本身，可以做到配置管理。AWS的支持，还是需要通过架构设计来做到，比如Router53支持带权值的DNS，另外还有今年发布的API Gateway也可以拿来帮忙。</p>
<blockquote>
<p>Q：目前AWS的一个趋势是推广基于事件的服务，就是逐步弱化服务器的概念，根据事件进行相关服务，这也是领先其它云厂商的一个方面，请问针对这一点，您是怎么想的？</p>
</blockquote>
<p>A：本来我也想聊聊lambda这个服务，考虑到时间的问题，没有讨论到。这确实是一个蛮好的想法。我了解的信息是，欧洲、北美有蛮多的公司采用了这种无服务器的方式，基本上不用自己来管理EC2机器，做好监控就可以。好处就是快，坏处就是和AWS耦合太紧。</p>
<hr>
<h3 id="2015-11-11：-一篇文章带你了解Cloud-Native"><a href="#2015-11-11：-一篇文章带你了解Cloud-Native" class="headerlink" title="2015-11-11： 一篇文章带你了解Cloud Native"></a>2015-11-11： 一篇文章带你了解Cloud Native</h3><blockquote>
<p>Q：如何达到分享老师这种技术深度、广度、理念？</p>
</blockquote>
<p>A：过奖了，谢谢。有几点可以和大家分享一下：1.  技术都是慢慢积累过来的，你做的久了，自然知道的就多些，做技术贵在坚持。2.  多和一些大牛学习和交流很重要，最直接的就是多向你的直接领导请教；3.  多学习，每天坚持学习；4.  平台很重要，有个很好的发展平台可以让你多学习很多内容。</p>
<blockquote>
<p>Q：唯品会属于康威定律中哪类公司，对促进Cloud Native都作了哪些组织结构上的调整？</p>
</blockquote>
<p>A：为了推行Cloud Native，我们成立专门的云计算部门。但是为了推行云，我们需要和周边各个部门打交道。推行IaaS还好说，因为这块基本上是标准化的东东，但是在推行CI、CD时碰到很多问题。CI、CD是和业务密切相关的，规范的推行，必然会给大家带来额外的工作量。针对这些问题，我们是联合多个部门一起搞，项目制运作。</p>
<blockquote>
<p>Q：在实际使用过程中，12因子是定性的还是定量的，如何检测？</p>
</blockquote>
<p>A：应该是定性和定量结合更为合适。比如代码统一放入Git库，这个是定性。但是代码提交次数，代码圈复杂度大小，CI成功率等就是定量的。</p>
<blockquote>
<p>Q：针对移动端的自动化测试，你们是怎么做的？你们的服务发现是如何做的？</p>
</blockquote>
<p>A：移动端的自动化测试，这块了解有限，暂时无法答复你。服务发现，我们有两种模式：DNS传统模式，另外一个就是基于自研OSP开放平台的服务注册、服务发现模式。</p>
<blockquote>
<p>Q：灰度发布采用的什么策略，是AB两个集群轮流替换的方式吗？</p>
</blockquote>
<p>A：目前是按批次分批发布的，比如50个节点，先升级1个，再升级20，最后升级29个。</p>
<blockquote>
<p>Q：自动化测试是怎么做的，尤其是Web应用的自动化测试，采用的什么工具？</p>
</blockquote>
<p>A：我知道的有Test link。</p>
<blockquote>
<p>Q：这些云上的数据库是如何部署的，处理的数据规模有多大，事务吞吐量多少，扩容这块如何实践的？</p>
</blockquote>
<p>A：DB有专门的部署工具，对于规模和事务吞吐量、扩容问题，这个比较敏感，可以线下专门交流。</p>
<blockquote>
<p>Q：请问，唯品会目前云上用的是什么数据库？</p>
</blockquote>
<p>A：MySQL、MongoDB。</p>
<blockquote>
<p>Q：请教一下，后台数据库是如何分离的，比如，是不是先从用户微服务中拿用户列表，在用用户ID去商品微服务中去拿这个用户的商品列表？</p>
</blockquote>
<p>A：后台DB链接信息一般可以作为环境变量注入App中。</p>
<blockquote>
<p>Q：在基础设施上您同时使用了虚拟机和Docker，请问这两种基础设施承载业务也不同吗？</p>
</blockquote>
<p>A：虚拟机目前是开发测试环境用。Docker后续会直接用在生产环境，主要是无状态App甚至缓存。其实VM大部分场景都可以使用Docker代替。</p>
<blockquote>
<p>Q：在服务注册和发现的图里Consumers应该不会直接连接Producer吧，一般会通过企业治理esg连接？</p>
</blockquote>
<p>A：Producer和Consumer之间一般还有个LB。</p>
<blockquote>
<p>Q：能把预发布环境理解为集成测试环境吗？</p>
</blockquote>
<p>A：预发布是上线前的一个环节，链接的DB都是线上真实环境的。集成测试环境，还在预发布环节的前面。</p>
<blockquote>
<p>Q：作为环境变量到终端DB安全性如何保证，难道是每个用户一个DB？</p>
</blockquote>
<p>A：一般是后台service链接DB的吧，用户是无法接触DB的。</p>
<blockquote>
<p>Q：那个动态更新配置的服务是需要启动一个守护进程去更新吗？</p>
</blockquote>
<p>A：一般来说，client都会安装一个配置agent，它来负责从配置server pull配置进行更新。</p>
<blockquote>
<p>Q：怎么理解版本控制的分布式配置中心，主要是配置的哪些信息？</p>
</blockquote>
<p>A：比如Nginx配置（端口、vhost等）、tomcat配置、DB链接信息、缓存链接信息等等。</p>
<blockquote>
<p>Q：12因子是否过于严格，嘉宾的表格里关于应用无状态也只是部分满足？</p>
</blockquote>
<p>A：12因子主要针对App的，它不适用于service层面，比如对于db，mc的服务是不适合的。</p>
<blockquote>
<p>Q：Gateway实现是使用开源框架（kong、loopback）还是自己实现？</p>
</blockquote>
<p>A：既可以自己实现（比如Java、Nginx），也可以采用开源的，比如Zuul。</p>
<blockquote>
<p>Q：必要时进行协议转换（比如Http转为AMQP）？</p>
</blockquote>
<p>A：比如外部是通过http rest请求的，拿到这个请求后，把参数封装，然后以mq的方式发给后台其他服务。</p>
<blockquote>
<p>Q：微服务一定是无状态的吗？</p>
</blockquote>
<p>A：这个不一定的。</p>
<blockquote>
<p>Q：能介绍OpenStack 在项目中怎么和Docker等结合使用的吗？</p>
</blockquote>
<p>A：目前我们的CI采用Docker，Docker直接跑在VM（VM由OpenStack创建）上。对于OpenStack底层和Docker如何结合，目前还在方案评估中。</p>
<hr>
<h3 id="2015-11-08：细节-｜谈谈CoreOS的etcd"><a href="#2015-11-08：细节-｜谈谈CoreOS的etcd" class="headerlink" title="2015-11-08：细节 ｜谈谈CoreOS的etcd"></a>2015-11-08：细节 ｜谈谈CoreOS的etcd</h3><blockquote>
<p>Q：请问下etcd目前的并发连接是多少，支持多少目录？</p>
</blockquote>
<p>A：这个要看你自身的服务器情况。目前每个watch都会占用一个tcp资源和一个go routine资源，大概要消耗30-40kb。etcd 3做了很多优化。支持目录和key是类似的，目前可以做到100k左右的小key。</p>
<blockquote>
<p>Q：etcd未来的版本会像ZooKeeper一样支持临时节点吗？</p>
</blockquote>
<p>A：目前etcd支持ttl key，etcd 3会支持lease，lease可以lease到多key，lease到期会把所有key自动删除。相当于group一些ttl keys。ZooKeeper的临时节点从我看来是一个broken的功能。</p>
<blockquote>
<p>Q：etcd在其他OS像CentOS上性能会有折扣吗？</p>
</blockquote>
<p>A：etcd对CoreOS本身没有任何依赖，所以不会。</p>
<blockquote>
<p>Q：etcd 2和ZooKeeper相比优势在哪些方面？</p>
</blockquote>
<p>A：和ZooKeeper的设计理念和方向不太一样。目前etcd着重于go stack和cloud  infra领域。很多上层系统例如Kubernetes、CloudFoundry、Mesos等都对稳定性、扩展性有更高的要求。由于理念的不同，导致了很多设计的不同。比如etcd会支持稳定的watch而不是简单的one  time trigger watch，因为很多调度系统是需要得到完整历史记录的。etcd支持mvcc，因为可能有协同系统需要无锁操作等等。在性能上今后etcd可能也要做更多工作，因为container infra有更多的大规模场景。</p>
<blockquote>
<p>Q：etcd能放到Docker里么，有没有这方面案例？</p>
</blockquote>
<p>A：<a href="https://github.com/coreos/etcd/blob/master/Documentation/docker_guide.md" target="_blank" rel="noopener">coreos/etcd.md</a>。</p>
<blockquote>
<p>Q：etcd与Consul比，有什么特色和差异？</p>
</blockquote>
<p>A：Consul是个full stack的工具。etcd只是一个简单的一致性kv。我们认为能把一致性kv这件事情完整的做好已经不容易了。 我们希望上层的系统可以在etcd上搭建，而不是让etcd本身服务最终用户。另外在某些程度上而言，Consul并不着重保证自身的稳定性和可靠性。HashiCorp自己的调度系统nomad也并没有采用Consul。这些差别导致了很多设计、实现上的不同。</p>
<blockquote>
<p>Q：请问Kubernetes中使用etcd主要用来做什么？</p>
</blockquote>
<p>A：存储重要的集群信息和做相关组建之间的协调。</p>
<blockquote>
<p>Q：etcd在n台（n大于等于3）机器组成的集群下，性能如何，性能会随机器数下降么？</p>
</blockquote>
<p>A：写性能会的。etcd 3做了相关优化，分配了一些写load，etcd 2下降一些。</p>
<blockquote>
<p>Q：外Masters实效后，要多久才能选出新的Masters恢复写？</p>
</blockquote>
<p>A：可以根据服务环境自行设置。默认的timeout是1秒，2秒内可以选出。如果网络经常不稳定，或者服务器忙，可以提高到5秒，10秒内选出。</p>
<hr>
<h3 id="2015-11-06：Docker-1-9新特性解读"><a href="#2015-11-06：Docker-1-9新特性解读" class="headerlink" title="2015-11-06：Docker 1.9新特性解读"></a>2015-11-06：Docker 1.9新特性解读</h3><blockquote>
<p>Q：请问ovs和vxlan在吞吐和延迟方面有性能损失吗，有无测试指标？</p>
</blockquote>
<p>A：损失肯定是有的，但是具体的指标，Docker方面没有给出测试结果。</p>
<blockquote>
<p>Q：本地化创建images咋样了，ovs是本地化吗，物理网卡需要多少带宽？</p>
</blockquote>
<p>A：这个本次更新没有提到。ovs的配置会本地化，具体物理网卡多大Docker官方没有给出说明。</p>
<blockquote>
<p>Q：1.9之后容器的网络栈是在容器启动之前就配置好了还是启动之后，之前版本的Docker，网络初始化是在容器启动前还是启动后？</p>
</blockquote>
<p>A：网络栈启动之前就会配置，启动时候进行加载。之前的Docker也是这样。</p>
<blockquote>
<p>Q：dockerdaemon为跨主机网络增加了哪些配置项，跨主机网络的信息存放在哪里？</p>
</blockquote>
<p>A：这个问题太具体了，需要仔细看看代码才知道，我只是大概看了一下，毕竟网络这部分更新太多了。</p>
<blockquote>
<p>Q：请问从1.9开始Docker就支持ovs了么，ovs还是需要自行安装吧？</p>
</blockquote>
<p>A：1.9开始使用ovs实现networking部分，底层还是调用的ovs。ovs需要自己安装。</p>
<blockquote>
<p>Q：也就是说从1.9以后ovs就是直接通过隧道使用，而不是通过route来实现，对么？</p>
</blockquote>
<p>A：可以这样理解。</p>
<blockquote>
<p>Q：请问volume特性现在有类似kubernetes persist volume的功能吗，对接第三方存储？</p>
</blockquote>
<p>A：现在的volume还是对接本地文件夹的，拥有了子命令，更多的是方便使用和管理。</p>
<blockquote>
<p>Q：1.9版本特性，是不是更容易建立固定IP类虚拟机的容器？</p>
</blockquote>
<p>A：是的。</p>
<blockquote>
<p>Q：跨主机的容器网络是由Docker daemon来维护的吗？</p>
</blockquote>
<p>A：是通过daemon维护的。</p>
<blockquote>
<p>Q：Docker1.9的CRIU方案相对前几个版本有哪些改进，新版本使用热迁移有哪些坑？</p>
</blockquote>
<p>A：Docker还是不能热迁移，runC才可以。</p>
<blockquote>
<p>Q：跨主机网络功能是全部在docker engine实现的么，还是需要依赖安装好的ovs相关环境？</p>
</blockquote>
<p>A：底层还是调用ovs。</p>
<blockquote>
<p>Q：如果容器重启或重新生成对已经构建的虚拟网络有影响吗？</p>
</blockquote>
<p>A：没有影响。</p>
<blockquote>
<p>Q：D能不能给个1.9网络新特性的实际使用的例子？</p>
</blockquote>
<p>A：我上面给的那个执行流大概就和实际使用的例子类似，就是创建Network，然后创建ep，创建沙盒，将ep装入沙盒中。实际使用的例子可以参考Docker官方文档。</p>
<blockquote>
<p>Q：多个容器共享一个存储如何解决同时写的问题？</p>
</blockquote>
<p>A：其实本质上Docker的数据卷就是一个bindmount，其工作原理和Linux主机上的共享卷原理一致。</p>
<hr>
<h3 id="2015-11-04：-蘑菇街基于Docker的私有云实践"><a href="#2015-11-04：-蘑菇街基于Docker的私有云实践" class="headerlink" title="2015-11-04： 蘑菇街基于Docker的私有云实践"></a>2015-11-04： 蘑菇街基于Docker的私有云实践</h3><blockquote>
<p>Q：请问容器间的负载均衡是如何做的？</p>
</blockquote>
<p>A：容器间的负载均衡，更多是PaaS和SaaS层面的。我们的P层支持4层和7层的动态路由，通过域名的方式，或者名字服务来暴露出对外的接口。我们能够做到基于容器的灰度升级，和弹性伸缩。</p>
<blockquote>
<p>Q：请问你们的OpenStack是运行在CentOS 6.5上的吗？</p>
</blockquote>
<p>A：是的，但是我们针对OpenStack和Docker依赖的包进行了升级。我们维护了内部的yum源。</p>
<blockquote>
<p>Q：请问容器IP是静态编排还是动态获取的？</p>
</blockquote>
<p>A：这个跟运维所管理的网络模式有关，我们内部的网络没有DHCP服务，因此对于IaaS层，容器的IP是静态分配的。对于PaaS层来说，如果有DHCP服务，容器的App所暴露出来IP和端口就可以做到动态的。</p>
<blockquote>
<p>Q：请问你们当时部署的时候有没有尝试过用Ubuntu，有没有研究过两个系统间的区别，另外请问你们在OpenStack上是怎样对这些虚拟机监控的？</p>
</blockquote>
<p>A：当然，容器的数据是需要从cgroups里来取，这部分提取数据的工作，是我们来实现的。</p>
<blockquote>
<p>Q：容器间的网络选型有什么建议，据说采用虚拟网卡比物理网卡有不小的性能损失，Docker自带的weaves和ovs能胜任吗？</p>
</blockquote>
<p>A：容器的网络不建议用默认的NAT方式，因为NAT会造成一定的性能损失。之前我的分享中提到过，不需要启动iptables，Docker的性能接近物理机的95%。Docker的weaves底层应该还是采用了网桥或者OpenvSwitch。建议可以看一下nova-docker的源码，这样会比较容易理解。</p>
<blockquote>
<p>Q：静态IP通过LXC实现的吗？</p>
</blockquote>
<p>A：静态IP的实现是在nova-docker的novadocker/virt/docker/vifs.py中实现的。实现的原理就是通过ip命令添加veth  pair，然后用ip link set/ip netns exec等一系列命令来实现的，设置的原理和weaves类似。</p>
<blockquote>
<p>Q：容器内的进程gdb你们怎么弄的，把gdb打包到容器内吗？</p>
</blockquote>
<p>A： 容器内的gdb不会有问题的，可以直接 <code>yum install gdb</code>。</p>
<blockquote>
<p>Q：共享存储能直接mount到容器里吗？</p>
</blockquote>
<p>A： 虽然没试过，但这个通过docker -v的方式应该没什么问题。</p>
<blockquote>
<p>Q：不启动Docker Daemon的情况下，离线恢复Docker中的数据是咋做到的？</p>
</blockquote>
<p>A： 离线恢复的原理是用dmsetup create命令创建一个临时的dm设备，映射到Docker实例所用的dm设备号，通过mount这个临时设备，就可以恢复出原来的数据。</p>
<blockquote>
<p>Q：Docker的跨物理机冷迁移，支持动态的CPU扩容／缩容，网络IO磁盘IO的限速，是怎么实现的，能具体说说吗？</p>
</blockquote>
<p>A：Docker的冷迁移是通过修改nova-docker，来实现OpenStack迁移的接口，具体来说，就是在两台物理机间通过docker commit，docker push到内部的registry，然后docker pull snapshot来完成的。动态的CPU扩容／缩容，网络IO磁盘IO的限速主要是通过novadocker来修改cgroups中的cpuset、iops、bps还有TC的参数来实现的。</p>
<blockquote>
<p>Q：请问你们未来会不会考虑使用Magnum项目，还是会选择Swarm？</p>
</blockquote>
<p>A：这些都是我们备选的方案，可能会考虑Swarm。因为Magnum底层还是调用了Kubernetes这样的集群管理方案，与其用Magnum，不如直接选择Swarm或者是Kubernetes。当然，这只是我个人的看法。</p>
<blockquote>
<p>Q：你们的业务是基于同一个镜像么，如果是不同的镜像，那么计算节点如何保证容器能够快速启动？</p>
</blockquote>
<p>A：运维会维护一套统一的基础镜像。其他业务的镜像会基于这个镜像来制作。我们在初始化计算节点的时候就会通过docker pull把基础镜像拉到本地，这也是很多公司通用的做法，据我了解，腾讯、360都是类似的做法。</p>
<blockquote>
<p>Q：做热迁移，有没有考虑继续使用传统共享存储的来做？</p>
</blockquote>
<p>A：分布式存储和共享存储都在考虑范围内，我们下一步，就计划做容器的热迁移。</p>
<blockquote>
<p>Q：请问你们是直接将公网IP绑定到容器吗，还是通过其他方式映射到容器的私有IP，如果是映射如何解决原本二层的VLAN隔离？</p>
</blockquote>
<p>A：因为我们是私有云，不涉及floating ip的问题，所以你可以认为是公网IP。VLAN的二层隔离完全可以在交换机上作。我们用Open vSwitch划分不同的VLAN，就实现了Docker容器和物理机的网络隔离。</p>
<blockquote>
<p>Q：Device mapper dm-thin discard问题能说的详细些吗？</p>
</blockquote>
<p>A：4月份的时候，有两台宿主机经常无故重启。首先想到的是查看/var/log/messages日志，但是在重启时间点附近没有找到与重启相关的信息。而后在/var/crash目录下，找到了内核crash的日志vmcore-dmesg.txt。日志的生成时间与宿主机重启时间一致，可以说明宿主机是发生了kernel crash然后导致的自动重启。”kernel BUG at drivers/md/persistent-data/dm-btree-remove.c:181!”。从堆栈可以看出在做dm-thin的discard操作（processprepared discard），虽然不知道引起bug的根本原因，但是直接原因是discard操作引发的，可以关闭discard support来规避。在今年CNUTCon的大会上，腾讯和大众点评在分享他们使用Docker的时候也提到了这个crash，他们的解决方法和我们完全一样。</p>
<blockquote>
<p>Q：阈值监控和告警那块，有高中低多种级别的告警吗，如果当前出现低级告警，是否会采取一些限制用户接入或者砍掉当前用户正在使用的业务，还是任由事态发展？</p>
</blockquote>
<p>A：告警这块，运维有专门的PE负责线上业务的稳定性。当出现告警时，业务方和PE会同时收到告警信息。如果是影响单个虚拟机的，PE会告知业务方，如果严重的，甚至可以及时下掉业务。我们会和PE合作，让业务方及时将业务迁移走。</p>
<blockquote>
<p>Q：你们自研的container tools有没有开源，GitHub上有没有你们的代码，如何还没开源，后期有望开源吗，关于监控容器的细粒度，你们是如何考虑的？</p>
</blockquote>
<p>A：虽然我们目前还没有开源，单我觉得开源出来的是完全没问题的，请大家等我们的好消息。关于监控容器的细粒度，主要想法是在宿主机层面来监控容器的健康状态，而容器内部的监控，是由业务方来做的。</p>
<blockquote>
<p>Q：请问容器的layer有关心过层数么，底层的文件系统是ext4么，有优化策略么？</p>
</blockquote>
<p>A：当然有关心，我们通过合并镜像层次来优化docker pull镜像的时间。在docker pull时，每一层校验的耗时很长，通过减小层数，不仅大小变小，docker pull时间也大幅缩短。</p>
<blockquote>
<p>Q：容器的memcg无法回收slab cache，也不对dirty cache量进行限制，更容易发生OOM问题。这个缓存问题你们是怎么处理的？</p>
</blockquote>
<p>A：我们根据实际的经验值，把一部分的cache当做used内存来计算，尽量逼近真实的使用值。另外针对容器，内存报警阈值适当调低。同时添加容器OOM的告警。如果升级到CentOS 7，还可以配置kmem.limit_in_bytes来做一定的限制。</p>
<blockquote>
<p>Q：能详细介绍下你们容器网络的隔离？</p>
</blockquote>
<p>A：访问隔离，目前二层隔离我们主要用VLAN，后面也会考虑VXLAN做隔离。网络流控，我们是就是使用OVS自带的基于port的QoS，底层用的还是TC，后面还会考虑基于flow的流控。</p>
<blockquote>
<p>Q：请问你们这一套都是用的CentOS6.5吗，这样技术的实现。是运维还是开发参与的多？</p>
</blockquote>
<p>A：生产环境上稳定性是第一位的。CentOS6.5主要是运维负责全公司的统一维护。我们会给运维在大版本升级时提建议。同时做好虚拟化本身的稳定性工作。</p>
<blockquote>
<p>Q：请问容器和容器直接是怎么通信的?网络怎么设置？</p>
</blockquote>
<p>A：你是指同一台物理机上的吗？我们目前还是通过IP方式来进行通信。具体的网络可以采用网桥模式，或者VLAN模式。我们用Open vSwitch支持VLAN模式，可以做到容器间的隔离或者通信。</p>
<blockquote>
<p>Q：你们是使用nova-api的方式集成Dcoker吗，Docker的高级特性是否可以使用，如docker-api，另外为什么不使用Heat集成Docker？</p>
</blockquote>
<p>A：我们是用nova-docker这个开源软件实现的，nova-docker是StackForge上一个开源项目，它做为nova的一个插件，替换了已有的libvirt，通过调用Docker的RESTful接口来控制容器的启停等动作。使用Heat还是NOVA来集成Docker业界确实一直存在争议的，我们更多的是考虑我们自身想解决的问题。Heat本身依赖的关系较为复杂，其实业界用的也并不多，否则社区就不会推出Magnum了。</p>
<blockquote>
<p>Q：目前你们有没有容器跨DC的实践或类似的方向？</p>
</blockquote>
<p>A：我们已经在多个机房部署了多套集群，每个机房有一套独立的集群，在此之上，我们开发了自己的管理平台，能够实现对多集群的统一管理。同时，我们搭建了Docker Registry V1，内部准备升级到Docker Registry V2，能够实现Docker镜像的跨DC mirror功能。</p>
<blockquote>
<p>Q：我现在也在推进Docker的持续集成与集群管理，但发现容器多了管理也是个问题，比如容器的弹性管理与资源监控，Kubernetes、Mesos哪个比较好一些，如果用在业务上，那对外的域名解析如何做呢，因为都是通过宿主机来通信，而它只有一个对外IP？</p>
</blockquote>
<p>A：对于Kubernetes和Mesos我们还在预研阶段，我们目前的P层调度是自研的，我们是通过etcd来维护实例的状态，端口等信息。对于7层的可以通过Nginx来解析，对于4层，需要依赖于naming服务。我们内部有自研的naming服务，因此我们可以解决这些问题。对外虽然只有一个IP，但是暴露的端口是不同的。</p>
<blockquote>
<p>Q：你们有考虑使用Hyper Hypernetes吗？实现容器与宿主机内核隔离同时保证启动速度?</p>
</blockquote>
<p>A：Hyper我们一直在关注，Hyper是个很不错的想法，未来也不排除会使用Hyper。其实我们最希望Hyper实现的是热迁移，这是目前Docker还做不到的。</p>
<blockquote>
<p>Q：你们宿主机一般用的什么配置？独立主机还是云服务器？</p>
</blockquote>
<p>A：我们有自己的机房，用的是独立的服务器，物理机。</p>
<blockquote>
<p>Q：容器跨host通信使用哪一种解决方案？</p>
</blockquote>
<p>A：容器跨host就必须使用3层来通信，也就是IP，容器可以有独立的IP，或者宿主机IP＋端口映射的方式来实现。我们目前用的比较多的还是独立ip的方式，易于管理。</p>
<blockquote>
<p>Q：感觉贵公司对Docker的使用比较像虚拟机，为什么不直接考虑从容器的角度来使用，是历史原因么？</p>
</blockquote>
<p>A：我们首先考虑的是用户的接受程度和改造的成本。从用户的角度来说，他并不关心业务是跑在容器里，还是虚拟机里，他更关心的是应用的部署效率，对应用本身的稳定性和性能的影响。从容器的角度，一些业务方已有的应用可能需要比较大的改造。比如日志系统，全链路监控等等。当然，最主要的是对已有运维系统的冲击会比较大。容器的管理对运维来说是个挑战，运维的接受是需要一个过程的。当然，把Docker当成容器来封装应用，来实现PaaS的部署和动态调度，这是我们的目标，事实上我们也在往这个方向努力。这个也需要业务方把应用进行拆分，实现微服务化，这个需要一个过程。</p>
<blockquote>
<p>Q：其实我们也想用容器当虚拟机使用。你们用虚拟机跑什么中间件？我们想解决测试关键对大量相对独立环境WebLogic的矛盾？</p>
</blockquote>
<p>A：我们跑的业务有很多，从前台的主站Web，到后端的中间件服务。我们的中间件服务是另外团队自研的产品，实现前后台业务逻辑的分离。</p>
<blockquote>
<p>Q：贵公司用OpenStack同时管理Docker和KVM是否有自己开发Web配置界面，还是单纯用API管理？</p>
</blockquote>
<p>A：我们有自研的Web管理平台，我们希望通过一个平台管理多个集群，并且对接运维、日志、监控等系统，对外暴露统一的API接口。</p>
<blockquote>
<p>Q：上面分享的一个案例中，关于2.6内核namespace的bug，这个低版本的内核可以安装Docker环境吗，Docker目前对procfs的隔离还不完善，你们开发的container tools是基于应用层的还是需要修改内核？</p>
</blockquote>
<p>A：安装和使用应该没问题，但如果上生产环境，是需要全面的考虑的，主要还是稳定性和隔离性不够，低版本的内核更容易造成系统crash或者各种严重的问题，有些其实不是bug，而是功能不完善，比如容器内创建网桥会导致crash，就是network namespace内核支持不完善引起的。我们开发的container tools是基于应用的，不需要修改内核。</p>
<blockquote>
<p>Q：关于冗灾方面有没有更详细的介绍，比如离线状态如何实现数据恢复的？</p>
</blockquote>
<p>A：离线状态如何实现恢复数据，这个我在之前已经回答过了，具体来说，是用dmsetup create命令创建一个临时的dm设备，映射到docker实例所用的dm设备号，通过mount这个临时设备，就可以恢复出原来的数据。其他的冗灾方案，因为内容比较多，可以再另外组织一次分享了。你可以关注一下<a href="http://mogu.io/" target="_blank" rel="noopener">mogu.io</a>，到时候我们会分享出来。</p>
<blockquote>
<p>Q：贵公司目前线上容器化的系统，无状态为主还是有状态为主，在场景选择上有什么考虑或难点？</p>
</blockquote>
<p>A：互联网公司的应用主要是以无状态的为主。有状态的业务其实从业务层面也可以改造成部分有状态，或者完全不状态的应用。不太明白你说的场景选择，但我们尽量满足业务方的各种需求。</p>
<hr>
<h3 id="2015-10-28：-OCI标准和runC原理解读"><a href="#2015-10-28：-OCI标准和runC原理解读" class="headerlink" title="2015-10-28： OCI标准和runC原理解读"></a>2015-10-28： OCI标准和runC原理解读</h3><blockquote>
<p>Q：对容器热迁移听得比较少，也比较好奇，想问问热迁移的时候容器依赖的文件系统怎么解决，是直接copy到目标机吗，可否使用公共网络文件系统解决呢，还有对目标机有什么特殊要求吗？</p>
</blockquote>
<p>A：依赖文件系统要保持一致。最好事先在目标机预置文件系统。有些容器涉及到不能迁移的设备之类的，那么这个容器则不能被迁移。目标机的OS位数要一样。</p>
<blockquote>
<p>Q：解runC，问下和Docker 对比，有那些不同，又有什么优势？</p>
</blockquote>
<p>A：runC的优势体现在轻量级和标准化，这是Docker没有的。而Docker那一套庞大的体系，也是runC没有的。</p>
<blockquote>
<p>Q：dumpfiles是可以持久化的吗，还是仅仅用于一次性的热迁移交换？</p>
</blockquote>
<p>A：保存在硬盘，可以进行多次使用。</p>
<blockquote>
<p>Q：CRIU 热迁移网络配置信息会保存么，还有就是大概热迁移延时是多少？</p>
</blockquote>
<p>A：只要设定了参数就会保存，热迁移的延时这个要看你配套设施和配套软件。</p>
<blockquote>
<p>Q：我对这个热迁移没了解过。想问下，这个热迁移主要是迁移配置rootfs么，能迁移当前的容器状态么，比如正在进行的计算？</p>
</blockquote>
<p>A：是的，这个要在对应的机器上有对应的rootfs才能迁移。状态什么的都可以迁移。</p>
<blockquote>
<p>Q：那是不是意味着我可以利用CRIU工具把容器固化下来，类似于虚拟机的快照，以便在未来的某个时刻进行恢复或者迁移？</p>
</blockquote>
<p>A：是的，就是这样。以的，容器内的状态都可以迁移。</p>
<hr>
<h3 id="2015-10-20：中兴软创（ZTEsoft）基于Jenkins和Docker的CI实践"><a href="#2015-10-20：中兴软创（ZTEsoft）基于Jenkins和Docker的CI实践" class="headerlink" title="2015-10-20：中兴软创（ZTEsoft）基于Jenkins和Docker的CI实践"></a>2015-10-20：中兴软创（ZTEsoft）基于Jenkins和Docker的CI实践</h3><blockquote>
<p>Q：你好，问一个问题，我们前段时间也把Dubbo框架运行在Docker里面，也是采用你们现在的把宿主机和端口作为环境变量传入的方式实现的，我比较想了解的是后继你们有什么更好的方式实现，我看你提到了基于OVS的方案？</p>
</blockquote>
<p>A：有两种解决办法：1.  一种是将显式传递环境变量做成隐式的自动获取宿主机和端口，从而减少配置工作；2.  另一种则是通用的Open vSwitch（OVS）方案，这是与Dubbo无关的。</p>
<blockquote>
<p>Q：容器中的Dubbo注册问题，扩展Dubbo的protocol配置，增加publishhost和publishport解决了注册问题，能不能说的详细一点？</p>
</blockquote>
<p>A：目前我们硬编码了Dubbo的protocol，在里面加了两个字段，这种扩展方式有点野蛮，但Dubbo本身提供的扩展方式目前很难支持传递环境变量方式，我们在考虑将环境变量隐式获取，这样就不用硬编码了。</p>
<blockquote>
<p>Q：你们用的还是端口映射吧，那么也会存在很多个端口的问题吧，像IP可以访问一样？</p>
</blockquote>
<p>A：在这个项目中作端口映射是运营商的要求，他们要求能通过配置来设置每个容器的端口映射，这与他们现有的运维方式有关，一开始我们考虑的是docker的自动端口映射，当然这种需求将来肯定是趋势，我们的”云应用管理平台”中也有考虑。</p>
<blockquote>
<p>Q：为何考虑Dubbo而不是etcd做服务发现，Dubbo的优势是什么？</p>
</blockquote>
<p>A：选中Dubbo是很偶然的，公司本身有ESB产品，但相对来说比较重，一般用于多个产品间的调用，而Dubbo我们一般用于产品内部多个模块之间的调用，是一种轻量级的服务总线，Dubbo这种方式不依赖于硬件和操作系统，etcd并不是所有操作系统都能支持的吧，当然我也没有对etcd作深入的研究。</p>
<blockquote>
<p>Q：Jenkins的slave是选用了虚拟机还是直接物理机？</p>
</blockquote>
<p>A：我们的Jenkins的master和slave都是用的虚拟机。</p>
<blockquote>
<p>Q：代码提交上去，如果测试有问题，回滚是肿么处理，也是通过Jenkins？</p>
</blockquote>
<p>A：这里要分情况来说，一种是测试发现问题，提单子给开发修改，开发修改完代码提交到scm，然后触发Jenkins下一轮的编译和部署；另一种情况是如果某次部署失败，则会用部署前的备份直接还原。</p>
<blockquote>
<p>Q：请问用的Registry V1还是V2 ，分布式存储用的什么，有没有加Nginx代理？</p>
</blockquote>
<p>A：目前我们用的是V1。生产环境多是集群环境，需要加Nginx作分发。目前应用中分布式存储用的并不多，一般来说用hdfs来存储一些日志便于后面分析，也有用FastDFS和MongoDB的。</p>
<blockquote>
<p>Q：底层云平台用的是私有云？</p>
</blockquote>
<p>A：底层平台一开始想用私有云，但运营商已经有了vCenter的环境，因此后来我们改用Ansible来管理各类物理机和虚机，用Docker API来管理容器。</p>
<blockquote>
<p>Q：Dubbo实现的服务发现是否具备failover功能，自动检测并迁移失败容器？</p>
</blockquote>
<p>A：Dubbo目前不具备迁移容器的功能，其failover是通过负载均衡和心跳连接来控制的，自动检测和容器迁移我们一般会考虑放在监控系统里面来做，如果放在Dubbo里面会加重Dubbo，只所以用Dubbo也是考虑到它的轻便性。</p>
<blockquote>
<p>Q：能否谈下对Jenkins+Mesos的看法，这个涉及到docker-in-docker的必要性？</p>
</blockquote>
<p>A：Mesos我们才刚刚接触，我了解的不太多，至于docker-in-docker我觉得生产上很难用，因为性能方面损失比较严重，我们做过性能测试，非<code>--net=host</code>{.prettyprint}方式的容器性能损失接近30%。</p>
<blockquote>
<p>Q：能具体介绍下利用Dockerfile打包镜像吗，jar包也是在这一步编译出来的吗，这样发布出去的镜像会既包括代码又包含jar包吧？</p>
</blockquote>
<p>A：我们的镜像中是不包含代码的，镜像里面是产品包，编译是在打镜像之前做的。</p>
<blockquote>
<p>Q：对不生产环境中不适合以容器运行的组件，Jenkins+Docker是否就没有优势了？</p>
</blockquote>
<p>A：开发和测试环境还是很有优势的，当然有些有大量IO操作的服务其实不适合放在容器里面，这主要是性能方面的考虑。</p>
<blockquote>
<p>Q：云平台是怎么管理容器的，有没有使用Docker生态系统相关的组件？</p>
</blockquote>
<p>A：目前没有用到Swarm\Compose之类的组件，将来要看这块的发展了，也有可能会引入k8s或者Mesos来作管理，这些目前都在考虑当中</p>
<blockquote>
<p>Q：在怎么判断部署Docker服务不可用，不可用后自动迁移还是如何操作？</p>
</blockquote>
<p>A：目前云应用平台只在发布时才对Docker容器进行状态检测，如果检测到失败，会根据指定的容器数目进行重新创建。后续我们会把对容器状态的持续检测统一放到监控系统中。</p>
<blockquote>
<p>Q：我是不是可以这么理解，你们的Jenkins是主要用来CI，而实际集群管理则是云应用平台做的？</p>
</blockquote>
<p>A：是的，这个是严格分工的，当时作云应用管理平台时，是以测试交付物为起始点的，这里的测试交付物就是CI的产物，容器方式下就是镜像了。</p>
<blockquote>
<p>Q：我可以理解Docker是部署在实体机，实体机上都有一个agent的东西负责与管理端通信，主要负责Docker的管理（安装，部署，监控等）吗？</p>
</blockquote>
<p>A：我们的Docker目前都是部署在虚拟机上的，操作系统是Redhat7.1，你所谓的agent其实应该就是Docker daemon吧。</p>
<ul>
<li>徐新坤：这个我补充一下，作为Jenkins的slave，会向slave里面启动一个agent来执行相关脚本命令的。这个属于Jenkins的功能，可以去体验下。</li>
</ul>
<blockquote>
<p>Q：一个应用多个容器你们怎么负载均衡？</p>
</blockquote>
<p>A：前面其实回答过，要加Nginx的。</p>
<blockquote>
<p>Q：利用Dockerfile打包镜像并上传到Registry更像是CD环节的事情，那在单元测试、集成测试环境是否有利用到Docker呢，是否使用Jenkins中Docker相关的插件了？</p>
</blockquote>
<p>A：当前项目的单元测试、集成测试都用到docker容器的。Jenkins中没有用Docker插件，试过感觉都不太成熟，目前还是Docker命令行最方便。</p>
<blockquote>
<p>Q：开始的时候有讲如果没有Docker自动部署会自动部署，这个是如何部署的？</p>
</blockquote>
<p>A：这个前面讲过，是通过lftp脚本比对编译环境与待部署的远程目录。</p>
<blockquote>
<p>Q：也就是你们在虚拟机里面部署的Docker？</p>
</blockquote>
<p>A：是的，当前的项目是在虚拟机里面部署Docker的，但我个人观点从长远看来，其实在物理机上部署Docker会更好，所以现在很多私有云比如OpenStack、CloudStack都能支持直接管理容器，不过目前虚拟机还是不能缺少的，容器的隔离性不如VM。</p>
<blockquote>
<p>Q：如果用nat模式 容器如何指定IP啊？</p>
</blockquote>
<p>A：不需要指定容器IP，只需要映射端口。</p>
<blockquote>
<p>Q：有通过Dubbo做服务路由么？</p>
</blockquote>
<p>A：Dubbo本身就有服务路由的功能。</p>
<hr>
<h3 id="2015-10-17：Docker-Registry-V1-to-V2"><a href="#2015-10-17：Docker-Registry-V1-to-V2" class="headerlink" title="2015-10-17：Docker Registry V1 to V2"></a>2015-10-17：Docker Registry V1 to V2</h3><blockquote>
<p>Q：想问下，那你们的layer数据是不是要存两份，V1、V2各一份？</p>
</blockquote>
<p>A：是要分开存两份的，因为他们的格式其实都是不一样的一个是tar包一个是gzip包，但内容一样。</p>
<blockquote>
<p>Q：为啥tar变为gzip会耗费CPU和网络，不就是不同的压缩格式么?</p>
</blockquote>
<p>A：网络其实是节省的，但是压缩是很耗CPU的tar其实并不太消耗。</p>
<blockquote>
<p>Q：V1如果做些优化，一次获取Ancestry，然后并行下载layer，是不是也可以提高吞吐量么？</p>
</blockquote>
<p>A：理论上是这样的，我看1.8的代码在pull v1也一次会拿到所有的Image ID但是并没有去并行下载，估计Docker自己把这块放弃了吧。</p>
<blockquote>
<p>Q：请问，您提到的利用Registry的hook，来获取image更新的信息，指的是利用Registry的notification API？</p>
</blockquote>
<p>A：V2是这样，V1是自己在Registry那里做了个hook。</p>
<blockquote>
<p>Q：请问关于镜像删除的问题，V2的删除感觉坑很多，如何删除，还有，如果同一个镜像名称及版本但是内容并不同的镜像重复push，有没有办法检测，以及同步？</p>
</blockquote>
<p>A：我们用的AWS对象存储，存储还比较便宜，所以没太关注，GitHub上有一个v2 gc的项目可以删除无用镜像，官方叫着做停机gc，叫了好久了，目前还没实现，只能自己造轮子了；重复push和刚才提到的乱序类似，我们会保证这种情况是串行的。</p>
<blockquote>
<p>Q：V2这么不成熟，眼下上还是不上，push到V2 registry的image能不能查询？</p>
</blockquote>
<p>A：我们当初的想法是照着Docker这么任性的态度，没准1.8就不支持V1了，所以就赶紧调研用上了。查询没有直接的API，我们很多tar没有的API都是自己造轮子造出来的。</p>
<blockquote>
<p>Q：V2.1后，Registry提供一个叫catalog API，具有一定image搜索的功能，但还不够完美？</p>
</blockquote>
<p>A：catalog会遍历整个存储消耗还是蛮大的，可以通过catalog做离线，然后notify做实时更新来实现search的一个索引。</p>
<blockquote>
<p>Q：请问，灵雀云的registry backend storage是什么类型，文件系统么，理由是什么？</p>
</blockquote>
<p>A：直接AWS在中国的s3，目前官方支持的最好的，不用自己造轮子，就酱紫。</p>
<blockquote>
<p>Q：针对V2的auth方式，有没有什么好的建议，对于平台类的开发？</p>
</blockquote>
<p>A：我的建议是使用token auth的方式，虽然复杂一步到位，可以做一些复杂的权限认证。类似的项目还是：<a href="https://github.com/SUSE/Portus" target="_blank" rel="noopener">https://github.com/SUSE/Portus</a>，不过建议每次Docker版本更新都跟着测一遍。</p>
<blockquote>
<p>Q：有没有类似docker auth的项目？</p>
</blockquote>
<p>A：<a href="https://github.com/SUSE/Portus" target="_blank" rel="noopener">SUSE/Portus</a> 一个开源的 auth server，但是比较坑的是Docker Engine老变，一升级可能就不一样，我们自己的auth server也改了好几次。</p>
<blockquote>
<p>Q：由V1升级到V2，为什么非得把旧仓库上的镜像迁移到新的V2这么折腾，直接两个版本并存一段时间不行吗，新上传用新的V2的url，如果要回退旧版本旧库上镜像url也还有吧，一段时间后旧库就能退役了？</p>
</blockquote>
<p>A：因为我们有用户的push而用户很多还在用旧版本，也有用户发现新版本不合适回滚的，如果只顾一头用户一变就发现镜像没了。</p>
<blockquote>
<p>Q：alauda云push的时候443端口拒绝连接怎么办？</p>
</blockquote>
<p>A：这个应该不会吧……，可以先下再联系复现一下，我们的两个版本Registry都是走HTTPS的。</p>
<blockquote>
<p>Q：V2好像仍然没有解决Registry最大的痛：单点，你们怎么对待这个问题的？</p>
</blockquote>
<p>A：Registry一直都是可以水平扩展的，只是一个HTTP的服务器是无状态的不存在单点问题。</p>
<blockquote>
<p>Q：企业私有云场景下用多个Registry实现HA该如何选择后端存储，京东的Speedy是否合适？</p>
</blockquote>
<p>A：Registry有Swift的driver私有云可以考虑，或者根据已有的情况选择自己的存储自己写个driver也是可以的，写的难度其实不大，七牛那个一个下午就能写出来。要求不高的话还是不难的。京东的不是太了解，我觉得主要看现有的技术框架和产品选一个易上手的就行。把Registry水平扩展挂载lb后面就好了。</p>
<blockquote>
<p>Q：V1已经被官方deprecated，V2仍然缺少一些基本的管理API，请问现在私有Registry升级到V2是否还为时过早？</p>
</blockquote>
<p>A：看需求了吧，我觉得要是稳定考虑deprecated也没啥影响，V2的很多好处确实在私有云表现不出来，反而会有一些表现不如V1的地方。</p>
<blockquote>
<p>Q：用七牛海外加速之前用哪种方案的？</p>
</blockquote>
<p>A：我先答一下这个吧，这个挺有意思的，我们发现一个tcp的拥塞算法是用于卫星通信的，卫星这种高延迟高丢包的拥塞算法貌似还蛮合适国外往国内传数据。</p>
<hr>
<h3 id="2015-10-14：企业级云平台的实践和思考"><a href="#2015-10-14：企业级云平台的实践和思考" class="headerlink" title="2015-10-14：企业级云平台的实践和思考"></a>2015-10-14：企业级云平台的实践和思考</h3><blockquote>
<p>Q：你认为面向资源和面向应用架构的区别是？</p>
</blockquote>
<p>A：一个关注的资源的供给，一个关注应用的架构、实现第2个其中会有一部分资源的申请、管理问题。面向应用更关注业务，所以上层的应用往往叫做负载管理系统或任务管理系统。</p>
<blockquote>
<p>Q：大数据HDFS是在虚拟机VM里面还是真实物理机里面？</p>
</blockquote>
<p>A：建议不要使用虚拟机，除非能将IOPS搞到类似物理机的程度，或者就是用来做算法验证，要不对存储系统冲击太大。</p>
<blockquote>
<p>Q：目前作者分享的一般都是基于互联网，针对企业级其实也有类似的技术，具体有哪些，怎么实现？</p>
</blockquote>
<p>A：我介绍的第一个产品EGO就是完全面向企业的，主要给金融等领域使用，比如花旗银行，倒闭的雷曼兄弟等，现在也在电信等行业使用，互联网行业基本没有用户。</p>
<blockquote>
<p>Q：在服务化的过程中，架构如何同时兼顾老的非服务化的部件和服务化的服务？</p>
</blockquote>
<p>A：其实我们有个实践就是，有的服务或部件就让它随着时间over吧。重要的考虑云化，实在不行考虑盖个帽子封装成服务，就是经典的设计模式中的门面，adapter等的在服务层面的使用，也可以叫做服务网关之类的。</p>
<blockquote>
<p>Q：你们是如何对集群资源做到细粒度的管理的，能说说你们遇到过哪些坑吗？</p>
</blockquote>
<p>A：主要通过设计了资源组和各种资源tag来过滤资源，同时设计了一种规则语言和引擎支持select、order，支持各种数学运算和与、或非的逻辑关系来让用户定义资源的需求。最大的坑其实就是资源粒度定义有点问题，一度都出现零点几个slot的情况，其实简单点就好了，甚至随机分配都会有个很好的效果，毕竟这个宇宙也是混沌的，呵呵。当然只是个人的看法，其他人不一定同意。</p>
<blockquote>
<p>Q：你们肯定有考虑过硬件资源使用情况负载的问题，Docker容器上前段时间倒是出了监控宝，可以监控容器的各种资源使用情况，但是想问下今天您提到的”应用的资源使用情况”，你们是做的实时监控吗？这个是怎么实现的？</p>
</blockquote>
<p>A：原来EGO的调度策略一直有个基于负载的规则，LIM会准实时的收集系统的负载，包括CPU、MEM、DISK等信息然后汇总到master LIM供 EGO master使用。天云的系统构建了一套自己的监控体系、也支持zabbix采集信息，还支持名的APM公司newrelic的agent 协议，另外也开放了API，可以自己定制监控采集系统。监控宝我们也看过，类似的都有几个，不过这是应用开发团队需要自己选择的。</p>
<blockquote>
<p>Q：Auto Scaling过程中是需要停止服务吗？</p>
</blockquote>
<p>A：不需要停止服务，参考AWS和具体业务，我们设计了多个AutoScaling group，一部分用于系统基本运行需要的最少的资源，其他则为动态改变的，也就是说会保留最少的服务节点。</p>
<blockquote>
<p>Q：天云的云平台如何解决单点问题，除了热备冷备，实现了分布式吗，怎么实现的，分布式的事务怎么处理的？</p>
</blockquote>
<p>A：天云云平台一开始就是Load Balance模式设计，类似OpenStack，单点主要就是数据库。DB的问题也是采用常规的做法，当然也可以采用类似etcd、zk的方式，不过规模大不了。</p>
<blockquote>
<p>Q：我觉得云平台最吸引人是弹性调度，能否就弹性调度如何实现这个问题，分享些经验给我们？</p>
</blockquote>
<p>A：个人建议，多研究一下AWS的autoScaling服务，比如QingCloud的调度服务其实也是它的简化版。它支持定时、手动、规则驱动等触发方式，对执行的动作也有很多可配置的方式，比如发消息、自动执行动作等。</p>
<blockquote>
<p>Q：EGO中对容错机制是怎么理解的么，能否讲下？</p>
</blockquote>
<p>A：EGO的容错分了2部分，一部分是系统本身的，主要靠共享存储来保存核心数据，然后每个模块做到可以随意重启。应用主要靠其中的egosc，它会监视应用的模块，做到按照定义的规则执行重启等动作，应用本身的数据一致问题，则要应用自己处理。</p>
<blockquote>
<p>Q：能介绍下Symphony在DCOS中的作用么？</p>
</blockquote>
<p>A：Symphony整体是个SOA的任务或负责管理系统，底层需要一个资源管理系统，类似Hadoop、Habase与Yarn的关系。</p>
<blockquote>
<p>Q：EGO核心Master它是基于插件的架构，支持热插拔吗？</p>
</blockquote>
<p>A：没有采用热插拔。因为系统的每个组件都能够做到重启不丢数据，启动时会和相关模块同步数据并纠正不一致的地方，所以对系统稳定运行没有影响，类似Google的思路，做到每个点都能很容易的重启。</p>
<blockquote>
<p>Q：能否介绍一个典型的调度器实现策略?如何考虑资源和需求的？</p>
</blockquote>
<p>A：简单来说，就是将所有的资源请求先放到队列中，然后针对请求采用背包算法，或者线性规划算法来找一个次优解就行。因为要近实时的给出资源分配结果，所以没有最优解。</p>
<blockquote>
<p>Q：云平台的容灾措施是怎么样，有什么好的方案？</p>
</blockquote>
<p>A：容灾关键还是数据，关键在企业的存储设计，我也没有太多建议。</p>
<blockquote>
<p>Q：Docker网络选择是host还是nat，性能损失分别是多少？</p>
</blockquote>
<p>A：Docker网络真实只在自己环境管理自己SkyForm使用过，其他的都是实验室环境，没有真实线上环境测试，没法给出实际数据，建议去看一下新浪、雪球等公司的建议。当前只是在一些项目中实验Docker，没有大规模去推。</p>
<blockquote>
<p>Q：目前我们都提倡服务抽象、组合化，我们目的是为了向稳定、便捷的方向进取，那么，我想问是着重管理，还是着重技术功能方向呢？</p>
</blockquote>
<p>A：具体分析，建议按照建设、实用、运维、优化管理的次序来考虑。</p>
<hr>
<h3 id="2015-10-08：容器和IaaS：谁动了谁的奶酪"><a href="#2015-10-08：容器和IaaS：谁动了谁的奶酪" class="headerlink" title="2015-10-08：容器和IaaS：谁动了谁的奶酪"></a>2015-10-08：容器和IaaS：谁动了谁的奶酪</h3><blockquote>
<p>Q：容器当做虚机，CloudFoundry现在能很好的支持Docker Hub的用法吗，如何做到的？</p>
</blockquote>
<p>A：很抱歉我不是容器的专家，对各个容器编排系统了解也有限。第一个问题我无法回答，因为我没有研究过CloudFoundry对Docker Hub是如何支持的。但从技术上来说，IaaS支持Docker Hub没有技术障碍。我以大家熟悉的OpenStack举例，Glance完全被Docker Hub做成一个后端，用户无需上传image，只要输入自己的账号，就可以浏览和下载image到cinder这样的块存储服务。将来ZStack对Docker Hub的支持也是这个思路，即把Docker Hub做成我们的backup storage的一个后端插件。</p>
<blockquote>
<p>Q：『Mesos是在大规模集群生产环境中运行Docker的黄金搭档。』对这句话你的看法是？你提到的容器编排系统，是否指Mesos，还是指Docker Swarm或Kubernetes?</p>
</blockquote>
<p>A：我指的容器编排系统主要就是k8s、Mesos、Rancher这些。他们的主要方向还是奔着App-Centric去的。至于谁是Docker的黄金搭档我不知道，我感觉每家都说自己是最佳选择和黄金搭档。当然这是因为他们对我国的新广告法不太了解。</p>
<blockquote>
<p>Q：容器适配不同的IaaS：容器是对操作系统的虚拟化，对网络、计算、存储的适配是操作系统的基本功能，容器适配不同的IaaS应该自然就有的功能吧？</p>
</blockquote>
<p>A：容器适配IaaS主要是指容器的编排系统可以通过IaaS的API去获取自己需要的计算、网络、存储的资源。例如通过IaaS的API去创建虚机，拿到虚机的IP地址去部署容器；又例如使用创建私有网络等功能。好的IaaS必定是提供全API给容器编排系统使用的。这样容器编排系统可以专注往上做，做DevOps的功能，而不是把精力浪费在管理存储、网络这些它自己不删除的东西。比如说容器编排系统去编程硬件交换机配置网络，我认为就是方向走偏了，是在做IaaS的东西。</p>
<blockquote>
<p>Q：能不能详细点解释一下App-Centric是什么样的？</p>
</blockquote>
<p>A：App-Centric要解释清楚比较难，这个跟Microservices、Cloud-Native Apps一样。要用简单的几句话解释清楚是比较难的。我个人简单理解是，App-Centric的编排系统的核心是应用的的部署、管理、发布、持续集成，一切功能以应用为中心设计。如果编排系统的核心是管理计算、存储、网络的硬件资源，那这个是iaas的编排系统，就不是App-Centric的。</p>
<blockquote>
<p>Q：问一下轻量级的IaaS，除了ZStack还有哪个比较成熟？</p>
</blockquote>
<p>A：我当然想说是ZStack。我看到后面有几个关于问ZStack的问题，为了避免在这次分享上打广告，我就不详细讲了。欢迎大家访问我们的网站zstack.org/cn，我们有16篇技术文章讲我们的不同和优势。另外关于跟OpenStack和CloudStack的对比，大家百度一下ZStack、OpenStack、CloudStack就可以搜到几篇业内人士写的对比文章。</p>
<blockquote>
<p>Q：虽然有京东和360案例，但你支持把容器当虚拟机使用吗，为什么？很多人曾经很质疑这种方案，包括我也反对。</p>
</blockquote>
<p>A：这个问题很难说支持和不支持，我刚才也说了，技术人员有自己的情怀和初衷，但市场是用脚投票的。用户选择了这样的方式一定有他自己的理由，没有对错之分。运维人员有一句话叫没有绝对好的技术，只有最适合的技术。其实很容易理解为啥大家会把容器当虚机用，因为已有的存量系统都是基于虚机设计的，要为了容器的出现而重写业务系统，我认为除非有巨大的痛点，否则很少有公司会主动去这么做。当然，很多新兴互联网公司，在没有历史包袱的情况下，我非常赞同以新的方式去构建业务系统，但这也不是那么容易的。借Netflix团队的一句话说：你看到了我们现在微服务做的这么好，是因为我没告诉我们填过多少坑。</p>
<blockquote>
<p>Q：请问IaaS+APP是怎样的一个架构呢，在您最后一段分享里”因为大部分运维人员和开发人员，最熟悉的还是以虚机的方式构建应用，当容器带来了更快、密度更高，更轻量级的虚拟化技术时，大量的存量系统还是以他们最熟悉的方式，就是虚机方式来使用容器技术。这个现实，为传统IaaS带来了巨大的机会。”，可以简单介绍下”为传统IaaS带来了巨大的机会”中有哪些机会吗？</p>
</blockquote>
<p>A：这个巨大的机会就是让我们反思大而重的IaaS系统到底是不是客户所需要的，IaaS系统自身是否需要做减法做虚拟化+。因为我们看到使用容器的很多公司，他们没有SDN，没有分布式存储，一样把业务搬迁到容器上了，运行的很好。那么现在大而重IaaS系统设计，是不是路走偏了，我们是不是能够把IaaS简化，提供最方便、最可靠、最容易的方式让容器使用IaaS，而不是让容器因为IaaS的大而重拒绝IaaS而自己去做IaaS的功能。</p>
<ul>
<li>林帆：容器和虚拟机本质上只是实现虚拟化的两种方式，一开始初衷不同，之后由于用户习惯而产生一些交叉，最终而言容器的应用场景还是会趋于PaaS化的。没记错的话，在京东和360的例子里，是先经过了Docker做虚拟机这样的过渡时期吧，但最终的目标同样是真正将容器的分布式调度、编排的优势发挥出来，也就是走向类似PaaS的方向。</li>
</ul>
<blockquote>
<p>Q：我的理解是容器做虚拟机使用这个过程更多的存在于产品底子已经比较重的企业，很多互联网企业会直接从容器的PaaS模式开始，不知道你怎么看这个观点？</p>
</blockquote>
<p>A：nova-docker不热是正常的，因为这种虚机用法不是容器社区的主流。k8s、Mesos是主流。但大家要认识到开发者圈子里的热并不代表市场热，技术圈是一个最容易自high的群体。当Hype Cycle过渡到谷底时大家才能看清楚到底市场需要的是什么技术。ZStack目前没有计划推出k8s这样的编排系统功能，技术上不是问题，我们的架构是编排系统的通用设计，用同行的评价说你们去做12306都没问题。我们的主要的考虑是要专注，当一个软件号称什么都能做，什么功能都有的时候，通常意味着它什么都做不好，用户也会搞不清楚这个软件到底要解决什么问题。但我们之后一定会推出虚拟机用法的容器集成，这个对我们来说非常简单，而且也看到很多用户在这样用了，所以我们一定会去做。</p>
<blockquote>
<p>Q：怎么理解什么是轻量级的IaaS，和现在的会有哪些变化和区别？</p>
</blockquote>
<p>A：这个前面一个问题谈到了。即现在大而重的IaaS设计不一定是市场需要的。举个例子，OpenStack在新版本里面去掉了nova-network，部署传统的扁平网络也需要用neutrons，这个我认为就是重了。轻量级的IaaS就是要使用最稳定、最简单的技术去实现用户的使用场景。而不是期望用一种技术就能够解决所有场景，这样只会越做越重，越做越复杂。</p>
<blockquote>
<p>Q：问一个计算的问题，我们的程序需要用到大量的GPU资源，容器理论上应该是可以和CPU/存储一样高效率使用的吧，有什么限制吗？</p>
</blockquote>
<p>A：理论上是可以的，CPU/存储的使用效率即使用传统虚拟化也已经比较高了，但IO相对于容器来说，路径太长有性能损失。使用容器是可以很大程度上缓解这个问题，这个也是为什么我们以前HPC用一个一台物理机一个容器的方案。</p>
<blockquote>
<p>Q：你怎么看hyper.sh和clear container等超轻量级hypervisor对容器技术的影响？</p>
</blockquote>
<p>A：hyper.sh、clear container解决的主要是容器的隔离性、安全性的问题。它们没改变容器社区倡导的主流。比如hyper.sh的用法跟Docker就很类似。所以我认为他们是对容器社区的补充。当然，半个月前我也在跟Intel的虚拟化团队沟通，建议他们做轻量级的虚机，因为我们感觉到市场对这个的需求还是很强的。</p>
<blockquote>
<p>Q：ZStack跟OpenStack下的Magnum有什么相同点和区别？</p>
</blockquote>
<p>A：完全没有相同点。我们还是纯IaaS，没有为容器做特别的编排系统。</p>
<blockquote>
<p>Q：因为我是HPC出身，我想问一下，算法开发绕不过去的Intel Cluster Studio怎么办，授权怎么处理。我们在开发算法的时候需要深度依赖MKL你们是怎么处理的。另外就是GPGPU computing貌似还没正式支持，这方面容器技术怎么处理呢？</p>
</blockquote>
<p>A：我们只是提供计算资源，应用层面、业务层面是用户自己需要解决的。我不认为容器可以帮助解决这些问题。</p>
<blockquote>
<p>Q：目前ZStack有没有什么成功案例吗？</p>
</blockquote>
<p>A：有的，我们已经有客户使用开源版生产上线几个月了。</p>
<blockquote>
<p>Q：我的理解是容器做虚拟机使用这个过程更多的存在于产品底子已经比较重的企业，很多互联网企业会直接从容器的PaaS模式开始，不知道你怎么看这个观点？</p>
</blockquote>
<p>A：这个取决于企业的历史包袱多重。老牌互联网公司的业务系统也很成熟稳定了，要完全改成容器的PaaS模式，例如容器单进程，不是用SSH，我个人觉得还是有一定难度，而且企业切换的意愿也不见得强烈，但在新业务系统里面使用PaaS的容器模式是非常可能的，我也知道很多公司正在这么做。</p>
<blockquote>
<p>Q：如何摆脱网络的依赖来创建个Docker的image呢，我觉得这个是Docker用户自己的基本权利？</p>
</blockquote>
<p>A：这个基本权利我觉得还是要问GFW。国外的开发人员是非常难理解有些他们认为跟水电一样普及的基础设施在某些地方还是很困难的。</p>
<blockquote>
<p>Q：我认为PaaS和IaaS是不可分的，现在人为分开是有问题的，长久必然和二为一，楼主怎么看？在合二为一的前提下，也不存在容器和IaaS之争了。</p>
</blockquote>
<p>A：其实从用户的层面来说他们是不分的，他们只关心自己的业务。但从开发人员的角度来说还是要分的，因为这个是理清楚自己软件的界限，对软件的架构和设计都非常重要。未来的产品可以提供IaaS和PaaS打包的产品交付给客户，但开发自己还是要分清楚产品里面那些是IaaS的东西，哪些是PaaS的东西，否者很难做产品，做设计。</p>
<blockquote>
<p>Q：真正App-Centric的是SaaS，容器编排顶多算PaaS，或者说是PaaS+IaaS（PaaS、IaaS相互依存的），跟SaaS没啥关系吧？</p>
</blockquote>
<p>A：这个前面也回答了。编排系统的App-Centric我认为是指编排系统的核心功能是围绕什么服务什么设计的。围绕部署、分发、管理、运维、持续集成的应该算App-Centric的编排系统。围绕计算、存储、网络的算IaaS。</p>
<blockquote>
<p>Q：你认为以后的趋势是容器只要配合轻量级别IaaS？SDN那些网络存储都不用考虑，那重IaaS又应用在什么场景?</p>
</blockquote>
<p>A：我是指大部分用户场景使用轻量级的IaaS+容器就足够了。因为现在很多容器应用也没有使用到SDN、SDS这些技术，也已经非常流行了。SDN、SDS解决了很多传统技术的痛点，当然他们也不是银子弹，对用户的要求也是比较高的。所以我的看法是不能用新技术去硬套所有的场景。重的IaaS我认为适合公有云场景、大规模私有云场景的容器使用，需要用户有较强的IT运维团队，解决复杂环境下多租户的容器使用问题。</p>
<hr>
<h3 id="2015-10-02：暴走漫画的Docker实践"><a href="#2015-10-02：暴走漫画的Docker实践" class="headerlink" title="2015-10-02：暴走漫画的Docker实践"></a>2015-10-02：暴走漫画的Docker实践</h3><blockquote>
<p>Q：统计某个板块同时在线人数的变化趋势。</p>
</blockquote>
<p>A：用户每次访问都有日志，日志里包括访问内容以及用户标识。首先 spark stream 从日志里抽取出特定板块不同用户的访问事件，以秒为单位合并相同用户事件。</p>
<blockquote>
<p>Q：请问Docker是部署在裸机还是虚拟机，Docker的管理用的什么？部署是人工吗？</p>
</blockquote>
<p>A：Docker 是跑在国内某云主机上的，所以应该算虚机。</p>
<blockquote>
<p>Q：传统关系数据库怎么Docker化的？</p>
</blockquote>
<p>A：我们传统关系数据库并没有Docker化，一方面我们直接用的云主机提供的sql数据库服务，另一方面，也许这部分原有的方案太成熟，短期Docker完全取代可能比较困难。</p>
<blockquote>
<p>Q：每台机器上都部署Logstash，那filter部分在哪处理？为什么不用syslog来转发日志到日志服务器？</p>
</blockquote>
<p>A：filter部分是通过spark stream来做的，Logstash纯粹收集转发，kafka是一个 MQ 系统，而且实时分析从Kafka到spark stream很方便。</p>
<blockquote>
<p>Q：如何做微服务拆分的，经验是什么？</p>
</blockquote>
<p>A：这个问题我感觉有点大，我尝试回答下：先做好详细的计划，尽量保证服务的平稳过渡，必要的时候，老系统和新系统同时保留一段时间。</p>
<blockquote>
<p>Q：Docker用的时候可以挂载存储？就是想把静态的网站图文数据Docker化，这些静态文件我们存储在单独的分布式存储和阵列中，走的nfs协议和私有api的形式。</p>
</blockquote>
<p>A：这个放image里好像不是好主意，要不用一些分布式的存储方案，要不用云存储服务?</p>
<blockquote>
<p>Q：”一份copy存到hdfs里”考虑过其他的存储吗？</p>
</blockquote>
<p>A：Spark有方便的对hdfs的接口，且云服务商有现成的hdfs服务提供，所以我们就用了。</p>
<blockquote>
<p>Q：为什么选择Logstash，而不选择Flume，它们有什么差异，比如对安装端的资源开销投入产出比等？</p>
</blockquote>
<p>A：最近在研究用heka，开始用Logstash的话是因团队本身的知识偏好(Ruby团队)。</p>
<blockquote>
<p>Q：我觉得在数据服务部分讲了太多，我更想知道Docker在开发，测试或生产环境怎么使用，利用什么方式管理Docker集群，部署服务？比如那个shell+etcd来启动Docker是怎么回事，为什么不用一些Docker生态相关的开源工具，比如k8s、swarm之类？</p>
</blockquote>
<p>A：关于为什么没用k8s。我开始也说了，选择技术架构不光要考虑技术本身，还要考虑团队资源，以及现有的限制。我们用的国内的云主机，这样的前提下要在生产环境中用k8s本身就不太可能。另外技术团队人手也很欠缺。</p>
<blockquote>
<p>Q：请问Docker容器是如何进行远程部署和自动部署的？</p>
</blockquote>
<p>A：我们用了传统的部署工具(Ansible)。</p>
<blockquote>
<p>Q：Ansible如何获取Docker主机列表，所有的Docker容器？</p>
</blockquote>
<p>A：Ansible 是操作云主机的，就和以前的用法一样。</p>
<blockquote>
<p>Q：请问ping nginx获得用户点击是怎么做的，可以详细介绍下吗？</p>
</blockquote>
<p>A：将某些统计数据放在ping接口的参数里，这样定制nginx的日志可以记录下来。</p>
<blockquote>
<p>Q：反垃圾系统数据库的数据是通过什么方式进入Kafka的，ogg、sqoop吗？</p>
</blockquote>
<p>A：样本数据的话是rails程序推进mq的。</p>
<blockquote>
<p>Q：搜索引擎选Elasticsearch而不是Solr，可以讲一下这样选择都有哪些考虑吗？</p>
</blockquote>
<p>A：Elasticsearch不仅仅是个搜索引擎，更是我们用来做结果聚合的database，而且有很好的水平扩展特性。</p>
<hr>
<h3 id="2015-09-23：基于Docker和Java的持续集成实践"><a href="#2015-09-23：基于Docker和Java的持续集成实践" class="headerlink" title="2015-09-23：基于Docker和Java的持续集成实践"></a>2015-09-23：基于Docker和Java的持续集成实践</h3><blockquote>
<p>Q：CI过程中test需要连接数据库的代码时，您在写测试案例方面有哪些经验分享？</p>
</blockquote>
<p>A：单元测试不能依赖外部资源，用mock，或者用h2等内存数据库替代。集成测试的时候是从接口层直接调用测试的，测试用例对数据库无感知。</p>
<blockquote>
<p>Q：请问部署到生产环境是自动触发还是需要手动审批？SQL执行或回滚是否自动化？</p>
</blockquote>
<p>A：当前是需要手动触发。SQL更新当前没做到自动化，这块正在改进，因为部署私有环境需要。SQL不支持回滚，代码做兼容。Docker镜像回滚没有自动化。</p>
<blockquote>
<p>Q： 问一下你们的Redis内存版是用的什么？</p>
</blockquote>
<p>A：我们用的内存版的redis是 <a href="https://github.com/spullara/redis-protocol" target="_blank" rel="noopener">spullara/redis-protocol</a>中的server实现。不过这个实现部分功能没支持，比如lua脚本，我们自己做了改进。</p>
<blockquote>
<p>Q：介绍下workflow带来的好处。</p>
</blockquote>
<p>A：workflow的好处我那篇文章中有说明，如果没有workflow，所有的步骤都在同一个配置的不同step实现，如果后面的失败，要重新从头开始。workflow可以中途开始，并且每一步骤完成都会触发通知。</p>
<blockquote>
<p>Q：h2并不完全兼容MySQL脚本，你们如何处理的？</p>
</blockquote>
<p>A：我们通过一些hack的办法，会探测下数据库是什么类型的，替换掉一些不兼容的SQL，进行容错。</p>
<blockquote>
<p>Q：请问你们在构建的时候，你说有些需要半个小时左右，那么构建过程的进度监控和健康监控你们怎么做的呢，如果有build失败了怎么处理呢？</p>
</blockquote>
<p>A：CI的每一步都有进度的，并且我们的团队通讯工具可以和CI集成，如果失败会发消息到群里通知大家。</p>
<blockquote>
<p>Q：cleanup脚本做哪些？</p>
</blockquote>
<p>A：主要是清理旧的Docker镜像，以及清理自动化测试产生的垃圾数据。</p>
<blockquote>
<p>Q：请问你们文件存储怎么解决的呢，使用自己的网络文件系统还是云服务？</p>
</blockquote>
<p>A：文件系统支持多种storage配置，可以是本地目录（便于测试），也可以使云服务（比如s3）。</p>
<blockquote>
<p>Q：刚才说你们能通过一键部署，但是中间无法监控，测试环境可以这么玩，那生产环境你们是怎么做的呢？还有你们后续的改造方向是自己开发？还是采用集成第三方软件？</p>
</blockquote>
<p>A：生产环境shell当前只能是多加错误判断。这块我们在改进，比如通过ansible等工具，以及使用Kubernetes内置的rolling-update。自动化部署这块还没有好的开源工具。</p>
<blockquote>
<p>Q：你们的测试用了很多代替方案、如h2代MySQL，要保证测试效果，除了你们用的hack方法之外，是不是从写代码的时候就开始做了方便测试的设计？</p>
</blockquote>
<p>A：对。这也是我文章中分享的观点之一。测试用例的编写人员要有业务代码的修改权限，最好是同一个人。要做自动化测试，业务代码必须要给测试留各种钩子以及后门。</p>
<blockquote>
<p>Q：请问你们的集群应用编排怎么做的？</p>
</blockquote>
<p>A：上面说了，还没用到编排。一直等编排工具的成熟。正在测试k8s。</p>
<blockquote>
<p>Q：你们做这个项目选型是出于什么考虑的，介绍里有提到使用一些脚本来管理容器解决开发和测试各种问题，感觉这种管理容器方式过于简单会带来管理问题，为何不用第三方开源项目来做二次开发，如：Kubernetes；另一个问题是，下一步有没有考虑如何让你的Docker和云服务平台结合，要解决运营成本问题（Docker最大吸引力在这里），而不只是解决开发测试问题？</p>
</blockquote>
<p>A：因为我们最早用的时候k8s 1.0 还没有，变化太大，创业团队没精力跟进，脚本是粗暴简单的办法。一直在等待各种基于Docker的云解决方案呀，肯定考虑结合。</p>
<blockquote>
<p>Q：对于Docker storage分区用完问题，我想问一下，你们是使用Docker官方提供的Registry仓库吗，如何解决仓库单点问题，这机器要是故障了怎么办？</p>
</blockquote>
<p>A：Registry用的是官方的，后端存储是挂载到s3上的。没有s3,推荐使用京东田琪团队开源的<a href="https://github.com/jcloudpub/speedy" target="_blank" rel="noopener">Speedy</a>，实现了分布式存储。</p>
<blockquote>
<p>Q：除了介绍的Java相关的CI方案，对于C/C++开发语言有没有推荐的CI方案？</p>
</blockquote>
<p>A：Teamcity/Jenkins等CI工具支持任何语言的。其实任何语言的CI都差不多，单元测试，集成测试。关键还在于依赖环境的准备以及集成测试用例的管理。</p>
<blockquote>
<p>Q：我看到你们为了方便测试和调试会有独立的集合Docker环境，这种环境和上线环境其实是有差别的，这样测试的结果能够代表线上环境吗？这种问题怎么看待？</p>
</blockquote>
<p>A：所以我们有多个流程。清理数据的测试环境，以及不清理环境的沙箱环境。但这也不能避免一部分线上环境的数据导致的bug。另外就是配合灰度上线机制。当前我们的灰度是通过代码中的开关实现的，使用这种方案的也很多，比如facebook的Gatekeeper。</p>
<blockquote>
<p>Q：请问Grouk有涉及前端（Node.js方面的）并结合Docker的CI/CD经历吗，可以分享下吗？</p>
</blockquote>
<p>A：这我们也在尝试。当前js的测试主要还是基于<a href="https://github.com/ariya/phantomjs" target="_blank" rel="noopener">ariya/phantomjs</a>，纯粹的js库比较方便测试，但如果牵扯到界面，就比较复杂些了。</p>
<hr>
<h3 id="2015-09-15：Mesos在去哪儿网的应用"><a href="#2015-09-15：Mesos在去哪儿网的应用" class="headerlink" title="2015-09-15：Mesos在去哪儿网的应用"></a>2015-09-15：Mesos在去哪儿网的应用</h3><blockquote>
<p>Q：Mesos和Yarn的区别在哪里？</p>
</blockquote>
<p>A：Mesos的主要目标就是去帮助管理不同框架（或者应用栈）间的集群资源。比如说，有一个业务需要在同一个物理集群上同时运行Hadoop，Storm及Spark。这种情况下，现有的调度器是无法完成跨框架间的如此细粒度的资源共享的。Hadoop的YARN调度器是一个中央调度器，它可以允许多个框架运行在一个集群里。但是，要使用框架特定的算法或者调度策略的话就变得很难了，因为多个框架间只有一种调度算法。比如说，MPI使用的是组调度算法，而Spark用的是延迟调度。它们两个同时运行在一个集群上会导致供求关系的冲突。还有一个办法就是将集群物理拆分成多个小的集群，然后将不同的框架独立地运行在这些小集群上。再有一个方法就是为每个框架分配一组虚拟机。正如Regola和Ducom所说的，虚拟化被认为是一个性能瓶颈，尤其是在高性能计算（HPC）系统中。这正是Mesos适合的场景——它允许用户跨框架来管理集群资源。</p>
<p>Mesos是一个双层调度器。在第一层中，Mesos将一定的资源提供（以容器的形式）给对应的框架。框架在第二层接收到资源后，会运行自己的调度算法来将任务分配到Mesos所提供的这些资源上。和Hadoop</p>
<p>YARN的这种中央调度器相比，或许它在集群资源使用方面并不是那么高效。但是它带来了灵活性——比如说，多个框架实例可以运行在一个集群里。这是现有的这些调度器都无法实现的。就算是Hadoop</p>
<p>YARN也只是尽量争取在同一个集群上支持类似MPI这样的第三方框架而已。更重要的是，随着新框架的诞生，比如说Samza最近就被LinkedIn开源出来了——有了Mesos这些新框架可以试验性地部署到现有的集群上，和其它的框架和平共处。</p>
<blockquote>
<p>Q：基础架构里面，数据持久化怎么做的？使用是么架构的存储？</p>
</blockquote>
<p>A：持久化剥离在集群外部，Mesos 0.23提供了持久化的支持，但是没敢上到生产环境中。</p>
<blockquote>
<p>Q：Storm on Mesos，快可用了吗？是否跟Spark on Mesos做过比较？</p>
</blockquote>
<p>A：Storm on Mesos的代码在GitHub可以找到，说实话只是基础功能，许多资源的控制和attributes的东西都没有做，而且我们的测试发现storm on mesos的消息ack特别慢。不建议直接拿来就跑。</p>
<blockquote>
<p>Q：发布用的业务镜像是怎么制作的，平台有相关功能支持吗？还是用户手工做好上传？</p>
</blockquote>
<p>A：Jenkins build的镜像，可以用Jenkins on Mesos这个框架，安装Docker和mesos插件就可以开始用了。</p>
<blockquote>
<p>Q：做这么个平台用多大规模的团队开发的？用了多久？</p>
</blockquote>
<p>A：开始2个人，最多的时候5个人，现在保持在4个人。从5月份到现在一点一点测试，扩容慢慢堆出来的。</p>
<blockquote>
<p>Q：镜像存储单机应该是不行的，你们是怎么管理镜像的？</p>
</blockquote>
<p>A：镜像放swift里了。</p>
<blockquote>
<p>Q：Docker采用host方式，是什么考虑或者限制，效果怎么样？</p>
</blockquote>
<p>A：平台本身就是大吞吐量的，bridge模式性能测试都偏低，就选择了host模式跑了。</p>
<blockquote>
<p>Q：Mesos的调度算法是怎样的？有没有做容器的高可用？</p>
</blockquote>
<p>A：双层调度，底层offer一个资源列表给framework，framework根据CPU和内存去列表中过滤，选中合适的slave部署，framework层的调度可以随意实现。Marathon已经帮忙做了高可用。</p>
<blockquote>
<p>Q：使用效果如何？600容器部在多少台机器上，CPU和内存使用率多少？有什么提升资源使用率的策略吗？</p>
</blockquote>
<p>A：效果达到预想了，600台分部在了混合集群上，有VM和实体机，全部折算的话大概30台左右吧，目前资源还有富余，主要是预留buffer。不推荐跑虚拟机，Mesos的资源分配就是一刀切，即使没用也算的，所以虚拟机利用率会很低。</p>
<blockquote>
<p>Q：mesos在哪一层面实施了paxos投票？</p>
</blockquote>
<p>A：leader的选举，mesos其实是两套选举，即使zk挂了mesos master也可以自己选举leader。</p>
<blockquote>
<p>Q：为什么选择heka，而不是fluend，然后logstash有什么问题？</p>
</blockquote>
<p>A：fluent和heka我们都在用，都是收容器日志，heka可以从容器的ENV里读更多东西出来。换logstash主要看重了heka的监控，资源占用和处理速度。</p>
<blockquote>
<p>Q：会涉及数据卷的迁移吗，有什么好解决方案？</p>
</blockquote>
<p>A：目前平台里没有持久化的东西。这块不敢说用什么合适，我们也没开始尝试。</p>
<blockquote>
<p>Q：镜像做成代码库和运行环境具体是什么意思，为什么运行环境方式合适？</p>
</blockquote>
<p>A：镜像具体做成什么样要根据自己的应用来判断，我们用的logstash、statsd什么的，都是配置文件描述流程的，所以我们选择了运行环境的方式。</p>
<blockquote>
<p>Q：镜方式像做成代码库和运行环境具体是什么意思？</p>
</blockquote>
<p>A：代码库就是说你把你工程的代码，配置什么的都全部打成一个镜像。运行环境就是有一些bin或者Java、PHP这些工具的，启动后才下载代码，配置。</p>
<blockquote>
<p>Q：你们会不会遇到跨机房的MesOS问题啊，如果跨机房，怎么办？</p>
</blockquote>
<p>A：有跨机房的情况，我们机房间有logstash专门转发日志流量，统一管控。</p>
<blockquote>
<p>Q：比如数据库初始化的脚本，做在镜像里合适还是有其他方式比较好？</p>
</blockquote>
<p>A：db的数据文件其实挺难脱离外层的应用单独说的，因为有业务线代码引起的schema变更，最好先解决db ci的问题，然后再考虑数据何时加载，可以映射上对应schema的时候，db文件可以先从swift等共享存储直接下载到本地使用，或者用脚本重新初始化也可以，我们的快速rebuild环境正在试验。业务线还不敢这么来。</p>
<blockquote>
<p>Q：用运行环境方式，容器启动后再拉代码和配置，不符合Docker设计镜像的初衷吧，怎么做到一处打包到处运行，镜像不是完整可执行的？</p>
</blockquote>
<p>A：主要是代码库版本和镜像的tag如何映射，为了简单点可以考虑启动后下载代码，如果代码已经编译好放到了共享存储里直接下载代码包也可以。我们目前没有考虑过把代码库版本和镜像tag映射这个问题。</p>
<blockquote>
<p>Q：Mesos资源统计会出现与实际不符，你们的解决思路是什么？</p>
</blockquote>
<p>A：要看是什么资源了，Mesos的划资源的格子属于一刀切的方式，即使你没用满也会被归入已使用的资源里，如果从这个角度看，实际运行的资源和Mesos内上报的资源确实不一致，但是考虑到计算资源的周期性，突发性，还是推荐以Mesos上报的资源为准。我们自己跑在Mesos上的监控framework本身也是这么做的。</p>
<blockquote>
<p>Q：cAdvisor好像只能监控单机容器情况，那对于集群的容器监控，使用ca怎么处理呢？</p>
</blockquote>
<p>A：我们目前是cAdvisor聚合好以后发给我们的公司的监控平台，由监控平台统一处理。最新版已经merge了许多storage-driver了，statsd值得试一下。</p>
<hr>
<h3 id="2015-09-08：Docker三剑客之Swarm介绍"><a href="#2015-09-08：Docker三剑客之Swarm介绍" class="headerlink" title="2015-09-08：Docker三剑客之Swarm介绍"></a>2015-09-08：Docker三剑客之Swarm介绍</h3><blockquote>
<p>Q：Kubernetes和Swarm 相比较来看如何选择呢？</p>
</blockquote>
<p>A：一个很Open的话题，根据特点，选择适合自己的就OK。Swarm对外提供Docker API，自身轻量、学习成本、二次开发成本都比较低，自身是插件式框架。从功能上讲，Swarm是 Kubernetes的一个子集，个人感觉，Compose+Swarm=Kubernetes。</p>
<blockquote>
<p>Q：Swarm最终目标是什么，只是为了管理容器吗，有没有考虑过提升资源利用率，会把资源弹性伸缩做上来吗，最终把所有机器负载提升，防止有些低负载或空负载浪费资源？</p>
</blockquote>
<p>A：Auto-scaling能力，个人感觉后边可能通过Compose来实现，感兴趣的话，可以在Swarm社区提一个proposal。</p>
<blockquote>
<p>Q：Swarm对节点的选取是否可定制化，指的是策略选择，感觉只有这三种不够强大？</p>
</blockquote>
<p>A：可以，可以根据自己的特点实现对应API。</p>
<blockquote>
<p>Q：调用Swarm API及Swarm调Docker API 安全认证是怎么做的？</p>
</blockquote>
<p>A：安全这部分是通过SSL协议实现通信安全以及认证，支持Swarm对外（比如与Client）之间的提供通信安全，同时Swarm与Docker Engine之间的也支持通信安全。</p>
<blockquote>
<p>Q：Swarm怎么跨节点link？</p>
</blockquote>
<p>A：目前不支持跨节点，如果使用了link，创建的容器和link的容器会被调度到同一个节点上。</p>
<blockquote>
<p>Q：Swarm的调度系统也是插件形式？可以使用Mesos的资源调度吗？</p>
</blockquote>
<p>A：Swarm调度器是插件形式。Mesos采用两层调度框架，第一层，由mesos将符合框架的资源上报给框架，第二层，框架（swarm）自身的调度器将资源分配给任务。</p>
<blockquote>
<p>Q：Swarm IP是怎么管理的？Swarm 下的各个节点是动态分配IP的么？</p>
</blockquote>
<p>A：当前网络部分还是用docker-engine自身的能力，后续会和libnetwork进行集成，具体怎么管理正在讨论中。</p>
<blockquote>
<p>Q：网络部分集成除了libnetwork还有其他计划或者考虑吗？</p>
</blockquote>
<p>A：libnetwork自身也提供了plugin机制，个人理解，和其他网络项目很好集成。</p>
<hr>
<h3 id="2015-09-02：畅谈PaaS"><a href="#2015-09-02：畅谈PaaS" class="headerlink" title="2015-09-02：畅谈PaaS"></a>2015-09-02：畅谈PaaS</h3><blockquote>
<p>Q：开源势必引入安全问题。Cloud Foundry的安全保护机制？</p>
</blockquote>
<p>A：Cloud Foundry对于应用有个安全组的特性，可以控制应用容器的访问。但是实际上能力不强，容器安全这块一直是被担心的地方。</p>
<blockquote>
<p>Q：Cloud Foundry的 DEA，即应用的运行时节点，是虚拟的操作系统么？Warden对底层的操作系统有和要求？Warden如何实现的隔离性？</p>
</blockquote>
<p>A：DEA是个服务，其实还是Linux系统Warden对内核有要求，实现原理和Docker类似。</p>
<blockquote>
<p>Q：va/spring/web 应用很容易在Docker/Kubernetes环境运行，如果要迁移到CF，工作量大吗？</p>
</blockquote>
<p>A：CF V2工作量应该挺大，V3的话因为支持Docker，所以还好。</p>
<blockquote>
<p>Q：关于k8s中Flannel和Weave两者哪个更适合生产环境？</p>
</blockquote>
<p>A：这个我最近正在分析，感觉Flannel和Weave都还不成熟，推荐OVS。</p>
<blockquote>
<p>Q：Docker既然是namespace隔离的，就算不安全应该也影响不是很大吧？</p>
</blockquote>
<p>A：其实如果你清楚原理，很容易进入到容器环境中的，没办法，安全是个大问题。</p>
<blockquote>
<p>Q：k8s可以实现应用的自主迁移吗？</p>
</blockquote>
<p>A：目前没有Pod迁移的API。</p>
<blockquote>
<p>Q：CloudFoundary中监控部分有插件机制么？</p>
</blockquote>
<p>A：支持导入到各种第三方监控系统。</p>
<blockquote>
<p>Q：Pod直接通信需要开通隧道么？换句话说他们之间是如何实现通信的？</p>
</blockquote>
<p>A：容器跨主机的通信，是对Docker的增强，像Flannel、ovs等。</p>
<blockquote>
<p>Q：PaaS的三个典型代表： Cloud Foundry、Docker和Kubernetes，最近的DaoCloud、灵雀云、时速云等以Docker为核心提出了新的CaaS概念。CaaS和PaaS都使用了Docker，Kubernetes等技术，您是怎么理解PaaS和CaaS的？</p>
</blockquote>
<p>A：CaaS容器即服务，我的理解就是PaaS，只不过主打这Docker容器，所以叫CaaS。</p>
<blockquote>
<p>Q：Docker在CentOS上使用devicemapper，据说容易使系统crash，对于其他的文件系统有没有推荐，brtfs和aufs哪个更好？</p>
</blockquote>
<p>A：aufs是内核不接受的，听说是因为代码太乱。</p>
<blockquote>
<p>Q：对于管理Docker这件事情，除了Kubernetes， OpenStack（IaaS阵营），YARN（Hadoop阵营）也开始发力，怎么看待这几者间的竞争？</p>
</blockquote>
<p>A：没有任何技术是银弹，不同需求不同设计。当然大家都想占据制高点了，这就是运作了。</p>
<blockquote>
<p>Q：k8s现在具备auto scaling能力吗，比如应用响应时间变长，k8s可以自动扩容？</p>
</blockquote>
<p>A：没有。</p>
<blockquote>
<p>Q：如果将Flannel替换成ovs是不是也可以替换掉kube-proxy，如果是那会不会影响集群中SVC的使用？</p>
</blockquote>
<p>A：flannel/ovs和kube-proxy的作用是不一样的，可以看下<a href="http://dockone.io/article/545" target="_blank" rel="noopener">dockone.io/article/545</a>。</p>
<hr>
<h3 id="2015-08-26：一篇文章带你了解Flannel"><a href="#2015-08-26：一篇文章带你了解Flannel" class="headerlink" title="2015-08-26：一篇文章带你了解Flannel"></a>2015-08-26：一篇文章带你了解Flannel</h3><blockquote>
<p>Q：数据从源容器中发出后，经由所在主机的docker0虚拟网卡转发到flannel0虚拟网卡，这种P2P实际生产中是否存在丢包，或者此机制有高可用保障么？</p>
</blockquote>
<p>A：只是本机的P2P网卡，没有经过外部网络，应该还比较稳定。但我这里没有具体数据。</p>
<blockquote>
<p>Q：UDP数据封装，转发的形式也是UDP么？我们一般知道UDP发送数据是无状态的，可靠么？</p>
</blockquote>
<p>A：转发的是UDP，高并发数据流时候也许会有问题，我这里同样没有数据。</p>
<blockquote>
<p>Q：实际上，kubernates是淡化了容器ip，外围用户只需关注所调用的服务，并不关心具体的ip，这里fannel将IP分开且唯一，这样做有什么好处？有实际应用的业务场景么？</p>
</blockquote>
<p>A： IP唯一是Kubernetes能够组网的条件之一，不把网络拉通后面的事情都不好整。</p>
<blockquote>
<p>Q：Flannel通过Etcd分配了每个节点可用的IP地址段后，偷偷的修改了Docker的启动参数：那么如果增加节点，或删除节点，这些地址段（ETCD上）会动态变化么？如果不是动态变化，会造成IP地址的浪费么？</p>
</blockquote>
<blockquote>
<p>Q：sudo mk-docker-opts.sh -i 这个命令具体干什么了？非coreos上使用flannel有什么不同？</p>
</blockquote>
<p>A：生成了一个Docker启动的环境变量文件，里面给Docker增加了启动参数。</p>
<blockquote>
<p>Q：容器IP都是固定的吗？外网与物理主机能ping通，也能ping通所有Docker集群的容器IP？</p>
</blockquote>
<p>A：不是固定的，IP分配还是Docker在做，Flannel只是分配了子网。</p>
<blockquote>
<p>Q：Flannel的能否实现VPN？你们有没有研究过？</p>
</blockquote>
<p>A： 应该不能，它要求这些容器本来就在一个内网里面。</p>
<blockquote>
<p>Q：Flannl是谁开发的？全是对k8s的二次开发吗？</p>
</blockquote>
<p>A： CoreOS公司，不是k8s的二次开发，独立的开源项目，给k8s提供基础网络环境。</p>
<blockquote>
<p>Q：Flannel支持非封包的纯转发吗？这样性能就不会有损失了？</p>
</blockquote>
<p>A：非封装怎样路由呢？发出来的TCP包本身并没有在网络间路由的信息，别忘了，两个Flannel不是直连的，隔着普通的局域网络。</p>
<blockquote>
<p>Q： Flanel现在到哪个版本了，后续版本有什么侧重点？性能优化，还是功能扩展？</p>
</blockquote>
<p>A：还没到1.0，在GitHub上面有他们的发展计划，性能是很大的一部分。</p>
<blockquote>
<p>Q： 就是在CoreOS中，客户还需要安装Flannel吗？</p>
</blockquote>
<p>A：不需要，在启动的Cloudinit配置里面给Etcd写入Flannel配置，然后加上flanneld.service command: start 就可以了，启动完直接可用，文档连接我不找了，有这段配置，现成的。</p>
<blockquote>
<p>Q： 可不可以直接用命令指定每个主机的ip范围，然后做gre隧道实现节点之间的通信？这样也可以实现不同主机上的容器ip不同且可以相互通信吧？</p>
</blockquote>
<p>A：还不支持指定哪个节点用那段IP，不过貌似可以在Etcd手改。</p>
<blockquote>
<p>Q： Flannel只是负责通信服务，那是不是还要安装k8s？</p>
</blockquote>
<p>A：是的，k8s是单独的。</p>
<blockquote>
<p>Q：现在Docker的网络组件还有什么可以选择或者推荐的?</p>
</blockquote>
<p>A：Overlay网络的常用就是Flannel和Weave，其他OVS之类的另说了。</p>
<hr>
<h3 id="2015-08-19：360的容器化之路"><a href="#2015-08-19：360的容器化之路" class="headerlink" title="2015-08-19：360的容器化之路"></a>2015-08-19：360的容器化之路</h3><blockquote>
<p>Q：开发自己的调度系统大概花了多久，有遇到特别的技术难点吗？</p>
</blockquote>
<p>A：大约2个工程师一个月样子，没有太多得困难。因为调度逻辑比较简单。</p>
<blockquote>
<p>Q：您刚才说，通过绑定独立的IP就可以直接使用SSH了。</p>
</blockquote>
<p>A：通过绑定独立的IP就可以直接使用SSH了，官方关于network那篇文档有介绍实现方案。</p>
<blockquote>
<p>Q：一般Docker的服务封装是no daemon的，这时如果重启服务，容器也会退出的，如何debug？</p>
</blockquote>
<p>A：可使用supvirsod或者monit等将no daemon封装一下。</p>
<blockquote>
<p>Q：你们服务的注册发现用的是什么？</p>
</blockquote>
<p>A：我们基础架构组开发了一个，名字叫QConf，已<a href="https://github.com/Qihoo360/QConf" target="_blank" rel="noopener">经开源在GitHub上</a>。</p>
<blockquote>
<p>Q：你说Zabbix做的一个容器监控，那有没有一个基于宿主机的监控方式？因为据我所知你这样的话每个容器都要运行一个代理吧。</p>
</blockquote>
<p>A：我们就是使用宿主机里安装Zabbix代理，通过Zabbix自发现来动态获取容器列表，再基于自定义的监控脚本获得每个容器的监控数值。</p>
<blockquote>
<p>Q：你们的那些业务跑在Docker里了？</p>
</blockquote>
<p>A：目前360的很多Web2.0业务已经跑在了上面，像影视、新闻、免费WIFI等。</p>
<blockquote>
<p>Q：Docker建议无状态，那么是否意味着不建议存放数据？比如MySQL，还是说通过-v来解决？</p>
</blockquote>
<p>A：这其实是数据存储问题，你可以使用分布式存储来存储数据，只要数据和逻辑分离容器就无状态了。</p>
<blockquote>
<p>Q：Docker建议无状态，那么是否意味着不建议存放数据？比如MySQL，还是说通过-v来解决？</p>
</blockquote>
<p>A：我理解就是容器无状态就是基于镜像创建的马上就能线上使用。</p>
<blockquote>
<p>Q：线上Docker的稳定性如何？</p>
</blockquote>
<p>A：目前运行都很稳定，没有出现容器异常崩溃等情况。</p>
<blockquote>
<p>Q：Container中跑多个进程，那么PID为1的进程你们是由什么控制的，直接由对应的应用程序还是其他什么？</p>
</blockquote>
<p>A：之前用了supervisord 现在使用S6。</p>
<blockquote>
<p>Q：Registry面对大量的并发，有测试出大致的性能占比吗，整个registry是mirror还是其他架构？</p>
</blockquote>
<p>A：Registry目前我们更新到了V2，我们测试V2在高并发pull和push上性能非常好，镜像存储使用共享存储，这样Registry也可以横向扩展。</p>
<blockquote>
<p>Q：如果容器配置用户可以直接访问的IP，在宿主虚拟机中是否可以基于Open vSwitch实现，否则会太依赖虚拟机网络？</p>
</blockquote>
<p>A：这个可以的，实际上我们也测试过没问题，当时基于稳定性考虑没有使用。</p>
<blockquote>
<p>Q：奇虎的CPU配额管理是如何实现的？</p>
</blockquote>
<p>A：这个Docker 1.7已经实现了，我们和官方的实现思路是一致的。</p>
<blockquote>
<p>Q：关于容器中数据存储是怎么做的，如果是共享存储如何进行对应？</p>
</blockquote>
<p>A：可以试试GlusterFS或者Ceph。</p>
<blockquote>
<p>Q：容器绑IP，容器重启后IP要重新绑吧，IP会变吗？</p>
</blockquote>
<p>A：需要重新绑，可做成自动化脚本。</p>
<hr>
<h3 id="2015-08-12：闲谈Kubernetes-的主要特性和经验分享"><a href="#2015-08-12：闲谈Kubernetes-的主要特性和经验分享" class="headerlink" title="2015-08-12：闲谈Kubernetes 的主要特性和经验分享"></a>2015-08-12：闲谈Kubernetes 的主要特性和经验分享</h3><blockquote>
<p>Q：kubelet本身也跑在pod里吗？</p>
</blockquote>
<p>A：可以跑在容器里，也可以跑在host上，可以尝试hyperkube的集成工具。</p>
<blockquote>
<p>Q：roollback的具体机制是？</p>
</blockquote>
<p>A：感觉应该通过lablel，再一个个替换已经升级的pod，不过还没仔细研究过。</p>
<blockquote>
<p>Q：Mesos和Kubernetes到底有什么区别？感觉有很多重合的地方。</p>
</blockquote>
<p>A：Mesos和Kubernetes侧重点不同，确实有一些重合的地方；mesos更擅长资源管理，支持上层framework，k8s原生为容器设计，更关注app相关的一些问题。</p>
<blockquote>
<p>Q：”比如用HAProxy，直接导流到service的endpoints或者Pods上”，haproxy如何导流到Pod上，podIP不是不固定的吗？</p>
</blockquote>
<p>A：可以通过watch etcd或者api server的方式，监听变化来更新haproxy；kubeproxy改用haproxy，只是external loadbalancer的方式；如果要替换，需要重新开发。</p>
<blockquote>
<p>Q：有没有可以推荐的分布式Volume方案？你们使用起来性能如何？</p>
</blockquote>
<p>A：分布式volume，可以尝试rbd，性能的话就需要自己多多测试，不断调优了；有用户提到在使用moosefs做存储，对glusterfs的支持也很多。</p>
<blockquote>
<p>Q：k8s的插件规范吗？还是直接硬改？</p>
</blockquote>
<p>A：有些还是比较规范的，可以plugin方式；有些还需要后续版本的调整，否则要动源码了。</p>
<blockquote>
<p>Q： k8s 如何监听docker 的事件，比如：在意外退出前，想抛出一些额外的事件，通知lb如何做？</p>
</blockquote>
<p>A：不确定这个是监听docker的哪些事件，再pod，rc层面可以进行watch。</p>
<blockquote>
<p>Q：k8s如何设置各个pod的依赖和启动顺序？</p>
</blockquote>
<p>A：目前没看到很好的控制Pod的依赖和启动顺序的机制可以在应用层面避免这些依赖和顺序问题。</p>
<blockquote>
<p>Q：问一下k8s 集群内部容器间网络这块的解决方案有哪些，类似flannel这类方案的性能问题有什么好的解决方案？</p>
</blockquote>
<p>A：目前flannel有其他的替代方案，但flannel部署比较方便，贴近Kubernetes的整体工作模式；性能上，如果做联机内网，总会有损耗，这个需要取舍了；有用户反映，华为的测试结果说ovs比flannel好，但是自己没有实际测试过；flannel的性能可以看coreos官网的blog，上面有测试报告。</p>
<blockquote>
<p>Q：先用容器做轻量级虚拟机，容器间可以通过hsotname访问，不知如何动手？</p>
</blockquote>
<p>A：k8上的内网DNS（kube2dns + skydns） 应该可以满足需求，可以尝试一下。</p>
<blockquote>
<p>Q：有没有好的监控工具？</p>
</blockquote>
<p>A：可以参考DockOne上的另外一篇<a href="http://dockone.io/article/397" target="_blank" rel="noopener">文章</a>。</p>
<hr>
<h3 id="2015-06-17：OpenStack-Magnum社区及项目介绍"><a href="#2015-06-17：OpenStack-Magnum社区及项目介绍" class="headerlink" title="2015-06-17：OpenStack Magnum社区及项目介绍"></a>2015-06-17：OpenStack Magnum社区及项目介绍</h3><blockquote>
<p>Q：我观察到k8s里面的cloud-provider里面有了OpenStack的插件。想问下，这个cloud-provider在magnum里是否有使用？如果使用了，是如何使用的？</p>
</blockquote>
<p>A：现在Magnum在和Kubernetes社区合作，这个是Kubernetes社区贡献给Magnum社区的，但是现在还没用。</p>
<blockquote>
<p>Q：magnum现在是可以创建swarm集群，但是Swarm没有pod/service/Replication Controller的概念，这个magnum后期会有这方面的计划把这些概念引入Swarm集群么？</p>
</blockquote>
<p>A：暂时没有，现在Magnum还是分开管理k8s和Swarm对象的，magnum api端的调用就可以指定用户用的是k8s还是Swarm。</p>
<blockquote>
<p>Q：magnum可以作为独立模块使用吗？</p>
</blockquote>
<p>A：现在还不行，因为需要依赖heat和keystone。</p>
<blockquote>
<p>Q：我看你的命令截图，想问下底层架构是OpenStack吗？</p>
</blockquote>
<p>A：是的，Magnum是OpenStack生态圈的一员，主打Container Service。</p>
<blockquote>
<p>Q：架构图中左边最下面那个micro os是Docker引擎的载体？这是相当于还是要起一个实例吗？能不能去掉这个载体，由OpenStack直接提供统一的Docker引擎。</p>
</blockquote>
<p>A：因为现在micro os已经提供了，所以社区暂时么有计划通过OpenStack去提供，可能不想重复造轮子。</p>
<blockquote>
<p>Q：Magnum支持GUI的 L版什么时候出 ，会区分个人版和企业版吗，会收费吗？</p>
</blockquote>
<p>A：L版会有个draft的gui，不收费的，OpenStack社区都是免费的。</p>
<blockquote>
<p>Q：bay可以动态扩容吗？</p>
</blockquote>
<p>A：可以，通过magnum bay-update。</p>
<blockquote>
<p>Q：在magnum的网络解决上libnetwork和Neutron区别在什么地方，各自的优势是什么，现在有哪些难点需要解决？</p>
</blockquote>
<p>A：这个我还在调查 现在还没有一些结论 具体的可以关注这个<a href="https://blueprints.launchpad.net/magnum" target="_blank" rel="noopener">bp</a> spec/native-docker-network,我会定期的去append一些调查结果.希望对网络感兴趣的人参与到<a href="https://blueprints.launchpad.net/magnum/&gt;spec/native-docker-network" target="_blank" rel="noopener">native-docker-network</a> 这个bp的讨论中来。</p>
<blockquote>
<p>Q：Magnum的Blueprint写着”Add support for mesos bay type”，bay type支持mesos, k8s,swarm，这个以后真的能做到统一抽象吗？这三者之间差异化还不小。Magnum社区是怎么考虑的？</p>
</blockquote>
<p>A：这是个非常难解的问题，这个可能还得需要在开发中，和社区讨论，看能不能有一个折中的办法：能抽象的尽量抽象，不能抽象的再定制。我们可以在OpenStack ML讨论。</p>
<blockquote>
<p>Q：Magnum相对Kubernetes的优势？</p>
</blockquote>
<p>A：magnum相对与Kubernetes的优势主要有这么几个：1）多租户，不同的租户有不同bay，baymodel等等</p>
<p>2）OpenStack为Kubernetes提供底层的基础设施服务，OpenStack负责IaaS，Kubernetes负责PaaS，Magnum负责联通Kubernetes和OpenStack。</p>
<blockquote>
<p>Q：magnum没有显式创建master node，是不是创建bay的时候就创建了k8s/swarm的master节点？多个k8s/swarm luster就是创建多个bay就ok了？</p>
</blockquote>
<p>A：答案都是yes，Magnum会自动创建Master节点。</p>
<hr>
<h3 id="2015-06-03：新浪SCE-Docker最佳实践"><a href="#2015-06-03：新浪SCE-Docker最佳实践" class="headerlink" title="2015-06-03：新浪SCE Docker最佳实践"></a>2015-06-03：新浪SCE Docker最佳实践</h3><blockquote>
<p>Q：如何实现跨机部署？</p>
</blockquote>
<p>A：shipyard和swarm都可，当然还有其它方案。shipyard有不错的web UI，支持container多机部署，调度基于tag，还可以scale。swarm调度策略比较灵活，可以依据你指定的filter、weighter进行调度部署。</p>
<blockquote>
<p>Q：Compose能否实现跨机编排？</p>
</blockquote>
<p>A：不行。目前只支持单机编排。</p>
<blockquote>
<p>Q：container监控是如何实现的？</p>
</blockquote>
<p>A：cadvisor做container监控。监控这部分也是有一定工作需要去想去做的，比如说可以考虑和EK结合提来，提供一个独立的docker集群监控解决方案出来。</p>
<blockquote>
<p>Q：如何对某一容器进行扩容？</p>
</blockquote>
<p>A：目前没有比较好的解决办法，我们的建议的做法是删了再启个大的。</p>
<blockquote>
<p>Q：SCE方案中，docker container大概是跑在那一层？</p>
</blockquote>
<p>A：大概的栈是IaaS，CaaS，SCE docker container是跑在CaaS。</p>
<hr>
<h3 id="2015-05-20：AppC和Docker的对比"><a href="#2015-05-20：AppC和Docker的对比" class="headerlink" title="2015-05-20：AppC和Docker的对比"></a>2015-05-20：AppC和Docker的对比</h3><blockquote>
<p>Q：关于镜像的问题是否可以基于本地源来创建？我个人觉得本地源对于企业来说很重要。</p>
</blockquote>
<p>A：AppC的镜像创建方式不太一样，现在还不支持用编写Dockerfile这样的方式创建，而是把文件放到指定结构的目录，然后直接用actool工具打包创建。</p>
<blockquote>
<p>Q：能支持不同的发行版？</p>
</blockquote>
<p>A：AppC是跨系统的，只是一个标准。Rkt可以在任意的Linux发型版使用。</p>
<blockquote>
<p>Q：Rkt的最小镜像是？</p>
</blockquote>
<p>A：Rkt的最小镜像可以小到里面只有一个可执行程序。</p>
<blockquote>
<p>Q：”信噪比”的概念不是很明白。</p>
</blockquote>
<p>A：内容”信噪比”就是说实际用户要的文件和其他辅助文件的比例。</p>
<blockquote>
<p>Q：Rkt容器可以起多进程吗？</p>
</blockquote>
<p>A：和Docker一样的，入口命令只能一个，里面可以后台运行多个进程。</p>
<blockquote>
<p>Q：”但Docker 的这种进程运行模型，使得不论是通过进程树还是 cgroup树都无法看出创建容器的 Docker令行与容器本身有任何关系。因此许多任务管理工具如果不对 Docker进程进行特别对待，就无法正常的管理通过 Docker启动的容器里的进程。”这里提到的任务工具对Docker进程特别对待，通常需要怎么处理，才可以方便用户的任务工具对Docker启动容器里的进程进行管理？</p>
</blockquote>
<p>A：就是说在比如结束容器进程的时候，不能通过启动容器的命令所在的pid或者cgroup来跟踪容器内的进程，而要和Docker后台服务进程去取。</p>
<blockquote>
<p>Q：那Rkt的日志网络等是怎么处理的呢？</p>
</blockquote>
<p>A：这个Rkt就撒手不管，让用户自己选择其他工具，比如Kubernetes或者Mesos这些框架都可以用，AppC目的就是做纯粹关注容器本身功能（环境隔离）的容器。</p>
<blockquote>
<p>Q：Rkt运行自己的镜像和Docker的镜像有什么区别吗？</p>
</blockquote>
<p>A：镜像格式上有些区别，不过其实两者应该是很容易转换的，Docker容器到AppC容器转换的工具已经有了，反转的还没有，估计Docker现在自己是主流，也没打算做这种事情。</p>
<blockquote>
<p>Q：Rkt有提供Restful的API吗？ A：没有，因为要实现Restful</p>
</blockquote>
<p>API就必需要有一个常驻后台的进程，这样就违背了Rkt做纯粹的容器工具，并尽可能的减少对系统入侵性的设计意图了。</p>
<blockquote>
<p>Q：感觉 Rkt+CoreOS 和 Docker+Machine/Swarm/Compose 这两种组合都在做集群的事情？</p>
</blockquote>
<p>A：是的，其实是存在一定竞争关系的。只不过CoreOS觉得Docker越做越复杂，不符合他们的应用场景，就新建了一套，顺便改进一些Docker的小毛病。但CoreOS依然会对Docker解决方案继续提供长期支持。</p>
<blockquote>
<p>Q：Rkt能使用Docker的镜像吗？</p>
</blockquote>
<p>A：能，Rkt支持直接下载DockerHub或其他Docker Repo的镜像，只是下载后会自动转换成AppC格式存储到本地。</p>
<hr>
<h3 id="2015-05-12：Docker-Registry的定制和性能分析"><a href="#2015-05-12：Docker-Registry的定制和性能分析" class="headerlink" title="2015-05-12：Docker Registry的定制和性能分析"></a>2015-05-12：Docker Registry的定制和性能分析</h3><blockquote>
<p>Q：2.0的性能也没什么变化啊，优势在哪里？</p>
</blockquote>
<p>A：客户端优化有限，在超过100个节点同时pull一个镜像时，2.0服务端资源占用少。</p>
<blockquote>
<p>Q：服务端的并发瓶颈在哪里？</p>
</blockquote>
<p>A：服务端的代码还没做过更多的分析，从经验判断主要还是IO，python的内存占用比较多。</p>
<blockquote>
<p>Q：考虑过多机房image存储CDN没？</p>
</blockquote>
<p>A：这个还真没考虑过，目前我们的镜像服务是个内部PaaS平台用的，只要保证集群所在机房能快速访问就行。</p>
<blockquote>
<p>Q：那还不如每机房加缓存？</p>
</blockquote>
<p>A：是的，也可以考虑registry的mirror机制，用了mirror后可以一个点push，其他点pull。</p>
<blockquote>
<p>Q：你们的调度器是自己开发的吗？</p>
</blockquote>
<p>A：我们底层用的是Kubernetes，调度器做一定的修改，主要是为了保证多个可用域。</p>
<blockquote>
<p>Q：内部的PaaS有没有做资源限制、网络隔离？</p>
</blockquote>
<p>A：有，目前我们的Docker是跑在kvm上。</p>
<blockquote>
<p>Q：昨天网易好多服务断片了，据说是网络攻击，那这些服务有跑在Docker上吗？</p>
</blockquote>
<p>A：断片是因为BGP的核心交换机问题，我也很好奇是什么引起的，目前还没有组织和个人声称对此事负责。</p>
<blockquote>
<p>Q：有没有考虑过nova-docker？</p>
</blockquote>
<p>A：社区不是很活跃，我们没有采用这个方案，但对于中小公司来说这是最快的方案。</p>
<blockquote>
<p>Q：为啥不考虑自己实现调度器？</p>
</blockquote>
<p>A：忙不过来，我们也想做啊，这个放在后面实现。</p>
<blockquote>
<p>Q：我们准备在某公有云上跑Docker集群。</p>
</blockquote>
<p>A：先这么用呗，我觉得Docker的优势就是底层平台无关，今后换了底层迁移也没有那么困难。</p>
]]></content>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kindle Oasis 和 Kindle Paperwhite3 使用体验</title>
    <url>/archives/Kindle-Oasis2-vs-Paperwhite3.html</url>
    <content><![CDATA[<h2 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h2><ul>
<li>2019-12-01 初稿</li>
<li>未完成、更新中</li>
</ul>
<h2 id="历史原因"><a href="#历史原因" class="headerlink" title="历史原因"></a>历史原因</h2><h3 id="nook2"><a href="#nook2" class="headerlink" title="nook2"></a>nook2</h3><p>我第一个电纸书是巴诺的 nook2 ，是我高三的时候买的。那时候折腾这个电纸书可费了不少劲。</p>
<p>当时还是 nook2 能刷成 Android  2.1 ，之后还能安装 QQ ，浏览器，冷阅 coolreader 。对，当时在 nook2 上最好用的阅读器就是 coolreader 冷阅。系统默默改制后还支持全局刷新和局部刷新。总之折腾起来很爽，虽然当时还是 Android 2.1 但运行个 QQ ，浏览器什么的都不在话下。达不到流畅但能用😂。之后 nook2 送给了我姐。后来直到 2017 年才再一次买电纸书。期间都是买纸质书或者找 PDF 资源看。</p>
<p><img src="../img/001968968.jpg" alt="巴诺 nook2 "></p>
<p><img src="../img/001968966.jpg" alt="img"></p>
<p><img src="../img/001968967.jpg" alt="刷成 Android 版的系统"></p>
<h4 id="使用感受"><a href="#使用感受" class="headerlink" title="使用感受"></a>使用感受</h4><p>我觉着但是</p>
<h3 id="Kindle-入门版"><a href="#Kindle-入门版" class="headerlink" title="Kindle 入门版"></a>Kindle 入门版</h3><p>自从上大学以来一直想买个 Kindle 来看，但学生时代嘛，自己赚的钱还不够生活费，所以只好在心里种草。直到 2018 年 5 月份的时候，我在读书月的时候参加的第二次校园十佳读者活动，被评为了十佳读者之一。那一年我在我们学校的借阅量排在全校前十，进馆次数全校第二😂。所以就很轻轻松松地获奖了。奖品是新华书店的代金券 400 元。正好我市的新华书店也卖 Kindle ，想了想 400 块钱的代金券自己再加两百块钱就能买到 Kindle 了，巨爽，所以就下狠心买了 Kindle 入门版。第一次拿到 Kindle 的那一刻，心情激动死了。</p>
<p>kindle 入门的使用体验就是能用，对、仅仅是能用而已。没有背光知识和白天或者光线下看，到了夜间就成瞎子了。</p>
<h3 id="Kindle-Paperwhite3"><a href="#Kindle-Paperwhite3" class="headerlink" title="Kindle Paperwhite3"></a>Kindle Paperwhite3</h3><p>Kindle 入门版使用了大概一个多月的时间，在此期间看完了《数学女孩》三部以及《数学史》等几本书。因为姐姐要去欧洲教学一年，在那里买书不方便，所以就把 kindle 入门版给了我姐。kindle 入门版送给我姐以后我就接着和以前一样在图书馆里看纸质书。因为图书月活动我推荐给图书馆 100 多本书如今都已经买到并入馆了。所以这段时间一直在图书馆里看纸质书。没有 kindle 的那段时间里总感觉缺少点什么，到九月份开学的时候想了想要不要再买个  kindle ？用花呗分期 12 期免息买 Kindle Paperwhite3 每个月才 80 多块钱 ，感觉还可以啊。所以在九月份开学的时候又下决定买了 Kindle Paperwhite3 。</p>
<p>Kindle Paperwhite3 使用体验就是已经达到够用的水准了，看书和看漫画都不在话下😂。</p>
<h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>工作之后，开始有了微薄的收入，开始渐渐有了一些积蓄，还了一半的助学贷款，都二十好几的人了，实在没脸让家人帮我还贷款了。加上上个月”加班“多挣了点，准备买点东西提升一下自己的幸福感。对于现在的我来说，买房？首付的十之一都还没攒到，别说厕所，连块地板砖大小的面积都买不起。</p>
<p>我是小有成就，我是有点小积蓄，但是这有什么用？在一线城市，一座房子至少 100万+ 才能买的下吧。生于穷人家的孩子总是在体验同龄人都在毕业游而我却要为生活而奔波的落差感。与其这么辛苦，不如早日享受。无论我再怎么勤俭节约，努力工作赚外快，我知道我这辈子注定也买不起 100万+ 的房子。</p>
<p>贷款买房？想想以后一个月的工资要有一半来还房贷，我实在无法接受。最起码我现在虽然住在一间小破房了，但我的工资 18 倍于我的房租。我不想牺牲快乐和自由去换一套房。原本生活中的必需品，此时却变成奢侈品。反正既然也买不起房，那就不如享受，人生就是这样，在自己的承受范围内，买一些自己喜欢的东西。</p>
<p>我不是圣人君子，我也是有物欲的人，甚至我更加贪婪，占有欲更强。对于目前的我来讲现在最需要升级的设备就是 Kindle Paperwhite3 了。虽然使用 Kindle Paperwhite3 已经一年多了，但它用来看书的体验仅仅够用，还没达到我满意的程度。尤其是拿来看漫画的时候，更是捉襟见肘，所以有必要升级一下啦。Kindle Paperwhite3 没有物理翻页键，翻页起来有时回失灵。就是你想翻回上一页的时候死活翻不回去，很僵硬的问题。其次就是屏幕尺寸有点小，看漫画的时候需要仔细盯着眼看一些比较小的字体。</p>
<p>其他没啥想要的，三月份的时候给姐借了点钱买了个二手的 ThinkPad Yoga 12 笔记本，因工作需要。六月份的用第一份工资加上在在校时勤工俭学赚的 1200 块钱凑一起组装了台 AMD R5 2600 😂 台式机。暑假的时候老姐把她用了好几年的 iPhone 6s 给了我，在我手里接着续命。目前来看没啥要买的，就缺个 kindle Oasis 了。</p>
<h3 id="为什么不要买房呢"><a href="#为什么不要买房呢" class="headerlink" title="为什么不要买房呢"></a>为什么不要买房呢</h3><p>想必大多数人的回答都是两个字 <code>结婚</code> ，没有一套房子丈母娘也肯定不愿意。没钱买房子难道要贷款买房子嘛？首付我都付不起，更不要提还房贷了。假如一对夫妻每个月的工资都要有三分之一以上用来还房贷，这样的生活我是无法接受的。何况我又不想谈恋爱更不想结婚。</p>
<h3 id="为什么不要结婚呢"><a href="#为什么不要结婚呢" class="headerlink" title="为什么不要结婚呢"></a>为什么不要结婚呢</h3><p>结婚生子，拥有一个属于自己的家庭，这是每个正常人的追求，是每个正常人的生活。</p>
<p>但我不想要孩子，恕我自私了、，我并不觉着拥有一个孩子是多么幸福的事情。对于我开说养育孩子是是一件麻烦事儿，又要照顾孩子，又要给孩子上学什么的。没有拿到工作城市的户口还要借读或者去老家上学。老家那种国家级贫困县，教育水平和资源及其低劣。反正我是绝对不会让我的孩子再走一遍我所走过的路。</p>
<p>尤其是看到当今的国内的教育让我气愤的不得了。小学生都开始强制要求学习宪法，都洗脑教育唱赞歌。从小就灌输这种红色教育，我是绝对无法接受，绝对，绝对不能接受所谓的红色教、爱国教育。在我看来国内的中小学阶段的爱国教育都是扭曲的，都是用来给当权者唱赞歌的，所以我是绝对我不能让我的孩子接受这样的教育。</p>
<p>所以，我是绝对不会在国内结婚生子，绝对不会让我的孩子接受这种扭曲的教育。我不结婚所以就再也不用担心买房的问题，用剩下来的钱买一些自己喜欢的东西，让自己一个人过的开心一些。</p>
<h2 id="怎么买"><a href="#怎么买" class="headerlink" title="怎么买"></a>怎么买</h2><p>在购买之前我做足了调查，甚至有表格来分析性价比😂。当时决定要在淘宝上买个美版 Kindle Oasis2 2017。虽然 2019 年已经推出了 Kindle Oasis3 2019。我觉着升级的性价比极低，Kindle Oasis3 2019 比 Kindle Oasis2 2017 硬件上只多了几个 LED 灯而已。尺寸、内存、处理器、存储等等都几乎无差别。所以说 Kindle Oasis2 性价是不错滴。</p>
<h3 id="美亚"><a href="#美亚" class="headerlink" title="美亚"></a>美亚</h3><p>在黑五当天美亚上<a href="https://amzn.to/2R02n88" target="_blank" rel="noopener">Kindle Oasis 3</a>  的价格是174.99美元（人民幣約1230元），相当诱人滴。但美亚上没无法直邮，只能转运。而转运的话更为麻烦，费时费心费力。到手破损损坏的话处理起来更为麻烦。所以我就放弃了在美亚上购买。况且我也实在等不了十几天😂。而且自己买从美亚上买和在淘宝上买美版的区别不大的，都无法在国内享受保修。收到后出现坏点的话退换货成本极大，几乎无法退换货。淘宝上还能多加 20 块钱买个坏点险，如果出现四个以上的坏点的话免费换新，四个以内的话赔偿 40 块钱。</p>

<blockquote class="twitter-tweet"><p lang="zh" dir="ltr">穷人的世界捡个垃圾都要做个表格分析一下性价比。<br>目前当务之急是把手头的 Kindle Paperwhite3 换到 Kindle Oasis 2，因为自从拿来看漫画就觉着 Kindle Paperwhite3 不够用了😂。<br>至于手机？等过几年再说吧，手头的 6s 还能续命接着用几年滴。毕竟每天 kindle 的使用时间(4h)三倍于手机。 <a href="https://t.co/EUGhXBZC7A" target="_blank" rel="noopener">pic.twitter.com/EUGhXBZC7A</a></p>&mdash; 502 (@muzi_ii) <a href="https://twitter.com/muzi_ii/status/1199731167697756161?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">November 27, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<h3 id="为什么买二手而不买未拆封美版？"><a href="#为什么买二手而不买未拆封美版？" class="headerlink" title="为什么买二手而不买未拆封美版？"></a>为什么买二手而不买未拆封美版？</h3><p>如果买国行的话，正品价格最低是 2399 ，而且依照 kindle 千年不降价的作风，对于咱来说买国行实在是买不起。如果你想买国行的话推荐淘宝上的梅先生的 kindle 店买。我上一个 Kindle Paperwhite3 就是在那里买的。</p>
<p>其实刚开始我是想买美版 Kindle Oasis2 的，淘宝上 1500 左右就能买到，如果自己在美亚上买的话加上转运费和税费价格也少不那里去。无论是在淘宝上还是美亚上买美版的 Kindle 都有一个共同点，退换货成本极大。淘宝上未拆封的 kindle ，买来拆封后是无法退货的，即便是有问题的机器那也算你倒霉无法退货。而在美亚上买，你邮寄回美国的运费又负担不起。</p>
<h3 id="闲鱼捡垃圾"><a href="#闲鱼捡垃圾" class="headerlink" title="闲鱼捡垃圾"></a>闲鱼捡垃圾</h3><p>综上决定在闲鱼上买，在咸鱼上搜了一下同城，正好找到一个卖家 。国行 Kindle Oasis2  8 GB 带官方 199￥ 的皮套，总价格 1280￥。和卖家沟通好第二天下午面交。😂第二天很顺利地完成了 PY 交易，卖家给便宜了 30￥，最终以 1250￥ 的价格买到手了 Kindle Oasis2。</p>
<h3 id="关于容量"><a href="#关于容量" class="headerlink" title="关于容量"></a>关于容量</h3><p>建议买 8 GB，你看书的话根本不需要 32 GB。两者价格相差 200 块钱，而仅仅多了 20 GB 的容量，性价比实在太低。 kindle 适合用来看书而不是用来存书，32 GB 的书你看十年都看不完😂，即便是 8GB 的容量也很难看完。所以没必要贪多，买 8 GB 足够。省出来那两百块钱订阅两年的 Kindle Unlimited 会员都要比多出那 20GB 的存储空间性价比高的多。</p>
<h2 id="开箱"><a href="#开箱" class="headerlink" title="开箱"></a>开箱</h2><p>在公交车上拍照<del>开箱</del>😂</p>
<p><img src="../img/image-20191202171108883.png" alt="KO2 在公交车上开箱😂"></p>
<p><img src="../img/image-20191202171129184.png" alt="KO2"></p>
<p><img src="../img/image-20191202171510337.png" alt="image-20191202171510337"></p>
<p><img src="../img/image-20191202172046660.png" alt="image-20191202172046660"></p>
<p><img src="../img/image-20191202172104805.png" alt="image-20191202172104805"></p>
<p><img src="../img/image-20191202172141495.png" alt="image-20191202172141495"></p>
<p><img src="../img/image-20191202172159248.png" alt="image-20191202172159248"></p>
<p><img src="../img/image-20191202172208956.png" alt="image-20191202172208956"></p>
<p><img src="../img/image-20191202172216921.png" alt="image-20191202172216921"></p>
<p><img src="../img/image-20191202172231655.png" alt="image-20191202172231655"></p>
<h3 id="看漫画"><a href="#看漫画" class="headerlink" title="看漫画"></a>看漫画</h3><p><img src="../img/image-20191203100634998.png" alt="image-20191203100634998"></p>
<p><img src="../img/image-20191203100645837.png" alt="image-20191203100645837"></p>
<p><img src="../img/image-20191203100655418.png" alt="image-20191203100655418"></p>
<p><img src="../img/image-20191203100706964.png" alt="image-20191203100706964"></p>
<h2 id="总体感受"><a href="#总体感受" class="headerlink" title="总体感受"></a>总体感受</h2><p>Kindle Oasis2 无论在尺寸还是在速度上已经满足我了，物理翻页键取代触屏翻页也方便多了。以前使用 Kindle Paperwhite3 看书的时候经常误触，按回退不知怎么地就翻到下一页。物理键取代触摸屏幕翻页效率和准确度上那是一天地上跑的和一个天上飞的区别😂。如果 Kindle Paperwhite3 能有个物理翻页键就完美无缺了。</p>
<p>但美中不足也有一些瑕疵，其中最大的问题就是 Kindle Oasis2 的电池太不耐用了，现在基本上是三天一充，而 Kindle Paperwhite3 一周一充。😥</p>
<p>另一个问题就是由于 KO2 是金属机身，冬天躲被窝里看书的时候手汗会留在上面🙃。但瑕不掩瑜，瑕不掩瑜😂</p>
<p><img src="../img/image-20191202172126512.png" alt="image-20191202172126512"></p>
<p>事后留下了一些不明液体🙃？其实是手汗😂</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.bennythink.com/first-mbp.html" target="_blank" rel="noopener">还是早日享乐吧——年轻人的第一台 MacBook</a></p>
]]></content>
      <tags>
        <tag>阅读</tag>
        <tag>Kindle</tag>
      </tags>
  </entry>
  <entry>
    <title>博客从 typecho 迁移到 hexo</title>
    <url>/archives/blog-typecho-to-hexo.html</url>
    <content><![CDATA[<h2 id="Typecho"><a href="#Typecho" class="headerlink" title="Typecho"></a>Typecho</h2><p>年初的时候终于把博客写了起来，到现在也水了大概 50 篇博客文章。大一大二的时候也整个，当时还是使用 Wordpress ，只是玩心太重没能坚持下来写。直到毕业后找到了第一份工作，955 工作制，才有时间精心打理这个博客。</p>
<p>博客使用的是  <a href="https://github.com/zgq354/typecho-theme-next" target="_blank" rel="noopener">NexT.Mist</a> 的主题 ，不得不说 <a href="https://github.com/zgq354/typecho-theme-next" target="_blank" rel="noopener">NexT.Mist</a>  主题是我用过的 typecho 里面最好的主题，没有之一。我拿来后经过大刀阔斧地删除了很多无用的内容，并把归档设置为首页。能精简的就精简掉，没有花里胡哨的花架子。但也有一些缺点，比如：对中文排版不够好，我希望二级标题三级标题还有引用等能呈现的突兀一些，尤其是在移动端的时候，三级标题以及四级标题几乎和正文一样了；代码高亮字体太小，不美观。</p>
<p><img src="../img/image-20191121112230084.png" alt="首页很精简"></p>
<p><img src="../img/image-20191121112335945.png" alt="中文排版多级标题很差"></p>
<p><img src="../img/image-20191121112940929.png" alt="代码高亮字体太小"></p>
<h2 id="hugo"><a href="#hugo" class="headerlink" title="hugo"></a>hugo</h2><p>期间也折腾了 hugo，但 hugo 的主题没有找到像 next 一样的，很僵硬。不过我平时写文档最后还是喜欢用  hugo 来生成。或者用 Typora 导出 PDF 然后上交给领导😂。在我看来 hugo 最大的优势就是精简和极速。就单单一个 hugo 二进制可执行文件即可创建站点，不像 hexo 那样要依赖上千的包和上万个文件。hugo 的这一点比 hexo 高到不知道哪里去了😂。</p>
<h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><p>感觉 hexo 的主题无论是在数量还是质量抑或是美学上不知道比 hugo 高到不知到哪里去了😂</p>
<p>无意间在发现了  <a href="https://www.elietio.xyz/" target="_blank" rel="noopener">零の轨迹</a>  的博客，使用的也是   <a href="https://theme-next.org/" target="_blank" rel="noopener">NexT.Gemini</a>  主题，主题很符合我的期望，遂采用了   <a href="https://theme-next.org/" target="_blank" rel="noopener">NexT.Gemini</a>  主题。克隆下来博主的 <a href="https://github.com/Elietio/Elietio.github.io" target="_blank" rel="noopener">Elietio.github.io</a> repo 就撸起袖子加油干。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p> 网上类似的教程一搜一大把，写得其实很详细 。由于 hexo 是使用 nodejs 开发，所以需要装 nodejs 以及 nodejs 的包管理器 yarn，不推荐用 npm。我的环境是 Debian 10。debian 10 上已经有 nodejs 的包了，所以直接 apt 一把梭就 ok </p>
<blockquote>
<p> 官方是使用 npm 进行安装，个人推荐使用 <a href="https://yarnpkg.com/zh-Hans/" target="_blank" rel="noopener">yarn</a> 进行安装，关于 yarn 和 npm 优劣分析，可以参考这篇文章《<a href="http://web.jobbole.com/88459/" target="_blank" rel="noopener">Yarn vs npm: 你需要知道的一切</a>》 </p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加 nodejs 包管理器 yarn 的源</span></span><br><span class="line">curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"deb https://dl.yarnpkg.com/debian/ stable main"</span> | sudo tee /etc/apt/sources.list.d/yarn.list</span><br><span class="line">sudo apt update &amp;&amp; sudo apt install yarn</span><br><span class="line"><span class="comment"># 安装 hexo</span></span><br><span class="line">yarn global add hexo-cli</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/Elietio/Elietio.github.io hexo</span><br><span class="line"><span class="built_in">cd</span> hexo</span><br><span class="line">git checkout hexo</span><br><span class="line">yarn install</span><br><span class="line">hexo g</span><br></pre></td></tr></table></figure>
<h3 id="精简"><a href="#精简" class="headerlink" title="精简"></a>精简</h3><p>使用 yarn 安装完依赖后，原项目太臃肿了，还是第一次见人把 models 放进 git repo 里的😂。咱就精简一下吧，去掉那些花里胡哨的东西，四博客更加轻量和精简。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">8.0K    _config.yml</span><br><span class="line">4.0K    gulpfile.js</span><br><span class="line">34M     live2d_models</span><br><span class="line">86M     node_modules</span><br><span class="line">4.0K    package.json</span><br><span class="line">368K    package-lock.json</span><br><span class="line">4.0K    README.md</span><br><span class="line">1.0K    scaffolds</span><br><span class="line">1.4M    <span class="built_in">source</span></span><br><span class="line">7.4M    themes</span><br><span class="line">260K    yarn.lock</span><br></pre></td></tr></table></figure>
<h3 id="精简第三方插件"><a href="#精简第三方插件" class="headerlink" title="精简第三方插件"></a>精简第三方插件</h3><p>第三方插件装在了 <code>themes/next/source/lib</code> ，有很多我不需要的。所以需要一个一个精简掉。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">3.8M    algolia-instant-search   <span class="comment"># 站内搜索</span></span><br><span class="line">20K     canvas-nest              <span class="comment"># 绘画</span></span><br><span class="line">16K     canvas-ribbon            <span class="comment"># 绘画</span></span><br><span class="line">436K    font-awesome             <span class="comment"># 字体</span></span><br><span class="line">84K     jquery</span><br><span class="line">84K     needsharebutton          <span class="comment"># 分享</span></span><br><span class="line">77K     pace                     <span class="comment"># 加载图标</span></span><br><span class="line">649K    three                    <span class="comment"># 3D</span></span><br><span class="line">304K    velocity                 <span class="comment"># 异步加载库</span></span><br></pre></td></tr></table></figure>
<h4 id="精简后"><a href="#精简后" class="headerlink" title="精简后"></a>精简后</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">432K    font-awesome</span><br><span class="line">84K     jquery</span><br><span class="line">24K     jquery_lazyload</span><br></pre></td></tr></table></figure>
<p>最后我只保留了字体和  jQuery 以及装了个 <code>jquery_lazyload</code> 用来延迟加载大量的图片文件。</p>
<p>同时在 <code>layout</code> 目录里的文件也精简掉了很多，去掉了看板娘、分享、赞赏、热度、加载进度条等花里胡哨的东西。对于我来说只追求文章内容的排版，这一堆幺蛾子没啥用，都是一堆花架子。</p>
<h3 id="fuck-baidu"><a href="#fuck-baidu" class="headerlink" title="fuck baidu"></a>fuck baidu</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sitemap</span></span><br><span class="line"><span class="attr">sitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">sitemap.xml</span></span><br><span class="line"><span class="attr">baidusitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">baidusitemap.xml</span></span><br></pre></td></tr></table></figure>
<p>原项目里使用的 <code>baidusitemap.xml</code> ，对于咱这种对 baidu 恨之入骨的人来说当人是无法忍受的了，所以就关键字搜索 baidu ，干掉了所有与百度相关的代码。</p>
<p><img src="../img/image-20191121132219406.png" alt="image-20191121132219406"></p>
<h2 id="精简后-1"><a href="#精简后-1" class="headerlink" title="精简后"></a>精简后</h2><p>经过四个多小时的精简终于达到了我所满足的地步，文件数量以及静态文件也比自带的减少一倍，在 Google page test 都能达到 92 分，如果加上 CDN 的话分还能再高一些。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1.0K    bower.json</span><br><span class="line">36K     _config.yml</span><br><span class="line">0       crowdin.yml</span><br><span class="line">4.0K    gulpfile.coffee</span><br><span class="line">72K     languages</span><br><span class="line">159K    layout</span><br><span class="line">4.0K    LICENSE.md</span><br><span class="line">4.0K    package.json</span><br><span class="line">32K     README.md</span><br><span class="line">94K     scripts</span><br><span class="line">868K    <span class="built_in">source</span></span><br></pre></td></tr></table></figure>
<h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h2><p><img src="../img/image-20191121112120336.png" alt="image-20191121112120336"></p>
<p><img src="../img/image-20191121112401015.png" alt="目录和多级标题很nice"></p>
<p>  <a href="https://theme-next.org/" target="_blank" rel="noopener">NexT.Gemini</a>  主题的引用部分背景色好评，用来提醒读者我是<del>引用</del>剽窃别人的还是不错滴😂，我倒是喜欢用 <code>剽窃</code>二字替代<code>引用</code>，用来自嘲自己知识水平不足只能靠剽窃😀。</p>
<h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>后续尝试着把目前在使用的 hexo 主题 移植到 hugo 上，对于这种菜鸡运维来说还是挺难的。</p>
]]></content>
      <tags>
        <tag>typecho</tag>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>娱乐至死 | 如何远离手机 | 阅读</title>
    <url>/archives/amusing-ourselves-to-death-reading-notes.html</url>
    <content><![CDATA[<h2 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h2><ul>
<li>2019-11-20 初稿</li>
</ul>
<p>未完成，继续更新</p>
<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>十一国庆回家的时候，见到七岁大的外甥已经戴上眼镜了。最主要是因为使用手机和平板电脑等时间太长，从而导致了散光，必须要戴眼镜才行。真的，整个国庆假期因为这件事儿心里难受了好几天。回来后也一直在思考如今的电子设备究竟给我们带来了什么？</p>
<p>大概思考了很久，这篇文章谈论的内容也比较多而杂，主要还是概括开讲以下几点：</p>
<ul>
<li>《娱乐至死》读书摘抄和思考总结</li>
<li>《浅薄：互联网如何毒化了我们的大脑》</li>
<li>短视频的危害</li>
<li>手机依赖症的表现</li>
<li>如何摆脱手机依赖症</li>
<li>广告如何使人不幸福的</li>
<li>碎片化阅读专注力</li>
<li></li>
</ul>
]]></content>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>与互联网相关的基金会和组织</title>
    <url>/archives/Internet-related-foundations-and-organizations.html</url>
    <content><![CDATA[<h2 id="为什么要写这？"><a href="#为什么要写这？" class="headerlink" title="为什么要写这？"></a>为什么要写这？</h2><p>最近想写一系列的文章，来<code>考古挖掘</code>一些知名的开源软件/自由软件基金会和非营利性组织的发展、以及他们成功运作的方式。所以这篇文章大概是罗列出以后要写的文章，今天顺便统计了一些这些基金会的捐款收入和支出状况，对这些基金会有个大致的了解。</p>
<p>引用 NASA 的  purposes  致敬这些与互联网息息相关的组织   <strong>For the Benefit of All</strong></p>
<h2 id="基金会及维护的项目"><a href="#基金会及维护的项目" class="headerlink" title="基金会及维护的项目"></a>基金会及维护的项目</h2><table>
<thead>
<tr>
<th>name</th>
<th>wikipedia</th>
<th>hosts project / work / service</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.linuxfoundation.org/" target="_blank" rel="noopener">Linux 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Linux_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://kernel.org" target="_blank" rel="noopener">kernel</a>  <a href="[https://nodejs.org">NodeJs</a>  <a href="https://xenproject.org/" target="_blank" rel="noopener">Xen</a>   <a href="https://www.dpdk.org/" target="_blank" rel="noopener">DPDK</a>  <a href="[https://etcd.io">etcd</a>  <a href="[https://jenkins.io">Jenkins</a>  <a href="[https://kubernetes.io">kubernetes</a> <a href="https://ceph.com/foundation/" target="_blank" rel="noopener">Ceph</a>  <a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">CNI</a>  <a href="https://www.fluentd.org/" target="_blank" rel="noopener">Fluentd</a>  <a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a>  <a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>  <a href="https://coredns.io/" target="_blank" rel="noopener">CoreDNS</a></td>
</tr>
<tr>
<td><a href="https://www.gnu.org" target="_blank" rel="noopener">FSF 自由软件基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Free_Software_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.gnu.org/" target="_blank" rel="noopener">GNU</a> <a href="https://www.gnu.org/software/libc/" target="_blank" rel="noopener">libc</a> <a href="https://www.gnu.org/software/glib/" target="_blank" rel="noopener">glib</a> <a href="https://www.gnu.org/software/bash/" target="_blank" rel="noopener">bash</a> <a href="https://www.gnu.org/software/gzip/" target="_blank" rel="noopener">gzip</a> <a href="https://www.gnu.org/software/wget/" target="_blank" rel="noopener">wget</a>  <a href="https://www.gnu.org/software/gcc/" target="_blank" rel="noopener">gcc</a> <a href="https://www.gnu.org/software/grub/" target="_blank" rel="noopener">grub</a> <a href="https://www.gnu.org/software/sed/" target="_blank" rel="noopener">sed</a>  <a href="https://www.gnu.org/software/tar/" target="_blank" rel="noopener">tar</a>  <a href="https://www.gnu.org/software/grep/" target="_blank" rel="noopener">grep</a></td>
</tr>
<tr>
<td><a href="https://foundation.mozilla.org" target="_blank" rel="noopener">Mozilla 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Mozilla_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="[https://www.mozilla.org">Firefox</a>  <a href="[https://www.thunderbird.net">Thunderbird</a></td>
</tr>
<tr>
<td><a href="https://wikimediafoundation.org/" target="_blank" rel="noopener">维基媒体基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Wikimedia_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.mediawiki.org/wiki/MediaWiki" target="_blank" rel="noopener">MediaWiki</a></td>
</tr>
<tr>
<td><a href="https://www.openssl.org/" target="_blank" rel="noopener">OpenSSL 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/OpenSSL" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.openssl.org/source/" target="_blank" rel="noopener">OpenSSL</a></td>
</tr>
<tr>
<td><a href="https://www.spi-inc.org/" target="_blank" rel="noopener">SPI 组织</a></td>
<td><a href="https://en.wikipedia.org/wiki/Software_in_the_Public_Interest" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.debian.org/distrib/" target="_blank" rel="noopener">Debian</a>  <a href="https://ffmpeg.org/" target="_blank" rel="noopener">FFmpeg</a>  <a href="https://openwrt.org/" target="_blank" rel="noopener">OpenWrt</a>  <a href="[https://www.postgresql.org">PostgreSQL</a>  <a href="https://www.libreoffice.org/" target="_blank" rel="noopener">LibreOffice</a> <a href="[https://jenkins.io">Jenkins</a>  <a href="https://www.archlinux.org/" target="_blank" rel="noopener">Arch Linux</a> <a href="https://www.spi-inc.org/projects/mingw" target="_blank" rel="noopener">MinGW</a> <a href="https://www.spi-inc.org/projects/x.org" target="_blank" rel="noopener">X.Org</a> <a href="https://www.spi-inc.org/projects/haskell" target="_blank" rel="noopener">haskell.org</a> <a href="https://www.spi-inc.org/projects/gallery" target="_blank" rel="noopener">Gallery</a> <a href="https://www.spi-inc.org/projects/openzfs" target="_blank" rel="noopener">OpenZFS</a></td>
</tr>
<tr>
<td><a href="https://www.eff.org/" target="_blank" rel="noopener">EFF 电子前哨基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Electronic_Frontier_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.eff.org/https-everywhere" target="_blank" rel="noopener">HTTPS Everywhere</a>  <a href="https://www.eff.org/privacybadger" target="_blank" rel="noopener">Privacy Badger</a>  <a href="https://letsencrypt.org/about/" target="_blank" rel="noopener">Let’s Encrypt</a></td>
</tr>
<tr>
<td><a href="https://www.openstack.org/foundation/" target="_blank" rel="noopener">OpenStack 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/OpenStack" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.openstack.org/software/releases/stein/components/nova" target="_blank" rel="noopener">nova</a>  <a href="https://www.openstack.org/software/project-navigator/openstack-components/#openstack-services" target="_blank" rel="noopener">OpenStack </a></td>
</tr>
<tr>
<td><a href="https://www.cncf.io/" target="_blank" rel="noopener">CNCF 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/CNCF" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="http://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a></td>
</tr>
<tr>
<td><a href="https://www.cloudfoundry.org" target="_blank" rel="noopener">Cloud Foundry 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Cloud_Foundry" target="_blank" rel="noopener">wikipedia</a></td>
<td></td>
</tr>
<tr>
<td><a href="https://www.apache.org/" target="_blank" rel="noopener">Apache 软件基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/The_Apache_Software_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.apache.org/" target="_blank" rel="noopener">Apache</a>  <a href="https://hadoop.apache.org/" target="_blank" rel="noopener">Hadoop</a>  <a href="http://kafka.apache.org/" target="_blank" rel="noopener">Kafka</a>  <a href="http://zookeeper.apache.org/" target="_blank" rel="noopener">Zookeeper</a>  <a href="http://hbase.apache.org/" target="_blank" rel="noopener">HBase</a>  <a href="http://maven.apache.org/" target="_blank" rel="noopener">Maven</a></td>
</tr>
<tr>
<td><a href="https://www.python.org/psf/" target="_blank" rel="noopener">Python 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Python_Software_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="[https://www.python.org">Python</a></td>
</tr>
<tr>
<td><a href="https://www.gnome.org/foundation/" target="_blank" rel="noopener">GNOME 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/GNOME_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="[https://www.gnome.org">GNOME</a>  <a href="http://www.freedesktop.org/wiki/Software/systemd/" target="_blank" rel="noopener">systemd</a>  <a href="https://developer.gnome.org/glib/" target="_blank" rel="noopener">GLib</a>  <a href="http://www.gtk.org/" target="_blank" rel="noopener">GTK+</a>  <a href="http://www.freedesktop.org/wiki/Software/dbus/" target="_blank" rel="noopener">D-Bus</a>  <a href="https://www.kernel.org/" target="_blank" rel="noopener">Linux Kernel</a>  <a href="https://wiki.gnome.org/Projects/GDM" target="_blank" rel="noopener">GDM</a></td>
</tr>
<tr>
<td><a href="http://openwebfoundation.org/" target="_blank" rel="noopener">OWF 开放 web 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Open_Web_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td></td>
</tr>
<tr>
<td><a href="https://www.opennetworking.org/" target="_blank" rel="noopener">ONF 开放网络基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Open_Networking_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.opennetworking.org/onos/" target="_blank" rel="noopener">onos</a> <a href="https://www.opennetworking.org/omec/" target="_blank" rel="noopener">OMEC</a>  <a href></a></td>
</tr>
<tr>
<td><a href="https://www.freebsdfoundation.org/" target="_blank" rel="noopener">FreeBSD 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/FreeBSD_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.freebsd.org" target="_blank" rel="noopener">FreeBSD</a></td>
</tr>
<tr>
<td><a href="http://www.openbsdfoundation.org/" target="_blank" rel="noopener">OpenBSD 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/OpenBSD_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="http://www.openssh.com/" target="_blank" rel="noopener"> OpenSSH</a>  <a href="http://www.libressl.org/" target="_blank" rel="noopener">LibreSSL</a>  <a href="http://www.openbsd.org/" target="_blank" rel="noopener">OpenBSD</a></td>
</tr>
<tr>
<td><a href="http://golangfoundation.org/about/" target="_blank" rel="noopener">Golang 基金会</a></td>
<td><a href="https://#" target="_blank" rel="noopener">wikipedia</a></td>
<td></td>
</tr>
<tr>
<td><a href="https://opensource.org/" target="_blank" rel="noopener">OSI 开放源代码组织</a></td>
<td><a href="https://en.wikipedia.org/wiki/Open_Source_Initiative" target="_blank" rel="noopener">wikipedia</a></td>
<td></td>
</tr>
<tr>
<td><a href="https://www.linaro.org/" target="_blank" rel="noopener">Linaro 非营利性组织</a></td>
<td><a href="https://en.wikipedia.org/wiki/Linaro" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.linaro.org/downloads/" target="_blank" rel="noopener">Linaro Toolchain</a></td>
</tr>
<tr>
<td><a href="https://www.torproject.org/" target="_blank" rel="noopener">Tor 项目</a></td>
<td><a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network" target="_blank" rel="noopener">wikipedia</a>)</td>
<td><a href="https://www.torproject.org/download/" target="_blank" rel="noopener">Tor </a></td>
</tr>
<tr>
<td><a href="https://freedom.press/" target="_blank" rel="noopener">FPF 新闻自由基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Freedom_of_the_Press_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://securedrop.org/" target="_blank" rel="noopener">SecureDrop</a>  <a href="https://securethe.news/" target="_blank" rel="noopener">Secure the News</a>  <a href="https://freedom.press/news/archiving-alternative-press-threatened-wealthy-buyers/" target="_blank" rel="noopener">Archive the News</a> <a href="https://twitter.com/foiafeed" target="_blank" rel="noopener">FOIAFeed</a></td>
</tr>
<tr>
<td><a href="https://cpj.org" target="_blank" rel="noopener">OPJ 保护记者委员会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Committee_to_Protect_Journalists" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://cpj.org/safety-kit/" target="_blank" rel="noopener">Safety Kit</a>  <a href="https://cpj.org/safety-advisories/" target="_blank" rel="noopener">Safety Advisories</a></td>
</tr>
<tr>
<td><a href="https://webfoundation.org/" target="_blank" rel="noopener">Web Foundation 万维网基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/World_Wide_Web_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://webfoundation.org/our-work/projects/alliance-for-affordable-internet/" target="_blank" rel="noopener">Alliance for Affordable Internet</a>  <a href="https://webfoundation.org/our-work/projects/open-data-barometer/" target="_blank" rel="noopener">Open Data Barometer</a>  <a href="https://webfoundation.org/our-work/projects/womens-rights-online/" target="_blank" rel="noopener">Women’s Rights Online</a> <a href="https://webfoundation.org/our-work/projects/the-web-index/" target="_blank" rel="noopener">The Web Index</a></td>
</tr>
<tr>
<td><a href="https://epic.org/" target="_blank" rel="noopener">EPIC 电子隐私信息中心</a></td>
<td><a href="https://en.wikipedia.org/wiki/Electronic_Privacy_Information_Center" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://epic.org/privacy/litigation/" target="_blank" rel="noopener">Litigation Docket</a> <a href="https://epic.org/campaigns/" target="_blank" rel="noopener">Privacy Campaigns</a> <a href="https://epic.org/privacy/surveillance/spotlight/" target="_blank" rel="noopener">Spotlight on Surveillance</a></td>
</tr>
<tr>
<td><a href="https://sfconservancy.org/" target="_blank" rel="noopener">SFC 软件自由保护组织</a></td>
<td><a href="https://en.wikipedia.org/wiki/Software_Freedom_Conservancy" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://busybox.net/" target="_blank" rel="noopener">BusyBox</a>  <a href="https://git-scm.com/" target="_blank" rel="noopener">Git</a>  <a href="https://phpmyadmin.net/" target="_blank" rel="noopener">phpMyAdmin</a>  <a href="http://qemu.org/" target="_blank" rel="noopener">QEMU</a>  <a href="https://www.samba.org/samba/" target="_blank" rel="noopener">Samba</a>  <a href="http://www.winehq.org/" target="_blank" rel="noopener">Wine</a> <a href></a></td>
</tr>
<tr>
<td><a href="https://www.softwarefreedom.org/" target="_blank" rel="noopener">SFLC 软件自由法律中心</a></td>
<td><a href="https://en.wikipedia.org/wiki/Software_Freedom_Law_Center" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.softwarefreedom.org/services/" target="_blank" rel="noopener">services</a></td>
</tr>
<tr>
<td><a href="https://archive.org/" target="_blank" rel="noopener">Internet Archive 互联网档案馆</a></td>
<td><a href="https://en.wikipedia.org/wiki/Internet_Archive" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://archive.org/projects/" target="_blank" rel="noopener">Building Libraries Together</a>  <a href="https://openlibrary.org/" target="_blank" rel="noopener">Open Library</a>  <a href="https://archive.org/details/301works" target="_blank" rel="noopener">301Works.org</a>  <a href="https://archive.org/web/sflan.php" target="_blank" rel="noopener">Open Community Networks</a></td>
</tr>
<tr>
<td><a href="https://www.x.org/wiki/" target="_blank" rel="noopener">X.Org 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/X.Org_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://www.x.org" target="_blank" rel="noopener">X.Org project</a></td>
</tr>
<tr>
<td><a href="https://riscv.org/" target="_blank" rel="noopener">RISC-V 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/RISC-V" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://riscv.org/" target="_blank" rel="noopener">RISC-V</a></td>
</tr>
<tr>
<td><a href="https://creativecommons.org/" target="_blank" rel="noopener">Creative Commons</a></td>
<td><a href="https://en.wikipedia.org/wiki/Creative_Commons" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://creativecommons.org/about/" target="_blank" rel="noopener">about</a></td>
</tr>
<tr>
<td><a href="https://www.eclipse.org/org/foundation/" target="_blank" rel="noopener">Eclipse 基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/Eclipse_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://projects.eclipse.org/" target="_blank" rel="noopener">Eclipse</a></td>
</tr>
<tr>
<td><a href="https://www.documentfoundation.org/" target="_blank" rel="noopener">TDF 文档基金会</a></td>
<td><a href="https://en.wikipedia.org/wiki/The_Document_Foundation" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="http://www.libreoffice.org/" target="_blank" rel="noopener">LibreOffice</a></td>
</tr>
<tr>
<td><a href="https://www.abetterinternet.org/" target="_blank" rel="noopener">ISRG 互联网安全研究小组</a></td>
<td><a href="https://en.wikipedia.org/wiki/Internet_Security_Research_Group" target="_blank" rel="noopener">wikipedia</a></td>
<td><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a></td>
</tr>
</tbody>
</table>
<h2 id="基金会-2017-年收入支出报告"><a href="#基金会-2017-年收入支出报告" class="headerlink" title="基金会 2017 年收入支出报告"></a>基金会 2017 年收入支出报告</h2><h3 id="按总收入排名"><a href="#按总收入排名" class="headerlink" title="按总收入排名"></a>按总收入排名</h3><table>
<thead>
<tr>
<th>基金会名称</th>
<th style="text-align:center">年总收入 $</th>
<th style="text-align:center">年总支出 $</th>
<th style="text-align:center">年净收入 $</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://wikimediafoundation.org/" target="_blank" rel="noopener">维基媒体基金会</a></td>
<td style="text-align:center">$89,973,967</td>
<td style="text-align:center">$69,076,192</td>
<td style="text-align:center">$20,897,775</td>
</tr>
<tr>
<td><a href="https://www.linuxfoundation.org/" target="_blank" rel="noopener">Linux   基金会</a></td>
<td style="text-align:center">$81,616,265</td>
<td style="text-align:center">$68,997,604</td>
<td style="text-align:center">$12,618,661</td>
</tr>
<tr>
<td><a href="https://www.openstack.org/foundation/" target="_blank" rel="noopener">OpenStack   基金会</a></td>
<td style="text-align:center">$22,829,442</td>
<td style="text-align:center">$29,047,402</td>
<td style="text-align:center">-$6,217,960)</td>
</tr>
<tr>
<td><a href="https://foundation.mozilla.org/" target="_blank" rel="noopener">Mozilla   基金会</a></td>
<td style="text-align:center">$20,586,446</td>
<td style="text-align:center">$24,206,401</td>
<td style="text-align:center">-$3,619,955)</td>
</tr>
<tr>
<td><a href="https://archive.org/" target="_blank" rel="noopener">Internet   Archive 互联网档案馆</a></td>
<td style="text-align:center">$17,811,981</td>
<td style="text-align:center">$18,468,621</td>
<td style="text-align:center">-$656,640)</td>
</tr>
<tr>
<td><a href="https://www.eff.org/" target="_blank" rel="noopener">EFF   电子前哨基金会</a></td>
<td style="text-align:center">$17,392,426</td>
<td style="text-align:center">$11,398,529</td>
<td style="text-align:center">$5,993,897</td>
</tr>
<tr>
<td><a href="https://cpj.org/" target="_blank" rel="noopener">CPJ   保护记者委员会</a></td>
<td style="text-align:center">$9,625,276</td>
<td style="text-align:center">$7,345,573</td>
<td style="text-align:center">$2,279,703</td>
</tr>
<tr>
<td><a href="https://www.opennetworking.org/" target="_blank" rel="noopener">ONF   开放网络基金会</a></td>
<td style="text-align:center">$7,722,940</td>
<td style="text-align:center">$6,525,599</td>
<td style="text-align:center">$1,197,341</td>
</tr>
<tr>
<td><a href="https://freedom.press/" target="_blank" rel="noopener">FPF   新闻自由基金会</a></td>
<td style="text-align:center">$5,949,008</td>
<td style="text-align:center">$2,960,503</td>
<td style="text-align:center">$2,988,505</td>
</tr>
<tr>
<td><a href="https://www.torproject.org/" target="_blank" rel="noopener">Tor   项目</a></td>
<td style="text-align:center">$4,130,882</td>
<td style="text-align:center">$4,078,419</td>
<td style="text-align:center">$52,463</td>
</tr>
<tr>
<td><a href="https://webfoundation.org/" target="_blank" rel="noopener">Web   Foundation 万维网基金会</a></td>
<td style="text-align:center">$3,579,820</td>
<td style="text-align:center">$3,966,177</td>
<td style="text-align:center">-$386,357</td>
</tr>
<tr>
<td><a href="https://www.python.org/psf/" target="_blank" rel="noopener">Python   基金会</a></td>
<td style="text-align:center">$2,870,521</td>
<td style="text-align:center">$2,475,335</td>
<td style="text-align:center">$395,186</td>
</tr>
<tr>
<td><a href="https://www.abetterinternet.org/" target="_blank" rel="noopener">ISRG   互联网安全研究小组</a></td>
<td style="text-align:center">$2,732,486</td>
<td style="text-align:center">$2,599,681</td>
<td style="text-align:center">$132,805</td>
</tr>
<tr>
<td><a href="https://sfconservancy.org/" target="_blank" rel="noopener">SFC   软件自由保护组织</a></td>
<td style="text-align:center">$2,125,670</td>
<td style="text-align:center">$1,500,209</td>
<td style="text-align:center">$625,461</td>
</tr>
<tr>
<td><a href="https://epic.org/" target="_blank" rel="noopener">EPIC   电子隐私信息中心</a></td>
<td style="text-align:center">$1,715,419</td>
<td style="text-align:center">$1,523,199</td>
<td style="text-align:center">$192,220</td>
</tr>
<tr>
<td><a href="https://creativecommons.org/" target="_blank" rel="noopener">Creative   Commons</a></td>
<td style="text-align:center">$1,639,408</td>
<td style="text-align:center">$3,600,414</td>
<td style="text-align:center">-$1,961,006</td>
</tr>
<tr>
<td><a href="https://www.gnu.org/" target="_blank" rel="noopener">FSF   自由软件基金会</a></td>
<td style="text-align:center">$1,373,574</td>
<td style="text-align:center">$1,233,394</td>
<td style="text-align:center">$140,180</td>
</tr>
<tr>
<td><a href="https://www.softwarefreedom.org/" target="_blank" rel="noopener">SFLC   软件自由法律中心</a></td>
<td style="text-align:center">$1,237,816</td>
<td style="text-align:center">$1,359,324</td>
<td style="text-align:center">-$121,508</td>
</tr>
<tr>
<td><a href="https://www.freebsdfoundation.org/" target="_blank" rel="noopener">FreeBSD   基金会</a></td>
<td style="text-align:center">$1,101,562</td>
<td style="text-align:center">$993,701</td>
<td style="text-align:center">$107,861</td>
</tr>
<tr>
<td><a href="https://www.apache.org/" target="_blank" rel="noopener">Apache   软件基金会</a></td>
<td style="text-align:center">$917,715</td>
<td style="text-align:center">$1,205,831</td>
<td style="text-align:center">-$288,116</td>
</tr>
<tr>
<td><a href="https://riscv.org/" target="_blank" rel="noopener">RISC-V   基金会</a></td>
<td style="text-align:center">$636,438</td>
<td style="text-align:center">$456,755</td>
<td style="text-align:center">$179,683</td>
</tr>
<tr>
<td><a href="https://www.spi-inc.org/" target="_blank" rel="noopener">SPI   组织</a></td>
<td style="text-align:center">$635,312</td>
<td style="text-align:center">$612,941</td>
<td style="text-align:center">$22,371</td>
</tr>
<tr>
<td><a href="https://www.gnome.org/foundation/" target="_blank" rel="noopener">GNOME   基金会</a></td>
<td style="text-align:center">$291,955</td>
<td style="text-align:center">$329,955</td>
<td style="text-align:center">-$38,000</td>
</tr>
<tr>
<td><a href="https://opensource.org/" target="_blank" rel="noopener">OSI   开放源代码组织</a></td>
<td style="text-align:center">$209,500</td>
<td style="text-align:center">$187,884</td>
<td style="text-align:center">$21,616</td>
</tr>
</tbody>
</table>
<h3 id="按净收入排名"><a href="#按净收入排名" class="headerlink" title="按净收入排名"></a>按净收入排名</h3><table>
<thead>
<tr>
<th>基金会名称</th>
<th style="text-align:center">年总收入 $</th>
<th style="text-align:center">年总支出 $</th>
<th style="text-align:center">年净收入 $</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://wikimediafoundation.org/" target="_blank" rel="noopener">维基媒体基金会</a></td>
<td style="text-align:center">$89,973,967</td>
<td style="text-align:center">$69,076,192</td>
<td style="text-align:center">$20,897,775</td>
</tr>
<tr>
<td><a href="https://www.linuxfoundation.org/" target="_blank" rel="noopener">Linux   基金会</a></td>
<td style="text-align:center">$81,616,265</td>
<td style="text-align:center">$68,997,604</td>
<td style="text-align:center">$12,618,661</td>
</tr>
<tr>
<td><a href="https://www.eff.org/" target="_blank" rel="noopener">EFF   电子前哨基金会</a></td>
<td style="text-align:center">$17,392,426</td>
<td style="text-align:center">$11,398,529</td>
<td style="text-align:center">$5,993,897</td>
</tr>
<tr>
<td><a href="https://freedom.press/" target="_blank" rel="noopener">FPF   新闻自由基金会</a></td>
<td style="text-align:center">$5,949,008</td>
<td style="text-align:center">$2,960,503</td>
<td style="text-align:center">$2,988,505</td>
</tr>
<tr>
<td><a href="https://cpj.org/" target="_blank" rel="noopener">CPJ   保护记者委员会</a></td>
<td style="text-align:center">$9,625,276</td>
<td style="text-align:center">$7,345,573</td>
<td style="text-align:center">$2,279,703</td>
</tr>
<tr>
<td><a href="https://www.opennetworking.org/" target="_blank" rel="noopener">ONF   开放网络基金会</a></td>
<td style="text-align:center">$7,722,940</td>
<td style="text-align:center">$6,525,599</td>
<td style="text-align:center">$1,197,341</td>
</tr>
<tr>
<td><a href="https://sfconservancy.org/" target="_blank" rel="noopener">SFC   软件自由保护组织</a></td>
<td style="text-align:center">$2,125,670</td>
<td style="text-align:center">$1,500,209</td>
<td style="text-align:center">$625,461</td>
</tr>
<tr>
<td><a href="https://www.python.org/psf/" target="_blank" rel="noopener">Python   基金会</a></td>
<td style="text-align:center">$2,870,521</td>
<td style="text-align:center">$2,475,335</td>
<td style="text-align:center">$395,186</td>
</tr>
<tr>
<td><a href="https://epic.org/" target="_blank" rel="noopener">EPIC   电子隐私信息中心</a></td>
<td style="text-align:center">$1,715,419</td>
<td style="text-align:center">$1,523,199</td>
<td style="text-align:center">$192,220</td>
</tr>
<tr>
<td><a href="https://riscv.org/" target="_blank" rel="noopener">RISC-V   基金会</a></td>
<td style="text-align:center">$636,438</td>
<td style="text-align:center">$456,755</td>
<td style="text-align:center">$179,683</td>
</tr>
<tr>
<td><a href="https://www.gnu.org/" target="_blank" rel="noopener">FSF   自由软件基金会</a></td>
<td style="text-align:center">$1,373,574</td>
<td style="text-align:center">$1,233,394</td>
<td style="text-align:center">$140,180</td>
</tr>
<tr>
<td><a href="https://www.abetterinternet.org/" target="_blank" rel="noopener">ISRG   互联网安全研究小组</a></td>
<td style="text-align:center">$2,732,486</td>
<td style="text-align:center">$2,599,681</td>
<td style="text-align:center">$132,805</td>
</tr>
<tr>
<td><a href="https://www.freebsdfoundation.org/" target="_blank" rel="noopener">FreeBSD   基金会</a></td>
<td style="text-align:center">$1,101,562</td>
<td style="text-align:center">$993,701</td>
<td style="text-align:center">$107,861</td>
</tr>
<tr>
<td><a href="https://www.torproject.org/" target="_blank" rel="noopener">Tor   项目</a></td>
<td style="text-align:center">$4,130,882</td>
<td style="text-align:center">$4,078,419</td>
<td style="text-align:center">$52,463</td>
</tr>
<tr>
<td><a href="https://www.spi-inc.org/" target="_blank" rel="noopener">SPI   组织</a></td>
<td style="text-align:center">$635,312</td>
<td style="text-align:center">$612,941</td>
<td style="text-align:center">$22,371</td>
</tr>
<tr>
<td><a href="https://opensource.org/" target="_blank" rel="noopener">OSI   开放源代码组织</a></td>
<td style="text-align:center">$209,500</td>
<td style="text-align:center">$187,884</td>
<td style="text-align:center">$21,616</td>
</tr>
<tr>
<td><a href="https://www.gnome.org/foundation/" target="_blank" rel="noopener">GNOME   基金会</a></td>
<td style="text-align:center">$291,955</td>
<td style="text-align:center">$329,955</td>
<td style="text-align:center">-$38,000</td>
</tr>
<tr>
<td><a href="https://www.softwarefreedom.org/" target="_blank" rel="noopener">SFLC   软件自由法律中心</a></td>
<td style="text-align:center">$1,237,816</td>
<td style="text-align:center">$1,359,324</td>
<td style="text-align:center">-$121,508</td>
</tr>
<tr>
<td><a href="https://www.apache.org/" target="_blank" rel="noopener">Apache   软件基金会</a></td>
<td style="text-align:center">$917,715</td>
<td style="text-align:center">$1,205,831</td>
<td style="text-align:center">-$288,116</td>
</tr>
<tr>
<td><a href="https://webfoundation.org/" target="_blank" rel="noopener">Web   Foundation 万维网基金会</a></td>
<td style="text-align:center">$3,579,820</td>
<td style="text-align:center">$3,966,177</td>
<td style="text-align:center">-$386,357</td>
</tr>
<tr>
<td><a href="https://archive.org/" target="_blank" rel="noopener">Internet   Archive 互联网档案馆</a></td>
<td style="text-align:center">$17,811,981</td>
<td style="text-align:center">$18,468,621</td>
<td style="text-align:center">-$656,640</td>
</tr>
<tr>
<td><a href="https://creativecommons.org/" target="_blank" rel="noopener">Creative   Commons</a></td>
<td style="text-align:center">$1,639,408</td>
<td style="text-align:center">$3,600,414</td>
<td style="text-align:center">-$1,961,006</td>
</tr>
<tr>
<td><a href="https://foundation.mozilla.org/" target="_blank" rel="noopener">Mozilla   基金会</a></td>
<td style="text-align:center">$20,586,446</td>
<td style="text-align:center">$24,206,401</td>
<td style="text-align:center">-$3,619,955</td>
</tr>
<tr>
<td><a href="https://www.openstack.org/foundation/" target="_blank" rel="noopener">OpenStack   基金会</a></td>
<td style="text-align:center">$22,829,442</td>
<td style="text-align:center">$29,047,402</td>
<td style="text-align:center">-$6,217,960</td>
</tr>
</tbody>
</table>
<h3 id="无序"><a href="#无序" class="headerlink" title="无序"></a>无序</h3><table>
<thead>
<tr>
<th>name</th>
<th style="text-align:center">2017 年总收入 $</th>
<th style="text-align:center">2017 年总支出 $</th>
<th style="text-align:center">2017 年净收入 $</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.linuxfoundation.org/" target="_blank" rel="noopener">Linux 基金会</a></td>
<td style="text-align:center">$81,616,265</td>
<td style="text-align:center">$68,997,604</td>
<td style="text-align:center">$12,618,661</td>
</tr>
<tr>
<td><a href="https://www.gnu.org" target="_blank" rel="noopener">FSF 自由软件基金会</a></td>
<td style="text-align:center">$1,373,574</td>
<td style="text-align:center">$1,233,394</td>
<td style="text-align:center">$140,180</td>
</tr>
<tr>
<td><a href="https://foundation.mozilla.org" target="_blank" rel="noopener">Mozilla 基金会</a></td>
<td style="text-align:center">$20,586,446</td>
<td style="text-align:center">$24,206,401</td>
<td style="text-align:center">-$3,619,955</td>
</tr>
<tr>
<td><a href="https://wikimediafoundation.org/" target="_blank" rel="noopener">维基媒体基金会</a></td>
<td style="text-align:center">$89,973,967</td>
<td style="text-align:center">$69,076,192</td>
<td style="text-align:center">$20,897,775</td>
</tr>
<tr>
<td><a href="https://www.openssl.org/" target="_blank" rel="noopener">OpenSSL 基金会</a></td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td><a href="https://www.spi-inc.org/" target="_blank" rel="noopener">SPI 组织</a></td>
<td style="text-align:center">$635,312</td>
<td style="text-align:center">$612,941</td>
<td style="text-align:center">$22,371</td>
</tr>
<tr>
<td><a href="https://www.eff.org/" target="_blank" rel="noopener">EFF 电子前哨基金会</a></td>
<td style="text-align:center">$17,392,426</td>
<td style="text-align:center">$11,398,529</td>
<td style="text-align:center">$5,993,897</td>
</tr>
<tr>
<td><a href="https://www.openstack.org/foundation/" target="_blank" rel="noopener">OpenStack 基金会</a></td>
<td style="text-align:center">$22,829,442</td>
<td style="text-align:center">$29,047,402</td>
<td style="text-align:center">-$6,217,960 (2016)</td>
</tr>
<tr>
<td><a href="https://www.cncf.io/" target="_blank" rel="noopener">CNCF 基金会</a></td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td><a href="https://www.cloudfoundry.org" target="_blank" rel="noopener">Cloud Foundry 基金会</a></td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td><a href="https://www.apache.org/" target="_blank" rel="noopener">Apache 软件基金会</a></td>
<td style="text-align:center">$917,715</td>
<td style="text-align:center">$1,205,831</td>
<td style="text-align:center">-$288,116</td>
</tr>
<tr>
<td><a href="https://www.python.org/psf/" target="_blank" rel="noopener">Python 基金会</a></td>
<td style="text-align:center">$2,870,521</td>
<td style="text-align:center">$2,475,335</td>
<td style="text-align:center">$395,186</td>
</tr>
<tr>
<td><a href="https://www.gnome.org/foundation/" target="_blank" rel="noopener">GNOME 基金会</a></td>
<td style="text-align:center">$291,955</td>
<td style="text-align:center">$329,955</td>
<td style="text-align:center">-$38,000</td>
</tr>
<tr>
<td><a href="http://openwebfoundation.org/" target="_blank" rel="noopener">OWF 开放 web 基金会</a></td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td><a href="https://www.opennetworking.org/" target="_blank" rel="noopener">ONF 开放网络基金会</a></td>
<td style="text-align:center">$7,722,940</td>
<td style="text-align:center">$6,525,599</td>
<td style="text-align:center">$1,197,341</td>
</tr>
<tr>
<td><a href="https://www.freebsdfoundation.org/" target="_blank" rel="noopener">FreeBSD 基金会</a></td>
<td style="text-align:center">$1,101,562</td>
<td style="text-align:center">$993,701</td>
<td style="text-align:center">$107,861</td>
</tr>
<tr>
<td><a href="http://www.openbsdfoundation.org/" target="_blank" rel="noopener">OpenBSD 基金会</a></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td><a href="http://golangfoundation.org/about/" target="_blank" rel="noopener">Golang 基金会</a></td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td><a href="https://opensource.org/" target="_blank" rel="noopener">OSI 开放源代码组织</a></td>
<td style="text-align:center">$209,500</td>
<td style="text-align:center">$187,884</td>
<td style="text-align:center">$21,616</td>
</tr>
<tr>
<td><a href="https://www.linaro.org/" target="_blank" rel="noopener">Linaro 非营利性组织</a></td>
<td style="text-align:center">UK</td>
<td style="text-align:center">UK</td>
<td style="text-align:center">UK</td>
</tr>
<tr>
<td><a href="https://www.torproject.org/" target="_blank" rel="noopener">Tor 项目</a></td>
<td style="text-align:center">$4,130,882</td>
<td style="text-align:center">$4,078,419</td>
<td style="text-align:center">$52,463</td>
</tr>
<tr>
<td><a href="https://freedom.press/" target="_blank" rel="noopener">FPF 新闻自由基金会</a></td>
<td style="text-align:center">$5,949,008</td>
<td style="text-align:center">$2,960,503</td>
<td style="text-align:center">$2,988,505</td>
</tr>
<tr>
<td><a href="https://cpj.org" target="_blank" rel="noopener">CPJ 保护记者委员会</a></td>
<td style="text-align:center">$9,625,276</td>
<td style="text-align:center">$7,345,573</td>
<td style="text-align:center">$2,279,703</td>
</tr>
<tr>
<td><a href="https://webfoundation.org/" target="_blank" rel="noopener">Web Foundation 万维网基金会</a></td>
<td style="text-align:center">$3,579,820</td>
<td style="text-align:center">$3,966,177</td>
<td style="text-align:center">-$386,357</td>
</tr>
<tr>
<td><a href="https://epic.org/" target="_blank" rel="noopener">EPIC 电子隐私信息中心</a></td>
<td style="text-align:center">$1,715,419</td>
<td style="text-align:center">$1,523,199</td>
<td style="text-align:center">$192,220</td>
</tr>
<tr>
<td><a href="https://sfconservancy.org/" target="_blank" rel="noopener">SFC 软件自由保护组织</a></td>
<td style="text-align:center">$2,125,670</td>
<td style="text-align:center">$1,500,209</td>
<td style="text-align:center">$625,461</td>
</tr>
<tr>
<td><a href="https://www.softwarefreedom.org/" target="_blank" rel="noopener">SFLC 软件自由法律中心</a></td>
<td style="text-align:center">$1,237,816</td>
<td style="text-align:center">$1,359,324</td>
<td style="text-align:center">-$121,508</td>
</tr>
<tr>
<td><a href="https://archive.org/" target="_blank" rel="noopener">Internet Archive 互联网档案馆</a></td>
<td style="text-align:center">$17,811,981</td>
<td style="text-align:center">$18,468,621</td>
<td style="text-align:center">-$656,640</td>
</tr>
<tr>
<td><a href="https://www.x.org/wiki/" target="_blank" rel="noopener">X.Org 基金会</a></td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td><a href="https://riscv.org/" target="_blank" rel="noopener">RISC-V 基金会</a></td>
<td style="text-align:center">$636,438</td>
<td style="text-align:center">$456,755</td>
<td style="text-align:center">$179,683</td>
</tr>
<tr>
<td><a href="https://creativecommons.org/" target="_blank" rel="noopener">Creative Commons</a></td>
<td style="text-align:center">$1,639,408</td>
<td style="text-align:center">$3,600,414</td>
<td style="text-align:center">-$1,961,006</td>
</tr>
<tr>
<td><a href="https://www.eclipse.org/org/foundation/" target="_blank" rel="noopener">Eclipse 基金会</a></td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td><a href="https://www.documentfoundation.org/" target="_blank" rel="noopener">TDF 文档基金会</a></td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td><a href="https://www.abetterinternet.org/" target="_blank" rel="noopener">ISRG 互联网安全研究小组</a></td>
<td style="text-align:center">$2,732,486</td>
<td style="text-align:center">$2,599,681</td>
<td style="text-align:center">$132,805</td>
</tr>
</tbody>
</table>
<h2 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h2><ul>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/460503801" target="_blank" rel="noopener">The Linux Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/42888848" target="_blank" rel="noopener">Free Software Foundation Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/200097189" target="_blank" rel="noopener">Mozilla Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/200049703" target="_blank" rel="noopener">Wikimedia Foundation Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/113390208" target="_blank" rel="noopener">Software In The Public Interest Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/460618689" target="_blank" rel="noopener">Openstack Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/470825376" target="_blank" rel="noopener">Apache Software Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/43594598" target="_blank" rel="noopener">Python Software Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/43572618" target="_blank" rel="noopener">Gnome Foundation Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/273327530" target="_blank" rel="noopener">Open Networking Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/841545163" target="_blank" rel="noopener">The Freebsd Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/912037395" target="_blank" rel="noopener">Open Source Initiative - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/208096820" target="_blank" rel="noopener">Tor Project Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/460967274" target="_blank" rel="noopener">Freedom Of The Press Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/133081500" target="_blank" rel="noopener">Committee To Protect Journalists Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/262852431" target="_blank" rel="noopener">World Wide Web Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/370794792" target="_blank" rel="noopener">Epic - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/522225921" target="_blank" rel="noopener">Electronic Privacy Information Center - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/260707261" target="_blank" rel="noopener">Epic Foundation Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/412203632" target="_blank" rel="noopener">Software Freedom Conservancy Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/412165986" target="_blank" rel="noopener">Software Freedom Law Center Inc - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/943242767" target="_blank" rel="noopener">Internet Archive - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/474893089" target="_blank" rel="noopener">Risc V Foundation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/43585301" target="_blank" rel="noopener">Creative Commons Corporation - Nonprofit Explorer - ProPublica</a></p>
</li>
<li><p><a href="https://projects.propublica.org/nonprofits/organizations/463344200" target="_blank" rel="noopener">Internet Security Research Group - Nonprofit Explorer - ProPublica</a></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>internet</tag>
        <tag>开源</tag>
      </tags>
  </entry>
  <entry>
    <title>业务上线前检查清单</title>
    <url>/archives/checklist.html</url>
    <content><![CDATA[<h2 id="拉清单？😂"><a href="#拉清单？😂" class="headerlink" title="拉清单？😂"></a>拉清单？😂</h2><blockquote>
<p>实际上那些错误执行者，他也是有一本账的，这个帐是记在那儿的。一旦他出事了，这个帐全给你拉出来了。别看你今天闹得欢，小心今后拉清单，这都得应验的。不要干这种事情。头上三尺有神明，一定要有敬畏之心。 </p>
<p>此处引用自  《将改革进行到底》 系列纪录片</p>
</blockquote>
<p>所以在我们应用上线之前一定要对生产环境有敬畏之心，切记不可马虎大意，不然会会酿出巨大的线上事故，造成巨大的经济损失。因此我们在上线之前要层层把关，<code>拉一个清单</code>出来，把一些该做的事项认真检查完毕后再按规矩上线。这样我们的业务上线后才能万无一失，让老板和领导都安心省事儿。</p>
<h2 id="1-硬件环境检查"><a href="#1-硬件环境检查" class="headerlink" title="1.硬件环境检查"></a>1.硬件环境检查</h2><ol>
<li><p>网络设备、分配公网IP、边界路由器</p>
</li>
<li><p>安全设备、硬件防火墙、负载均衡器、堡垒机</p>
</li>
<li><p>主机硬件资源(磁盘、内存、CPU、带宽)是否满足业务需求</p>
</li>
<li><p>边界完整性检查、访问控制检查</p>
</li>
<li><p>检查域名解析是否正确、SSL 证书有效期</p>
</li>
</ol>
<h2 id="2-系统安全检查"><a href="#2-系统安全检查" class="headerlink" title="2.系统安全检查"></a>2.系统安全检查</h2><ol>
<li><p>检查是否禁止 ssh 密码登录、是否禁止root用户远程登录</p>
</li>
<li><p>修改 ssh 默认端口号、添加 ssh 防火墙白名单规则</p>
</li>
<li><p>添加 ssh 远程登录IP白名单、禁止白名单以外IP登录</p>
</li>
<li><p>防火墙默认规则、确保过滤所有传入端口、只开放服务端口</p>
</li>
<li><p>开启系统权限审计日志、认证登录日志</p>
</li>
<li><p>日志收集与监控服务运行状态</p>
</li>
<li><p>检查进程运行用户的权限</p>
</li>
<li><p>外部安全扫描(nmap扫描端口)</p>
</li>
<li><p>系统运行服务检查</p>
</li>
<li><p>检查 SSH 与 PGP 的私钥</p>
</li>
<li><p>文件系统完整性检查</p>
</li>
<li><p>检查系统安全更新</p>
</li>
<li><p>检查时钟是否同步为北京时间</p>
</li>
<li><p>检查是否需要开启swap，预防业务高峰时期内存不足引起OOM</p>
</li>
</ol>
<h2 id="3-应用服务器安全检查"><a href="#3-应用服务器安全检查" class="headerlink" title="3.应用服务器安全检查"></a>3.应用服务器安全检查</h2><ol>
<li><p>统一设置40X错误页面、禁止输出服务器状态信息</p>
</li>
<li><p>检查Tomcat后台管理弱口令或禁用Tomcat后台默认应用</p>
</li>
<li><p>Web服务器配置文件检查、避免端口或域名冲突</p>
</li>
<li><p>删除 Tomcat 默认安装的应用</p>
</li>
<li><p>设置禁止列出目录，防止直接访问目录时由于找不到默认页面，而列出目录下的文件的情况</p>
</li>
<li><p>确保生产环境与开发环境所需的依赖一致</p>
</li>
</ol>
<blockquote>
<p>搞企业先扫描，扫描器商业好；默密码都知道 ，社工库找一找；</p>
<p>邮箱号先列好，九头蛇跑一跑 ；搞不定放大招，发邮件凭伪造；</p>
<p>没邮箱搞网站 ，二级域皆可爆；老漏洞没修好，新漏洞刷一票 ；</p>
<p>干研发 Git 找，源代码全都要；CDN 可以跳， 防火墙可以撬；</p>
<p>堡垒机可以秒，云防护可以秒 ；是企业都可搞 </p>
<p>此处引用自  <a href="https://fanqxu.com/" target="_blank" rel="noopener">考えるF4n9X</a> </p>
</blockquote>
<h2 id="4-数据库安全检查"><a href="#4-数据库安全检查" class="headerlink" title="4.数据库安全检查"></a>4.数据库安全检查</h2><ol>
<li><p>确保数据库连接的正确性</p>
</li>
<li><p>检查连接数据库用户的权限、开启数据库连接用户审计</p>
</li>
<li><p>上线前数据库做一次备份</p>
</li>
<li><p>检查数据库监听地址和端口、禁止监听外网IP地址</p>
</li>
</ol>
<h2 id="5-代码控制"><a href="#5-代码控制" class="headerlink" title="5.代码控制"></a>5.代码控制</h2><ol>
<li><p>使用sonar进行代码质量检测</p>
</li>
<li><p>备份旧数据、做好回滚准备</p>
</li>
<li><p>jar包版本检查、检查内部jar包引用</p>
</li>
<li><p>检查 webshell 漏洞、SQL 注入漏洞等</p>
</li>
</ol>
<h2 id="6-监控和日志收集"><a href="#6-监控和日志收集" class="headerlink" title="6.监控和日志收集"></a>6.监控和日志收集</h2><ol>
<li><p>确保监控和日志收集的数据正确</p>
</li>
<li><p>确保异常监控警报可以触发并做好处理措施</p>
</li>
</ol>
<h2 id="7-监控"><a href="#7-监控" class="headerlink" title="7.监控"></a>7.监控</h2><ol>
<li>确保监控服务正常运行</li>
<li>确保监控指标采集正常</li>
<li>确保监控报警系统面对突发事故时能准时准确地通知到相应人员</li>
</ol>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解 Linux 内核读书笔记</title>
    <url>/archives/kernel-note-book.html</url>
    <content><![CDATA[<ol>
<li>在ps命令的输出中很容易识别内核线程，其名称都置于方括号内</li>
<li>linux内核把虚拟地址空间划分为两个部分：核心态和用户状态。两种状态的关键差别在于对高于TASK_SIZE的内存区域的访问</li>
<li>伙伴系统。 系统中的空闲内存块总是两两分组，每组中的两个内存块称作伙伴。伙伴的分配可以是彼此独立 的。但如果两个伙伴都是空闲的，内核会将其合并为一个更大的内存块，作为下一层次上某个内存块 的伙伴。</li>
<li>字符设备：提供连续的数据流，应用程序可以顺序读取，通常不支持随机存取。相反，此类 设备支持按字节/字符来读写数据。举例来说，调制解调器是典型的字符设备。</li>
<li><p>块设备：应用程序可以随机访问设备数据，程序可自行确定读取数据的位置。硬盘是典型的 块设备，应用程序可以寻址磁盘上的任何位置，并由此读取数据。此外，数据的读写只能以块（通常 是512B）的倍数进行。与字符设备不同，块设备并不支持基于字符的寻址。 编写块设备的驱动程序比字符设备要复杂得多，因为内核为提高系统性能广泛地使用了缓存 机制。</p>
</li>
<li><p>Linux使用了源于BSD的套接字抽象。 套接字可以看作应用程序、文件接口、内核的网络实现之间的代理</p>
</li>
<li><p>进程可以分为实时进程和非实时进程，硬实时进程有严格的时间限制，某些任务必须在指定的时限内完成。硬实时进程的关键特征是，它 们必须在可保证的时间范围内得到处理。Linux不支持硬实时处理。 软实时进程是硬实时进程的一种弱化形式。</p>
</li>
<li>抢占式多任务处理（preemptive multitasking)，各个进程都分配到一定的时间段 可以执行。时间段到期后，内核会从进程收回控制权，让一个不同的进程运行，而不考虑前一进程所 执行的上一个任务。被抢占进程的运行时环境，即所有CPU寄存器的内容和页表，都会保存起来，因 此其执行结果不会丢失。在该进程恢复执行时，其进程环境可以完全恢复。时间片的长度会根据进程</li>
<li>完全公平调度器（completely fair scheduler）在内核版本2.6.23开发期间合并进来。新的代码再 一次完全放弃了 原有的设计原则，例如，前一个调度器中为确保用户交互任务响应快速，需要许多启 发式原则。该调度器的关键特性是，它试图尽可能地模仿理想情况下的公平调度。此外，它不仅可以 调度单个进程，还能够处理更一般性的调度实体（scheduling entity）。例如，该调度器分配可用时间时， 可以首先在不同用户之间分配，接下来在各个用户的进程之间分配。</li>
<li>进程运行的状态：<br>10.1. 运行：该进程此刻正在执行。<br>10.2. 等待：进程能够运行，但没有得到许可，因为CPU分配给另一个进程。调度器可以在下一次 任务切换时选择该进程。<br>10.3. 睡眠：进程正在睡眠无法运行，因为它在等待一个外部事件。调度器无法在下一次任务切换 时选择该进程</li>
<li>僵尸进程的资源已经释放但在进程表中仍存在对应的表项</li>
<li>僵尸是如何产生的？其原因在于UNIX操作系统下进程创建和销毁的方式。在两种事件发生时， 程序将终止运行。第一，程序必须由另一个进程或一个用户杀死（通常是通过发送SIGTERM或SIGKILL 信号来完成，这等价于正常地终止进程）；进程的父进程在子进程终止时必须调用或已经调用wait4 （读做wait for）系统调用。 这相当于向内核证实父进程已经确认子进程的终结。该系统调用使得内核 可以释放为子进程保留的资源。 只有在第一个条件发生（程序终止）而第二个条件不成立的情况下（wait4），才会出现“僵尸” 状态。在进程终止之后，其数据尚未从进程表删除之前，进程总是暂时处于“僵尸”状态。有时候（例 如，如果父进程编程极其糟糕，没有发出wait调用），僵尸进程可能稳定地寄身于进程表中，直至下 一次系统重启。</li>
<li>内核抢占（kernel preemption）的选项添加到内核。 该选项支持 在紧急情况下切换到另一个进程，甚至当前是处于核心态执行系统调用（中断处理期间是不行的） 。 尽管内核会试图尽快执行系统调用，但对于依赖恒定数据流的应用程序来说，系统调用所需的时间仍 然太长了。内核抢占可以减少这样的等待时间，因而保证“更平滑的”程序执行。但该特性的代价是 增加内核的复杂度，因为接下来有许多数据结构需要针对并发访问进行保护，即使在单处理器系统上 也是如此。</li>
<li><p>Linux内核涉及进程和程序的所有算法都围绕一个名为task_struct的数据结构建立，该结构定 义在include/sched.h中。</p>
</li>
<li><p>Linux提供资源限制（resource limit，rlimit）机制，对进程使用系统资源施加某些限制。该机制利 用了task_struct中的rlim数组，数组项类型为struct rlimit。<br>打开文件的数目（RLIMIT_NOFILE，默认限制在1 024）。  每用户的大进程数（RLIMIT_NPROC），定义为max_threads/2。max_threads是一个全局变 量，指定了在把八分之一可用内存用于管理线程信息的情况下，可以创建的线程数目。在计 算时，提前给定了20个线程的小可能内存用量。</p>
</li>
<li>典型的UNIX进程包括：由二进制代码组成的应用程序、单线程（计算机沿单一路径通过代码， 不会有其他路径同时运行）、分配给应用程序的一组资源（如内存、文件等）。<br>16.1. fork生成当前进程的一个相同副本，该副本称之为子进程。原进程的所有资源都以适当的方 式复制到子进程，因此 该系统调用之后，原来的进程就有了两个独立的实例。这两个实例的 联系包括：同一组打开文件、同样的工作目录、内存中同样的数据（两个进程各有一份副本）， 等等。此外二者别无关联。<br>16.2. exec从一个可执行的二进制文件加载另一个应用程序，来代替当前运行的进程。加载了一个新程序。因为exec并不创建新进程，所以必须首先使用fork复制一个旧的程序， 然后调用exec在系统上创建另一个应用程序。<br>16.3. clone的工作原理基本上与fork相同，但新进程不是独立于父进程的， 而可以与其共享某些资源。写时复制，直至新进程对内存页执行写操作才会复制内存页面，这比在 执行fork时盲目地立即复制所有内存页要更高效。父子进程内存页之间的联系，只有对内核才是可见的，对应用 程序是透明的可以指定需要共享和复制的资源种类，例如，父进程的内存数据、打开文 件或安装的信号处理程序。 clone用于实现线程，但仅仅该系统调用不足以做到这一点，还需要用户空间库才能提供完整的 实现。线程库的例子，有Linuxthreads和Next Generation Posix Threads等</li>
<li>进程总是会分配一个号码用于在其命名空间中唯一地标识它们。简称PID。用fork或clone产生的每个进程都由内核自动地分配了一个新的唯一的PID值</li>
<li>task_struct数据结构提供了两个链表表头，用于实现进程家族关系</li>
<li>内核线程是直接由内核本身启动的进程。内核线程实际上是将内核函数委托给独立的进程，与系 统中其他进程“并行”执行（实际上，也并行于内核自身的执行）。<br>19.1. 内核线程经常称之为（内核）守 护进程。它们用于执行下列任务。<br>19.2. 周期性地将修改的内存页与页来源块设备同步（例如，使用mmap的文件映射）。<br>19.3. 如果内存页很少使用，则写入交换区。<br>19.4. 管理延时动作（deferred action）。<br>19.5. 实现文件系统的事务日志。</li>
<li>基本上，有两种类型的内核线程：<br>20.1.线程启动后一直等待，直至内核请求线程执行某一特定操作。<br>20.2.线程启动后按周期性间隔运行，检测特定资源的使用，在用量超出或低于预置的限制值时采取行动。内核使用这类线程用于连续监测任务。<br>调用kernel_thread函数可启动一个内核线程。其定义是特定于体系结构的，但原型总是相同的。</li>
</ol>
]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>一段在法律与技术冲突的地方捍卫自由的历史</title>
    <url>/archives/A-History-of-Protecting-Freedom-Where-Law-and-Technology-Collide.html</url>
    <content><![CDATA[<ul>
<li>2019-10-14 初稿</li>
<li>2019-10-30 发布</li>
<li>2019-11-01 修正漏译的那一句，见评论区</li>
<li>2019-11-08 修正几处明显的翻译错误，见评论区</li>
</ul>
<h2 id="题记"><a href="#题记" class="headerlink" title="题记"></a>题记</h2><p>本篇文章翻译自 <a href="https://eff.org" target="_blank" rel="noopener">eff.org</a> 官网上的 <a href="https://www.eff.org/about/history" target="_blank" rel="noopener">A History of Protecting Freedom Where Law and Technology Collide</a> </p>
<p>由于是第一次独立翻译整篇文章，肯请读者们能够指出翻译不当的部分，让这篇翻译文章更加完善</p>
<hr>
<blockquote>
<h1 id="A-History-of-Protecting-Freedom-Where-Law-and-Technology-Collide"><a href="#A-History-of-Protecting-Freedom-Where-Law-and-Technology-Collide" class="headerlink" title="A History of Protecting Freedom Where Law and Technology Collide"></a>A History of Protecting Freedom Where Law and Technology Collide</h1></blockquote>
<blockquote>
<h1 id="一段在法律与技术冲突的地方捍卫自由的历史"><a href="#一段在法律与技术冲突的地方捍卫自由的历史" class="headerlink" title="一段在法律与技术冲突的地方捍卫自由的历史"></a>一段在法律与技术冲突的地方捍卫自由的历史</h1></blockquote>
<blockquote>
<p>The Electronic Frontier Foundation was founded in July of 1990 in response to a basic threat to speech.</p>
<p>电子前哨基金会成立于 1990 年 7 月，皆在应对基本的言论威胁。</p>
<p>The United States Secret Service conducted a series of raids tracking the distribution of a document illegally copied from a BellSouth computer that described how the emergency 911 system worked, referred to as the E911 document.</p>
<p>美国特勤局进行了一系列的突击搜查，追踪一份来自南方贝尔公司电脑非法复制文档的分发情况。这份文档描述了紧急 911系统的工作原理，称之为E911文档。</p>
<p>The Secret Service believed that if “hackers” knew how to use the telephone lines set aside for receiving emergency phone calls, the lines would become overloaded and people facing true emergencies would be unable to get through.</p>
<p>特勤局认为，如果“黑客”知道如何使用空闲的通信线路来接听紧急电话，则通信线路将变得超负荷，面对真正紧急情况的人将因此无法打通电话。</p>
</blockquote>
<blockquote>
<p>One of the alleged recipients of the E911 document was the systems operator at a small games book publisher out of Austin, Texas, named Steve Jackson Games.</p>
<p>E911 文档的嫌疑接收者之一，是德克萨斯州奥斯汀市史蒂夫·杰克逊游戏的小型游戏图书发行商的系统操作员。</p>
<p>The Secret Service executed a warrant against the innocent Jackson and took all electronic equipment and copies of an upcoming game book from Steve Jackson Games’ premises.</p>
<p>特勤局对无辜的杰克逊执行了逮捕令，并从史蒂夫·杰克逊游戏公司取走了所有电子设备和一本即将发行的游戏书籍的副本。</p>
<p>Steve Jackson panicked as he watched the deadline come and go for his latest release and still hadn’t received his computers back.</p>
<p>史蒂夫·杰克逊为发行游戏书籍最后期限的来临惊慌失措，因为他要发布他的最新的版本，但他的电脑仍未归还。</p>
<p>He was forced to lay off nearly half of his staff. </p>
<p>他被迫解雇了将近一半的员工。</p>
<p>In the end, the Secret Service returned all of Steve Jackson’s computers and decided not to press charges against the company, since they were unable to find any copies of the E911 document on any of the computers.</p>
<p>最后，特勤局归还了史蒂夫·杰克逊所有的计算机，因为他们无法在任何计算机上找到 E911 文档的任何副本，所以就决定不对这家公司提起诉讼。</p>
</blockquote>
<blockquote>
<p><img src="../img/eff-logo-stack-rgb.png" alt="&quot;EFF&#39;s original logo, in use from 1990-2018"></p>
</blockquote>
<blockquote>
<p>EFF’s original logo, in use from 1990-2018</p>
</blockquote>
<blockquote>
<p>In the meantime, Steve Jackson’s business was nearly ruined.</p>
<p>与此同时，史蒂夫·杰克逊的游戏生意几乎破产。</p>
<p>And when he and his employees had the opportunity to investigate the returned computers, they noticed that all of the electronic mail that had been stored on the company’s electronic bulletin board computer, where non-employee users had dialed in and sent personal messages to one another, had been individually accessed and deleted.</p>
<p>当他和他的员工们事后调查归还的计算机时，他们注意到特勤局访问并删除了所有存储在公司 BBS 上的电子邮件，而这些电子邮件是用户用来相互通信用的。</p>
<p>Steve Jackson was furious, as he believed his rights as a publisher had been violated and the free speech and privacy rights of his users had been violated.</p>
<p>史蒂夫·杰克逊感到作为出版商的权利受到侵犯以及用户的言论自由和隐私权也遭到侵犯而愤怒。</p>
<p>Steve Jackson tried desperately to find a civil liberties group to help him, to no avail.</p>
<p>史蒂夫·杰克逊竭尽所能找一个公民自由组织来帮助他，但无济于事。</p>
<p>Unfortunately, none of the existing groups understood the technology well enough to understand the importance of the issues.</p>
<p>不幸的是，现有的组织中没有一个充分了解有关技术以意识到这些问题的重要性。</p>
</blockquote>
<blockquote>
<p>In an electronic community called the Whole Earth ‘Lectronic Link (now WELL.com) several informed technologists understood exactly what civil liberties issues were involved.</p>
<p>在一个名为“全球电子链接”的电子社区（现为WELL.com）中，几位见多识广的技术专家确切地知晓涉及的公民自由问题。</p>
<p>Mitch Kapor, former president of Lotus Development Corporation, John Perry Barlow, Wyoming cattle rancher and lyricist for the Grateful Dead, and John Gilmore, an early employee of Sun Microsystems, decided to do something about it.</p>
<p>米奇·卡普尔，莲花开发公司前总裁，约翰·佩里·巴洛，怀俄明州养牛主，《感恩之死》的抒情作家，以及太阳微系统公司的早期雇员约翰·吉尔莫尔，决定对此采取一些行动。</p>
<p>They formed an organization to work on civil liberties issues raised by new technologies.</p>
<p>他们成立了一个组织，致力于解决新技术带来的公民自由问题。</p>
<p>On the day they formally unveiled the new organization, they announced that they were representing Steve Jackson Games and several of the company’s bulletin board users in a lawsuit they were bringing against the United States Secret Service.</p>
<p>在电子前哨基金会宣布正式成立的当天，他们宣布他们代表史蒂夫·杰克逊游戏公司和几位公司的 BBS 用户，对美国特勤局提起了诉讼。</p>
<p>The Electronic Frontier Foundation was born!</p>
<p>由此电子前哨基金会诞生了！</p>
</blockquote>
<blockquote>
<p>The Steve Jackson Games case turned out to be an extremely important one in the development of a proper legal framework for cyberspace.</p>
<p>事实证明，史蒂夫•杰克逊游戏案对网络空间法律框架的制定极为重要。</p>
<p>For the first time, a court held that electronic mail deserves at least as much protection as telephone calls.</p>
<p>法院首次裁定，电子邮件至少应该得到与电话一样多的保护。</p>
<p>We take for granted today that law enforcement must have a warrant that particularly describes all electronic mail messages before seizing and reading them.</p>
<p>今天我们理所当然地认为，执法部门在扣押和阅读所有电子邮件之前，必须持有特别描述这些电子邮件的搜查令。</p>
<p>The Steve Jackson Games case established that principle.</p>
<p>而正是史蒂夫·杰克逊游戏案确立了这一 判例。</p>
</blockquote>
<blockquote>
<p>The Electronic Frontier Foundation continues to take on cases that set important precedents for the treatment of rights in cyberspace.</p>
<p>电子前哨基金会继续受理为网络空间权利处理树立重要先例的案件。</p>
<p>In our second big case, <em>Bernstein v. U.S. Dept. of Justice</em>, the United States government prohibited a University of California mathematics Ph.D. student from publishing on the Internet an encryption computer program he had created.</p>
<p>在我们的第二个重大案件，即伯恩斯坦诉美国司法部案中，美国政府禁止加州大学的一名数学博士生在互联网上分发他创建的一个加密软件。</p>
<p>Encryption is a method for scrambling messages so they can only be understood by their intended recipients.</p>
<p>加密技术是一种加扰信息的方法，这样信息只能被它们的目标接收者理解。</p>
<p>Years before, the government had placed encryption on the United States Munitions List, alongside bombs and flamethrowers, as a weapon to be regulated for national security purposes.</p>
<p>数年前，政府已经将加密技术与炸弹、火焰喷射器一同置于军需品清单，作为国家安全目的的管制武器。</p>
</blockquote>
<blockquote>
<p>Companies and individuals exporting items on the munitions list, including software with encryption capabilities, had to obtain prior State Department approval.</p>
<p>公司或个人出口军需品清单上的物品，具有加密功能的软件，必须事先获得(美国)国务院的批准。</p>
</blockquote>
<blockquote>
<p>Encryption export restrictions crippled American businesses and damaged the free speech rights of individuals.</p>
<p>加密技术出口限制削弱了美国企业，并侵犯了个人的言论自由。</p>
<p>Critical for ecommerce, companies use encryption to safeguard sensitive information, such as credit card numbers, which they send or receive over electronic networks.</p>
<p>企业使用加密技术来保护信用卡号码等敏感信息并通过网络发送或接收，因此加密技术对电子商务至关重要。</p>
<p> Companies also secure access to software programs and provide system security using encryption.</p>
<p>使用加密技术，公司还可以保护对软件程序的访问，并确保系统的安全。</p>
<p>By limiting the export of encryption, technologies, and methods, the U.S. government drove development of security software overseas, where American companies were unable to compete.</p>
<p>通过限制加密、技术和方法的出口，美国政府将安全软件的开发逼到了海外，使得美国公司无法与国外公司竞争 。</p>
</blockquote>
<blockquote>
<p>The State Department was unsympathetic to Bernstein’s situation and told Bernstein he would need a license to be an arms dealer before he could simply post the text of his encryption program on the Internet.</p>
<p>（美国）国务院并同情伯恩斯坦，并告诉伯恩斯坦，他需要获得军火商的许可证才能将他的加密软件的代码发布到互联网上。</p>
<p>They also told him that they would deny him an export license if he actually applied for one, because his technology was too secure.</p>
<p>（美国）国务院还告诉伯恩斯坦，如果他真的申请出口许可证，那么他们将会拒绝，因为他的技术太安全了。</p>
</blockquote>
<blockquote>
<p>The Electronic Frontier Foundation pulled together a top-notch legal team and sued the United States government on behalf of Dan Bernstein.</p>
<p>电子前哨基金会召集了一个顶尖的法律团队，代表伯恩斯坦起诉美国政府。</p>
<p> The court ruled, for the first time ever, that written software code is speech protected by the First Amendment.</p>
<p>法院有史以来第一次裁定，编写的软件代码是受宪法第一修正案保护的言论。</p>
<p> The court further ruled that the export control laws on encryption violated Bernstein’s First Amendment rights by prohibiting his constitutionally protected speech.</p>
<p>法院进一步裁定，有关加密技术出口管制的法律 禁止伯恩斯坦发表受宪法保护的言论，因此侵犯了伯恩斯坦的第一修正案权利。</p>
<p>As a result, the government changed its export regulations.</p>
<p>因此，美国政府改变了他的出口条例。</p>
<p>Now everyone has the right to “export” encryption software – by publishing it on the Internet – without prior permission from the U.S. government.</p>
<p>现在，每个人都有权利通过在互联网上发布加密软件而无需事先获得美国政府的许可。</p>
<p>Once again, the Electronic Frontier Foundation led the charge to establish important cyberspace rights.</p>
<p>电子前哨基金会再次领导确立了重要的网络空间权利</p>
</blockquote>
<blockquote>
<h2 id="Today’s-Issues"><a href="#Today’s-Issues" class="headerlink" title="Today’s Issues"></a>Today’s Issues</h2></blockquote>
<blockquote>
<p>While many early battles over the right to communicate freely and privately stemmed from government censorship, today EFF is fighting for users on many other fronts as well.</p>
<p>虽然早期许多关于自由和私密通讯权利的斗争源于政府的审查制度，但今天 EFF 也在许多其他领域为用户而战。</p>
</blockquote>
<blockquote>
<p>Today, certain powerful corporations are attempting to shut down online speech, prevent new innovation from reaching consumers, and facilitating government surveillance.</p>
<p>今天，某些互联网巨头正试图封杀网络言论，阻止新创新惠及消费者，并为政府监控提供便利。</p>
<p>We challenge corporate overreach just as we challenge government abuses of power.</p>
<p>我们挑战公司的越权，就像我们挑战政府的权力滥用一样。</p>
</blockquote>
<blockquote>
<p>We also develop technologies that can help individuals protect their privacy and security online, which our technologists build and release freely to the public for anyone to use.</p>
<p>我们技术人员还开发了保护个人隐私和网络安全的技术，这些技术免费向公众开放以供所有人使用。</p>
</blockquote>
<blockquote>
<p>In addition, EFF is engaged in major legislative fights, beating back digital censorship bills disguised as intellectual property proposals, opposing attempts to force companies to spy on users, championing reform bills that rein in government surveillance, and much more.</p>
<p>此外，EFF 还参与了重大的立法斗争，阻止伪装成知识产权法案的网络审查法案通过，反击强迫公司监视用户的企图， 力推改革限制政府监视的法案，等等。</p>
</blockquote>
<blockquote>
<p>We are working with advocates worldwide to create a global digital environment that upholds both human rights and Constitutional rights, and we continue to take on cutting-edge legal cases to win victories for user rights.</p>
<p>我们正在与世界各地的倡议者们合作，去创造一个既维护人权又维护宪法权利的数字世界，我们继续受理前沿的法律案件，为用户权利赢得胜利。</p>
</blockquote>
]]></content>
      <tags>
        <tag>翻译</tag>
        <tag>电子前哨基金会</tag>
      </tags>
  </entry>
  <entry>
    <title>六年前思考的一些东西</title>
    <url>/archives/life-sciences.html</url>
    <content><![CDATA[<p>偶然间翻到了 OneDrive 里六年前写下的疑问，大概是我高三的时候思考的生物学问题。当时梦想着大学的时候能去研究生命科学、去研究生命如何进化来的、去研究地球是如何孕育出生命、又是经历了几十亿年的进化之旅，生命的奇迹降临在我身上。一个鲜活的生命由此诞生。那时的我对高中生物学的知识早已学的滚瓜烂熟，甚至但是还拿来大学教材《普通生物学》、《细胞生物学》、《植物学》来自学😂。我只是想迫切地知道大学里我要学的知识。高三的时候，我在生物这们学科上花费的事件和精力甚至远远高于数学，因为数学实在是太枯燥难懂了，一点都没有生物学好玩儿。可想而知，高考时，数学仅仅考了 62 分、而理综的生物我估分是满分90，没有任何一个错的。幸运之神没有光顾我，高考失败，注定了我与生物学此生无缘。从此踏上了从不熟悉的计算机专业。</p>
<p>有时一直在思考，这样做值得吗？你得到了什么？</p>
<p>大概我永远不会忘记一个高三学生，手捧大学教材《普通生物学》、《细胞生物学》、《植物学》在知识和真理的海洋里是多么地快乐，甚至看这些书籍要比那些小说和杂志还有趣。在数学课上翻看生物学教材，去搞清楚光合作用每一个过程、去画图分析每一个化学反应是如何进行的。因为当时对于我来说，数学简直就是噩梦、看到他我就头疼、所以我选择看逃避，很早很早第就放弃了数学的复习，从而去陪伴我最喜欢的生物学。</p>
<p>当然，逃避终将会受到惩罚的、高考惨败、一段一段伤心往事儿</p>
<p>2013年，我想那应该是我近十年来最开心的一年。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─debian@debian /mnt/f/OneDrive/Time Machine/生命科学</span><br><span class="line">╰─$ ls -alh</span><br><span class="line">-rwxrwxrwx 1 debian debian  521 Dec 15  2013 大学目标及计划.txt</span><br><span class="line">-rwxrwxrwx 1 debian debian 101K Nov 29  2013 报名信息.jpg</span><br><span class="line">-rwxrwxrwx 1 debian debian 4.9K Dec 15  2013 生命科学1.txt</span><br><span class="line">-rwxrwxrwx 1 debian debian  235 Dec 15  2013 生命科学2.txt</span><br><span class="line">-rwxrwxrwx 1 debian debian 1.1K Mar 21  2014 生命科学.txt</span><br><span class="line">-rwxrwxrwx 1 debian debian  778 Dec  1  2013 病毒学.txt</span><br><span class="line">-rwxrwxrwx 1 debian debian 3.4K Nov 14  2013 研究课题1-70.txt</span><br></pre></td></tr></table></figure>
<blockquote>
<p>一次饭桌上和读初中的表妹聊天，我问她，初中科学不是很好玩嘛，你为啥学不好？ 她一脸诧异，很无聊好嘛。 作为一个大xiáo毕业生的，我一脸兴奋地回应，你难道不好奇为什么世界是这个样子？为什么你能看到颜色？光线是怎么变化的…… 她一脸无奈，并喊停了我，「我十岁的时候挺好奇的，现在不了。」 </p>
<p>此处引用 <a href="https://twitter.com/Philo2018/status/1179595180552245248" target="_blank" rel="noopener">Philo</a> 的推文</p>
</blockquote>
<p>今天把这些问题都整理了一下，有些问题现在想想可能会觉着当时思考这些问题时很搞笑。但、即便搞笑我也一字不该地贴出来😂。我觉着修改了的话就忘记初心了。我想每段时间再去思考这些问题，然后的到答案后就把整理的答案放在这里。</p>
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th>高三时对关于生物学的奇思异想</th>
<th>进度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td>植物细胞发育起源，及各种细胞进化。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td>细胞器的来源及进化，以及联系功能。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td>原核细胞的发展史，及细胞结构。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td>生物界的分类，及植物界细分。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td>研究新的耕作方式，抛弃话费，研究新的增肥农作物</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td>农作物秸秆在农田里高效率降解，减少化肥污染。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td>研究新的农田增肥方法，彻底摆脱化肥的需求。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td>核细胞分裂，转录机制，核糖体的形成。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td>将目的基因导入细胞的方法改进研究。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td>植物受精卵细胞初期的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td>动物配子细胞结构特点，染色体的特异。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td>减数分裂联会后染色体的变化，全能型的影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td>动物受精卵及胚胎发育早期细胞的全能性特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td>细胞全能性的变化与细胞分化的关联。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">15</td>
<td>培育出高效的光合作用农作物，生产酒精。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">16</td>
<td>酒精发酵的改进，用植物秸秆发酵技术改进研究。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">17</td>
<td>植物蒸腾作用是否能净化水，怎样收集水。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">18</td>
<td>研究一些南瓜等藤类植物茎中运输的水的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">19</td>
<td>藤类农作物是否可以净化术，由此改进净水系统。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">20</td>
<td>光合作用的全部过程，完全详细研究。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">21</td>
<td>多倍体染色体联会产配子，及染色体表达的情况。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">22</td>
<td>同源染色体联会的调控，正常细胞诱导联会后变化。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">23</td>
<td>植物细胞动物细胞在人体内怎样被消化，细胞器去向。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">24</td>
<td>核酸 及细胞器怎样消化，及各种细胞器的营养价值</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">25</td>
<td>植物有机物的积累，变化，。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">26</td>
<td>两条互补DNA链表达的蛋白质存在怎样的联系及特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">27</td>
<td>显性基因和隐性基因表达的关系，及控制表达的机制。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">28</td>
<td>具有胚性分生组织细胞特点，染色体及细胞器的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">29</td>
<td>受精卵基因表达与细胞全能性的关系，表达基因的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">30</td>
<td>植物细胞与动物细胞内基因表达的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">31</td>
<td>动手实践植物体细胞杂交及植物组织培养。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">32</td>
<td>人类，动物思维的物质基础及与细胞功能的联系。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">33</td>
<td>神经细胞基因表达的特点，与思维的关系。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">34</td>
<td>植物蛋白与动物蛋白各自的特点，及营养价值。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">35</td>
<td>连续光照对植物光合作用的影响，及净光合作速率的变化</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">36</td>
<td>光合作用与细胞呼吸的联系，相互影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">37</td>
<td>线粒体与叶绿体内核糖体的特点，DNA的特点，相似处。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">38</td>
<td>DNA转录，复制时染色体上的蛋白质变化去向作用。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">39</td>
<td>把一条染色体离在细胞核外基因是否能表达，及影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">40</td>
<td>受精作用时阻止细胞核融合，及后来的变化，是否存活</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">41</td>
<td>细胞核融合的原理，怎样阻止细胞核融合。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">42</td>
<td>植物体细胞杂交与动物细胞融合，受精作用。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">43</td>
<td>细胞核融合的特点，是否相似 怎样阻止细胞核融合</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">44</td>
<td>高等生物是否存在具有两个细胞核的生物体?</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">45</td>
<td>病毒侵入细胞后怎样转录表达，地点 方式 酶</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">46</td>
<td>利用病毒基因的特性能否将核基因分离在细胞核外。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">47</td>
<td>显隐性基因表达出的蛋白质有什么相似特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">48</td>
<td>蛋白质的分类及酶的分类。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">49</td>
<td>配子细胞核与衰老细胞细胞核的差异及特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">50</td>
<td>癌细胞细胞核的特点，基因表达的特点，染色体端粒特点</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">51</td>
<td>细胞生命与个体生命与原癌基因和抑癌基因的关系。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">52</td>
<td>研究染色体端粒学说，比较受精卵，配子，不同细胞端粒</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">53</td>
<td>人工控制核酸的合成，用核酸储存一些信息</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">54</td>
<td>讲线粒体和叶绿体在细胞外培养，是否能长时间存活。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">55</td>
<td>将控制呼吸和光合的核基因导入线粒体和叶绿体，研究</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">56</td>
<td>研究癌细胞的一些基因表达的特点，一些基因对它的影响</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">57</td>
<td>将细胞器分离出怎样表现生物活性。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">58</td>
<td>植物细胞的动物细胞线粒体的相似或起源特点，核酸特点</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">59</td>
<td>不同线粒体和叶绿体基因是否存在很大的差异或联系</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">60</td>
<td>动物细胞的植物细胞内化合物的差异</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">61</td>
<td>动物细胞和植物细胞对环境的适应要求</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">62</td>
<td>不同细胞对PH要求的差异，及PH的影响原因。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">63</td>
<td>动物细胞和植物细胞细胞器之间的差异和联系，相似之处</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">64</td>
<td>不同细胞对外界环境的要求差异及原因。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">65</td>
<td>红细胞无细胞核后特点，能否在适宜条件下无限存活</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">66</td>
<td>生殖隔离的基因阻碍交流的分子基础，怎样克服。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">67</td>
<td>为什么不同种子对水的亲水能力不同。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">68</td>
<td>在细胞外模拟DNA复制对基因染色体端粒的影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">69</td>
<td>DNA复制过程中是否缺失一些片段，及与端粒的关系。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">70</td>
<td>非编码区片段的作用，切掉后的影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">71</td>
<td>根尖细胞是否可以进行植物组织培养，培养出来的个体叶绿体怎样形成的。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">72</td>
<td>皮肤生发层细胞，癌细胞，胚胎干细胞等细胞内基因表达的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">73</td>
<td>端粒酶,HIV病毒，逆转录病毒，致癌因子的研究</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">74</td>
<td>能否将细胞呼吸产生的ATP用到光合作用上。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">75</td>
<td>怎样将细胞的亚显微结构镜像放大，便于研究和观察。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">76</td>
<td>怎样提高光合怎样速率，以及人造太阳的研究。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">77</td>
<td>反复研究HIV病毒的致病机理，及HIV的特点怎样加强人体抗体的杀伤力。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">78</td>
<td>人体产生的HIV抗体及免疫细胞的特点，及怎样加强免疫</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">79</td>
<td>怎样控制HIV反转录酶的活性影响HIV的增殖。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">80</td>
<td>加强吞噬细胞对HIV的免疫作用，在人体内找到合适的抗体</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">81</td>
<td>利用其它动物研究不同免疫细胞及抗体对HIV的作用。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">82</td>
<td>研究HIV的起源，以及HIV遗传信息表达出蛋白质的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">83</td>
<td>把HIV病毒的基因整合到细胞中，观察基因表达的情况。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">84</td>
<td>HIV是否能感染其它细胞，如癌细胞，以及为什么能感染T细胞</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">85</td>
<td>破解HIV的遗传信息，以及HIV怎样识别出T细胞</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">86</td>
<td>研究不同人感染HIV后体内产生免疫细胞及抗体的特点，产生的抗体是否相同</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">87</td>
<td>怎样提高免疫能力是癌细胞消除，以及产生癌细胞抗体的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">88</td>
<td>其它动物是否都能被HIV感染，及不同动物产生的免疫反应特点差异</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">89</td>
<td>T细胞完全能清楚是否可以将HIV清除。是否可以经过换雪技术将HIV清除</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">90</td>
<td>在交换血液时，研究识别HIV的药物，将之清除</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">91</td>
<td>癌细胞表面减少 与细胞内内质网高尔基体等有关关系 以及癌细胞是否向外分泌物质</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">92</td>
<td>细胞膜表面蛋白质形成的控制机制 及相关基因控制情况</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">93</td>
<td>不同HIV感染人体，人体产生相应抗体的特点及种类与变异HIV的关系</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">94</td>
<td>DNA复制出现的差错对后代的影响  是否积累影响后代 与动物细胞培养细胞核改变的机制</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">95</td>
<td>叶绿体对强光和弱光的感应机制</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">96</td>
<td>硝化细菌 轮虫  线虫 研究生命历程  生命力前的硫细菌及一些古细菌</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">97</td>
<td>整合细胞细胞质基质能利用氧气吗？ 以及利用氧气的反应及场所出细胞呼吸外</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">98</td>
<td>食草动物与肉食动物身体蛋白质的差异</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">99</td>
<td>TI质粒上的TDNA怎么整合到染色体上的 与病毒整合到染色体上的相似之处</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">100</td>
<td>主动运输必须从低浓度运输到高浓度吗？从高浓度到底浓度为什么不消耗能量？</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">102</td>
<td>叶绿体在植物生长繁殖过程中的变化 以及怎样把基因遗传给子代</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">102</td>
<td>叶绿体基因的来源 根尖细胞无叶绿体经植物组织培养后的植株怎样形成叶绿体的</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">103</td>
<td>记录一片树叶的生命历程变化</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">104</td>
<td>出国参观P3   P4实验室</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">105</td>
<td>脱分化再分化植物细胞的变化</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">106</td>
<td>蛋白质的合成机制及其分类 以及有利核糖体合成的蛋白质与内质网上合成蛋白质的差异</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">107</td>
<td>个细胞器的形成机制起源 生命历程 及其控制的物质</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">108</td>
<td>将软病毒蛋白质的基因序列合成 研究起源</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">109</td>
<td>卵细胞内所含与的特殊物质促进全能型表达</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">110</td>
<td>研究动植物细胞在使用后消化的过程及最终物质的变化</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">111</td>
<td>细胞有无活性的判断及细胞器在细胞外的活性</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">112</td>
<td>植物细胞发育起源，及各种细胞进化。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">113</td>
<td>细胞器的来源及进化，以及联系功能。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">114</td>
<td>原核细胞的发展史，及细胞结构。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">115</td>
<td>生物界的分类，及植物界细分。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">116</td>
<td>研究新的耕作方式，抛弃话费，研究新的增肥农作物</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">117</td>
<td>农作物秸秆在农田里高效率降解，减少化肥污染。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">118</td>
<td>研究新的农田增肥方法，彻底摆脱化肥的需求。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">119</td>
<td>核细胞分裂，转录机制，核糖体的形成。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">120</td>
<td>将目的基因导入细胞的方法改进研究。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">121</td>
<td>植物受精卵细胞初期的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">122</td>
<td>动物配子细胞结构特点，染色体的特异。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">123</td>
<td>减数分裂联会后染色体的变化，全能型的影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">124</td>
<td>动物受精卵及胚胎发育早期细胞的全能性特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">125</td>
<td>细胞全能性的变化与细胞分化的关联。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">126</td>
<td>培育出高效的光合作用农作物，生产酒精。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">127</td>
<td>酒精发酵的改进，用植物秸秆发酵技术改进研究。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">128</td>
<td>植物蒸腾作用是否能净化水，怎样收集水。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">129</td>
<td>研究一些南瓜等藤类植物茎中运输的水的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">130</td>
<td>藤类农作物是否可以净化术，由此改进净水系统。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">131</td>
<td>光合作用的全部过程，完全详细研究。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">132</td>
<td>多倍体染色体联会产配子，及染色体表达的情况。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">133</td>
<td>同源染色体联会的调控，正常细胞诱导联会后变化。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">134</td>
<td>植物细胞动物细胞在人体内怎样被消化，细胞器去向。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">135</td>
<td>核酸 及细胞器怎样消化，及各种细胞器的营养价值</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">136</td>
<td>植物有机物的积累，变化，。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">137</td>
<td>两条互补DNA链表达的蛋白质存在怎样的联系及特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">138</td>
<td>显性基因和隐性基因表达的关系，及控制表达的机制。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">139</td>
<td>具有胚性分生组织细胞特点，染色体及细胞器的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">140</td>
<td>受精卵基因表达与细胞全能性的关系，表达基因的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">141</td>
<td>植物细胞与动物细胞内基因表达的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">142</td>
<td>动手实践植物体细胞杂交及植物组织培养。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">143</td>
<td>人类，动物思维的物质基础及与细胞功能的联系。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">144</td>
<td>神经细胞基因表达的特点，与思维的关系。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">145</td>
<td>植物蛋白与动物蛋白各自的特点，及营养价值。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">146</td>
<td>连续光照对植物光合作用的影响，及净光合作速率的变化</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">147</td>
<td>光合作用与细胞呼吸的联系，相互影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">148</td>
<td>线粒体与叶绿体内核糖体的特点，DNA的特点，相似处。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">149</td>
<td>DNA转录，复制时染色体上的蛋白质变化去向作用。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">150</td>
<td>把一条染色体离在细胞核外基因是否能表达，及影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">151</td>
<td>受精作用时阻止细胞核融合，及后来的变化，是否存活</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">152</td>
<td>细胞核融合的原理，怎样阻止细胞核融合。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">153</td>
<td>植物体细胞杂交与动物细胞融合，受精作用。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">154</td>
<td>细胞核融合的特点，是否相似 怎样阻止细胞核融合</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">155</td>
<td>高等生物是否存在具有两个细胞核的生物体?</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">156</td>
<td>病毒侵入细胞后怎样转录表达，地点 方式 酶</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">157</td>
<td>利用病毒基因的特性能否将核基因分离在细胞核外。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">158</td>
<td>显隐性基因表达出的蛋白质有什么相似特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">159</td>
<td>蛋白质的分类及酶的分类。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">160</td>
<td>配子细胞核与衰老细胞细胞核的差异及特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">161</td>
<td>癌细胞细胞核的特点，基因表达的特点，染色体端粒特点</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">162</td>
<td>细胞生命与个体生命与原癌基因和抑癌基因的关系。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">163</td>
<td>研究染色体端粒学说，比较受精卵，配子，不同细胞端粒</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">164</td>
<td>人工控制核酸的合成，用核酸储存一些信息</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">165</td>
<td>讲线粒体和叶绿体在细胞外培养，是否能长时间存活。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">166</td>
<td>将控制呼吸和光合的核基因导入线粒体和叶绿体，研究</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">167</td>
<td>研究癌细胞的一些基因表达的特点，一些基因对它的影响</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">168</td>
<td>将细胞器分离出怎样表现生物活性。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">169</td>
<td>植物细胞的动物细胞线粒体的相似或起源特点，核酸特点</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">170</td>
<td>不同线粒体和叶绿体基因是否存在很大的差异或联系</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">171</td>
<td>动物细胞的植物细胞内化合物的差异</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">172</td>
<td>动物细胞和植物细胞对环境的适应要求</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">173</td>
<td>不同细胞对PH要求的差异，及PH的影响原因。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">174</td>
<td>动物细胞和植物细胞细胞器之间的差异和联系，相似之处</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">175</td>
<td>不同细胞对外界环境的要求差异及原因。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">176</td>
<td>红细胞无细胞核后特点，能否在适宜条件下无限存活</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">177</td>
<td>生殖隔离的基因阻碍交流的分子基础，怎样克服。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">178</td>
<td>为什么不同种子对水的亲水能力不同。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">179</td>
<td>在细胞外模拟DNA复制对基因染色体端粒的影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">180</td>
<td>DNA复制过程中是否缺失一些片段，及与端粒的关系。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">181</td>
<td>非编码区片段的作用，切掉后的影响。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">182</td>
<td>根尖细胞是否可以进行植物组织培养，培养出来的个体叶绿体怎样形成的。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">183</td>
<td>皮肤生发层细胞，癌细胞，胚胎干细胞等细胞内基因表达的特点。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">184</td>
<td>端粒酶,HIV病毒，逆转录病毒，致癌因子的研究</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">185</td>
<td>能否将细胞呼吸产生的ATP用到光合作用上。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">186</td>
<td>怎样将细胞的亚显微结构镜像放大，便于研究和观察。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">187</td>
<td>怎样提高光合怎样速率，以及人造太阳的研究。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">188</td>
<td>经常使用素食 素食主义者的身体情况，及蔬菜水果对人体的好处及不利影响</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">189</td>
<td>植物熟食与生食营养价值的差别，怎样使用更加健康。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">190</td>
<td>给素食者研究出合理健康的食谱</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">191</td>
<td>肉类蛋白一植物蛋白在人体内消化的过程差别，及脂肪的利用。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">192</td>
<td>人在有困意时脑电波的变化及怎样帮助学生消除困意，与脑电波的关系</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">193</td>
<td>研究水果蔬菜的口感味道酸甜气味与细胞内化学物质的关系，怎样提高质量</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">194</td>
<td>种子储藏脱落酸的影响因素，及休眠种子种脱落酸对种子的影响，原因。</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">195</td>
<td>休眠时间与脱落酸的关系，及怎样控制种子的休眠，及休眠种子细胞代谢特点，基因表达特点</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">196</td>
<td>休眠时间长的种子如莲子细胞内脱落酸的含量，</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">197</td>
<td>细胞对物质运输有选择吸收作用，为什么主动运输若高浓度时则为协助扩散</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">198</td>
<td>离体培养的叶绿体或其他细胞器是否可以长时间存活及独立代谢</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">199</td>
<td>研究硝化细菌和反硝化细菌的特点，及代谢的差异特点</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">200</td>
<td>细胞器的活性与细胞生命的关系，胚胎干细胞细胞/癌细胞器的特点</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">201</td>
<td>双核细胞（双核草履虫）两个细胞核对细胞的控制，及基因表达情况，</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">202</td>
<td>研究豆科植物与根瘤菌共生的机制及结构基础</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">203</td>
<td>研究水葫芦的价值利用，以及怎样应用于污水治理</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">204</td>
<td>研究轮虫和线虫耐低温的特点，及细胞内化合物的特点，蛋白质，，基因表达特点，休眠机制</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">205</td>
<td>抗体基因的数目，以及人类和动物免疫系统的差异，海洋动物免疫系统的特点，差异</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">206</td>
<td>研究怎样提高农作物秸秆的分解后的价值，以及联系微生物研究</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">207</td>
<td>研究轮虫与线虫耐低温的特点及细胞结构的特点，以及细胞内特殊蛋白质的特点，寻找新的应用</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">209</td>
<td>抗体基因的数目及种类，以及人和其他动物相同抗原产生的抗体的差异及原因，以及免疫功能的差异</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">209</td>
<td>分析一些植物种子萌发过程中细胞内化合物的变化</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">210</td>
<td>植物（红薯等）蒸熟过程中细胞内化合物的变化及营养价差异</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">211</td>
<td>黑种人脚为什么是白色的？</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">212</td>
<td>人类喜欢吃其他动物的肉以及一些和稀有的物种，其他动物是否存在喜欢吃人肉的?</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">213</td>
<td>休眠时间很长的生物细胞的特点，基因表达的情况</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">214</td>
<td>膜蛋白是分泌蛋白吗？</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">215</td>
<td>母体为什么对外来胚胎不产生免疫排斥反应，研究应用于器官移植</td>
</tr>
</tbody>
</table>
]]></content>
      <tags>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title>wndr3700v4  刷 openwrt 一些小优化</title>
    <url>/archives/wndr3700v4-openwrt.html</url>
    <content><![CDATA[<h2 id="1-WNDR3700V4-扩展分区大小"><a href="#1-WNDR3700V4-扩展分区大小" class="headerlink" title="1. WNDR3700V4 扩展分区大小"></a>1. WNDR3700V4 扩展分区大小</h2><p>刷完<code>OpenWrt-18.06.0</code>后，根分区只利用了 14 MB，大多数帖子都是通过修改源码分区表，重新编译固件而全部利用剩余空间，不过这样做可以一劳永逸。但很容易变砖，而且刷回原厂变砖的概率极大。索性还是不动分区表，直接重新新建一个分区即可。重新建立一个分区坑也比较多😂</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@OpenWrt:~<span class="comment"># df -h</span></span><br><span class="line">Filesystem                Size      Used Available Use% Mounted on</span><br><span class="line">/dev/root                 2.5M      2.5M         0 100% /rom</span><br><span class="line">tmpfs                    61.0M      6.7M     54.4M  11% /tmp</span><br><span class="line">/dev/ubi0_1              14.0M      8.1M      5.1M  61% /overlay</span><br><span class="line">overlayfs:/overlay       14.0M      8.1M      5.1M  61% /</span><br><span class="line">tmpfs                   512.0K         0    512.0K   0% /dev</span><br></pre></td></tr></table></figure>
<p><a href="http://geekwagner.blogspot.com/2019/02/create-ubifs-volumes-in-linux-openwrt.html" target="_blank" rel="noopener">Create ubifs volumes in Linux (OpenWRT</a></p>
<p>When using a router flashed with OpenWRT, you may find that the capacity of the filesystem is much smaller than the real capacity. For example, the router I use is Netgear WNDR4300 which has a 128MB Nand flash. But when using the ‘df -h’ command to inspect the space usage status, I surprisingly found that the space of the total mounting point ‘/‘ is only 14MB.</p>
<p>So to find out the reason and try to expand usable space, I used the command “dmesg” and “cat /proc/mtd” to collect the information of mtd devices.</p>
<p>Then, make the ubifs I need.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ubiformat /dev/mtd11 </span><br><span class="line">ubiattach -p /dev/mtd11 </span><br><span class="line">ubimkvol /dev/ubi1 -N data -s 90MiB</span><br><span class="line">mount -t ubifs ubi1:data /opt</span><br><span class="line">Finally, add the following lines to /etc/rc.local to make it mount when router starts.</span><br><span class="line">ubiattach -p /dev/mtd11</span><br><span class="line">mount -t ubifs ubi1:data /opt</span><br></pre></td></tr></table></figure>
<p>完活后的分区信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@OpenWrt:~<span class="comment"># df -h</span></span><br><span class="line">Filesystem                Size      Used Available Use% Mounted on</span><br><span class="line">/dev/root                 2.5M      2.5M         0 100% /rom</span><br><span class="line">tmpfs                    61.0M      6.7M     54.4M  11% /tmp</span><br><span class="line">/dev/ubi0_1              14.0M      8.1M      5.1M  61% /overlay</span><br><span class="line">overlayfs:/overlay       14.0M      8.1M      5.1M  61% /</span><br><span class="line">tmpfs                   512.0K         0    512.0K   0% /dev</span><br><span class="line">ubi1:data                81.4M      4.9M     72.3M   6% /opt</span><br></pre></td></tr></table></figure>
<h2 id="2-修改-opkg-默认安装路径"><a href="#2-修改-opkg-默认安装路径" class="headerlink" title="2.修改 opkg 默认安装路径"></a>2.修改 opkg 默认安装路径</h2><p>参照官方 Wiki  <a href="https://openwrt.org/zh/docs/techref/opkg" target="_blank" rel="noopener">opkg</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/opkg.conf</span><br><span class="line">src/gz snapshots http://downloads.openwrt.org/snapshots/trunk/ar71xx/packages</span><br><span class="line">dest root /</span><br><span class="line">dest opt /opt</span><br><span class="line">lists_dir ext /var/opkg-lists</span><br><span class="line">option overlay_root /overlay</span><br><span class="line"></span><br><span class="line">opkg install zsh git -d opt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加环境变量</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="string">"/opt/lib:/opt/usr/lib"</span></span><br><span class="line"><span class="built_in">export</span> PATH=/usr/bin:/usr/sbin:/bin:/sbin:/opt/usr/bin:/opt/bin</span><br></pre></td></tr></table></figure>
<h2 id="3-安装-frpc-并设置开机自启"><a href="#3-安装-frpc-并设置开机自启" class="headerlink" title="3.安装 frpc 并设置开机自启"></a>3.安装 frpc 并设置开机自启</h2><p>先去现在自己路由器架构相同的编译 ipk 包，如果不清楚自己路由器芯片的架构，当你使用opkg install 安装软件的时候软件源的 url 里有你的芯片架构。<br><a href="https://github.com/kuoruan/openwrt-frp/releases" target="_blank" rel="noopener">openwrt-frp</a> </p>
<p>我的 wndr3700v4 是 mips_24kc 的架构</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://github.com/kuoruan/openwrt-frp/releases/download/v0.29.0-1/frpc_0.29.0-1_mips_24kc.ipk</span><br><span class="line">opkg install frpc_0.29.0-1_mips_24kc.ipk -d opt</span><br><span class="line">ln -s /opt/usr/bin/frpc /usr/bin/frpc</span><br></pre></td></tr></table></figure>
<p>可能会报错 😂 需要安装 <code>libustream-openssl  ca-bundle ca-certificates</code> 这三个包</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@OpenWrt:/opt<span class="comment"># wget https://github.com/kuoruan/openwrt-frp/releases/download/v0.29.0-1/frpc_0.29.0-1_mips_24kc.ipk</span></span><br><span class="line">wget: SSL support not available, please install one of the libustream-.*[ssl|tls] packages as well as the ca-bundle and ca-certificates packages.</span><br><span class="line"></span><br><span class="line">opkg install libustream-openssl  ca-bundle ca-certificates</span><br></pre></td></tr></table></figure>
<h2 id="4-安装git"><a href="#4-安装git" class="headerlink" title="4.安装git"></a>4.安装git</h2><p>根分区剩余空间太小了，于是就安装在单独的分区 opt 分区 下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">opkg install git -d opt</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /opt/usr/bin/git-upload-pack /usr/bin/git-upload-pack</span><br><span class="line">ln -s /opt/usr/bin/git-upload-archive /usr/bin/git-upload-archive</span><br><span class="line">ln -s /opt/usr/bin/git-receive-pack /usr/bin/git-receive-pack</span><br><span class="line">ln -s /opt/usr/bin/git-receive-pack /usr/bin/git</span><br></pre></td></tr></table></figure>
<h2 id="5-https"><a href="#5-https" class="headerlink" title="5. https"></a>5. https</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">opkg install libustream-openssl  ca-bundle ca-certificates</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>openwrt</tag>
      </tags>
  </entry>
  <entry>
    <title>监控某个端口是否存活并发短信报警</title>
    <url>/archives/frps-prot-monitor.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近国庆了，需要回家一趟。但是有点不放心自己的主机，毕竟是辛辛苦苦搬砖买来的主机嘛。而且房东那里也不太安全，所以干脆想着通过 frp 内网穿透把主机的 3389 端口转发到我的服务器上，在服务器上检测这个端口的存活状态，设置为定时任务。一旦检测到端口不存活了，就发短信通知我。</p>
<p>由于国内的短信服务都必须需要实名认证加备案，真鸡儿操蛋，老子最恶心这一套了，备案你个锤子。所以还是用国外的服务吧。找了一会找到了 <a href="https://www.twilio.com/" target="_blank" rel="noopener">https://www.twilio.com</a> ，能给国内的手机号发短信，不过需要 visa 信用卡验证和一个 +1 的手机号码，咱手里这两个都不缺，索性注册使用了吧。</p>
<h2 id="使用-twilio"><a href="#使用-twilio" class="headerlink" title="使用 twilio"></a>使用 twilio</h2><h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h3><p>我的 twilio 账号是四个月前注册的了，注册过程也忘了，大致就是填写邮箱账号、设置密码、绑定信用卡、验证 +1 手机号，巴拉巴拉。</p>
<p>注册绑定信用卡赠送 10 $，这些足够发送 1000 条短信了，足够咱使用了😂</p>
<p><img src="../img/1569744256905.png" alt="1569744256905"></p>
<p><img src="../img/image-20191029173931185.png" alt="image-20191029173931185"></p>
<p><img src="../img/image-20191029174001829.png" alt="image-20191029174001829"></p>
<h3 id="验证手机号"><a href="#验证手机号" class="headerlink" title="验证手机号"></a>验证手机号</h3><p>只有验证手机号才能分配一个 twilio 的的手机号，用来发送短信</p>
<p>发送短信过程比较长，耐心等个三四分钟</p>
<h3 id="发送给短信测试"><a href="#发送给短信测试" class="headerlink" title="发送给短信测试"></a>发送给短信测试</h3><p>验证完手机号后，进入控制台 <a href="https://www.twilio.com/console" target="_blank" rel="noopener">console</a> ，</p>
<p><img src="../img/1569744103630.png" alt="1569744103630"></p>
<p>官方已经给出了各个语言的示例代码  <a href="https://www.twilio.com/docs/sms/send-messages" target="_blank" rel="noopener">Sending Messages</a> </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">EXCLAMATION_MARK=<span class="string">'!'</span></span><br><span class="line">curl -X POST https://api.twilio.com/2010-04-01/Accounts/ACe4a6468bf04cd72fb4ffda94718c3749/Messages.json \</span><br><span class="line">--data-urlencode <span class="string">"Body=Hi there<span class="variable">$EXCLAMATION_MARK</span>"</span> \</span><br><span class="line">--data-urlencode <span class="string">"From=+15017122661"</span> \</span><br><span class="line">--data-urlencode <span class="string">"To=+15558675310"</span> \</span><br><span class="line">-u ACe4a6468bf04cd72fb4ffda94718c3749:your_auth_token</span><br></pre></td></tr></table></figure>
<p>发送成功后会提示下面的</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"account_sid"</span>: <span class="string">"ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"</span>,</span><br><span class="line">  <span class="attr">"api_version"</span>: <span class="string">"2010-04-01"</span>,</span><br><span class="line">  <span class="attr">"body"</span>: <span class="string">"Hi there!"</span>,</span><br><span class="line">  <span class="attr">"date_created"</span>: <span class="string">"Thu, 30 Jul 2015 20:12:31 +0000"</span>,</span><br><span class="line">  <span class="attr">"date_sent"</span>: <span class="string">"Thu, 30 Jul 2015 20:12:33 +0000"</span>,</span><br><span class="line">  <span class="attr">"date_updated"</span>: <span class="string">"Thu, 30 Jul 2015 20:12:33 +0000"</span>,</span><br><span class="line">  <span class="attr">"direction"</span>: <span class="string">"outbound-api"</span>,</span><br><span class="line">  <span class="attr">"error_code"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"error_message"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"from"</span>: <span class="string">"+14155552345"</span>,</span><br><span class="line">  <span class="attr">"messaging_service_sid"</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">"num_media"</span>: <span class="string">"0"</span>,</span><br><span class="line">  <span class="attr">"num_segments"</span>: <span class="string">"1"</span>,</span><br><span class="line">  <span class="attr">"price"</span>: <span class="string">"-0.00750"</span>,</span><br><span class="line">  <span class="attr">"price_unit"</span>: <span class="string">"USD"</span>,</span><br><span class="line">  <span class="attr">"sid"</span>: <span class="string">"MMXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"</span>,</span><br><span class="line">  <span class="attr">"status"</span>: <span class="string">"sent"</span>,</span><br><span class="line">  <span class="attr">"subresource_uris"</span>: &#123;</span><br><span class="line">    <span class="attr">"media"</span>: <span class="string">"/2010-04-01/Accounts/ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Messages/SMXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Media.json"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"to"</span>: <span class="string">"+14155552345"</span>,</span><br><span class="line">  <span class="attr">"uri"</span>: <span class="string">"/2010-04-01/Accounts/ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Messages/SMXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.json"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="设置权限"><a href="#设置权限" class="headerlink" title="设置权限"></a>设置权限</h3><p>如果你是要 curl 命令发送短信后提示下面的错误，是因为你的账号没有开发 TO 手机号的区域限制</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">"code"</span>: 20003, <span class="string">"detail"</span>: <span class="string">"Your AccountSid or AuthToken was incorrect."</span>, <span class="string">"message"</span>: <span class="string">"Authentication Error - No credentials provided"</span>, <span class="string">"more_info"</span>: <span class="string">"https://www.twilio.com/docs/errors/20003"</span>, <span class="string">"status"</span>: 401&#125;curl: (6) Could not resolve host: lls</span><br></pre></td></tr></table></figure>
<p> 进入到这个页面 <a href="https://www.twilio.com/console/sms/settings/geo-permissions" target="_blank" rel="noopener">geo-permissions)</a> ，在对应的国家区号上✔就行。</p>
<h2 id="检测端口"><a href="#检测端口" class="headerlink" title="检测端口"></a>检测端口</h2><p>直接使用 netstat 检测就可以，写的比较简单</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">check_port</span></span>() &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Checking instance port ..."</span></span><br><span class="line">        netstat -tlpn | grep <span class="string">"\b<span class="variable">$1</span>\b"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> check_port 3389</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"PC NOW UP"</span> &gt;&gt; /root/PC_STATUS</span><br><span class="line">        TZ=UTC-8 date +<span class="string">"%Y-%m-%d %H:%M:%S"</span> &gt;&gt; /root/PC_STATUS</span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        curl</span><br></pre></td></tr></table></figure>
<h2 id="定时任务"><a href="#定时任务" class="headerlink" title="定时任务"></a>定时任务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">*/10 * * * * /root/check.sh</span><br></pre></td></tr></table></figure>
<p>每隔十分钟执行一次下面的脚本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">check_port</span></span>() &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Checking instance port ..."</span></span><br><span class="line">        netstat -tlpn | grep <span class="string">"\b<span class="variable">$1</span>\b"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> check_port 3389</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"PC NOW UP"</span> &gt;&gt; /root/PC_STATUS</span><br><span class="line">        TZ=UTC-8 date +<span class="string">"%Y-%m-%d %H:%M:%S"</span> &gt;&gt; /root/PC_STATUS</span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        curl <span class="string">'https://api.twilio.com/2010-04-01/Accounts/a99/Messages.json'</span> -X POST \</span><br><span class="line">        --data-urlencode <span class="string">'To=+86110110110110'</span> \</span><br><span class="line">        --data-urlencode <span class="string">'From=+1110110110'</span> \</span><br><span class="line">        --data-urlencode <span class="string">'Body=PC DOWN !'</span> \</span><br><span class="line">        -u <span class="comment"># 修改成你自己的</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>端口存活的状态下就输出到日志，端口没存活的话就发短信</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@sg-02 ~</span><br><span class="line">╰─<span class="comment"># cat PC_STATUS</span></span><br><span class="line">PC NOW UP</span><br><span class="line">2019-09-29 15:42:52</span><br><span class="line">PC NOW UP</span><br><span class="line">2019-09-29 15:50:01</span><br><span class="line">PC NOW UP</span><br><span class="line">2019-09-29 16:00:01</span><br><span class="line">PC NOW UP</span><br><span class="line">2019-09-29 16:10:01</span><br><span class="line">PC NOW UP</span><br><span class="line">2019-09-29 16:20:01</span><br><span class="line">PC NOW UP</span><br><span class="line">2019-09-29 16:30:01</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>monitor</tag>
      </tags>
  </entry>
  <entry>
    <title>Lua + Redis 对 nginx 做动态路由</title>
    <url>/archives/fastdfs-lua-redis.html</url>
    <content><![CDATA[<h2 id="0-项目背景"><a href="#0-项目背景" class="headerlink" title="0.项目背景"></a>0.项目背景</h2><p>由于 FastDFS 分布式文件存储在上传文件时不保留原文件名，当上传完文件后会返回如下面格式的文件 ID。在文件 ID 中包含了文件所在的组，二级目录，以及由客户端 IP 、时间戳、文件大小生成的 base64 编码文件名。客户端数据库里存储这个着文件 ID ，且只能通过文件 ID 来访问获取文件。如果其他系统想要访问 FastDFS 文件存储就必须从上传客户端保存的数据库中获取该文件的文件 ID 。这样增加了系统的耦合程度，也不利于后续文件存储的迁移和运维。由于 FastDFS 是将文件直接存放在本地磁盘，并不对文件进行分块、合并操作，所以我们可以直接让 nginx 去请求获取本地磁盘上的文件，不经过查询客户端数据库获取文件 ID，无需经过 FastDFS 也可以获取到文件。</p>
<p><strong>文件 ID 的组成</strong></p>
<p><img src="../img/1564650409284.png" alt="1564650409284"></p>
<p><code>group1</code> 是文件所在组名</p>
<p><code>M00</code> 是文件所在的 storage 服务器上的分区</p>
<p> <code>00/05</code> 就是文件所在的一级子目录/二级子目录，是文件所在的真实路径</p>
<p><code>Cgpr6F1A7O6ASWv9AAA-az6haWc850.jpg</code> 是新生成的文件名</p>
<p><strong>文件存储的根目录，由 <code>base_path=</code> 配置参数设定，data 目录为文件存储目录，logs 目录存储日志</strong></p>
<p><img src="../img/1564706728602.png" alt="1564706728602"></p>
<p><strong>文件存储的一级子目录</strong></p>
<p><img src="../img/1564706752461.png" alt="1564706752461"></p>
<p><strong>文件存储的二级子目录</strong></p>
<p><img src="../img/1564706786739.png" alt="1564706786739"></p>
<p><strong>FastDFS 存储真实的文件，不对文件做分块、合并</strong></p>
<p><img src="../img/1564706883566.png" alt="1564706883566"></p>
<p><strong>为方便测试，在这里打开了 <code>nginx</code> 列出目录选项</strong></p>
<p><img src="../img/1564708725763.png" alt="1564708725763"></p>
<p><img src="../img/1564708780114.png" alt="1564708780114"></p>
<h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><h2 id="1-获取原文件名和新生成的文件-ID"><a href="#1-获取原文件名和新生成的文件-ID" class="headerlink" title="1. 获取原文件名和新生成的文件 ID"></a>1. 获取原文件名和新生成的文件 ID</h2><p>在客户端(C语言版)的日志中提取出以下格式的日志，其他版本的客户端可以在数据库中获取，该日志记录了原文件名和上传后由 FastDFS 存储服务生成的文件 ID 。</p>
<p><img src="../img/1564650287719.png" alt="1564650287719"></p>
<p>需要在原文件名前加上一个 <figure class="highlight plain"><figcaption><span>作为 请求的 `uri`头 ,转换后的格式如下</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">![1564650709667](../img/1564650709667.png)</span><br><span class="line"></span><br><span class="line">### 2. 将数据导入 Redis</span><br><span class="line"></span><br><span class="line">使用 shell 脚本将原文件名（也可以自定义）作为 KEY ，文件 ID 为 VALUE 导入  Redis  数据库</span><br><span class="line"></span><br><span class="line">`awk &apos;BEGIN&#123; FS=&quot; &quot;&#125;&#123;arr[$NF]=$1&#125;END&#123;for( k in arr)&#123; cmd=d=&quot;redis-cli set &quot;k&quot; &quot;arr[k];system(cmd)&#125;&#125;&apos; url.log`</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line"># 通过脚本导入</span><br><span class="line">#!/bin/bash</span><br><span class="line"># import data</span><br><span class="line">cat $1 | while read line</span><br><span class="line">do</span><br><span class="line">    key=$(echo $line | cut -d &apos; &apos; -f2)</span><br><span class="line">    value=$(echo $line | cut -d &apos; &apos; -f1)</span><br><span class="line">    redis-cli set $key $value </span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 10W 条 K/V 键值对占用不到15MB 内存</span></span><br><span class="line">╭─root@ubuntu-238 /tmp</span><br><span class="line">╰─# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; info</span><br><span class="line"><span class="comment"># Memory</span></span><br><span class="line">used_memory:14690296</span><br><span class="line">used_memory_human:14.01M</span><br><span class="line">used_memory_rss:18280448</span><br><span class="line">used_memory_rss_human:17.43M</span><br><span class="line">used_memory_peak:18094392</span><br><span class="line">used_memory_peak_human:17.26M</span><br><span class="line">used_memory_peak_perc:81.19%</span><br><span class="line">used_memory_overhead:5881110</span><br><span class="line">used_memory_startup:782504</span><br><span class="line">used_memory_dataset:8809186</span><br><span class="line">used_memory_dataset_perc:63.34%</span><br><span class="line">total_system_memory:4136931328</span><br><span class="line">total_system_memory_human:3.85G</span><br><span class="line">used_memory_lua:37888</span><br><span class="line">used_memory_lua_human:37.00K</span><br><span class="line">maxmemory:0</span><br><span class="line">maxmemory_human:0B</span><br><span class="line">maxmemory_policy:noeviction</span><br><span class="line">mem_fragmentation_ratio:1.24</span><br><span class="line">mem_allocator:jemalloc-3.6.0</span><br><span class="line">active_defrag_running:0</span><br><span class="line">lazyfree_pending_objects:0</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; get /000001.jpg</span><br><span class="line">"group1/M00/00/05/Cgpr6F1A6oOARgfgAAAdDglAWL4368.jpg"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>
<h3 id="3-编译-nginx-加入-lua-和-lua-Redis-模块"><a href="#3-编译-nginx-加入-lua-和-lua-Redis-模块" class="headerlink" title="3. 编译 nginx 加入 lua 和 lua-Redis 模块"></a>3. 编译 nginx 加入 lua 和 lua-Redis 模块</h3><p><strong>3.1.1 编译环境</strong> </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y gcc g++ gcc-c++  zlib zlib-devel openssl openssl--devel pcre pcre-devel</span><br></pre></td></tr></table></figure>
<p><strong>3.1.2 编译 luajit</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编译安装 luajit</span></span><br><span class="line">wget http://luajit.org/download/LuaJIT-2.1.0-beta2.tar.gz</span><br><span class="line">tar zxf LuaJIT-2.1.0-beta2.tar.gz</span><br><span class="line">cd LuaJIT-2.1.0-beta2</span><br><span class="line">make PREFIX=/usr/local/luajit</span><br><span class="line">make install PREFIX=/usr/local/luajit</span><br></pre></td></tr></table></figure>
<p><strong>3.1.3 下载 ngx_devel_kit（NDK）模块</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/simpl/ngx_devel_kit/archive/v0.2.19.tar.gz</span><br><span class="line">tar -xzvf v0.2.19.tar.gz</span><br></pre></td></tr></table></figure>
<p><strong>3.1.4 下载 lua-nginx-module 模块</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/openresty/lua-nginx-module/archive/v0.10.2.tar.gz</span><br><span class="line">tar -xzvf v0.10.2.tar.gz</span><br></pre></td></tr></table></figure>
<p><strong>3.1.5 编译 nginx</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar zxvf nginx-1.15.1.tar.gz</span><br><span class="line">cd nginx-1.15.1/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> tell nginx<span class="string">'s build system where to find LuaJIT 2.1:</span></span></span><br><span class="line">export LUAJIT_LIB=/usr/local/luajit/lib</span><br><span class="line">export LUAJIT_INC=/usr/local/luajit/include/luajit-2.1</span><br><span class="line"></span><br><span class="line">./configure --prefix=/usr/local/nginx --with-ld-opt="-Wl,-rpath,/usr/local/luajit/lib" --with-http_stub_status_module --with-http_ssl_module --with-http_realip_module --with-http_gzip_static_module --with-debug \</span><br><span class="line">--add-module=/usr/local/src/nginx_lua_tools/ngx_devel_kit-0.2.19</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重新编译</span></span><br><span class="line">./configure (之前安装的参数) --with-ld-opt="-Wl,-rpath,/usr/local/luajit/lib" --add-module=/path/to/ngx_devel_kit --add-module=/path/to/lua-nginx-module</span><br><span class="line">--add-module后参数路径根据解压路径为准</span><br><span class="line">make -j4 &amp; make install</span><br><span class="line"><span class="meta">#</span><span class="bash"> --with-debug <span class="string">"调试日志"</span>默认是禁用的，因为它会引入比较大的运行时开销，让 Nginx 服务器显著变慢。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启用 --with-debug 选项重新构建好调试版的 Nginx 之后，还需要同时在配置文件中通过标准的 error_log 配置指令为错误日志使用 debug 日志级别（这同时也是最低的日志级别）</span></span><br></pre></td></tr></table></figure>
<h3 id="4-配置-nginx"><a href="#4-配置-nginx" class="headerlink" title="4. 配置 nginx"></a>4. 配置 nginx</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    </span><br><span class="line">    location ~/group[0-9]/ &#123;</span><br><span class="line">    autoindex on;</span><br><span class="line">    root /home/dfs/data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location = /Redis &#123;</span><br><span class="line">        internal;</span><br><span class="line">        set_unescape_uri $key $arg_key;</span><br><span class="line">        Redis2_query get $key;</span><br><span class="line">        Redis2_pass 127.0.0.1:6379;</span><br><span class="line">    &#125;</span><br><span class="line"># 此处根据业务的需求来写正则表达式，一定要个 redis 里的 KEY  对应上</span><br><span class="line">    location  ~/[0-9].*\.(gif|jpg|jpeg|png)$ &#123;</span><br><span class="line">        set $target &apos;&apos;;</span><br><span class="line">        access_by_lua &apos;</span><br><span class="line"># 使用 nginx 的内部参数 ngx.var.uri 来获取请求的 uri 地址，如 /000001.jpg </span><br><span class="line">            local key = ngx.var.uri</span><br><span class="line"># 根据正则匹配到 KEY ，从 redis 数据库里获取文件 ID (路径和文件名)</span><br><span class="line">            local res = ngx.location.capture(</span><br><span class="line">                &quot;/Redis&quot;, &#123; args = &#123; key = key &#125; &#125;</span><br><span class="line">            )</span><br><span class="line">            if res.status ~= 200 then</span><br><span class="line">                ngx.log(ngx.ERR, &quot;Redis server returned bad status: &quot;,</span><br><span class="line">                    res.status)</span><br><span class="line">                ngx.exit(res.status)</span><br><span class="line">            end</span><br><span class="line">            if not res.body then</span><br><span class="line">                ngx.log(ngx.ERR, &quot;Redis returned empty body&quot;)</span><br><span class="line">                ngx.exit(500)</span><br><span class="line">            end</span><br><span class="line">            local parser = require &quot;Redis.parser&quot;</span><br><span class="line">            local filename, typ = parser.parse_reply(res.body)</span><br><span class="line">            if typ ~= parser.BULK_REPLY or not server then</span><br><span class="line">                ngx.log(ngx.ERR, &quot;bad Redis response: &quot;, res.body)</span><br><span class="line">                ngx.exit(500)</span><br><span class="line">            end</span><br><span class="line"></span><br><span class="line">            ngx.var.target = filename</span><br><span class="line">        &apos;;</span><br><span class="line">        proxy_pass http://10.20.172.196/$target;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="5-测试访问"><a href="#5-测试访问" class="headerlink" title="5. 测试访问"></a>5. 测试访问</h3><p><strong>5.1.1 拼接图片文件的 <code>url</code> 地址</strong></p>
<p><img src="../img/1564712537149.png" alt="1564712537149"></p>
<p><strong>5.1.2 通过浏览器访问</strong></p>
<p><img src="../img/1564712890280.png" alt="1564712890280"></p>
<p><strong>5.1.3 使用 wget 和 xargs 并行下载</strong></p>
<p><img src="../img/1564650129311.png" alt="1564650129311"></p>
<h3 id="6-不足和改进方案"><a href="#6-不足和改进方案" class="headerlink" title="6. 不足和改进方案"></a>6. 不足和改进方案</h3><p><strong>优势</strong></p>
<p>此方案的好处就是可以从过自定义访问的文件名来获取已经上传的文件，自定义的文件名根据业务的需求来设定。在 nginx location 模块写相应的正则表达式。从而将 FastDFS 与上传客户端解耦，使得访问文件无需依赖 FastDFS 存储，减少运维成本。同时由于使用的是 Redis 数据库和内部转发，对访问的客户端来说是透明的，性能损耗几乎可以忽略不计。</p>
<p><strong>6.1 不足</strong></p>
<ol>
<li>由于 Redis 数据库里的数据需要从客户端日志或数据库中导入，所以无法对 Redis 数据库进行实时更新，如果对上传后的文件进行了修改或删除操作，无法更新到 Redis 数据库中。</li>
<li>需要重新编译安装 nginx 加入 lua-nginx 模块、还需要安装 Redis 数据库</li>
</ol>
<p><strong>6.2 改进</strong></p>
<ol>
<li><p>修改 FastDFS 日志输出的内容，添加元文件名字段，根据日志的操作记录对 Redis 进行增删改查</p>
<p> 通过源码可知，FastDFS 在日志中记录了文件的操作类型，可以根据这些类型对 Redis 数据库进行增删改查，从而可以监控日志的而输出来对 Redis 数据库进行增删改查。</p>
 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//storage access log actions</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_UPLOAD_FILE    <span class="meta-string">"upload"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_DOWNLOAD_FILE  <span class="meta-string">"download"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_DELETE_FILE    <span class="meta-string">"delete"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_GET_METADATA   <span class="meta-string">"get_metadata"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_SET_METADATA   <span class="meta-string">"set_metadata"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_MODIFY_FILE    <span class="meta-string">"modify"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_APPEND_FILE    <span class="meta-string">"append"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_TRUNCATE_FILE  <span class="meta-string">"truncate"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_LOG_ACTION_QUERY_FILE     <span class="meta-string">"status"</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>仔细阅读了 FastDFS  storage 模块的源代码后发现， FastDFS 服务端是不保存原文件名的，而且在相应的文件属性结构体里也未包含原文件名。需要修改源码才能将原文件名输出到日志，难度较大。</p>
</li>
</ol>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">	<span class="keyword">bool</span> if_gen_filename;	  <span class="comment">//if upload generate filename</span></span><br><span class="line">	<span class="keyword">char</span> file_type;           <span class="comment">//regular or link file</span></span><br><span class="line">	<span class="keyword">bool</span> if_sub_path_alloced; <span class="comment">//if sub path alloced since V3.0</span></span><br><span class="line">	<span class="keyword">char</span> master_filename[<span class="number">128</span>];</span><br><span class="line">	<span class="keyword">char</span> file_ext_name[FDFS_FILE_EXT_NAME_MAX_LEN + <span class="number">1</span>];</span><br><span class="line">	<span class="keyword">char</span> formatted_ext_name[FDFS_FILE_EXT_NAME_MAX_LEN + <span class="number">2</span>];</span><br><span class="line">	<span class="keyword">char</span> prefix_name[FDFS_FILE_PREFIX_MAX_LEN + <span class="number">1</span>];</span><br><span class="line">	<span class="keyword">char</span> group_name[FDFS_GROUP_NAME_MAX_LEN + <span class="number">1</span>];  	<span class="comment">//the upload group name</span></span><br><span class="line">	<span class="keyword">int</span> start_time;		<span class="comment">//upload start timestamp</span></span><br><span class="line">	FDFSTrunkFullInfo trunk_info;</span><br><span class="line">	FileBeforeOpenCallback before_open_callback;</span><br><span class="line">	FileBeforeCloseCallback before_close_callback;</span><br><span class="line">&#125; StorageUploadInfo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">	<span class="keyword">char</span> op_flag;</span><br><span class="line">	<span class="keyword">char</span> *meta_buff;</span><br><span class="line">	<span class="keyword">int</span> meta_bytes;</span><br><span class="line">&#125; StorageSetMetaInfo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">	<span class="keyword">char</span> filename[MAX_PATH_SIZE + <span class="number">128</span>];  	<span class="comment">//full filename</span></span><br><span class="line">	<span class="comment">/* FDFS logic filename to log not including group name */</span></span><br><span class="line">	<span class="keyword">char</span> fname2log[<span class="number">128</span>+<span class="keyword">sizeof</span>(FDFS_STORAGE_META_FILE_EXT)];</span><br><span class="line">	<span class="keyword">char</span> op;            <span class="comment">//w for writing, r for reading, d for deleting etc.</span></span><br><span class="line">	<span class="keyword">char</span> sync_flag;     <span class="comment">//sync flag log to binlog</span></span><br><span class="line">	<span class="keyword">bool</span> calc_crc32;    <span class="comment">//if calculate file content hash code</span></span><br><span class="line">	<span class="keyword">bool</span> calc_file_hash;      <span class="comment">//if calculate file content hash code</span></span><br><span class="line">	<span class="keyword">int</span> open_flags;           <span class="comment">//open file flags</span></span><br><span class="line">	<span class="keyword">int</span> file_hash_codes[<span class="number">4</span>];   <span class="comment">//file hash code</span></span><br><span class="line">	<span class="keyword">int64_t</span> crc32;            <span class="comment">//file content crc32 signature</span></span><br><span class="line">	MD5_CTX md5_context;</span><br><span class="line">	<span class="keyword">union</span></span><br><span class="line">	&#123;</span><br><span class="line">		StorageUploadInfo upload;</span><br><span class="line">		StorageSetMetaInfo setmeta;</span><br><span class="line">	&#125; extra_info;</span><br><span class="line">	<span class="keyword">int</span> dio_thread_index;		<span class="comment">//dio thread index</span></span><br><span class="line">	<span class="keyword">int</span> timestamp2log;		<span class="comment">//timestamp to log</span></span><br><span class="line">	<span class="keyword">int</span> delete_flag;     <span class="comment">//delete file flag</span></span><br><span class="line">	<span class="keyword">int</span> create_flag;    <span class="comment">//create file flag</span></span><br><span class="line">	<span class="keyword">int</span> buff_offset;    <span class="comment">//buffer offset after recv to write to file</span></span><br><span class="line">	<span class="keyword">int</span> fd;         <span class="comment">//file description no</span></span><br><span class="line">	<span class="keyword">int64_t</span> start;  <span class="comment">//the start offset of file</span></span><br><span class="line">	<span class="keyword">int64_t</span> <span class="built_in">end</span>;    <span class="comment">//the end offset of file</span></span><br><span class="line">	<span class="keyword">int64_t</span> offset; <span class="comment">//the current offset of file</span></span><br><span class="line">	FileDealDoneCallback done_callback;</span><br><span class="line">	DeleteFileLogCallback log_callback;</span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">tv_deal_start</span>;</span> <span class="comment">//task deal start tv for access log</span></span><br><span class="line">&#125; StorageFileContext;</span><br></pre></td></tr></table></figure>
<p><strong>通过 FastDFS 日志记录的文件操作类型来实时更新 Redis 数据库</strong></p>
<p><img src="../img/1564716508129.png" alt="1564716508129"></p>
]]></content>
      <tags>
        <tag>FastDFS</tag>
        <tag>nginx</tag>
        <tag>lua</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 部署 FastDFS</title>
    <url>/archives/docker-deploy-fastdfs.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>如果你的 FastDFS 文件系统需要高可用，需要部署在多台机器上的话，并且你的这些服务器上只跑 FastDFS 这个服务，那么 FastDFS 可能并不适合用 Docker 来部署，按照官方文档直接部署在机器上就可以，没必要采用容器来部署。其实 FastDFS 并不适合容器化部署，因为 tracker 服务器向 storage 服务器报告自己的 IP， 而这个 IP 是容器内的 IP 。是 Docker 的一个私有 IP 段，这将导致客户端无法访问 storage 服务器。当然如果使用 host 网络或者能打通客户端到 storage 的网络解决方案，比如 flannel ，calico 等，这都可以，在 Kubernetes 基于服务发现，客户端也可以访问到 storage 服务器。</p>
<p>那么 FastDFS 采用 Docker 部署适用于什么场景呢？其实比较适合中小型的项目，对高可用，高性能要求不大的情况下。或者将 FastDFS 所有的服务封装在一个容器里运行，和其他服务一起使用 docker-compose 启动，这样用再适合不过了。我的项目就是这种场景，由于服务器资源有限，不可能去单独部署一个 FastDFS 服务器集群，巴拉巴拉整个高可用。所有的项目组件都采用 Docker 部署在一台机器上，FastDFS 里的  nginx 也是没有单独去部署，和 tracker、storage 服务器一起装在一个容器里。为了节省资源没得办法😂</p>
<h2 id="构建-docker-镜像"><a href="#构建-docker-镜像" class="headerlink" title="构建 docker 镜像"></a>构建 docker 镜像</h2><p>官方给出了两种构建 docker 镜像的方式，但是我感觉都不好，一是使用的 的是 centos 基础镜像构建，构建出来的大小将近，根本就不用区分本地构建或者网络构建。你构建的整个过程都要都需要连接外网下载构建的包之类的，还用区分什么网络构建和本地构建？所以在这里我们仅仅需要准备配置文件即可。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> ╭─root@docker-230 ~/root/container/fastdfs/fastdfs/docker/dockerfile_network ‹master›</span><br><span class="line">╰─<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">fastdfs             centos              c1488537c23c        8 seconds ago       483MB</span><br></pre></td></tr></table></figure>
<h3 id="准备配置文件"><a href="#准备配置文件" class="headerlink" title="准备配置文件"></a>准备配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将所有的配置文件一并放到 conf 目录下</span></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">mkdir  -p fastdfs/conf</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/happyfish100/fastdfs.git --depth 1</span><br><span class="line">cp -rf fastdfs/docker/dockerfile_local/conf/* conf</span><br><span class="line">cp fastdfs/docker/dockerfile_local/fastdfs.sh conf</span><br><span class="line">touch Dockerfile.debian</span><br><span class="line">touch Dockerfile.alpine</span><br><span class="line"><span class="comment"># 复制出来配置文件，把源码移除掉就可以</span></span><br><span class="line">rm -rf fastdfs</span><br></pre></td></tr></table></figure>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>所有的配置文件都在 conf 里，我们根据自身的需要修改一下各个配置文件即可，关于 fastdfs 配置文件的各个参数可以去参考一下下面的博客。</p>
<ul>
<li><p><a href="https://www.cnblogs.com/chiangchou/p/fastdfs.html" target="_blank" rel="noopener">用FastDFS一步步搭建文件管理系统</a></p>
</li>
<li><p><a href="https://mhl.xyz/Linux/fastdfs-tracker-storage.html" target="_blank" rel="noopener">FastDFS配置参数tracker.conf、storage.conf详解</a></p>
</li>
</ul>
<p>我修改了默认的配置，数据存放目录修改成了 <code>/var/fdfs</code> ,在写 <code>Dockerfile</code> 的时候需要建立这个目录，如果你的目录没有修改的话，就把 Dockerfile 里后面那里建立文件夹的路径修改成默认的即可。</p>
<p>把 <code>tracker_server</code> 修改成 <code>tracker_server=tracker_ip:22122</code> ，容器启动的时候使用环境变量注入的 <code>FASTDFS_IPADDR</code> 替换掉就可以。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@debian-deploy-132 ~/fastdfs/conf</span><br><span class="line">╰─<span class="comment"># tree</span></span><br><span class="line">.</span><br><span class="line">├── client.conf             <span class="comment"># C 语言版本客户端配置文件，可以忽略</span></span><br><span class="line">├── fastdfs.sh              <span class="comment"># docker 容器启动 fastdfs 服务的脚本</span></span><br><span class="line">├── http.conf               <span class="comment"># http 配置文件，参考官方文档</span></span><br><span class="line">├── mime.types              <span class="comment">#</span></span><br><span class="line">├── mod_fastdfs.conf        <span class="comment"># fastdfs nginx 模块配置文件</span></span><br><span class="line">├── nginx.conf              <span class="comment"># nginx 配置文件，根据自身项目修改</span></span><br><span class="line">├── storage.conf            <span class="comment"># storage 服务配置文件</span></span><br><span class="line">└── tracker.conf            <span class="comment"># tracker 服务配置文件</span></span><br></pre></td></tr></table></figure>
<h4 id="tracker-服务配置文件-tracker-conf"><a href="#tracker-服务配置文件-tracker-conf" class="headerlink" title="tracker 服务配置文件 tracker.conf"></a>tracker 服务配置文件 tracker.conf</h4><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">disabled</span>=<span class="literal">false</span>                <span class="comment">#启用配置文件</span></span><br><span class="line"><span class="attr">port</span>=<span class="number">22122</span>                    <span class="comment">#设置tracker的端口号</span></span><br><span class="line"><span class="attr">base_path</span>=/var/dfs           <span class="comment">#设置tracker的数据文件和日志目录（需预先创建）</span></span><br><span class="line"><span class="attr">http.server_port</span>=<span class="number">28080</span>         <span class="comment">#设置http端口号</span></span><br></pre></td></tr></table></figure>
<h4 id="storage-服务配置文件-storage-ids-conf"><a href="#storage-服务配置文件-storage-ids-conf" class="headerlink" title="storage 服务配置文件 storage_ids.conf"></a>storage 服务配置文件 storage_ids.conf</h4><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="comment"># storage服务端口</span></span><br><span class="line"><span class="attr">port</span>=<span class="number">23000</span>                         <span class="comment"># 监听端口号</span></span><br><span class="line"><span class="attr">base_path</span>=/var/dfs                <span class="comment"># 数据和日志文件存储根目录</span></span><br><span class="line"><span class="attr">store_path0</span>=/var/dfs              <span class="comment"># 第一个存储目录</span></span><br><span class="line"><span class="attr">tracker_server</span>=tracker_ip:<span class="number">22122</span>    <span class="comment"># tracker服务器IP和端口</span></span><br><span class="line"><span class="attr">http.server_port</span>=<span class="number">28888</span></span><br></pre></td></tr></table></figure>
<h4 id="nginx-配置文件-nginx-conf"><a href="#nginx-配置文件-nginx-conf" class="headerlink" title="nginx 配置文件 nginx.conf"></a>nginx 配置文件 nginx.conf</h4><figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在 nginx 配置文件中添加修改下面这段</span></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span>       <span class="number">28888</span>;    <span class="comment">## 该端口为storage.conf中的http.server_port相同</span></span><br><span class="line">    <span class="attribute">server_name</span>  localhost;</span><br><span class="line">    <span class="attribute">location</span> ~/group[<span class="number">0</span>-<span class="number">9</span>]/ &#123;</span><br><span class="line">        ngx_fastdfs_module;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="attribute">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /50x.html;</span><br><span class="line">    <span class="attribute">location</span> = /50x.html &#123;</span><br><span class="line">    <span class="attribute">root</span>   html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="nginx-模块配置文件-mod-fastdfs-conf"><a href="#nginx-模块配置文件-mod-fastdfs-conf" class="headerlink" title="nginx 模块配置文件 mod_fastdfs.conf"></a>nginx 模块配置文件 mod_fastdfs.conf</h4><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">tracker_server</span>=tracker_ip:<span class="number">22122</span>   <span class="comment"># tracker服务器IP和端口</span></span><br><span class="line"><span class="attr">url_have_group_name</span>=<span class="literal">true</span>             <span class="comment"># url 中包含 group 的名称</span></span><br><span class="line"><span class="attr">store_path0</span>=/var/dfs                <span class="comment"># 数据和日志文件存储根目录</span></span><br></pre></td></tr></table></figure>
<h4 id="fastdfs-服务的脚本-fastdfs-sh"><a href="#fastdfs-服务的脚本-fastdfs-sh" class="headerlink" title="fastdfs 服务的脚本 fastdfs.sh"></a>fastdfs 服务的脚本 fastdfs.sh</h4><p>官方的脚本写的很随意，我就修改了一哈，不修改按照官方的来也 ok</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">new_val=<span class="variable">$FASTDFS_IPADDR</span></span><br><span class="line">old=<span class="string">"tracker_ip"</span></span><br><span class="line"></span><br><span class="line">sed -i <span class="string">"s/<span class="variable">$old</span>/<span class="variable">$new_val</span>/g"</span> /etc/fdfs/storage.conf</span><br><span class="line">sed -i <span class="string">"s/<span class="variable">$old</span>/<span class="variable">$new_val</span>/g"</span> /etc/fdfs/mod_fastdfs.conf</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"start trackerd"</span></span><br><span class="line">/etc/init.d/fdfs_trackerd start</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"start storage"</span></span><br><span class="line">/etc/init.d/fdfs_storaged start</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"start nginx"</span></span><br><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx</span><br><span class="line"></span><br><span class="line">tail -f  /dev/null</span><br></pre></td></tr></table></figure>
<h4 id="把-bash-替换成-sh"><a href="#把-bash-替换成-sh" class="headerlink" title="把 bash 替换成 sh"></a>把 bash 替换成 sh</h4><p>其实这一步骤可以不做，使用 bash 启动的话，需要在 alpine 安装 bash ，会增加 6MB 左右的镜像大小，感觉也没必要这样做😂</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s/bash/sh/g'</span> `grep -nr bash | awk -F <span class="string">':'</span> <span class="string">'&#123;print $1&#125;'</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换后</span></span><br><span class="line">grep -nr \<span class="comment">#\!\/bin\/sh</span></span><br><span class="line">stop.sh:1:<span class="comment">#!/bin/sh</span></span><br><span class="line">init.d/fdfs_storaged:1:<span class="comment">#!/bin/sh</span></span><br><span class="line">init.d/fdfs_trackerd:1:<span class="comment">#!/bin/sh</span></span><br><span class="line">conf/fastdfs.sh:1:<span class="comment">#!/bin/sh</span></span><br><span class="line">restart.sh:1:<span class="comment">#!/bin/sh</span></span><br><span class="line">docker/dockerfile_local/fastdfs.sh:1:<span class="comment">#!/bin/sh</span></span><br><span class="line">docker/dockerfile_network/fastdfs.sh:1:<span class="comment">#!/bin/sh</span></span><br></pre></td></tr></table></figure>
<h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><h4 id="alpine-3-10"><a href="#alpine-3-10" class="headerlink" title="alpine:3.10"></a>alpine:3.10</h4><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine:<span class="number">3.10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> conf/ /home</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -xe \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"http://mirrors.aliyun.com/alpine/latest-stable/main/"</span> &gt; /etc/apk/repositories \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"http://mirrors.aliyun.com/alpine/latest-stable/community/"</span> &gt;&gt; /etc/apk/repositories \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk update \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add --no-cache --virtual .build-deps alpine-sdk gcc libc-dev make perl-dev openssl-dev pcre-dev zlib-dev tzdata \</span></span><br><span class="line"><span class="bash">    &amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"Asia/Shanghai"</span> &gt; /etc/timezone \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mkdir -p /usr/<span class="built_in">local</span>/src \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src \</span></span><br><span class="line"><span class="bash">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/libfastcommon.git --depth 1 \</span></span><br><span class="line"><span class="bash">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/fastdfs.git --depth 1    \</span></span><br><span class="line"><span class="bash">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1  \</span></span><br><span class="line"><span class="bash">    &amp;&amp; wget http://nginx.org/download/nginx-1.15.4.tar.gz \</span></span><br><span class="line"><span class="bash">    &amp;&amp; tar -xf nginx-1.15.4.tar.gz \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/libfastcommon \</span></span><br><span class="line"><span class="bash">    &amp;&amp; sed -i <span class="string">'s/sys\/poll\.h/poll\.h/g'</span> src/sockopt.c \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./make.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./make.sh install \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/fastdfs/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./make.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./make.sh install \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/nginx-1.15.4/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./configure --add-module=/usr/<span class="built_in">local</span>/src/fastdfs-nginx-module/src/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; make &amp;&amp; make install \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk del .build-deps tzdata \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add --no-cache pcre-dev bash \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mkdir -p /var/fdfs /home/fastdfs/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv /home/fastdfs.sh /home/fastdfs/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv /home/*.conf /home/mime.types /etc/fdfs \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv /home/nginx.conf /usr/<span class="built_in">local</span>/nginx/conf/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; chmod +x /home/fastdfs/fastdfs.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; sed -i <span class="string">'s/bash/sh/g'</span> /etc/init.d/fdfs_storaged \</span></span><br><span class="line"><span class="bash">    &amp;&amp; sed -i <span class="string">'s/bash/sh/g'</span> /etc/init.d/fdfs_trackerd \</span></span><br><span class="line"><span class="bash">    &amp;&amp; sed -i <span class="string">'s/bash/sh/g'</span> /home/fastdfs/fastdfs.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -rf /usr/<span class="built_in">local</span>/src/* /var/cache/apk/* /tmp/* /var/tmp/* <span class="variable">$HOME</span>/.cache</span></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /var/fdfs</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">22122</span> <span class="number">23000</span> <span class="number">28888</span> <span class="number">28080</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"/home/fastdfs/fastdfs.sh"</span>]</span></span><br></pre></td></tr></table></figure>
<h4 id="debian-stretch-slim"><a href="#debian-stretch-slim" class="headerlink" title="debian:stretch-slim"></a>debian:stretch-slim</h4><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> debian:stretch-slim</span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> conf/ /home/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -x \</span></span><br><span class="line"><span class="bash">    &amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"Asia/shanghai"</span> &gt; /etc/timezone \</span></span><br><span class="line"><span class="bash">    &amp;&amp; sed -i <span class="string">'s/deb.debian.org/mirrors.aliyun.com/g'</span> /etc/apt/sources.list \</span></span><br><span class="line"><span class="bash">    &amp;&amp; sed -i <span class="string">'s|security.debian.org/debian-security|mirrors.aliyun.com/debian-security|g'</span> /etc/apt/sources.list \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt update \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt install  --no-install-recommends --no-install-suggests -y build-essential libpcre3 libpcre3-dev zlib1g \</span></span><br><span class="line"><span class="bash">                   git wget ca-certificates  zlib1g-dev libtool libssl-dev \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -rf /var/lib/apt/lists/* \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mkdir -p /usr/<span class="built_in">local</span>/src \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src \</span></span><br><span class="line"><span class="bash">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/libfastcommon.git --depth 1 \</span></span><br><span class="line"><span class="bash">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/fastdfs.git --depth 1    \</span></span><br><span class="line"><span class="bash">    &amp;&amp; git <span class="built_in">clone</span> https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1  \</span></span><br><span class="line"><span class="bash">    &amp;&amp; wget http://nginx.org/download/nginx-1.15.4.tar.gz \</span></span><br><span class="line"><span class="bash">    &amp;&amp; tar -xf nginx-1.15.4.tar.gz \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/libfastcommon \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./make.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./make.sh install \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/fastdfs/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./make.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./make.sh install \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/nginx-1.15.4/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./configure --add-module=/usr/<span class="built_in">local</span>/src/fastdfs-nginx-module/src/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; make &amp;&amp; make install \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt purge -y build-essential libtool git wget ca-certificates \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt autoremove -y \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mkdir -p /var/dfs /home/fastdfs/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv /home/fastdfs.sh /home/fastdfs/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv /home/*.conf /home/mime.types /etc/fdfs \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv /home/nginx.conf /usr/<span class="built_in">local</span>/nginx/conf/ \</span></span><br><span class="line"><span class="bash">    &amp;&amp; chmod +x /home/fastdfs/fastdfs.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -rf /var/lib/apt/list  /usr/<span class="built_in">local</span>/src/*</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /var/fdfs</span></span><br><span class="line"><span class="keyword">EXPOSE</span>  <span class="number">22122</span> <span class="number">23000</span> <span class="number">28888</span> <span class="number">28080</span></span><br></pre></td></tr></table></figure>
<h3 id="构不同基础镜像构建出的大小对比"><a href="#构不同基础镜像构建出的大小对比" class="headerlink" title="构不同基础镜像构建出的大小对比"></a>构不同基础镜像构建出的大小对比</h3><p>哭了，官方构建出来的镜像将近 500MB</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fastdfs             alpine              e855bd197dbe        10 seconds ago      29.3MB</span><br><span class="line">fastdfs             debian              e05ca1616604        20 minutes ago      103MB</span><br><span class="line">fastdfs             centos              c1488537c23c        30 minutes ago      483MB</span><br></pre></td></tr></table></figure>
<h4 id="使用-dive-分析各个镜像"><a href="#使用-dive-分析各个镜像" class="headerlink" title="使用 dive 分析各个镜像"></a>使用 dive 分析各个镜像</h4><p>官方的</p>
<p><img src="../img/1569728664464.png" alt="1569728664464"></p>
<h4 id="alpine"><a href="#alpine" class="headerlink" title="alpine"></a>alpine</h4><p>基于 alpine 的基础镜像构建完成后，只有三层镜像😂</p>
<p><img src="../img/1569728744655.png" alt="1569728744655"></p>
<h4 id="debian"><a href="#debian" class="headerlink" title="debian"></a>debian</h4><p><img src="../img/1569729043301.png" alt="1569729043301"></p>
<h3 id="musl-libc-带来的问题"><a href="#musl-libc-带来的问题" class="headerlink" title="musl libc 带来的问题"></a><code>musl libc</code> 带来的问题</h3><p>不过需要注意的是，使用 CentOS 和 Alpine 基础镜像分别构建出来的镜像，使用 ldd 查看二者编译出来的 fastdfs ，两者的动态链接库存在很大的差异， Alpine 缺少了很多动态链接库，这是因为 alpine 的 c 库是 <code>musl libc</code> ，而不是正统的 <code>glibc</code> ，另外对于一些依赖 <code>glibc</code> 的大型项目，像 openjdk 、tomcat、rabbitmq 等都不建议使用 alpine 基础镜像，因为  <code>musl libc</code> 会导致 jvm 一些奇怪的问题。这也是为什么 tomcat 官方没有给出基础镜像是 alpine 的 Dockerfile</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">centos<span class="comment"># find /usr/bin/ -name "fdfs*" | xargs ldd</span></span><br><span class="line">        linux-vdso.so.1 =&gt;  (0x00007fffe1d30000)</span><br><span class="line">        libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f86036e6000)</span><br><span class="line">        libfastcommon.so =&gt; /lib/libfastcommon.so (0x00007f86034a5000)</span><br><span class="line">        libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f86030d8000)</span><br><span class="line">        /lib64/ld-linux-x86-64.so.2 (0x00007f8603902000)</span><br><span class="line">        libm.so.6 =&gt; /lib64/libm.so.6 (0x00007f8602dd6000)</span><br><span class="line">        libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f8602bd2000)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">alpine <span class="comment"># find /usr/bin/ -name "fdfs*" | xargs ldd</span></span><br><span class="line">        /lib/ld-musl-x86_64.so.1 (0x7f4f91585000)</span><br><span class="line">        libfastcommon.so =&gt; /usr/lib/libfastcommon.so (0x7f4f91528000)</span><br><span class="line">        libc.musl-x86_64.so.1 =&gt; /lib/ld-musl-x86_64.so.1 (0x7f4f91585000)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">debian <span class="comment"># find /usr/bin/ -name "fdfs*" | xargs ldd</span></span><br><span class="line">        linux-vdso.so.1 (0x00007ffd17e50000)</span><br><span class="line">        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007feadf317000)</span><br><span class="line">        libfastcommon.so =&gt; /usr/lib/libfastcommon.so (0x00007feadf0d6000)</span><br><span class="line">        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007feaded37000)</span><br><span class="line">        /lib64/ld-linux-x86-64.so.2 (0x00007feadf74a000)</span><br><span class="line">        libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007feadea33000)</span><br><span class="line">        libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007feade82f000)</span><br></pre></td></tr></table></figure>
<h3 id="容器启动方法"><a href="#容器启动方法" class="headerlink" title="容器启动方法"></a>容器启动方法</h3><p>需要注意的是，FastDFS 的容器需要使用 host 网络，因为 fastdfs storage 服务器需要向 tracker 服务器汇报自己 IP，这个 IP 还需要通过环境变量的方式注入到相关的配置文件当中。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -e FASTDFS_IPADDR=10.10.107.230 \</span><br><span class="line">           -p 28888:28888 -p 22122:22122 -p 23000:23000 -p 28088:28080 \</span><br><span class="line">           -v <span class="variable">$PWD</span>/data:/var/fdfs --net=host --name fastdfs fastdfs:alpine</span><br></pre></td></tr></table></figure>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="测试工具"><a href="#测试工具" class="headerlink" title="测试工具"></a>测试工具</h3><ol>
<li>上传客户端：<code>fdfs_upload_file</code></li>
<li>并发执行工具 ：<code>xargs</code></li>
<li>测试样本：10W  张表情包图片 ，大小在 <strong>8KB–128KB</strong> 之间</li>
<li>上传测试命令：<code>time ls  | xargs -n 1 -I {} -P 256 sh -c &quot;/usr/bin/fdfs_upload_file /etc/fdfs/client.conf {}&quot;`</code>-p 参数指定并发执行的任务数量</li>
<li>下载测试工具： <code>wget</code></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">下载测试命令：`time cat url.log  | xargs -n 1 -I &#123;&#125; -P 256 sh -c <span class="string">"wget  &#123;&#125;"</span>`</span><br></pre></td></tr></table></figure>
<h3 id="文件上传测试"><a href="#文件上传测试" class="headerlink" title="文件上传测试"></a>文件上传测试</h3><p>  测试样本为 10W 张 8KB-100 KB 大小不等的图片</p>
<p><img src="../img/1564128425387.png" alt="1564128425387"></p>
<p><strong>测试文件数量和大小</strong></p>
<p><img src="../img/1564128874832.png" alt="1564128874832"></p>
<p><strong>使用 xargs 执行 256 个进程并发上传 10w 张照片所用所用时间 为 2 分钟左右（内网）</strong></p>
<p><img src="../img/1564128721547.png" alt="1564128721547"></p>
<p><strong>用时 2 分 11 秒</strong></p>
<p><img src="../img/1564364594777.png" alt="1564364594777"></p>
<p><strong>客户端负载情况</strong></p>
<p><img src="../img/1564127683217.png" alt="1564127683217"></p>
<p><strong>服务端负载情况</strong></p>
<p><img src="../img/1564364294952.png" alt="1564364294952"></p>
<p><strong>服务端带宽流量</strong></p>
<p><img src="../img/1564365025177.png" alt="1564365025177"></p>
<p><strong>服务端带宽流量</strong></p>
<p><img src="../img/1564363829960.png" alt="服务端带宽流量"></p>
<p><strong>服务端上传结果</strong></p>
<p><img src="../img/1564125161155.png" alt="1564125161155"></p>
<p><strong>服务端上传日志记录 ，均无错误输出</strong></p>
<p><img src="../img/1564130238346.png" alt="1564130238346"></p>
<h3 id="文件下载测试"><a href="#文件下载测试" class="headerlink" title="文件下载测试"></a>文件下载测试</h3><p><strong>从日志中提取文件路径</strong></p>
<p>从服务端的 <code>storage_access.log</code> 日志里提取出文件的路径，使用 <code>sed</code> 添加 <code>nginx</code> 的访问端口地址得到 10W 个记录 上传文件的 <code>http</code> 访问 <code>url</code> 地址</p>
<p><img src="../img/1564130789416.png" alt="1564130789416"></p>
<p><strong>wget 下载</strong></p>
<p>使用 <code>wget -i</code> 参数指定 <code>url.log</code> 为标准输出来测试下载刚刚上传的 10W 张图片 用时 3 分 23 秒</p>
<p><img src="../img/1564023927851.png" alt="1564023927851"></p>
<h3 id="测试结果分析"><a href="#测试结果分析" class="headerlink" title="测试结果分析"></a>测试结果分析</h3><p>使用 FastDFS 自带的上传测试工具和 xargs 并发执行工具，通过 xargs -P 参数指定的并发请求数，测得结果为单机性能在网络环境稳定的情况下可以达到 5000 并发上传请求。10W 张图片上传时间耗时 2 分 11 秒左右。使用定时脚本持续测试，总测试上传 100W 张图片。分析 tracker 服务器和 storage 服务器的日志，无论上传还是下载均未发现错误和异常，性能和稳定性较好。</p>
<h2 id="优化参数"><a href="#优化参数" class="headerlink" title="优化参数"></a>优化参数</h2><p>根据业务需求和线上环境调整一下参数，可充分发挥 FastDFS 文件系统的性能</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 接收请求的线程数数量</span></span><br><span class="line"><span class="attr">accept_threads</span>=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># work thread count, should &lt;= max_connections</span></span><br><span class="line"><span class="comment"># default value is 4</span></span><br><span class="line"><span class="comment"># since V2.00</span></span><br><span class="line"><span class="comment"># 工作线程数量，应当小于等于最大连接数</span></span><br><span class="line"><span class="attr">work_threads</span>=<span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># min buff size</span></span><br><span class="line"><span class="comment"># default value 8KB</span></span><br><span class="line"><span class="comment"># 最小缓冲大小，默认值为 8KB</span></span><br><span class="line"><span class="attr">min_buff_size</span> = <span class="number">8</span>KB</span><br><span class="line"></span><br><span class="line"><span class="comment"># max buff size</span></span><br><span class="line"><span class="comment"># default value 128KB</span></span><br><span class="line"><span class="comment"># 最大缓冲大小，默认值为 128KB</span></span><br><span class="line"><span class="attr">max_buff_size</span> = <span class="number">128</span>KB</span><br><span class="line"></span><br><span class="line"><span class="comment"># thread stack size, should &gt;= 64KB</span></span><br><span class="line"><span class="comment"># default value is 256KB</span></span><br><span class="line"><span class="comment"># 线程栈的大小，应当大于 64KB，默认为 256KB</span></span><br><span class="line"><span class="attr">thread_stack_size</span> = <span class="number">256</span>KB</span><br><span class="line"></span><br><span class="line"><span class="comment"># if use connection pool</span></span><br><span class="line"><span class="comment"># default value is false</span></span><br><span class="line"><span class="comment"># since V4.05</span></span><br><span class="line"><span class="comment"># 是否使用连接池</span></span><br><span class="line"><span class="attr">use_connection_pool</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># connections whose the idle time exceeds this time will be closed</span></span><br><span class="line"><span class="comment"># unit: second</span></span><br><span class="line"><span class="comment"># default value is 3600</span></span><br><span class="line"><span class="comment"># since V4.05</span></span><br><span class="line"><span class="comment"># 连接池的最大空闲时间</span></span><br><span class="line"><span class="attr">connection_pool_max_idle_time</span> = <span class="number">3600</span></span><br></pre></td></tr></table></figure>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h4 id="无法连接到-tracker-服务器"><a href="#无法连接到-tracker-服务器" class="headerlink" title="无法连接到 tracker 服务器"></a>无法连接到 tracker 服务器</h4><p>需要在 tracker.conf 配置文件中添加允许访问的 IP ,并添加防火墙规则</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[2019-07-25 10:40:54] ERROR - file: ../client/storage_client.c, line: 996, fdfs_recv_response fail, result: 107</span><br><span class="line">upload file fail, error no: 107, error info: Transport endpoint is not connected</span><br><span class="line">[2019-07-25 10:40:54] ERROR - file: tracker_proto.c, line: 37, server: 10.20.172.192:23000, recv data fail, errno: 107, error info: Transport endpoint is not connected</span><br></pre></td></tr></table></figure>
<h4 id="服务器磁盘用尽"><a href="#服务器磁盘用尽" class="headerlink" title="服务器磁盘用尽"></a>服务器磁盘用尽</h4><p>当 storage 服务器设定的上传存储目录所在的分区磁盘用尽将会出现无剩余空间的错误日志</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[2019-07-26 16:16:45] ERROR - file: tracker_proto.c, line: 48, server: 10.10.107.232:22122, response status 28 != 0</span><br><span class="line">[2019-07-26 16:16:45] ERROR - file: ../client/tracker_client.c, line: 907, fdfs_recv_response fail, result: 28</span><br><span class="line">tracker_query_storage fail, error no: 28, error info: No space left on device</span><br></pre></td></tr></table></figure>
<h4 id="重启服务时失败"><a href="#重启服务时失败" class="headerlink" title="重启服务时失败"></a>重启服务时失败</h4><p>使用 service fdfs_trackerd restart 重启 tracker 或者 storage 服务时会报错，会提示端口已经占用。解决的方案就是使用 kill -9 命令杀死 tracker 服务或者 storage 服务，然后再重新启动相应服务即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[2019-07-25 10:36:55] INFO - FastDFS v5.12, base_path=/home/dfs, run_by_group=, run_by_user=, connect_timeout=10s, network_timeout=60s, port=22122, bind_addr=, max_connections=1024, accept_threads=1, work_threads=4, min_buff_size=8,192, max_buff_size=131,072, store_lookup=2, store_group=, store_server=0, store_path=0, reserved_storage_space=10.00%, download_server=0, allow_ip_count=-1, sync_log_buff_interval=10s, check_active_interval=120s, thread_stack_size=256 KB, storage_ip_changed_auto_adjust=1, storage_sync_file_max_delay=86400s, storage_sync_file_max_time=300s, use_trunk_file=0, slot_min_size=256, slot_max_size=16 MB, trunk_file_size=64 MB, trunk_create_file_advance=0, trunk_create_file_time_base=02:00, trunk_create_file_interval=86400, trunk_create_file_space_threshold=20 GB, trunk_init_check_occupying=0, trunk_init_reload_from_binlog=0, trunk_compress_binlog_min_interval=0, use_storage_id=0, id_type_in_filename=ip, storage_id_count=0, rotate_error_log=0, error_log_rotate_time=00:00, rotate_error_log_size=0, log_file_keep_days=0, store_slave_file_use_link=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s</span><br><span class="line">[2019-07-25 10:36:55] ERROR - file: sockopt.c, line: 868, <span class="built_in">bind</span> port 22122 failed, errno: 98, error info: Address already <span class="keyword">in</span> use.</span><br><span class="line">[2019-07-25 10:36:55] CRIT - <span class="built_in">exit</span> abnormally!</span><br></pre></td></tr></table></figure>
<h3 id="安全相关"><a href="#安全相关" class="headerlink" title="安全相关"></a>安全相关</h3><ol>
<li>tracker.conf 、storage.conf 配置文件默认允许所有 IP 地址访问 ，建议去掉  <code>allow_hosts=*</code> 修改为 FastDFS 客户端所在的内网 IP 地址。</li>
</ol>
<p><img src="../img/1564384530137.png" alt="1564384530137"></p>
<p>2.tracker.conf 、storage.conf  默认配置文件监听的地址为 0.0.0.0 即本机所有的 IP 地址，建议修改为 FastDFS 服务器所在的内网 IP 地址。</p>
<p><img src="../img/1564384711746.png" alt="1564384711746"></p>
<p>3.默认运行用户为当前用户和用户组为当前用户，建议指定为权限最小的用户来运行此进程。</p>
<p><img src="../img/1564384906456.png" alt="1564384906456"></p>
]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title>《假如没有今天，明天会不会有昨天？》</title>
    <url>/archives/reading.html</url>
    <content><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><h3 id="幸福"><a href="#幸福" class="headerlink" title="幸福"></a>幸福</h3><blockquote>
<p>假设只要连上幸福机器，就能体验到渴望的一切，你会连上机器，享受如真实般的梦幻人生吗？</p>
</blockquote>
<h4 id="身后的幸福"><a href="#身后的幸福" class="headerlink" title="身后的幸福"></a>身后的幸福</h4><h4 id="被链住的狗"><a href="#被链住的狗" class="headerlink" title="被链住的狗"></a>被链住的狗</h4><h4 id="圆满的幸福"><a href="#圆满的幸福" class="headerlink" title="圆满的幸福"></a>圆满的幸福</h4><h4 id="永劫回归"><a href="#永劫回归" class="headerlink" title="永劫回归"></a>永劫回归</h4><h4 id="西绪弗斯与大石头"><a href="#西绪弗斯与大石头" class="headerlink" title="西绪弗斯与大石头"></a>西绪弗斯与大石头</h4><h4 id="幸福机器"><a href="#幸福机器" class="headerlink" title="幸福机器"></a>幸福机器</h4><h3 id="知识"><a href="#知识" class="headerlink" title="知识"></a>知识</h3><blockquote>
<p>假设有人说你只是颗泡在培养皿里的大脑，感受到的世界是计算机制造的梦幻泡影，要如何证明自己是活生生的人？</p>
</blockquote>
<h4 id="洞穴囚徒"><a href="#洞穴囚徒" class="headerlink" title="洞穴囚徒"></a>洞穴囚徒</h4><h4 id="缸中之脑"><a href="#缸中之脑" class="headerlink" title="缸中之脑"></a>缸中之脑</h4><h4 id="明希豪森的三难困境"><a href="#明希豪森的三难困境" class="headerlink" title="明希豪森的三难困境"></a>明希豪森的三难困境</h4><h4 id="缺少的蓝"><a href="#缺少的蓝" class="headerlink" title="缺少的蓝"></a>缺少的蓝</h4><h4 id="故障的钟，正确的时间"><a href="#故障的钟，正确的时间" class="headerlink" title="故障的钟，正确的时间"></a>故障的钟，正确的时间</h4><h3 id="道德"><a href="#道德" class="headerlink" title="道德"></a>道德</h3><blockquote>
<p>假设你在桥上，目睹电车即将撞上轨道上的五个人，拯救他们的唯一办法，就是把站在你身旁的一个人推下去，你会怎么选择？</p>
</blockquote>
<h4 id="电车与胖子"><a href="#电车与胖子" class="headerlink" title="电车与胖子"></a>电车与胖子</h4><h4 id="特蕾莎修女与精神病患"><a href="#特蕾莎修女与精神病患" class="headerlink" title="特蕾莎修女与精神病患"></a>特蕾莎修女与精神病患</h4><h4 id="池中小孩"><a href="#池中小孩" class="headerlink" title="池中小孩"></a>池中小孩</h4><h4 id="吃人肉的外星人"><a href="#吃人肉的外星人" class="headerlink" title="吃人肉的外星人"></a>吃人肉的外星人</h4><h4 id="背上的小提琴家"><a href="#背上的小提琴家" class="headerlink" title="背上的小提琴家"></a>背上的小提琴家</h4><h3 id="美与艺术"><a href="#美与艺术" class="headerlink" title="美与艺术"></a>美与艺术</h3><blockquote>
<p>假设博物馆里每一幅画都是相同的红色画布，只有画名和简介不同，策展人说每幅画想传达的意念也有所不同，你可以要求退钱吗？</p>
</blockquote>
<h4 id="无生命的朋友"><a href="#无生命的朋友" class="headerlink" title="无生命的朋友"></a>无生命的朋友</h4><h4 id="没有感情的音乐"><a href="#没有感情的音乐" class="headerlink" title="没有感情的音乐"></a>没有感情的音乐</h4><h4 id="红色四方形"><a href="#红色四方形" class="headerlink" title="红色四方形"></a>红色四方形</h4><h3 id="自由"><a href="#自由" class="headerlink" title="自由"></a>自由</h3><blockquote>
<p>假设你拥有全知的能力，通晓宇宙的一切，你是否就能预测未来？</p>
</blockquote>
<h4 id="我们能否预测未来"><a href="#我们能否预测未来" class="headerlink" title="我们能否预测未来"></a>我们能否预测未来</h4><h4 id="我本来可以做出不同决定吗？"><a href="#我本来可以做出不同决定吗？" class="headerlink" title="我本来可以做出不同决定吗？"></a>我本来可以做出不同决定吗？</h4><h4 id="凶手无法不行凶"><a href="#凶手无法不行凶" class="headerlink" title="凶手无法不行凶"></a>凶手无法不行凶</h4><h3 id="法理与公平正义"><a href="#法理与公平正义" class="headerlink" title="法理与公平正义"></a>法理与公平正义</h3><blockquote>
<p>假设你是新社会的绝对立法者，不过无法预知自己在新社会中的地位，你是否能打造出公平正义的社会？</p>
</blockquote>
<h4 id="野蛮人"><a href="#野蛮人" class="headerlink" title="野蛮人"></a>野蛮人</h4><h4 id="无知之幕"><a href="#无知之幕" class="headerlink" title="无知之幕"></a>无知之幕</h4><h4 id="谁拿最大块蛋糕？"><a href="#谁拿最大块蛋糕？" class="headerlink" title="谁拿最大块蛋糕？"></a>谁拿最大块蛋糕？</h4><h3 id="心智与大脑"><a href="#心智与大脑" class="headerlink" title="心智与大脑"></a>心智与大脑</h3><blockquote>
<p>假设你是蝙蝠专家，对蝙蝠的一切了如指掌，你是否就能点出蝙蝠心里在想些什么？</p>
</blockquote>
<h4 id="蝙蝠的秘密"><a href="#蝙蝠的秘密" class="headerlink" title="蝙蝠的秘密"></a>蝙蝠的秘密</h4><h4 id="脑中漫步"><a href="#脑中漫步" class="headerlink" title="脑中漫步"></a>脑中漫步</h4><h4 id="玛莉与颜色"><a href="#玛莉与颜色" class="headerlink" title="玛莉与颜色"></a>玛莉与颜色</h4><h4 id="我的邻居是好僵尸"><a href="#我的邻居是好僵尸" class="headerlink" title="我的邻居是好僵尸"></a>我的邻居是好僵尸</h4><h4 id="大脑义肢"><a href="#大脑义肢" class="headerlink" title="大脑义肢"></a>大脑义肢</h4><h4 id="中文房间"><a href="#中文房间" class="headerlink" title="中文房间"></a>中文房间</h4><h4 id="智能手机里的心智"><a href="#智能手机里的心智" class="headerlink" title="智能手机里的心智"></a>智能手机里的心智</h4><h3 id="上帝与信仰"><a href="#上帝与信仰" class="headerlink" title="上帝与信仰"></a>上帝与信仰</h3><blockquote>
<p>假设所有的运动都有其推动者，世界上最早的第一起运动，究竟是谁推动的？</p>
</blockquote>
<h4 id="可设想的最高存在"><a href="#可设想的最高存在" class="headerlink" title="可设想的最高存在"></a>可设想的最高存在</h4><h4 id="上帝——这颗绊脚的石头"><a href="#上帝——这颗绊脚的石头" class="headerlink" title="上帝——这颗绊脚的石头"></a>上帝——这颗绊脚的石头</h4><h4 id="上帝与瑞士钟表匠"><a href="#上帝与瑞士钟表匠" class="headerlink" title="上帝与瑞士钟表匠"></a>上帝与瑞士钟表匠</h4><h4 id="帕斯卡尔的赌注论证"><a href="#帕斯卡尔的赌注论证" class="headerlink" title="帕斯卡尔的赌注论证"></a>帕斯卡尔的赌注论证</h4><h4 id="道德的拐杖"><a href="#道德的拐杖" class="headerlink" title="道德的拐杖"></a>道德的拐杖</h4><h4 id="帮超人辩护"><a href="#帮超人辩护" class="headerlink" title="帮超人辩护"></a>帮超人辩护</h4><h4 id="太空茶壶"><a href="#太空茶壶" class="headerlink" title="太空茶壶"></a>太空茶壶</h4><h3 id="逻辑与语言"><a href="#逻辑与语言" class="headerlink" title="逻辑与语言"></a>逻辑与语言</h3><blockquote>
<p>假设村里的理发师只能帮不自己刮胡子的村民刮胡子，不能帮会自己刮胡子的村民刮胡子，他自己的胡子要由谁来帮他刮？</p>
</blockquote>
<h4 id="理发师"><a href="#理发师" class="headerlink" title="理发师"></a>理发师</h4><h4 id="秃头"><a href="#秃头" class="headerlink" title="秃头"></a>秃头</h4><h4 id="小松鼠"><a href="#小松鼠" class="headerlink" title="小松鼠"></a>小松鼠</h4><h4 id="Gavagai"><a href="#Gavagai" class="headerlink" title="Gavagai"></a>Gavagai</h4><h4 id="启明星与长庚星"><a href="#启明星与长庚星" class="headerlink" title="启明星与长庚星"></a>启明星与长庚星</h4><h4 id="家族的类似性"><a href="#家族的类似性" class="headerlink" title="家族的类似性"></a>家族的类似性</h4><h4 id="孪生地球"><a href="#孪生地球" class="headerlink" title="孪生地球"></a>孪生地球</h4><h4 id="会咬人的狗"><a href="#会咬人的狗" class="headerlink" title="会咬人的狗"></a>会咬人的狗</h4><h4 id="理解的循环"><a href="#理解的循环" class="headerlink" title="理解的循环"></a>理解的循环</h4><h4 id="沉默的意义"><a href="#沉默的意义" class="headerlink" title="沉默的意义"></a>沉默的意义</h4><h3 id="空间与时间"><a href="#空间与时间" class="headerlink" title="空间与时间"></a>空间与时间</h3><blockquote>
<p>假设你回到过去，杀害了尚未有子嗣的祖父，你还能存在于这个世上吗？</p>
</blockquote>
<h4 id="阿基里斯与乌龟"><a href="#阿基里斯与乌龟" class="headerlink" title="阿基里斯与乌龟"></a>阿基里斯与乌龟</h4><h4 id="时间能静止多久？"><a href="#时间能静止多久？" class="headerlink" title="时间能静止多久？"></a>时间能静止多久？</h4><h4 id="祖父谋杀悖论"><a href="#祖父谋杀悖论" class="headerlink" title="祖父谋杀悖论"></a>祖父谋杀悖论</h4><h4 id="如果没有今天，明天就没有昨天"><a href="#如果没有今天，明天就没有昨天" class="headerlink" title="如果没有今天，明天就没有昨天"></a>如果没有今天，明天就没有昨天</h4><h3 id="自我"><a href="#自我" class="headerlink" title="自我"></a>自我</h3><blockquote>
<p>假设你在柏林被全身扫描过一遍，就能在北京被复制出来，世界上会存在两个你吗？哪一个才是真实的你？</p>
</blockquote>
<h4 id="忒修斯的船"><a href="#忒修斯的船" class="headerlink" title="忒修斯的船"></a>忒修斯的船</h4><h4 id="斯科特，把我传送出去！"><a href="#斯科特，把我传送出去！" class="headerlink" title="斯科特，把我传送出去！"></a>斯科特，把我传送出去！</h4>]]></content>
      <tags>
        <tag>阅读</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 ESP8266 NodeMCU 打造 WiFi 开关</title>
    <url>/archives/esp8266-pc-switch.html</url>
    <content><![CDATA[<p>在办公室希望连接到家里的电脑，内网穿透方案选的是 frp，但家里的电脑在走的时候会忘记打开，亦或者死机蓝屏的时候出现故障无法手动重启。正好手头里有两台路由器，一台 <code>R6300 V2</code> 刷了梅林固件，一台 <code>WNDR 3700 V4</code> 刷了 <code>OpenWRT</code>  ，另外还有一块 <code>ESP8266 NodeMcu Lua WIFI V3 ESP-12N</code>的板子。另外还需要一个 3.3 v/5v 的继电器，某宝上 3.9 包邮。</p>
<p>方案图</p>
<h3 id="路由器控制-USB-电源开关"><a href="#路由器控制-USB-电源开关" class="headerlink" title="路由器控制 USB 电源开关"></a>路由器控制 USB 电源开关</h3><p>其实我第一个想到的方案就是直接通过路由器的 USB 接口控制继电器来控制 PC 主板开关，网上也有文章可以通过 echo 命令控制 USB 电源。Linux 内核官方网也有说明 <a href="https://www.kernel.org/doc/Documentation/usb/power-management.txt" target="_blank" rel="noopener">Power Management for USB</a></p>
<p><a href="https://openwrt.org/docs/guide-user/hardware/usb.overview" target="_blank" rel="noopener">Turning USB power on and off</a> 这个是通过 GPIO 引脚驱动来控制的</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 打开电源</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /sys/class/gpio/gpioN/value</span><br><span class="line"><span class="comment"># 关闭电源</span></span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /sys/class/gpio/gpioN/value</span><br></pre></td></tr></table></figure>
<p>但我的 R6300V2 上没有这些 GPIO 的引脚设备文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lede@R6300V2-5501:/tmp/home/root<span class="comment"># tree /sys/class/gpio/</span></span><br><span class="line">/sys/class/gpio/</span><br><span class="line">└── gpio</span><br><span class="line">    ├── dev</span><br><span class="line">    ├── subsystem -&gt; ../../gpio</span><br><span class="line">    └── uevent</span><br><span class="line">lede@R6300V2-5501:/sys/class/gpio/gpio<span class="comment"># cat dev</span></span><br><span class="line">254:0</span><br><span class="line">lede@R6300V2-5501:/sys/class/gpio/gpio<span class="comment"># cat uevent</span></span><br><span class="line">MAJOR=254</span><br><span class="line">MINOR=0</span><br><span class="line">DEVNAME=gpio</span><br></pre></td></tr></table></figure>
<p>无功而返，最后在又找到了另外一种通过命令行来控制 USB 电源开关的办法 <a href="https://stackoverflow.com/questions/4702216/controlling-a-usb-power-supply-on-off-with-linux" target="_blank" rel="noopener">Controlling a USB power supply (on/off) with linux</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># disable external wake-up; do this only once</span></span><br><span class="line"><span class="built_in">echo</span> disabled &gt; /sys/bus/usb/devices/usb1/power/wakeup</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> on &gt; /sys/bus/usb/devices/usb1/power/level       <span class="comment"># turn on</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">suspend</span> &gt; /sys/bus/usb/devices/usb1/power/level  <span class="comment"># turn off</span></span><br></pre></td></tr></table></figure>
<p>但我的R6300V2路由器里也没有这个文件，无功而返。但在这个 USB 设备文件里却发现了有意思的事情</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lede@R6300V2-5501:/tmp/home/root<span class="comment"># ls -al /sys/bus/usb/devices/ | awk '&#123;print $9,$10,$11&#125;'</span></span><br><span class="line">./</span><br><span class="line">../</span><br><span class="line">1-0:1.0 -&gt; ../../../devices/pci0000:00/0000:00:0b.1/usb1/1-0:1.0/</span><br><span class="line">1-1 -&gt; ../../../devices/pci0000:00/0000:00:0b.1/usb1/1-1/</span><br><span class="line">1-1:1.0 -&gt; ../../../devices/pci0000:00/0000:00:0b.1/usb1/1-1/1-1:1.0/</span><br><span class="line">2-0:1.0 -&gt; ../../../devices/pci0000:00/0000:00:0b.0/usb2/2-0:1.0/</span><br><span class="line">usb1 -&gt; ../../../devices/pci0000:00/0000:00:0b.1/usb1/</span><br><span class="line">usb2 -&gt; ../../../devices/pci0000:00/0000:00:0b.0/usb2/</span><br><span class="line">lede@R6300V2-5501:/tmp/home/root<span class="comment">#</span></span><br></pre></td></tr></table></figure>
<p>R6300V2 支持的 USB 设备类型驱动有以下几种</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lede@R6300V2-5501:/sys/bus/usb/drivers<span class="comment"># ls</span></span><br><span class="line">asix/        cdc_mbim/    cdc_wdm/     qmi_wwan/    usb/         usbfs/</span><br><span class="line">cdc_ether/   cdc_ncm/     hub/         rndis_host/  usb-storage/ usblp/</span><br></pre></td></tr></table></figure>
<p>虽然 R6300V2 号称有一个 USB3.0 和一个 USB2.0 ，但设备速度还是 480Mbps ，USB2.0 的速度，不明白这是为什么？使用 dd 测了一下速度，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lede@R6300V2-5501:/sys/devices/pci0000:00/0000:00:0b.1/usb1<span class="comment"># cat speed</span></span><br><span class="line">480</span><br></pre></td></tr></table></figure>
<h2 id="还是用吃灰的-ESP8266-😂"><a href="#还是用吃灰的-ESP8266-😂" class="headerlink" title="还是用吃灰的  ESP8266 😂"></a>还是用吃灰的  ESP8266 😂</h2><p>尝试了多种办法试着使用路由器的 USB 口当继电器的控制端，均无功而返，看来是不能使用路由器来搞了。正好手里还有一块 <code>ESP8266 NodeMcu Lua WIFI V3 ESP-12N</code> ，大二时好奇就入手了一块搞 WiFi 攻击了😂，玩了几次一直在吃灰了，今天终于派上用场了。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ESP8266WiFi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;WiFiClient.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ESP8266WebServer.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//设置路由器和静态 IP</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* ssid = <span class="string">" "</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* password = <span class="string">" "</span>;</span><br><span class="line"><span class="function"><span class="built_in">IPAddress</span> <span class="title">staticIP</span><span class="params">(<span class="number">192</span>, <span class="number">168</span>, <span class="number">0</span>, <span class="number">230</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">IPAddress</span> <span class="title">gateway</span><span class="params">(<span class="number">192</span>, <span class="number">168</span>, <span class="number">0</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">IPAddress</span> <span class="title">subnet</span><span class="params">(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// web 服务器监听端口</span></span><br><span class="line"><span class="function">ESP8266WebServer <span class="title">server</span><span class="params">(<span class="number">80</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义相关控制针脚</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> LED = <span class="number">13</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> SW = <span class="number">14</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义认证用户和密码</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* user = <span class="string">"esp8266"</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* pass = <span class="string">"esp8266"</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* realm = <span class="string">"Custom Auth Realm"</span>;</span><br><span class="line"><span class="keyword">String</span> authFailResponse = <span class="string">"Authentication Failed"</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span> MAIN_page[] PROGMEM = R<span class="string">"=====(</span></span><br><span class="line"><span class="string">&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;a href="</span>pcon<span class="string">"&gt;PC POWER TRUN ON&lt;/a&gt;&lt;br&gt;&lt;a href="</span>pcoff<span class="string">"&gt;PC POWER TRUN OFF&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;</span></span><br><span class="line"><span class="string">)====="</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">handleRoot</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">"GET INDEX PAGE"</span>);</span><br><span class="line">    <span class="keyword">String</span> s = MAIN_page;</span><br><span class="line">    server.send(<span class="number">200</span>, <span class="string">"text/html"</span>, s);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">handlePCon</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">"LED on page"</span>);</span><br><span class="line"> <span class="built_in">digitalWrite</span>(LED,<span class="literal">LOW</span>); <span class="comment">//LED</span></span><br><span class="line"> <span class="built_in">digitalWrite</span>(SW,<span class="literal">LOW</span>); <span class="comment">//LED</span></span><br><span class="line"> <span class="built_in">delay</span>(<span class="number">800</span>);</span><br><span class="line"> <span class="built_in">digitalWrite</span>(SW,<span class="literal">HIGH</span>);</span><br><span class="line"> server.send(<span class="number">200</span>, <span class="string">"text/html"</span>, <span class="string">"LED is ON"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">handlePCoff</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">"LED off page"</span>);</span><br><span class="line"> <span class="built_in">digitalWrite</span>(LED,<span class="literal">HIGH</span>); <span class="comment">//LED off</span></span><br><span class="line"> <span class="built_in">digitalWrite</span>(SW,<span class="literal">HIGH</span>); <span class="comment">//LED off</span></span><br><span class="line"> server.send(<span class="number">200</span>, <span class="string">"text/html"</span>, <span class="string">"LED is OFF"</span>); <span class="comment">//Send ADC value only to client ajax request</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">setup</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">pinMode</span>(LED, <span class="literal">OUTPUT</span>);</span><br><span class="line">    <span class="built_in">digitalWrite</span>(LED, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">pinMode</span>(SW, <span class="literal">OUTPUT</span>);</span><br><span class="line">    <span class="built_in">digitalWrite</span>(SW, <span class="number">1</span>);</span><br><span class="line">    <span class="built_in">Serial</span>.<span class="built_in">begin</span>(<span class="number">115200</span>);</span><br><span class="line">    <span class="built_in">WiFi</span>.<span class="built_in">begin</span>(ssid, password);</span><br><span class="line">    <span class="built_in">WiFi</span>.<span class="built_in">config</span>(staticIP, subnet, gateway);</span><br><span class="line">    <span class="built_in">WiFi</span>.mode(WIFI_STA);</span><br><span class="line">    <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">""</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Wait for connection</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">WiFi</span>.status() != WL_CONNECTED) &#123;</span><br><span class="line">        <span class="built_in">delay</span>(<span class="number">500</span>);</span><br><span class="line">        <span class="built_in">Serial</span>.<span class="built_in">print</span>(<span class="string">"."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">""</span>);</span><br><span class="line">    <span class="built_in">Serial</span>.<span class="built_in">print</span>(<span class="string">"Connected to "</span>);</span><br><span class="line">    <span class="built_in">Serial</span>.<span class="built_in">println</span>(ssid);</span><br><span class="line">    <span class="built_in">Serial</span>.<span class="built_in">print</span>(<span class="string">"IP address: "</span>);</span><br><span class="line">    <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="built_in">WiFi</span>.<span class="built_in">localIP</span>());</span><br><span class="line"></span><br><span class="line">    server.on(<span class="string">"/"</span>, []() &#123;</span><br><span class="line">        <span class="keyword">if</span> (!server.authenticate(user,pass))</span><br><span class="line">        <span class="keyword">return</span> server.requestAuthentication(DIGEST_AUTH, realm, authFailResponse);</span><br><span class="line">        <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">"GET INDEX PAGE"</span>);</span><br><span class="line">        <span class="keyword">String</span> s = MAIN_page;</span><br><span class="line">        server.send(<span class="number">200</span>, <span class="string">"text/html"</span>, s);</span><br><span class="line">   &#125;);</span><br><span class="line">   server.on(<span class="string">"/pcon"</span>,[]() &#123;</span><br><span class="line">        <span class="keyword">if</span> (!server.authenticate(user,pass))</span><br><span class="line">        <span class="keyword">return</span> server.requestAuthentication(DIGEST_AUTH, realm, authFailResponse);</span><br><span class="line">        <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">"PC POWER TRUN ON"</span>);</span><br><span class="line">        <span class="built_in">digitalWrite</span>(LED,<span class="literal">LOW</span>);</span><br><span class="line">        <span class="built_in">digitalWrite</span>(SW,<span class="literal">LOW</span>);</span><br><span class="line">        <span class="built_in">delay</span>(<span class="number">800</span>);</span><br><span class="line">        <span class="built_in">digitalWrite</span>(SW,<span class="literal">HIGH</span>);</span><br><span class="line">        server.send(<span class="number">200</span>, <span class="string">"text/html"</span>, <span class="string">"PC POWER TRUN ON"</span>);</span><br><span class="line">   &#125;);</span><br><span class="line">   server.on(<span class="string">"/pcoff"</span>, []() &#123;</span><br><span class="line">        <span class="keyword">if</span> (!server.authenticate(user,pass))</span><br><span class="line">        <span class="keyword">return</span> server.requestAuthentication(DIGEST_AUTH, realm, authFailResponse);</span><br><span class="line">        <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">"PC POWER TRUN OFF"</span>);</span><br><span class="line">        <span class="built_in">digitalWrite</span>(LED,<span class="literal">HIGH</span>); <span class="comment">//LED off</span></span><br><span class="line">        <span class="built_in">digitalWrite</span>(SW,<span class="literal">HIGH</span>); <span class="comment">//LED off</span></span><br><span class="line">        server.send(<span class="number">200</span>, <span class="string">"text/html"</span>, <span class="string">"PC POWER TRUN OFF"</span>);</span><br><span class="line">   &#125;);</span><br><span class="line">   server.on(<span class="string">"/pcon"</span>, handlePCon);</span><br><span class="line">   server.on(<span class="string">"/pcoff"</span>, handlePCoff);</span><br><span class="line">   server.<span class="built_in">begin</span>();</span><br><span class="line">   <span class="built_in">Serial</span>.<span class="built_in">println</span>(<span class="string">"HTTP server started"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">loop</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  server.handleClient();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>本来第一版写的很复杂，还整了个 HTML  页面，加了个权限认证什么的，杂七杂八的的，最后还是全都去掉了，因为开机的话我习惯于命令行，还是直接在路由器上使用一个 curl 命令就能搞定（已配置好 frp 内网穿透）。另外在路由器上配置好防火墙规则，仅允许路由器本机 IP 访问  ESP8266 的 IP，这样就免去的认证的麻烦，省事儿😂。为了安全起见，就没有把 ESP8266 监听的端口内网穿透到我的服务器。我一般都是通过 frp 连接到我家里的路由器，然后再在上面操作，当然写了别名就更方便了。</p>
]]></content>
      <tags>
        <tag>ESP8266</tag>
        <tag>嵌入式</tag>
      </tags>
  </entry>
  <entry>
    <title>OVF 与 OVA 区别与转换</title>
    <url>/archives/ovf-to-ova.html</url>
    <content><![CDATA[<p>在 ESXi 上导出虚拟机的时候，vSphere Web 端只能导出 ovf 格式的虚拟机，无法导出 OVA 格式的，使用 vSphere client 能导出这两种格式。看来一哈官方文档和标准手册，才明白。其实 OVA 是 ovf 的打包文件，导入 ova 格式的时候会自动解包出虚拟机的元数据信息。</p>
<h2 id="OVF"><a href="#OVF" class="headerlink" title="OVF"></a>OVF</h2><blockquote>
<p>The OVF descriptor contains the metadata about the OVF package. This is an extensible XML document  for encoding information, such as product details, virtual hardware requirements, and licensing.</p>
</blockquote>
<p>根据 <code>Open Virtualization Format</code> 的标准手册 <a href="https://www.dmtf.org/sites/default/files/standards/documents/DSP0243_2.1.1.pdf" target="_blank" rel="noopener">Open Virtualization Format Specification</a> 的描述，OVF 包含以下文件。确切地来讲 OVF 不是单个文件，而是一个未打包成一个文件的包？ 虽然这样讲不太严格😂。打包成一个文件就时 OVA 而已。</p>
<ul>
<li>one OVF descriptor with extension .ovf</li>
</ul>
<blockquote>
<p>描述符用于指定服务对虚拟硬件的要求，并且还包括其他信息，例如虚拟磁盘的说明、服务本身、来宾操作系统、许可协议 (EULA)、在设备中启动和停止 VM 的说明以及服务安装说明。描述符文件的扩展名为 .ovf 。</p>
</blockquote>
<ul>
<li>zero or one OVF manifest with extension .mf</li>
</ul>
<p>清单文件是软件包中每个文件的 SHA-1 摘要，可以用来检测任何损坏，以验证软件包的内容。清单文件的扩展名为 .mf 。</p>
<ul>
<li>zero or one OVF certificate with extension .cert</li>
</ul>
<blockquote>
<p>签名是用软件包所含 X.509 证书中的公钥进行签名的清单文件摘要，用于对软件包作者进行验证。签名文件的扩展名为 .cert 。</p>
</blockquote>
<ul>
<li>zero or more disk image files</li>
</ul>
<blockquote>
<p>OVF 不指定磁盘映像格式。OVF 包中包含组成虚拟磁盘的文件（格式由导出虚拟磁盘所用的虚拟化产品定义）。XenServer 生成的 OVF 包具有动态 VHD 格式的磁盘映像；VMware 产品和 Virtual Box 生成的 OVF 包具有流技术优化 VMDK 格式的虚拟磁盘。</p>
</blockquote>
<ul>
<li>zero or more additional resource files, such as ISO images</li>
</ul>
<h3 id="mf"><a href="#mf" class="headerlink" title=".mf"></a>.mf</h3><blockquote>
<p> An OVF package may have a manifest file containing the SHA digests of individual files in the package.OVF packages authored according to this version of the specification shall use SHA256 digests. The manifest file shall have an extension .mf and the same base name as the .ovf file and be a sibling of the .ovf file. If the manifest file is present, a consumer of the OVF package should verify the digests in the manifest file in the OVF package by computing the actual SHA digests and comparing them with the digests listed in the manifest file. The manifest file shall contain SHA digests for all distinct files referenced in the References element of the OVF descriptor and for no other files.</p>
</blockquote>
<p>翻译一哈</p>
<blockquote>
<p>一个 OVF 包可能会有一个</p>
</blockquote>
<table>
<thead>
<tr>
<th>file</th>
<th>usage</th>
<th style="text-align:center">need</th>
</tr>
</thead>
<tbody>
<tr>
<td>one OVF descriptor with extension .ovf</td>
<td>虚拟机配置信息</td>
<td style="text-align:center">必须</td>
</tr>
<tr>
<td>zero or one OVF manifest with extension .mf</td>
<td>SHA256</td>
<td style="text-align:center">非必须</td>
</tr>
<tr>
<td>zero or one OVF certificate with extension .cert</td>
<td>验证证书</td>
<td style="text-align:center">非必须</td>
</tr>
<tr>
<td>zero or more disk image files</td>
<td>虚拟机磁盘</td>
<td style="text-align:center">非必须</td>
</tr>
<tr>
<td>zero or more additional resource files, such as ISO images</td>
<td>其他资源</td>
<td style="text-align:center">非必须</td>
</tr>
</tbody>
</table>
<p>下面看一个 ovf 文件的示例 ，可以看出 ovf 是 xml 格式的，描述了虚拟机的配置信息、元数据信息</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version='1.0' encoding='UTF-8'?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Envelope</span> <span class="attr">xmlns</span>=<span class="string">"http://schemas.dmtf.org/ovf/envelope/1"</span> <span class="attr">xmlns:ovf</span>=<span class="string">"http://schemas.dmtf.org/ovf/envelope/1"</span> <span class="attr">xmlns:vmw</span>=<span class="string">"http://www.vmware.com/schema/ovf"</span> <span class="attr">xmlns:rasd</span>=<span class="string">"http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/CIM_ResourceAllocationSettingData"</span> <span class="attr">xmlns:vssd</span>=<span class="string">"http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/CIM_VirtualSystemSettingData"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">References</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">File</span> <span class="attr">ovf:id</span>=<span class="string">"file1"</span> <span class="attr">ovf:href</span>=<span class="string">"Alpine-240-1.vmdk"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">References</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">DiskSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Info</span>&gt;</span>List of the virtual disks<span class="tag">&lt;/<span class="name">Info</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Disk</span> <span class="attr">ovf:capacityAllocationUnits</span>=<span class="string">"byte"</span> <span class="attr">ovf:format</span>=<span class="string">"http://www.vmware.com/interfaces/specifications/vmdk.html#streamOptimized"</span> <span class="attr">ovf:diskId</span>=<span class="string">"vmdisk1"</span> <span class="attr">ovf:capacity</span>=<span class="string">"2147483648"</span> <span class="attr">ovf:fileRef</span>=<span class="string">"file1"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">DiskSection</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">NetworkSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Info</span>&gt;</span>The list of logical networks<span class="tag">&lt;/<span class="name">Info</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Network</span> <span class="attr">ovf:name</span>=<span class="string">"VM Network"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Description</span>&gt;</span>The VM Network network<span class="tag">&lt;/<span class="name">Description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Network</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">NetworkSection</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">VirtualSystem</span> <span class="attr">ovf:id</span>=<span class="string">"Alpine-240"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Info</span>&gt;</span>A Virtual system<span class="tag">&lt;/<span class="name">Info</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Name</span>&gt;</span>Alpine-240<span class="tag">&lt;/<span class="name">Name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OperatingSystemSection</span> <span class="attr">ovf:id</span>=<span class="string">"101"</span> <span class="attr">vmw:osType</span>=<span class="string">"otherLinux64Guest"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Info</span>&gt;</span>The operating system installed<span class="tag">&lt;/<span class="name">Info</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Description</span>&gt;</span>其他 Linux (64 位)<span class="tag">&lt;/<span class="name">Description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">OperatingSystemSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">VirtualHardwareSection</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Info</span>&gt;</span>Virtual hardware requirements<span class="tag">&lt;/<span class="name">Info</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">System</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vssd:ElementName</span>&gt;</span>Virtual Hardware Family<span class="tag">&lt;/<span class="name">vssd:ElementName</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vssd:InstanceID</span>&gt;</span>0<span class="tag">&lt;/<span class="name">vssd:InstanceID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vssd:VirtualSystemType</span>&gt;</span>vmx-11<span class="tag">&lt;/<span class="name">vssd:VirtualSystemType</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">System</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Item</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:AllocationUnits</span>&gt;</span>hertz * 10^6<span class="tag">&lt;/<span class="name">rasd:AllocationUnits</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:Description</span>&gt;</span>Number of Virtual CPUs<span class="tag">&lt;/<span class="name">rasd:Description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ElementName</span>&gt;</span>2 virtual CPU(s)<span class="tag">&lt;/<span class="name">rasd:ElementName</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:InstanceID</span>&gt;</span>1<span class="tag">&lt;/<span class="name">rasd:InstanceID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ResourceType</span>&gt;</span>3<span class="tag">&lt;/<span class="name">rasd:ResourceType</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:VirtualQuantity</span>&gt;</span>2<span class="tag">&lt;/<span class="name">rasd:VirtualQuantity</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:CoresPerSocket</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span>&gt;</span>1<span class="tag">&lt;/<span class="name">vmw:CoresPerSocket</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">Item</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Item</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:AllocationUnits</span>&gt;</span>byte * 2^20<span class="tag">&lt;/<span class="name">rasd:AllocationUnits</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:Description</span>&gt;</span>Memory Size<span class="tag">&lt;/<span class="name">rasd:Description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ElementName</span>&gt;</span>2048MB of memory<span class="tag">&lt;/<span class="name">rasd:ElementName</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:InstanceID</span>&gt;</span>2<span class="tag">&lt;/<span class="name">rasd:InstanceID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ResourceType</span>&gt;</span>4<span class="tag">&lt;/<span class="name">rasd:ResourceType</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:VirtualQuantity</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">rasd:VirtualQuantity</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">Item</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Item</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:Address</span>&gt;</span>0<span class="tag">&lt;/<span class="name">rasd:Address</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:Description</span>&gt;</span>SCSI Controller<span class="tag">&lt;/<span class="name">rasd:Description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ElementName</span>&gt;</span>SCSI Controller 1<span class="tag">&lt;/<span class="name">rasd:ElementName</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:InstanceID</span>&gt;</span>3<span class="tag">&lt;/<span class="name">rasd:InstanceID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ResourceSubType</span>&gt;</span>lsilogic<span class="tag">&lt;/<span class="name">rasd:ResourceSubType</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ResourceType</span>&gt;</span>6<span class="tag">&lt;/<span class="name">rasd:ResourceType</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"slotInfo.pciSlotNumber"</span> <span class="attr">vmw:value</span>=<span class="string">"16"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">Item</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Item</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:AddressOnParent</span>&gt;</span>0<span class="tag">&lt;/<span class="name">rasd:AddressOnParent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ElementName</span>&gt;</span>Hard Disk 1<span class="tag">&lt;/<span class="name">rasd:ElementName</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:HostResource</span>&gt;</span>ovf:/disk/vmdisk1<span class="tag">&lt;/<span class="name">rasd:HostResource</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:InstanceID</span>&gt;</span>4<span class="tag">&lt;/<span class="name">rasd:InstanceID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:Parent</span>&gt;</span>3<span class="tag">&lt;/<span class="name">rasd:Parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ResourceType</span>&gt;</span>17<span class="tag">&lt;/<span class="name">rasd:ResourceType</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">Item</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Item</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:AddressOnParent</span>&gt;</span>0<span class="tag">&lt;/<span class="name">rasd:AddressOnParent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:AutomaticAllocation</span>&gt;</span>true<span class="tag">&lt;/<span class="name">rasd:AutomaticAllocation</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:Connection</span>&gt;</span>VM Network<span class="tag">&lt;/<span class="name">rasd:Connection</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ElementName</span>&gt;</span>Network adapter 1<span class="tag">&lt;/<span class="name">rasd:ElementName</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:InstanceID</span>&gt;</span>5<span class="tag">&lt;/<span class="name">rasd:InstanceID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ResourceSubType</span>&gt;</span>E1000<span class="tag">&lt;/<span class="name">rasd:ResourceSubType</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ResourceType</span>&gt;</span>10<span class="tag">&lt;/<span class="name">rasd:ResourceType</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"connectable.allowGuestControl"</span> <span class="attr">vmw:value</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"slotInfo.pciSlotNumber"</span> <span class="attr">vmw:value</span>=<span class="string">"32"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"wakeOnLanEnabled"</span> <span class="attr">vmw:value</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">Item</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Item</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ElementName</span>&gt;</span>Video card<span class="tag">&lt;/<span class="name">rasd:ElementName</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:InstanceID</span>&gt;</span>6<span class="tag">&lt;/<span class="name">rasd:InstanceID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rasd:ResourceType</span>&gt;</span>24<span class="tag">&lt;/<span class="name">rasd:ResourceType</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"videoRamSizeInKB"</span> <span class="attr">vmw:value</span>=<span class="string">"4096"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"useAutoDetect"</span> <span class="attr">vmw:value</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"graphicsMemorySizeInKB"</span> <span class="attr">vmw:value</span>=<span class="string">"262144"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"numDisplays"</span> <span class="attr">vmw:value</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"enable3DSupport"</span> <span class="attr">vmw:value</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"use3dRenderer"</span> <span class="attr">vmw:value</span>=<span class="string">"automatic"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">Item</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"cpuHotAddEnabled"</span> <span class="attr">vmw:value</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"nestedHVEnabled"</span> <span class="attr">vmw:value</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"virtualSMCPresent"</span> <span class="attr">vmw:value</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"cpuHotRemoveEnabled"</span> <span class="attr">vmw:value</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"memoryHotAddEnabled"</span> <span class="attr">vmw:value</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"firmware"</span> <span class="attr">vmw:value</span>=<span class="string">"bios"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:Config</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"virtualICH7MPresent"</span> <span class="attr">vmw:value</span>=<span class="string">"false"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:ExtraConfig</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"nvram"</span> <span class="attr">vmw:value</span>=<span class="string">"Alpine-240.nvram"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">vmw:ExtraConfig</span> <span class="attr">ovf:required</span>=<span class="string">"false"</span> <span class="attr">vmw:key</span>=<span class="string">"virtualHW.productCompatibility"</span> <span class="attr">vmw:value</span>=<span class="string">"hosted"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">VirtualHardwareSection</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">VirtualSystem</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Envelope</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>下面是 mf 文件信息</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">SHA256(Alpine-240.ovf)= 3d5b06e6741da7919e33775fb2c1b3e77968b4d7b020f4055a8a401f1127be29</span><br><span class="line">SHA256(Alpine-240-1.vmdk)= b41596be4a846877cf82c4fd221763ba1cb4384f178454dc064f60f2ccdfd50e</span><br></pre></td></tr></table></figure>
<p>在导入 ovf 格式的虚拟机文件时，会解析这个ovf 文件，通过这个文件里描述的设备信息自动创建新的虚拟机。</p>
<h2 id="OVA"><a href="#OVA" class="headerlink" title="OVA"></a>OVA</h2><p>根据官方的描述</p>
<blockquote>
<p>An OVF package can be stored as either a single compressed file (.ova) or a set of files</p>
<p>An OVF package may be stored as a compressed OVF package or as a set of files in a directory structure. A compressed OVF package is stored as single file. The file extension is .ova (open virtual appliance or application).</p>
<p>In addition, the entries shall be in one of the following orders inside the OVF package:</p>
<ul>
<li>1) OVF descriptor</li>
<li>2) The remaining files shall be in the same order as listed in the References section</li>
</ul>
<p>or</p>
<ul>
<li>1) OVF descriptor</li>
<li>2) OVF manifest</li>
<li>3) OVF certificate</li>
</ul>
<p>or</p>
<ul>
<li>1) OVF descriptor</li>
<li>2) The intermediate files shall be in the same order as listed in the References section</li>
<li>3) OVF manifest</li>
<li>4) OVF certificate</li>
</ul>
</blockquote>
<p>需要注意的是，OVA 单个文件里打包了 OVF 所有的文件，文件是有顺序的，第一个一定要是 OVF 描述文件，即导出虚拟机时的那个 .ovf 后缀的文件</p>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>OVF 包包含一系列未压缩的文件，对于需要访问文件中各个磁盘映像的用户而言较为方便，而 OVA 包只是一个大型文件。尽管您可以压缩此文件，但它不像一系列文件（如 OVF）那样灵活。</p>
<p>OVA 更适用于适合只使用一个文件的特定应用场合（例如创建用于 Web 下载的软件包），这种情况下软件包更易于处理。与 OVF 相比，导出和导入 OVA 包所需的时间更长。</p>
<h2 id="转换"><a href="#转换" class="headerlink" title="转换"></a>转换</h2><h3 id="OVA-转-OVF-很简单，使用-tar-解包就行"><a href="#OVA-转-OVF-很简单，使用-tar-解包就行" class="headerlink" title="OVA 转 OVF 很简单，使用 tar 解包就行"></a>OVA 转 OVF 很简单，使用 tar 解包就行</h3><p>比如任意解包一个 OVA 文件后会出来 <code>ovf  vmdk mf</code> 这三个文件，而且解包出来的顺序也是和 OVA 标准定义的那样，第一个必须未 .ovf 文件。这里我讲的是解包而不是解压，是因为 OVA 和 OVF 里包含的文件，最大的就是磁盘文件，而磁盘文件在导出的时候虚拟机已经进行了压缩，你可以使用 df 命令看看磁盘占用的空间，以及导出的磁盘占用的空间，你就会发现导出的磁盘文件大小远小于系统占用的空间。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -xvf Ubuntu1804.ova</span><br><span class="line">Ubuntu1804.ovf</span><br><span class="line">Ubuntu1804-disk1.vmdk</span><br><span class="line">Ubuntu1804.mf</span><br></pre></td></tr></table></figure>
<h3 id="OVF-转-OVA"><a href="#OVF-转-OVA" class="headerlink" title="OVF 转 OVA"></a>OVF 转 OVA</h3><p>按照 OVA 标准的格式，按顺序打包 OVF 包里的文件就行，注意 .ovf 文件一定要在第一个</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -cf OP.ova Ubuntu1804.ovf Ubuntu1804-disk1.vmdk Ubuntu1804.mf</span><br></pre></td></tr></table></figure>
<h3 id="OVA-tar-OVF-？"><a href="#OVA-tar-OVF-？" class="headerlink" title="OVA = tar OVF ？"></a>OVA = tar OVF ？</h3><p>我们把 OVA 解包出来，再打包回去，两者文件是否一样呢？</p>
<p>看一下两者的 sha256sum 信息就可以了，结果证明是不一样的</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">e6b0f08dc80ef6509cd547b87d8fe9373069d6758b86f3cbb43e804a3c9b7e7d  Ubuntu1804.ova</span><br><span class="line">d56d3fa5f3a57f7210726303ef32fd96d98cc7522af4f4fdbac2be7f23a5cadb  OP.ova</span><br></pre></td></tr></table></figure>
<p>两者导入虚拟机后没有任何差别，都可以导进去，都能开机和使用，但新生成的 OVA 文件元数据信息是不一样的。</p>
<p>使用 less 命令看一下两者的文件头</p>
<p>原来的 OVA 文件头</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Ubuntu1804.ovf^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@0000644^@0000100^@0000100^@00000017732^@13531417642^@0012505^@0^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@ustar^@ ^@VMware^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@VMware^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br></pre></td></tr></table></figure>
<p>新生成的 OVA 文件头</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Ubuntu1804.ovf^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@0000777^@0001750^@0001750^@00000017732^@13531417642^@012152^@ 0^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@ustar  ^@muzi^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@muzi^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@</span><br><span class="line">^@^@&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br></pre></td></tr></table></figure>
<p>第一眼看到 <code>644 755 777</code> 就发现，这一定是文件的权限，其中还有文件所属用户，原来的是 VMware 用户，而新生成的是我本地的用户。</p>
<p>刨根到底，去看一哈 tar 包的定义<a href="https://www.gnu.org/software/tar/manual/html_node/Standard.html#SEC188" target="_blank" rel="noopener">Basic Tar Format</a>  tar 包就是由一个个文件顺序排列而成，每个文件由两部分组成：文件头和文件内容。就像下面这样</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">|文件头|文件内容|--|文件头|文件内容|--|文件头|文件内容|--|文件头|文件内容|</span><br></pre></td></tr></table></figure>
<p>我们从 OVA 解包出来后，文件头的内容就会更改为我们本机的内容，而不再是原有的文件所主。</p>
<p>文件头的定义在</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/* tar Header Block, from POSIX 1003.1-1990.  */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* POSIX header.  */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">posix_header</span></span></span><br><span class="line"><span class="class">&#123;</span>                       <span class="comment">/* byte offset */</span></span><br><span class="line">  <span class="keyword">char</span> name[<span class="number">100</span>];       <span class="comment">/*   0 */</span>   文件名</span><br><span class="line">  <span class="keyword">char</span> mode[<span class="number">8</span>];         <span class="comment">/* 100 */</span>   用户权限</span><br><span class="line">  <span class="keyword">char</span> uid[<span class="number">8</span>];          <span class="comment">/* 108 */</span>   user id</span><br><span class="line">  <span class="keyword">char</span> gid[<span class="number">8</span>];          <span class="comment">/* 116 */</span>   group id</span><br><span class="line">  <span class="keyword">char</span> <span class="built_in">size</span>[<span class="number">12</span>];        <span class="comment">/* 124 */</span>   文件大小</span><br><span class="line">  <span class="keyword">char</span> mtime[<span class="number">12</span>];       <span class="comment">/* 136 */</span>   修改时间</span><br><span class="line">  <span class="keyword">char</span> chksum[<span class="number">8</span>];       <span class="comment">/* 148 */</span>   校验值</span><br><span class="line">  <span class="keyword">char</span> typeflag;        <span class="comment">/* 156 */</span>   文件类型标志</span><br><span class="line">  <span class="keyword">char</span> linkname[<span class="number">100</span>];   <span class="comment">/* 157 */</span>   符号链接指向</span><br><span class="line">  <span class="keyword">char</span> magic[<span class="number">6</span>];        <span class="comment">/* 257 */</span></span><br><span class="line">  <span class="keyword">char</span> version[<span class="number">2</span>];      <span class="comment">/* 263 */</span></span><br><span class="line">  <span class="keyword">char</span> uname[<span class="number">32</span>];       <span class="comment">/* 265 */</span>   user name</span><br><span class="line">  <span class="keyword">char</span> gname[<span class="number">32</span>];       <span class="comment">/* 297 */</span>   group name</span><br><span class="line">  <span class="keyword">char</span> devmajor[<span class="number">8</span>];     <span class="comment">/* 329 */</span>   设备文件 major</span><br><span class="line">  <span class="keyword">char</span> devminor[<span class="number">8</span>];     <span class="comment">/* 337 */</span>   设备文件 minor</span><br><span class="line">  <span class="keyword">char</span> prefix[<span class="number">155</span>];     <span class="comment">/* 345 */</span></span><br><span class="line">                        <span class="comment">/* 500 */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TMAGIC   <span class="meta-string">"ustar"</span>        <span class="comment">/* ustar and a null */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TMAGLEN  6</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TVERSION <span class="meta-string">"00"</span>           <span class="comment">/* 00 and no null */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TVERSLEN 2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Values used in typeflag field.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> REGTYPE  <span class="meta-string">'0'</span>            <span class="comment">/* regular file */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> AREGTYPE <span class="meta-string">'\0'</span>           <span class="comment">/* regular file */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> LNKTYPE  <span class="meta-string">'1'</span>            <span class="comment">/* link */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SYMTYPE  <span class="meta-string">'2'</span>            <span class="comment">/* reserved */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CHRTYPE  <span class="meta-string">'3'</span>            <span class="comment">/* character special */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BLKTYPE  <span class="meta-string">'4'</span>            <span class="comment">/* block special */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DIRTYPE  <span class="meta-string">'5'</span>            <span class="comment">/* directory */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FIFOTYPE <span class="meta-string">'6'</span>            <span class="comment">/* FIFO special */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CONTTYPE <span class="meta-string">'7'</span>            <span class="comment">/* reserved */</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> XHDTYPE  <span class="meta-string">'x'</span>            <span class="comment">/* Extended header referring to the</span></span></span><br><span class="line"><span class="meta"><span class="comment">                                   next file in the archive */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> XGLTYPE  <span class="meta-string">'g'</span>            <span class="comment">/* Global extended header */</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Bits used in the mode field, values in octal.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TSUID    04000          <span class="comment">/* set UID on execution */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TSGID    02000          <span class="comment">/* set GID on execution */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TSVTX    01000          <span class="comment">/* reserved */</span></span></span><br><span class="line">                                <span class="comment">/* file permissions */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TUREAD   00400          <span class="comment">/* read by owner */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TUWRITE  00200          <span class="comment">/* write by owner */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TUEXEC   00100          <span class="comment">/* execute/search by owner */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TGREAD   00040          <span class="comment">/* read by group */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TGWRITE  00020          <span class="comment">/* write by group */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TGEXEC   00010          <span class="comment">/* execute/search by group */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TOREAD   00004          <span class="comment">/* read by other */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TOWRITE  00002          <span class="comment">/* write by other */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TOEXEC   00001          <span class="comment">/* execute/search by other */</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* tar Header Block, GNU extensions.  */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* In GNU tar, SYMTYPE is for to symbolic links, and CONTTYPE is for</span></span><br><span class="line"><span class="comment">   contiguous files, so maybe disobeying the "reserved" comment in POSIX</span></span><br><span class="line"><span class="comment">   header description.  I suspect these were meant to be used this way, and</span></span><br><span class="line"><span class="comment">   should not have really been "reserved" in the published standards.  */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* *BEWARE* *BEWARE* *BEWARE* that the following information is still</span></span><br><span class="line"><span class="comment">   boiling, and may change.  Even if the OLDGNU format description should be</span></span><br><span class="line"><span class="comment">   accurate, the so-called GNU format is not yet fully decided.  It is</span></span><br><span class="line"><span class="comment">   surely meant to use only extensions allowed by POSIX, but the sketch</span></span><br><span class="line"><span class="comment">   below repeats some ugliness from the OLDGNU format, which should rather</span></span><br><span class="line"><span class="comment">   go away.  Sparse files should be saved in such a way that they do *not*</span></span><br><span class="line"><span class="comment">   require two passes at archive creation time.  Huge files get some POSIX</span></span><br><span class="line"><span class="comment">   fields to overflow, alternate solutions have to be sought for this.  */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Descriptor for a single file hole.  */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sparse</span></span></span><br><span class="line"><span class="class">&#123;</span>                              <span class="comment">/* byte offset */</span></span><br><span class="line">  <span class="keyword">char</span> offset[<span class="number">12</span>];              <span class="comment">/*   0 */</span></span><br><span class="line">  <span class="keyword">char</span> numbytes[<span class="number">12</span>];            <span class="comment">/*  12 */</span></span><br><span class="line">                                <span class="comment">/*  24 */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Sparse files are not supported in POSIX ustar format.  For sparse files</span></span><br><span class="line"><span class="comment">   with a POSIX header, a GNU extra header is provided which holds overall</span></span><br><span class="line"><span class="comment">   sparse information and a few sparse descriptors.  When an old GNU header</span></span><br><span class="line"><span class="comment">   replaces both the POSIX header and the GNU extra header, it holds some</span></span><br><span class="line"><span class="comment">   sparse descriptors too.  Whether POSIX or not, if more sparse descriptors</span></span><br><span class="line"><span class="comment">   are still needed, they are put into as many successive sparse headers as</span></span><br><span class="line"><span class="comment">   necessary.  The following constants tell how many sparse descriptors fit</span></span><br><span class="line"><span class="comment">   in each kind of header able to hold them.  */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SPARSES_IN_EXTRA_HEADER  16</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SPARSES_IN_OLDGNU_HEADER 4</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SPARSES_IN_SPARSE_HEADER 21</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Extension header for sparse files, used immediately after the GNU extra</span></span><br><span class="line"><span class="comment">   header, and used only if all sparse information cannot fit into that</span></span><br><span class="line"><span class="comment">   extra header.  There might even be many such extension headers, one after</span></span><br><span class="line"><span class="comment">   the other, until all sparse information has been recorded.  */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sparse_header</span></span></span><br><span class="line"><span class="class">&#123;</span>                              <span class="comment">/* byte offset */</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">sparse</span> <span class="title">sp</span>[<span class="title">SPARSES_IN_SPARSE_HEADER</span>];</span></span><br><span class="line">                                <span class="comment">/*   0 */</span></span><br><span class="line">  <span class="keyword">char</span> isextended;              <span class="comment">/* 504 */</span></span><br><span class="line">                                <span class="comment">/* 505 */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* The old GNU format header conflicts with POSIX format in such a way that</span></span><br><span class="line"><span class="comment">   POSIX archives may fool old GNU tar's, and POSIX tar's might well be</span></span><br><span class="line"><span class="comment">   fooled by old GNU tar archives.  An old GNU format header uses the space</span></span><br><span class="line"><span class="comment">   used by the prefix field in a POSIX header, and cumulates information</span></span><br><span class="line"><span class="comment">   normally found in a GNU extra header.  With an old GNU tar header, we</span></span><br><span class="line"><span class="comment">   never see any POSIX header nor GNU extra header.  Supplementary sparse</span></span><br><span class="line"><span class="comment">   headers are allowed, however.  */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">oldgnu_header</span></span></span><br><span class="line"><span class="class">&#123;</span>                              <span class="comment">/* byte offset */</span></span><br><span class="line">  <span class="keyword">char</span> unused_pad1[<span class="number">345</span>];        <span class="comment">/*   0 */</span></span><br><span class="line">  <span class="keyword">char</span> atime[<span class="number">12</span>];               <span class="comment">/* 345 Incr. archive: atime of the file */</span></span><br><span class="line">  <span class="keyword">char</span> ctime[<span class="number">12</span>];               <span class="comment">/* 357 Incr. archive: ctime of the file */</span></span><br><span class="line">  <span class="keyword">char</span> offset[<span class="number">12</span>];              <span class="comment">/* 369 Multivolume archive: the offset of</span></span><br><span class="line"><span class="comment">                                   the start of this volume */</span></span><br><span class="line">  <span class="keyword">char</span> longnames[<span class="number">4</span>];            <span class="comment">/* 381 Not used */</span></span><br><span class="line">  <span class="keyword">char</span> unused_pad2;             <span class="comment">/* 385 */</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">sparse</span> <span class="title">sp</span>[<span class="title">SPARSES_IN_OLDGNU_HEADER</span>];</span></span><br><span class="line">                                <span class="comment">/* 386 */</span></span><br><span class="line">  <span class="keyword">char</span> isextended;              <span class="comment">/* 482 Sparse file: Extension sparse header</span></span><br><span class="line"><span class="comment">                                   follows */</span></span><br><span class="line">  <span class="keyword">char</span> realsize[<span class="number">12</span>];            <span class="comment">/* 483 Sparse file: Real size*/</span></span><br><span class="line">                                <span class="comment">/* 495 */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* OLDGNU_MAGIC uses both magic and version fields, which are contiguous.</span></span><br><span class="line"><span class="comment">   Found in an archive, it indicates an old GNU header format, which will be</span></span><br><span class="line"><span class="comment">   hopefully become obsolescent.  With OLDGNU_MAGIC, uname and gname are</span></span><br><span class="line"><span class="comment">   valid, though the header is not truly POSIX conforming.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OLDGNU_MAGIC <span class="meta-string">"ustar  "</span>  <span class="comment">/* 7 chars and a null */</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* The standards committee allows only capital A through capital Z for</span></span><br><span class="line"><span class="comment">   user-defined expansion.  Other letters in use include:</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">   'A' Solaris Access Control List</span></span><br><span class="line"><span class="comment">   'E' Solaris Extended Attribute File</span></span><br><span class="line"><span class="comment">   'I' Inode only, as in 'star'</span></span><br><span class="line"><span class="comment">   'N' Obsolete GNU tar, for file names that do not fit into the main header.</span></span><br><span class="line"><span class="comment">   'X' POSIX 1003.1-2001 eXtended (VU version)  */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* This is a dir entry that contains the names of files that were in the</span></span><br><span class="line"><span class="comment">   dir at the time the dump was made.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GNUTYPE_DUMPDIR <span class="meta-string">'D'</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Identifies the *next* file on the tape as having a long linkname.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GNUTYPE_LONGLINK <span class="meta-string">'K'</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Identifies the *next* file on the tape as having a long name.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GNUTYPE_LONGNAME <span class="meta-string">'L'</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* This is the continuation of a file that began on another volume.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GNUTYPE_MULTIVOL <span class="meta-string">'M'</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* This is for sparse files.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GNUTYPE_SPARSE <span class="meta-string">'S'</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* This file is a tape/volume header.  Ignore it on extraction.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GNUTYPE_VOLHDR <span class="meta-string">'V'</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Solaris extended header */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SOLARIS_XHDTYPE <span class="meta-string">'X'</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Jörg Schilling star header */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">star_header</span></span></span><br><span class="line"><span class="class">&#123;</span>                              <span class="comment">/* byte offset */</span></span><br><span class="line">  <span class="keyword">char</span> name[<span class="number">100</span>];               <span class="comment">/*   0 */</span></span><br><span class="line">  <span class="keyword">char</span> mode[<span class="number">8</span>];                 <span class="comment">/* 100 */</span></span><br><span class="line">  <span class="keyword">char</span> uid[<span class="number">8</span>];                  <span class="comment">/* 108 */</span></span><br><span class="line">  <span class="keyword">char</span> gid[<span class="number">8</span>];                  <span class="comment">/* 116 */</span></span><br><span class="line">  <span class="keyword">char</span> <span class="built_in">size</span>[<span class="number">12</span>];                <span class="comment">/* 124 */</span></span><br><span class="line">  <span class="keyword">char</span> mtime[<span class="number">12</span>];               <span class="comment">/* 136 */</span></span><br><span class="line">  <span class="keyword">char</span> chksum[<span class="number">8</span>];               <span class="comment">/* 148 */</span></span><br><span class="line">  <span class="keyword">char</span> typeflag;                <span class="comment">/* 156 */</span></span><br><span class="line">  <span class="keyword">char</span> linkname[<span class="number">100</span>];           <span class="comment">/* 157 */</span></span><br><span class="line">  <span class="keyword">char</span> magic[<span class="number">6</span>];                <span class="comment">/* 257 */</span></span><br><span class="line">  <span class="keyword">char</span> version[<span class="number">2</span>];              <span class="comment">/* 263 */</span></span><br><span class="line">  <span class="keyword">char</span> uname[<span class="number">32</span>];               <span class="comment">/* 265 */</span></span><br><span class="line">  <span class="keyword">char</span> gname[<span class="number">32</span>];               <span class="comment">/* 297 */</span></span><br><span class="line">  <span class="keyword">char</span> devmajor[<span class="number">8</span>];             <span class="comment">/* 329 */</span></span><br><span class="line">  <span class="keyword">char</span> devminor[<span class="number">8</span>];             <span class="comment">/* 337 */</span></span><br><span class="line">  <span class="keyword">char</span> prefix[<span class="number">131</span>];             <span class="comment">/* 345 */</span></span><br><span class="line">  <span class="keyword">char</span> atime[<span class="number">12</span>];               <span class="comment">/* 476 */</span></span><br><span class="line">  <span class="keyword">char</span> ctime[<span class="number">12</span>];               <span class="comment">/* 488 */</span></span><br><span class="line">                                <span class="comment">/* 500 */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SPARSES_IN_STAR_HEADER      4</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SPARSES_IN_STAR_EXT_HEADER  21</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">star_in_header</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="keyword">char</span> <span class="built_in">fill</span>[<span class="number">345</span>];       <span class="comment">/*   0  Everything that is before t_prefix */</span></span><br><span class="line">  <span class="keyword">char</span> prefix[<span class="number">1</span>];       <span class="comment">/* 345  t_name prefix */</span></span><br><span class="line">  <span class="keyword">char</span> fill2;           <span class="comment">/* 346  */</span></span><br><span class="line">  <span class="keyword">char</span> fill3[<span class="number">8</span>];        <span class="comment">/* 347  */</span></span><br><span class="line">  <span class="keyword">char</span> isextended;      <span class="comment">/* 355  */</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">sparse</span> <span class="title">sp</span>[<span class="title">SPARSES_IN_STAR_HEADER</span>];</span> <span class="comment">/* 356  */</span></span><br><span class="line">  <span class="keyword">char</span> realsize[<span class="number">12</span>];    <span class="comment">/* 452  Actual size of the file */</span></span><br><span class="line">  <span class="keyword">char</span> offset[<span class="number">12</span>];      <span class="comment">/* 464  Offset of multivolume contents */</span></span><br><span class="line">  <span class="keyword">char</span> atime[<span class="number">12</span>];       <span class="comment">/* 476  */</span></span><br><span class="line">  <span class="keyword">char</span> ctime[<span class="number">12</span>];       <span class="comment">/* 488  */</span></span><br><span class="line">  <span class="keyword">char</span> mfill[<span class="number">8</span>];        <span class="comment">/* 500  */</span></span><br><span class="line">  <span class="keyword">char</span> xmagic[<span class="number">4</span>];       <span class="comment">/* 508  "tar" */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">star_ext_header</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">sparse</span> <span class="title">sp</span>[<span class="title">SPARSES_IN_STAR_EXT_HEADER</span>];</span></span><br><span class="line">  <span class="keyword">char</span> isextended;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h2><p>通过阅读官方标准手册对 OVF 和 OVA 有两个更深刻的了解，对 tar 包的格式和 Unix 文件头初次了解。这么好的资料准备有空翻译几个关键的章节来水一篇博客😂</p>
]]></content>
      <tags>
        <tag>虚拟机</tag>
        <tag>VMware</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenWRT 软路由</title>
    <url>/archives/esxi-openwrt.html</url>
    <content><![CDATA[<p><strong>切记：先关闭 DHCP 再连网卡、先关闭 DHCP 再连网卡、先关闭 DHCP 再连网卡。重要事情说三遍。</strong></p>
<h2 id="Debian-透明代理网关？"><a href="#Debian-透明代理网关？" class="headerlink" title="Debian 透明代理网关？"></a>Debian 透明代理网关？</h2><p>之前写过一篇，用了一段时间后，感觉太难用了。其中最大的问题还是DNS ，不知道是怎么配置的问题， DNS 查询特别慢，往往需要将近一分钟才能查询到域名。速度上还算可以，能跑满我的 VPS 带宽。</p>
<h2 id="下载安装-x86-OpenWRT"><a href="#下载安装-x86-OpenWRT" class="headerlink" title="下载安装 x86 OpenWRT"></a>下载安装 x86 OpenWRT</h2><p>下载地址在 OpenWRT <a href="https://downloads.openwrt.org/releases/18.06.4/targets/x86/generic/" target="_blank" rel="noopener">官网</a>，固件选择<a href="https://downloads.openwrt.org/releases/18.06.4/targets/x86/legacy/openwrt-18.06.4-x86-legacy-combined-ext4.img.gz" target="_blank" rel="noopener">openwrt-18.06.4-x86-legacy-combined-ext4.img.gz</a> 就可以，他们之间的<a href="https://antkillerfarm.github.io/linux/2015/02/01/Openwrt.html" target="_blank" rel="noopener">区别在与</a></p>
<blockquote>
<p>这里解释一下该文件夹下各个文件的区别：</p>
<p>openwrt-x86-generic-combined-ext4.img.gz</p>
<p>rootfs工作区存储格式为ext4</p>
<p>openwrt-x86-generic-combined-jffs2-128k.img</p>
<p>jffs2可以修改，也就是可以自行更换（删除）rootfs的配置文件，而不需要重新刷固件。</p>
<p>openwrt-x86-generic-combined-squashfs.img</p>
<p>squashfs是个只读的文件系统，相当于win的ghost，使用中配置错误，可直接恢复默认。</p>
<p>openwrt-x86-generic-rootfs-ext4.img.gz</p>
<p>rootfs的镜像，不带引导，可自行定义用grub或者syslinux来引导，存储区为ext4。</p>
</blockquote>
<p>下载好 <code>openwrt-18.06.4-x86-legacy-combined-ext4.img.gz</code> 文件后解压后得到 <code>openwrt-18.06.4-x86-legacy-combined-ext4.img</code> 是 img 格式的文件，不过这个并不能直接供 ESXi 使用，需要使用镜像转换的工具转换成 vmdk 磁盘格式的才可以。</p>
<p>Windows 下可以使用 <a href="https://www.starwindsoftware.com/starwind-v2v-converter" target="_blank" rel="noopener">StarWind V2V Converter</a> 工具来进行转换，下载安装后按照下面的来就行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Local File --&gt; Source image --&gt; Local File --&gt; VMDK --&gt; ESXi server image</span><br></pre></td></tr></table></figure>
<p><img src="../img/1568876856613.png" alt="1568876856613"></p>
<p><img src="../img/1568876894451.png" alt="1568876894451"></p>
<p><img src="../img/1568876920080.png" alt="1568876920080"></p>
<p><img src="../img/1568876940778.png" alt="1568876940778"></p>
<p>转换完成后会有两个文件 <code>openwrt-18.06.4-x86-legacy-combined-ext4.vmdk</code> 和 <code>openwrt-18.06.4-x86-legacy-combined-ext4-flat.vmdk</code> ，这两个文件一并上传到 ESXi 服务器的数据存储里就行，上传完两个文件和，ESXi 会自动合并这两个文件为 <code>VMDK/openwrt-18.06.4-x86-legacy-combined-ext4.vmdk</code>。其实看这两个文件的大小我们就会明白，<code>openwrt-18.06.4-x86-legacy-combined-ext4.vmdk</code> 是个 vmdk 文件描述符文件，里面记录着 vmdk 的元数据信息。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">273M  openwrt-18.06.4-x86-legacy-combined-ext4-flat.img</span><br><span class="line">417B  openwrt-18.06.4-x86-legacy-combined-ext4.vmdk</span><br></pre></td></tr></table></figure>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Disk DescriptorFile</span></span><br><span class="line"><span class="attr">version</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">encoding</span>=<span class="string">"UTF-8"</span></span><br><span class="line"><span class="attr">CID</span>=<span class="number">3</span>b677c54</span><br><span class="line"><span class="attr">parentCID</span>=ffffffff</span><br><span class="line"><span class="attr">createType</span>=<span class="string">"vmfs"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extent description</span></span><br><span class="line">RW 558080 VMFS "openwrt-18.06.4-x86-legacy-combined-ext4-flat.vmdk" 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># The Disk Data Base</span></span><br><span class="line"><span class="comment">#DDB</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ddb.adapterType</span> = <span class="string">"lsilogic"</span></span><br><span class="line"><span class="attr">ddb.geometry.cylinders</span> = <span class="string">"35"</span></span><br><span class="line"><span class="attr">ddb.geometry.heads</span> = <span class="string">"255"</span></span><br><span class="line"><span class="attr">ddb.geometry.sectors</span> = <span class="string">"63"</span></span><br><span class="line"><span class="attr">ddb.uuid</span> = <span class="string">"73 5a 46 7e 46 7e a5 f2-98 88 0e 71 f3 88 92 42"</span></span><br><span class="line"><span class="attr">ddb.virtualHWVersion</span> = <span class="string">"4"</span></span><br></pre></td></tr></table></figure>
<p>接下来就是安装啦</p>
<p>在 ESXi 控制台页面使用刚才上传的那个 VMDK 磁盘文件搓一个虚拟机就行。</p>
<p><code>创建/注册虚拟机</code> –&gt; <code>创建新虚拟机</code> –&gt; <code>设置选择名称和客户机操作系统</code> –-&gt; <code>选择存储</code> –&gt; <code>自定义设置</code></p>
<p><img src="../img/1568860424585.png" alt="1568860424585"></p>
<p><strong>自定义设置</strong> 这一块一定要注意</p>
<p><img src="../img/1568860493961.png" alt="1568860493961"></p>
<p>选择添加硬盘为我们刚才新上传的哪个 VMDK 磁盘即可，然后网络适配器添加一个足够使用，如果你的 ESXi 主机有多块网卡的话可以考虑选择添加两个适配器，在此只把 OpenWRT 虚拟机当作一个旁路网关，一个网口足够了。把网络适配器 <code>连接</code> 那里<strong>关掉</strong>、把网络适配器 <code>连接</code> 那里<strong>关掉</strong>、把网络适配器 <code>连接</code> 那里<strong>关掉</strong>。不然你启动的时候这台 OpenWRT 软路由会在 LAN 口开启 DHCP 服务，如果你的网络环境是办公网络的话，这台开启 DHCP 的软路由可能会把整个办公网络弄瘫痪的。开启虚拟机后把 LAN 口的 DHCP 禁用掉，同时配置一个静态 IP 就可以。一个局域网里开两台 DHCP 服务器，当然会出问题的，惨痛的教训啊。</p>
<p>安装开机之后先上 <code>passwd</code> 命令设置一下 root 用户的密码。</p>
<p>接着修改一下网卡配置信息，在 lan 那个网口下配置一个静态 IP 和网关，然后</p>
<p><img src="../img/1568877917688.png" alt="1568877917688"></p>
<p>然后使用命令 <code>service dnsmasq disable</code> 、<code>service odhcp disable</code>  禁用掉 dhcp 服务即可。然后再编辑虚拟机的设置，把网卡连接上，再重启一下虚拟机即可。通过浏览器访问我们刚才配置的那个静态 IP。</p>
<p>也可以参照 OpenWRT 的<a href="https://openwrt.org/docs/guide-user/base-system/dhcp" target="_blank" rel="noopener">官方说明</a>，使用 uci 命令禁用掉 DHCP</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">uci del dhcp.cfg01411c.authoritative</span><br><span class="line">uci del dhcp.cfg01411c.boguspriv</span><br><span class="line">uci del dhcp.cfg01411c.filterwin2k</span><br><span class="line">uci del dhcp.cfg01411c.nonegcache</span><br></pre></td></tr></table></figure>
<p><img src="../img/1568878441039.png" alt="1568878441039"></p>
<h2 id="初始化安装系统"><a href="#初始化安装系统" class="headerlink" title="初始化安装系统"></a>初始化安装系统</h2>]]></content>
      <tags>
        <tag>科学上网</tag>
        <tag>OpenWRT</tag>
      </tags>
  </entry>
  <entry>
    <title>国内镜像源伪评测</title>
    <url>/archives/mirrors-test.html</url>
    <content><![CDATA[<p>根据自己的网络，如何选择一个适合自己的镜像源呢？可能大家使用的发行版不同，还好有了 docker 这个玩具，能使用不同的发行版镜像启动容器来测试。那么就选定国内知名的镜像源来个测试，供大家参考选择一个合适的发行版。如果是公有云服务器的话，肯定是选择厂商的镜像源啦，内网传输速度超快，所以这次的测试对公有云服务器毫无意义，仅仅针对于办公或家用网络哈。</p>
<h2 id="国内知名镜像源"><a href="#国内知名镜像源" class="headerlink" title="国内知名镜像源"></a>国内知名镜像源</h2><table>
<thead>
<tr>
<th style="text-align:center">所属</th>
<th style="text-align:center">官网</th>
<th style="text-align:center">评价</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">清华</td>
<td style="text-align:center"><a href="https://mirrors.tuna.tsinghua.edu.cn/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/</a></td>
<td style="text-align:center">速度 NO.1</td>
</tr>
<tr>
<td style="text-align:center">中科大</td>
<td style="text-align:center"><a href="https://mirrors.ustc.edu.cn/" target="_blank" rel="noopener">https://mirrors.ustc.edu.cn/</a></td>
<td style="text-align:center">速度最差</td>
</tr>
<tr>
<td style="text-align:center">163</td>
<td style="text-align:center"><a href="https://mirrors.163.com/" target="_blank" rel="noopener">https://mirrors.163.com/</a></td>
<td style="text-align:center">速度 NO.3</td>
</tr>
<tr>
<td style="text-align:center">阿里云</td>
<td style="text-align:center"><a href="https://mirrors.aliyun.com/" target="_blank" rel="noopener">https://mirrors.aliyun.com/</a></td>
<td style="text-align:center">速度 NO.2</td>
</tr>
<tr>
<td style="text-align:center">华为</td>
<td style="text-align:center"><a href="https://mirrors.huaweicloud.com/" target="_blank" rel="noopener">https://mirrors.huaweicloud.com/</a></td>
<td style="text-align:center">速度最快</td>
</tr>
</tbody>
</table>
<h2 id="测试系统"><a href="#测试系统" class="headerlink" title="测试系统"></a>测试系统</h2><p>选用 debian 10 ，安装的软件包有 <code>xfce4 gnome libreoffice  vlc</code> ，这三个包总大小 1014MB</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt install xfce4 gnome libreoffice  vlc -d -y</span><br><span class="line">0 upgraded, 1574 newly installed, 0 to remove and 0 not upgraded.</span><br><span class="line">Need to get 1014 MB of archives.</span><br><span class="line">After this operation, 3471 MB of additional disk space will be used.</span><br></pre></td></tr></table></figure>
<h2 id="测试过程"><a href="#测试过程" class="headerlink" title="测试过程"></a>测试过程</h2><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>公司办公网络是千兆内网，外网访问速度最快能达到 <code>50MB/s</code></p>
<p>测试方法很简单，使用 sed 替换掉原来的镜像域名就行，都使用 http 的方式下载 加上 -d 参数只下载即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">set</span> -xue</span><br><span class="line">sed -i <span class="string">'s/deb.debian.org/mirrors.aliyun.com/g'</span> /etc/apt/sources.list</span><br><span class="line">sed -i <span class="string">'s|security.debian.org/debian-security|mirrors.aliyun.com/debian-security|g'</span> /etc/apt/sources.list</span><br><span class="line">time apt update</span><br><span class="line">time apt install xfce4 gnome libreoffice  vlc -d -y</span><br></pre></td></tr></table></figure>
<h3 id="清华"><a href="#清华" class="headerlink" title="清华"></a>清华</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s/deb.debian.org/mirrors.tuna.tsinghua.edu.cn/g'</span> /etc/apt/sources.list</span><br><span class="line">sed -i <span class="string">'s|security.debian.org/debian-security|mirrors.tuna.tsinghua.edu.cn/debian-security|g'</span> /etc/apt/sources.list</span><br><span class="line">apt update</span><br><span class="line">root@6586bff7e2bf:/<span class="comment"># time apt update</span></span><br><span class="line">Get:1 http://mirrors.tuna.tsinghua.edu.cn/debian buster InRelease [122 kB]</span><br><span class="line">Get:2 http://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates InRelease [39.1 kB]</span><br><span class="line">Get:3 http://mirrors.tuna.tsinghua.edu.cn/debian buster-updates InRelease [49.3 kB]</span><br><span class="line">Get:4 http://mirrors.tuna.tsinghua.edu.cn/debian buster/main amd64 Packages [7899 kB]</span><br><span class="line">Get:5 http://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates/main amd64 Packages [85.3 kB]</span><br><span class="line">Get:6 http://mirrors.tuna.tsinghua.edu.cn/debian buster-updates/main amd64 Packages [884 B]</span><br><span class="line">Fetched 8195 kB <span class="keyword">in</span> 2s (3821 kB/s)</span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree</span><br><span class="line">Reading state information... Done</span><br><span class="line">All packages are up to date.</span><br><span class="line"></span><br><span class="line">apt install xfce4 gnome libreoffice  vlc -d -y</span><br><span class="line">0 upgraded, 1574 newly installed, 0 to remove and 0 not upgraded.</span><br><span class="line">Need to get 1014 MB of archives.</span><br><span class="line">After this operation, 3471 MB of additional disk space will be used.</span><br><span class="line">Fetched 1014 MB <span class="keyword">in</span> 2min 3s (8246 kB/s)</span><br><span class="line">Download complete and <span class="keyword">in</span> download only mode</span><br></pre></td></tr></table></figure>
<p>测试结果 <code>Fetched 1014 MB in 2min 3s (8246 kB/s)</code></p>
<h3 id="中科大"><a href="#中科大" class="headerlink" title="中科大"></a>中科大</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i 's/deb.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list</span><br><span class="line">sed -i 's|security.debian.org/debian-security|mirrors.ustc.edu.cn/debian-security|g' /etc/apt/sources.list</span><br><span class="line">apt update</span><br><span class="line">root@1242bc5d5e5a:/# time apt update</span><br><span class="line">Get:1 http://mirrors.ustc.edu.cn/debian buster InRelease [122 kB]</span><br><span class="line">Get:2 http://mirrors.ustc.edu.cn/debian-security buster/updates InRelease [39.1 kB]</span><br><span class="line">Get:3 http://mirrors.ustc.edu.cn/debian buster-updates InRelease [49.3 kB]</span><br><span class="line">Get:4 http://mirrors.ustc.edu.cn/debian buster/main amd64 Packages [7899 kB]</span><br><span class="line">Get:5 http://mirrors.ustc.edu.cn/debian-security buster/updates/main amd64 Packages [85.3 kB]</span><br><span class="line">Get:6 http://mirrors.ustc.edu.cn/debian buster-updates/main amd64 Packages [884 B]</span><br><span class="line">Fetched 8195 kB in 4s (1896 kB/s)</span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree</span><br><span class="line">Reading state information... Done</span><br><span class="line">All packages are up to date.</span><br><span class="line"></span><br><span class="line">apt install xfce4 gnome libreoffice  vlc -d -y</span><br><span class="line">0 upgraded, 1574 newly installed, 0 to remove and 0 not upgraded.</span><br><span class="line">Need to get 1014 MB of archives.</span><br><span class="line">Fetched 1005 MB in 37min 31s (446 kB/s)</span><br><span class="line">E: Failed to fetch http://mirrors.ustc.edu.cn/debian/pool/main/t/totem/totem-common_3.30.0-4_all.deb  Connection failed [IP: 202.141.176.110 80]</span><br><span class="line">E: Failed to fetch http://mirrors.ustc.edu.cn/debian/pool/main/s/shotwell/shotwell_0.30.1-1_amd64.deb  Connection failed [IP: 202.141.176.110 80]</span><br><span class="line">E: Failed to fetch http://mirrors.ustc.edu.cn/debian/pool/main/d/dom4j/libdom4j-java_2.1.1-2_all.deb  Connection failed [IP: 202.141.176.110 80]</span><br><span class="line">E: Failed to fetch http://mirrors.ustc.edu.cn/debian/pool/main/x/xfonts-scalable/xfonts-scalable_1.0.3-1.1_all.deb  Connection failed [IP: 202.141.176.110 80]</span><br><span class="line">E: Some files failed to download</span><br></pre></td></tr></table></figure>
<p>测试结果 <code>Fetched 1005 MB in 37min 31s (446 kB/s)</code> ，1000MB 的包下载用时将近 40 分钟</p>
<p>测试过程中多次出现 <code>[Waiting for headers]</code>  速度有几分钟都在<code>17.6 kB/s 13h 58min 9s</code>、 <code>159 kB/s 1h 38min 9s</code> 🤦‍♂️ ，其中还出现了 <code>2850 PB/s 0s</code> 😂</p>
<h3 id="163"><a href="#163" class="headerlink" title="163"></a>163</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i 's/deb.debian.org/mirrors.163.com/g' /etc/apt/sources.list</span><br><span class="line">sed -i 's|security.debian.org/debian-security|mirrors.163.com/debian-security|g' /etc/apt/sources.list</span><br><span class="line">apt update</span><br><span class="line">root@66e0d532818e:/# apt update</span><br><span class="line">Get:1 http://mirrors.163.com/debian buster InRelease [122 kB]</span><br><span class="line">Get:2 http://mirrors.163.com/debian-security buster/updates InRelease [39.1 kB]</span><br><span class="line">Get:3 http://mirrors.163.com/debian buster-updates InRelease [49.3 kB]</span><br><span class="line">Get:4 http://mirrors.163.com/debian buster/main amd64 Packages [7899 kB]</span><br><span class="line">Get:5 http://mirrors.163.com/debian-security buster/updates/main amd64 Packages [85.3 kB]</span><br><span class="line">Get:6 http://mirrors.163.com/debian buster-updates/main amd64 Packages [884 B]</span><br><span class="line">Fetched 8195 kB in 3s (2939 kB/s)</span><br><span class="line"></span><br><span class="line">apt install xfce4 gnome libreoffice  vlc -d -y</span><br><span class="line">0 upgraded, 1574 newly installed, 0 to remove and 0 not upgraded.</span><br><span class="line">Need to get 1014 MB of archives.</span><br><span class="line"></span><br><span class="line">Fetched 1012 MB in 7min 21s (2295 kB/s)</span><br><span class="line">Download complete and in download only mode</span><br></pre></td></tr></table></figure>
<p>测试结果 <code>Fetched 1012 MB in 7min 21s (2295 kB/s)</code></p>
<h3 id="阿里云"><a href="#阿里云" class="headerlink" title="阿里云"></a>阿里云</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s/deb.debian.org/mirrors.aliyun.com/g'</span> /etc/apt/sources.list</span><br><span class="line">sed -i <span class="string">'s|security.debian.org/debian-security|mirrors.aliyun.com/debian-security|g'</span> /etc/apt/sources.list</span><br><span class="line">root@e4b82e40b6c6:/<span class="comment"># apt update</span></span><br><span class="line">Get:1 http://mirrors.aliyun.com/debian buster InRelease [122 kB]</span><br><span class="line">Get:2 http://mirrors.aliyun.com/debian-security buster/updates InRelease [39.1 kB]</span><br><span class="line">Get:3 http://mirrors.aliyun.com/debian buster-updates InRelease [49.3 kB]</span><br><span class="line">Get:4 http://mirrors.aliyun.com/debian buster/main amd64 Packages [7899 kB]</span><br><span class="line">Get:5 http://mirrors.aliyun.com/debian-security buster/updates/main amd64 Packages [85.3 kB]</span><br><span class="line">Get:6 http://mirrors.aliyun.com/debian buster-updates/main amd64 Packages [884 B]</span><br><span class="line">Fetched 8195 kB <span class="keyword">in</span> 1s (6489 kB/s)</span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree</span><br><span class="line">Reading state information... Done</span><br><span class="line">All packages are up to date.</span><br><span class="line"></span><br><span class="line">apt install xfce4 gnome libreoffice  vlc -d -y</span><br><span class="line">0 upgraded, 1574 newly installed, 0 to remove and 0 not upgraded.</span><br><span class="line">Need to get 1014 MB of archives.</span><br><span class="line">After this operation, 3471 MB of additional disk space will be used.</span><br><span class="line">Fetched 1014 MB <span class="keyword">in</span> 2min 54s (5815 kB/s)</span><br><span class="line">Download complete and <span class="keyword">in</span> download only mode</span><br></pre></td></tr></table></figure>
<p>测试结果 <code>Fetched 1014 MB in 2min 54s (5815 kB/s)</code></p>
<h3 id="华为"><a href="#华为" class="headerlink" title="华为"></a>华为</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s/deb.debian.org/mirrors.huaweicloud.com/g'</span> /etc/apt/sources.list</span><br><span class="line">sed -i <span class="string">'s|security.debian.org/debian-security|mirrors.huaweicloud.com/debian-security|g'</span> /etc/apt/sources.list</span><br><span class="line">apt update</span><br><span class="line"></span><br><span class="line">root@659549fb7f12:/<span class="comment"># apt update</span></span><br><span class="line">Get:1 http://mirrors.huaweicloud.com/debian buster InRelease [122 kB]</span><br><span class="line">Get:2 http://mirrors.huaweicloud.com/debian-security buster/updates InRelease [39.1 kB]</span><br><span class="line">Get:3 http://mirrors.huaweicloud.com/debian buster-updates InRelease [49.3 kB]</span><br><span class="line">Get:4 http://mirrors.huaweicloud.com/debian buster/main amd64 Packages [7899 kB]</span><br><span class="line">Get:5 http://mirrors.huaweicloud.com/debian-security buster/updates/main amd64 Packages [85.0 kB]</span><br><span class="line">Get:6 http://mirrors.huaweicloud.com/debian buster-updates/main amd64 Packages [884 B]</span><br><span class="line">Fetched 8194 kB <span class="keyword">in</span> 2s (4766 kB/s)</span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree</span><br><span class="line">Reading state information... Done</span><br><span class="line">All packages are up to date.</span><br><span class="line"></span><br><span class="line">apt install xfce4 gnome libreoffice  vlc -d -y</span><br><span class="line">0 upgraded, 1574 newly installed, 0 to remove and 0 not upgraded.</span><br><span class="line">Need to get 1014 MB of archives.</span><br><span class="line">After this operation, 3471 MB of additional disk space will be used.</span><br><span class="line">Fetched 1014 MB <span class="keyword">in</span> 1min 25s (12.0 MB/s)</span><br><span class="line">Download complete and <span class="keyword">in</span> download only mode</span><br></pre></td></tr></table></figure>
<p>测试结果 <code>Fetched 1014 MB in 1min 25s (12.0 MB/s)</code> </p>
<p>不得不说华为云镜像站真香啊。进度条上基本上都是 10MB/s 以上，从没出现低于 10MB/s 的，甚至峰值能达到 20MB/s</p>
<h2 id="附录—测试数据表格"><a href="#附录—测试数据表格" class="headerlink" title="附录—测试数据表格"></a>附录—测试数据表格</h2><p><code>xfce4 、gnome 、libreoffice 、 vlc</code>  1574 个包，总大小 <code>1014 MB</code> 测试时间为白天工作时间</p>
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">清华</th>
<th style="text-align:center">中科大</th>
<th style="text-align:center">163</th>
<th style="text-align:center">阿里云</th>
<th style="text-align:center">华为云</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">8246 kB/s</td>
<td style="text-align:center">446 kB/s</td>
<td style="text-align:center">2295 kB/s</td>
<td style="text-align:center">5815 kB/s</td>
<td style="text-align:center">12.0 MB/s</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">462 kB/s</td>
<td style="text-align:center">980 kB/s</td>
<td style="text-align:center">5498 kB/s</td>
<td style="text-align:center">2642 kB/s</td>
<td style="text-align:center">15.8 MB/s</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">1144 kB/s</td>
<td style="text-align:center">657 kB/s</td>
<td style="text-align:center">1333 kB/s</td>
<td style="text-align:center">5938 kB/s</td>
<td style="text-align:center">13.1 MB/s</td>
</tr>
</tbody>
</table>
<h2 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h2><p>根据一轮的测试速度来看，华为胜出😂</p>
<ol>
<li>华为</li>
<li>阿里云</li>
<li>163</li>
<li>清华</li>
<li>中国科大</li>
</ol>
<p>就这四个选择吧，也和本地的网络有关系，我的是电信网络。之前我的测试环境的服务器一直在使用中科大的镜像站，每次都很慢，今天一测才知道，中科大的镜像站这么慢啊，以后还是选择华为云吧。</p>
<p>撇开偏见，今天评论华为开源镜像站，前端 UI 无疑是国内镜像站里边做的最好的（虽然我不喜欢卡片式设计），下载速度是所有镜像站里面最快的（1574 个包，总大小 1014MB，平均都在 12MB/s 以上，峰值能达到 20MB/s）。其他的镜像站基本上都没能达到 10MB/s 以上。如果注册会员是不是下载速度翻倍，都能跑到 20MB/s 以上？</p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>独裁者手册读书笔记</title>
    <url>/archives/The-Dictator%E2%80%99s-Handbook.html</url>
    <content><![CDATA[<p>今年年初的时候，在栋叔（软件那些事儿电台博主、绿帽子大学校长、钢管舞演员、滴滴车司机）群里见到他推荐的这本书《独裁者手册》。最近一个月才抽空花了10个小时读完了它，在此记录一下（大部分内容照抄自原文）：</p>
<p>PS：栋叔是个很有趣的中年油腻老男人，这是他博客<a href="https://liuyandong.com/" target="_blank" rel="noopener">栋哥的博客</a>，在微信公众号叫 <code>软件那些事儿</code>，还有他的<a href="https://lmzdx.com/" target="_blank" rel="noopener">绿帽子大学</a></p>
<h2 id="个人评价"><a href="#个人评价" class="headerlink" title="个人评价"></a>个人评价</h2><p>这本书最主要的还是从统治的三个维度来分析专制国家和民主国家的区别，以及一些企业上对管理层权力斗争的原则。介绍一个理解政治的三维视角，即名义选择人、实际选择人、致胜联盟。而我们这帮屁民属于哪个维度？对不起，你没有选举权、你没有选票，你不属于其中的任何一个维度，你只是颗韭菜。</p>
<h2 id="内容简介"><a href="#内容简介" class="headerlink" title="内容简介"></a>内容简介</h2><p>下面直接剽窃一段豆瓣上的<a href="https://book.douban.com/subject/25881102/" target="_blank" rel="noopener">简介</a></p>
<blockquote>
<p>为什么同样一个人可以在一个国家推行善政却在另一个国家施行最残暴的独裁？在这里，与其说制度是答案还不如说是问题本身。为什么比利时的制度越来越民主，而同一时期，同一领导人的刚果，却越来越独裁？难道是因为利奥波德二世只爱本国人或者有种族歧视？但后来刚果自己“选”出来的领导人并没有做得更好，仍然是一个糟糕的独裁者。</p>
<p>在《独裁者手册》这本书里，梅斯奎塔和史密斯研究多年，得出了一个能够相当完美地解释这一政治现象的理论，即：不管是国家、公司还是国际组织，其政治格局不能简单地以“民主”和“独裁”来划分，而必须用民意选民、实际选民、胜利联盟的数字多少来描写。如果胜利联盟的人数很多，那么这个国家就是我们通常所说的民主国家。反过来，如果胜利联盟的人数非常少，那么不管这个国家有没有选举，都是事实上的非民主国家。据此，很容易明白：在刚果，利奥波德二世只需要让少数人高兴就足以维持自己的统治；而在比利时，他必须让很多人满意才行。</p>
<p>不得不提，对任何想理解政治的真正运作方式的人来说，《独裁者手册》都是一本必读的书，无论是政治领域的政治还是商业界的政治，无论是在独裁国家还是在民主国家。</p>
</blockquote>
<h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><blockquote>
<p>布鲁斯·布鲁诺·德·梅斯奎塔，纽约大学政治学系Julius Silver讲座教授、亚历山大•汉密尔顿政治经济学研究中心主任和斯坦福大学胡佛研究所高级研究员。他通过设立于纽约的咨询公司长期担任美国政府国家安全事务方面的顾问，也为众多公司提供谈判指导与结果预测方面的咨询服务。梅斯奎塔1971年从密歇根大学获得政治科学博士学位。2001—2002年他担任国际研究学会主席。他是美国艺术与科学院院士、美国对外关系理事会会员以及古根海姆基金会学者。梅斯奎塔迄今出版了16本书，超过120篇论文，并在《纽约时报》、《洛杉矶时报》、《芝加哥论坛报》、《国际先驱论坛报》等报刊上发表过大量文章。</p>
<p>阿拉斯泰尔·史密斯，纽约大学政治学教授。他此前在圣路易斯华盛顿大学和耶鲁大学任教。他从美国罗彻斯特大学获得政治科学博士学位，从牛津大学获得化学学士学位。他从美国国家科学基金会获得过三项研究津贴，2005年他获得卡尔•多伊奇奖（Karl Deutsch Award），该奖每两年一次颁发给40岁以下最出色的国际关系研究学者。1997—1998年他被斯坦福大学胡佛研究所选为国家研究员。</p>
</blockquote>
<p>作者水平还是相当不错的，比起国内那些唱赞歌的教授不知道高到哪里去了😂</p>
<h2 id="纽约时报中文网书评"><a href="#纽约时报中文网书评" class="headerlink" title="纽约时报中文网书评"></a>纽约时报中文网书评</h2><p><a href="https://cn.nytimes.com/books/20140630/tc30liuyu/" target="_blank" rel="noopener">原文连接</a></p>
<blockquote>
<p>《独裁者手册》(The Dictator’s Handbook)可真是一部典型的“标题党”作品。根据这个书名，这本书将手把手教会我们如何成为一个呼风唤雨的独裁者。真有这样的秘笈？原以为征服世界需要千军万马，现在看来只需要42元。</p>
<p>可是，掏钱买书之后，打开一读，我们就会发现自己“上当”了。这本书真正的标题似乎应该是《如何理解政治：一个三维的视角》。但是鉴于多数人一读到“三维”这个字眼就睡着了，所以，还是用个吸引眼球的书名、让人们先掏钱再说吧。</p>
</blockquote>
<h2 id="政治的三个维度"><a href="#政治的三个维度" class="headerlink" title="政治的三个维度"></a>政治的三个维度</h2><h3 id="名义选择人集团"><a href="#名义选择人集团" class="headerlink" title="名义选择人集团"></a>名义选择人集团</h3><p><code>名义选择人集团</code>、<code>可相互替代者</code>、<code>领导人的潜在支持者</code> 、<code>合格选民</code></p>
<p>包含了所有在选择领导人时至少具有某些法定发言权的人。说白了就是有选票的合格选民。从根本上来讲名义选择人就是领导人的潜在支持者。</p>
<h3 id="实际选择人集团"><a href="#实际选择人集团" class="headerlink" title="实际选择人集团"></a>实际选择人集团</h3><p><code>实际选择人集团</code>、<code>有影响者</code> 、<code>真正选出总统的选举人团成员</code></p>
<p>实际选择人则指那些其对领导人的支持确实有重要影响的人</p>
<blockquote>
<p>在美国，名义选择人和实际选择人相当紧密地结合在一起。这就是为什么尽管你只是与他人可相互替代的无数选民中的一员，却仍感觉你的那一票很有影响—它有价值，也算数。</p>
</blockquote>
<p>在国内，一般是指官二代和红二代。但除了官二代红二代之外的普通人几乎不可能到达这个维度。</p>
<h3 id="致胜联盟"><a href="#致胜联盟" class="headerlink" title="致胜联盟"></a>致胜联盟</h3><p><code>致胜联盟</code>、<code>不可或缺者</code> 、<code>核心领导层</code></p>
<p>实际选择人集团的一个子集，构成了一个致胜联盟。他们的支持对于一个领导人的政治生存至关重要。</p>
<p>在国内就是那几个常委，这里面的斗争特别激烈，翻看一下历任的常委的遭遇你就会明白</p>
<h3 id="补充一个维度"><a href="#补充一个维度" class="headerlink" title="补充一个维度"></a>补充一个维度</h3><p>你仔细思考这三个维度后，你会发现，在有些国家比如朝鲜，他们的老百姓属于哪一类人？不好意思，他们不属于上面三个维度的任何一个。我更喜欢重新划分一个维度 <code>被剥夺选举权的人</code> ，也就是<code>屁民</code>、<code>韭菜</code>、<code>穷苦的老百姓</code>、<code>低端人口</code> 、<code>五毛</code>、<code>粉红</code> 等等，因为他们根本就没有实际的选举权。这也是香港返送中五大诉求里要求实现真普选的要求，即从这些被剥夺选举权的群体中选出自己的领导人，而不是<strong>钦定</strong>。</p>
<h3 id="三维政治的特点"><a href="#三维政治的特点" class="headerlink" title="三维政治的特点"></a>三维政治的特点</h3><blockquote>
<p><strong>独裁制：</strong>这个术语在我们这里的真正意思是，政府建立在极少数不可或缺者的基础上，而他们是从数量非常庞大的可相互替代者以及通常相对较少的一群有影响者当中产生出来的。</p>
<p><strong>民主制：</strong>政府建立在数量庞大的不可或缺者和可相互替代者的基础上；同时，有影响者的数量几乎与可相互替代者一样多。</p>
<p><strong>君主制或军事独裁制：</strong>可相互替代者、有影响者、不可或缺者的数量都很少。</p>
</blockquote>
<ul>
<li><strong>独裁制</strong></li>
</ul>
<p>政府建立在极少数 致胜联盟、不可或缺者 的基础上，致胜联盟、不可或缺者 从从数量非常庞大的名义选择人集团、可相互替代者、领导人的潜在支持者 以及较少的实际选择人集团、有影响者 、真正选出总统的选举人团成员 当中产生出来的。</p>
<ul>
<li><strong>民主制</strong></li>
</ul>
<p>政府建立在数量<strong>庞大</strong>的<code>致胜联盟</code>、<code>不可或缺者</code>和<code>名义选择人集团</code>、<code>可相互替代者</code>、<code>领导人的潜在支持者</code>的基础上，同时<code>实际选择人集团</code>、<code>有影响者</code> 、<code>真正选出总统的选举人团成员</code> 与 <code>名义选择人集团</code>、<code>可相互替代者</code>、<code>领导人的潜在支持者</code> 一样多，这也反映了下面这段：</p>
<blockquote>
<p>在美国，名义选择人和实际选择人相当紧密地结合在一起。这就是为什么尽管你只是与他人可相互替代的无数选民中的一员，却仍感觉你的那一票很有影响—它有价值，也算数。</p>
</blockquote>
<ul>
<li><strong>君主制或军事独裁制</strong></li>
</ul>
<p>可相互替代者、有影响者、不可或缺者的数量都很少，皇帝一人说了算，明朝和清朝就属于这</p>
<ul>
<li><strong>注意，在此一定要认真思考极少数、庞大两个词语，因为这从本质上决定了两种制度，民主与独裁</strong></li>
</ul>
<blockquote>
<p>以不可或缺者、有影响者和可相互替代者这样的概念来看待各类组织的优点是，这些范畴使我们能克制自己，避免在各种政府形式之间武断地划线，宣称这个国家是“民主国家”，那个国家是“专制国家”，或这个国家是大共和国，那个国家是小共和国，也避免了一些历史上主要政治哲学家们持有的一维政治观。政府之间和组织之间更具重要意义和可观察到的行为差异取决于可相互替代者、有影响者和不可或缺者这三个集团的绝对和相对规模。</p>
</blockquote>
<h2 id="本书章节"><a href="#本书章节" class="headerlink" title="本书章节"></a>本书章节</h2><h3 id="一-、政治的法则"><a href="#一-、政治的法则" class="headerlink" title="一 、政治的法则"></a>一 、政治的法则</h3><blockquote>
<p>任何一个有能力的领导人都希望掌握尽可能多的权力，并尽可能长久地掌握权力。设法利用可相互替代者、有影响者和不可或缺者来达到自己的目的，这就是统治的行为、艺术和科学。<br>民主国家或任何一个致胜联盟很庞大的体系内，通过私人回报的方式来收买忠诚代价太大。钱会被极大摊薄。所以，依赖大型致胜联盟的、较民主的政府趋向于着重把钱花在能增进普遍福利的有效公共政策上，这很接近詹姆斯·麦迪逊倡导的理念。<br>与此形成对照的是，独裁者、君主、军政府领导人以及大部分企业首席执行官只依赖一小撮不可或缺者。正如马基雅维利所言，他们通过大慷公家之慨、以私人回报的方式收买致胜联盟的忠诚，这种统治方式更有成效，尽管这意味着要牺牲广大纳税人或千百万小股民的利益。因此，小型致胜联盟助长了稳定、腐败、以私人物品为导向的体制。</p>
</blockquote>
<h4 id="政治统治的五大基本法则"><a href="#政治统治的五大基本法则" class="headerlink" title="政治统治的五大基本法则"></a>政治统治的五大基本法则</h4><p>也就是想要成为一名合格的独裁者，哪些原则不可避免</p>
<p>下面的内容直接剽窃原文</p>
<h5 id="法则1：让你的致胜联盟越小越好"><a href="#法则1：让你的致胜联盟越小越好" class="headerlink" title="法则1：让你的致胜联盟越小越好"></a>法则1：让你的致胜联盟越小越好</h5><blockquote>
<p>一个小规模的致胜联盟使领导人只需依赖极少数人就能保持权位。越少的不可或缺者相当于领导人拥有更多控制权，对支出的自由裁量权也越大。</p>
</blockquote>
<p>在国内，这个规模就是几大常委和那些政治老人，规模极少数</p>
<p>在美国，就是众多选民们，而且规模巨大</p>
<h5 id="法则2：让你的名义选择人集团越大越好"><a href="#法则2：让你的名义选择人集团越大越好" class="headerlink" title="法则2：让你的名义选择人集团越大越好"></a>法则2：让你的名义选择人集团越大越好</h5><blockquote>
<p>保持一个很大的选择人集团你就能很容易地替换掉致胜联盟里的捣蛋分子，无论是有影响者还是不可或缺者。毕竟，一个很大的选择人集团提供了充足的替代支持者，让不可或缺者时刻谨记必须保持忠诚、规规矩矩，不然就会被别人取代。</p>
</blockquote>
<p>在国内应该是官二代红二代以及九千万中少数</p>
<h5 id="法则3：掌控收入的分配"><a href="#法则3：掌控收入的分配" class="headerlink" title="法则3：掌控收入的分配"></a>法则3：掌控收入的分配</h5><blockquote>
<p>对一个统治者来说，与其拥有一张让人民可以喂饱自己的更大的饼，永远不如他能够决定谁吃这张饼。对领导人来说，最有效的资金分配方式是让很多人受穷，通过重新分配让挑选出来的支持者发财。<br>让我们为巴基斯坦总统阿西夫·阿里·扎尔达里喝彩，他的财富估计高达40亿美元，尽管他统治着一个人均国民收入几乎全球垫底的国家。</p>
</blockquote>
<h5 id="法则4：支付给你的核心支持者刚好足够确保他们忠诚的钱"><a href="#法则4：支付给你的核心支持者刚好足够确保他们忠诚的钱" class="headerlink" title="法则4：支付给你的核心支持者刚好足够确保他们忠诚的钱"></a>法则4：支付给你的核心支持者刚好足够确保他们忠诚的钱</h5><blockquote>
<p>记住，你的支持者宁愿成为你而不是仰赖你。你的巨大优势在于你知道钱在哪里而他们不知道。给你的联盟足够的钱，以免他们到处寻找取代你的人，但一分钱都不要多给。<br>让我们为津巴布韦的罗伯特·穆加贝喝彩，他无论何时面临军事政变的威胁，最终总能用钱摆平，在重重困难下始终保持军队忠诚。</p>
</blockquote>
<h5 id="法则5：不要从你的支持者的口袋里挪钱去改善人民的生活"><a href="#法则5：不要从你的支持者的口袋里挪钱去改善人民的生活" class="headerlink" title="法则5：不要从你的支持者的口袋里挪钱去改善人民的生活"></a>法则5：不要从你的支持者的口袋里挪钱去改善人民的生活</h5><blockquote>
<p>法则4的反面就是不要对你的支持者太抠门。如果你以损害致胜联盟的利益为代价而善待人民，很快你的“朋友们”就会伺机找你的麻烦。有利于普通老百姓的政策不仅未必能让核心支持者产生忠诚，而且太贵。饥饿的人民不可能有精力推翻你，大可不必担心他们。相反地，失望的致胜联盟成员则会变节，让你深陷麻烦。<br>让我们为缅甸的丹瑞将军喝彩，在2008年的纳尔吉斯飓风之后他控制了外界提供的粮食援助，让他的军队支持者拿到黑市上去倒卖，而不是援助灾民——至少13.8万人死于那场风灾，有的报告甚至认为死亡人数高达50万人</p>
</blockquote>
<h4 id="在民主国家呢？"><a href="#在民主国家呢？" class="headerlink" title="在民主国家呢？"></a>在民主国家呢？</h4><p>假如在民主国家的领导人，比如川普使用上面五种法则呢？</p>
<p><code>如果一位民选领导人遵循上述独裁统治的规则，他肯定马上下台</code></p>
<h5 id="第一条"><a href="#第一条" class="headerlink" title="第一条"></a>第一条</h5><p>假如川普想要掠夺国家财产的同时维持总统的位置确实比较困难，何况川普人家不缺钱😂。他受到该国法律的约束太多，就是因为<code>官员财产必须公布</code>。因为美国的选举制度，在法律上通过选举程序决定了他上台所需致胜联盟的规模必须相对较大。所以在民主国家的领导人并不具备规模尽可能少的致胜联盟，而是规模巨大的选民们。</p>
<p><code>但这并不意味着他不会尽力去遵循这一法则（以及其他法则）</code> ，任何一个国家的领导人都希望极可能长期手握权力不放，同时加大自己的权力。<strong>老话仍然是真的——所有政客都一个样。</strong>比如：</p>
<ul>
<li>为什么国会为了选举利益而改划选区？恰恰是因为<strong>法则1</strong>：让你的致胜联盟越小越好。</li>
<li>为什么某些政党赞成移民？<strong>法则2</strong>：扩大可相互替代者的规模。</li>
<li>为什么在税收法规上有这么多争斗？<strong>法则3</strong>：控制政府收入来源。</li>
<li>为什么民主党人花掉那么多税收在公共福利和社会工程上？或，究竟为什么会有指定用途的资金？<strong>法则4</strong>：不计代价地回报你的核心支持者。</li>
<li>为什么共和党人希望降低最高税率并对全国性医保体系的想法百般反对？<strong>法则5</strong>：不要打劫自己的支持者以利对手。</li>
</ul>
<p>PS: 在独裁专制集权暴政的国家，官员财产是绝对不能公布的，这是铁定的法则。因为各自的政治派系都要依靠金钱贿赂来收买各自的<code>致胜联盟</code> ，而这个致胜联盟规模及其地小，从而进一步加深看腐败。假如贫苦的老百信手里有真正的选票，那么选举出来的官员必须要为他们负责，他们的规模是及其巨大的，想要收买他们必须听从他们的声音，给与他们自由。</p>
<h3 id="二、上台"><a href="#二、上台" class="headerlink" title="二、上台"></a>二、上台</h3><p>这个章节开头讲解了，约翰·多伊从一名士官一跃成为利比里亚国家的最高领导人。感觉故事就像电影一样，伊出生于利比里亚偏远的内陆部族，相当于朝鲜的老百姓？他走出了西非的丛林到外面讨生活。来到了首都蒙罗维亚后参军，因为没有发工资，就和16名士一起翻过总统官邸的围墙向总统讨工资，本来是希望面见总统，质询为什么没有发工资。在总统威廉·托尔伯特的卧室里，多伊就发现了这么一个机会。多伊用刺刀捅死总统，将他的内脏丢去喂狗，然后宣布自己是利比里亚的新总统。</p>
<p>是不是很奇幻？😂</p>
<p>上台后的第一件事儿就是找钱捞钱，收买致胜联盟，铲除竞争对手。去他妈的什么善治理念，别把人民关心的事置于你和你的支持者之上：这是给那些想要成为独裁者的人的金玉良言。不用考虑穷苦老百姓的死活，他们威胁不了你的统治，在这时你就应该花钱收买致胜联盟。在独裁专制国家，造福人民的好的理念几乎不可能助你掌权。</p>
<h4 id="夺取权力三步走？"><a href="#夺取权力三步走？" class="headerlink" title="夺取权力三步走？"></a>夺取权力三步走？</h4><ul>
<li>第一，他必须除掉在位者</li>
<li>第二，他必须控制政府机关</li>
<li>第三，他需要成立一个由支持者组成的、足以确保他成为新在位者的联盟。</li>
</ul>
<p>这三步走我不怎么赞同，确切地说人人皆知啊，是个正常的人都会这名做吧，和古代的那些谋朝篡位的相比差远了。革命的一般经验法则是，当现存制度的守卫者们对报偿十分不满、有意寻找新的领导人来关照他们时，革命就会发生。</p>
<h3 id="三、掌权"><a href="#三、掌权" class="headerlink" title="三、掌权"></a>三、掌权</h3><p>总结一句话，收买致胜联盟，让他们忠诚于你</p>
<h3 id="四、窃贫济富"><a href="#四、窃贫济富" class="headerlink" title="四、窃贫济富"></a>四、窃贫济富</h3><p>领导人从屁民那里征税面临的三个限制</p>
<ul>
<li>征税会削弱人们工作的热、情阻碍辛勤工作、创业精神和投资</li>
<li>一些税收方面的负担不可避免地会落到领导人的关键支持者身上。</li>
<li>收税需要专业知识和资源。收税的成本限制了领导人能够榨取什么并影响到征税方法的制定。</li>
</ul>
<h3 id="五、获取与花费"><a href="#五、获取与花费" class="headerlink" title="五、获取与花费"></a>五、获取与花费</h3><p><code>那些依赖小联盟的国家领导人们有一种普遍的说辞是，能够促进政府改善人民福利的那些自由权利太奢侈——比如言论自由、新闻自由，特别是集会自由——只可能在获得经济繁荣之后才能让民众享有，而不是之前</code></p>
<h3 id="六、腐败"><a href="#六、腐败" class="headerlink" title="六、腐败"></a>六、腐败</h3><p>绝对的权力将会导致绝对的腐败，比如《巴拿马文件》里面的那些官员，那些最成功的领导人，特别在现代，也拥有获得巨额收入的可靠手段，比如矿产财富，比如独占某些企业，比如投资离岸公司等。只要他们保持身体健康，这样的领导人是无懈可击的。也就是说，他们无限接近于成为一名绝对领袖。</p>
<blockquote>
<p>根据透明国际2010年的腐败指数，25个世界上最腐败的国家没有一个是成熟的民主国家。</p>
</blockquote>
<h3 id="七、对外援助"><a href="#七、对外援助" class="headerlink" title="七、对外援助"></a>七、对外援助</h3><p>略</p>
<h3 id="八、-反叛中的人民"><a href="#八、-反叛中的人民" class="headerlink" title="八、 反叛中的人民"></a>八、 反叛中的人民</h3><blockquote>
<p>一名成功的领导人总是把核心支持者的需要置于人民的需要之上。[1]没有他的致胜联盟的支持，一名领导人什么都不是，很快就会被对手横扫出局。但如果领导人的统治权只依赖于少数人，让联盟满意是得花钱的。通常来说，联盟成员获得的酬劳以牺牲社会其他部分的利益为代价。没错，是有一些独裁者让人民生活过得更好而成了名人堂成员。大多数独裁者不这么做。那些不这么做的独裁者将坐在办公室里为了自己和联盟的利益将国家的经济搞得一蹶不振。最终形势发展到足够恶化的地步，导致一些人民开始厌倦身上的重负。他们也会对领导人的生存产生威胁。</p>
</blockquote>
<h4 id="贸易战"><a href="#贸易战" class="headerlink" title="贸易战"></a>贸易战</h4><p>关于贸易战的本质问题，可以去读一下这篇文章 <a href="https://terminus2049.github.io/archive/2019/05/23/China-America-trade-war.html" target="_blank" rel="noopener">贸易战的本质问题是什么</a></p>
<blockquote>
<p>美国的诉求是 “三零二停一允许”。“三零” 是零关税、零非关税壁垒、零补贴，“二停” 是停止盗窃知识产权、停止强行技术转让，“一允许” 是允许美国人到中国独立开设公司。</p>
<p>需要指出的是，这 “三零二停一允许” 不是单方的，而是双方的。你对我 “三零两停一允许”，我也对你 “三零两停一允许”。这个政策也是美国给到全体盟友的，美国对于中国，除了部分关税以外 (仍比中国低很多)，已经大部分实现 “三零二停一允许” 了，中国人去美国开设公司的政策上早已执行很久了。</p>
</blockquote>
<p>美国的诉求，几乎每一条都影响到了掌权者统治的根基，就拿最后一条来讲，<code>允许美国人到中国独立开设公司</code> ，假如谷歌推特脸书来到中国开公司，他们会配合当权者进行言论审查和打击抗议人士吗？蜻蜓计划的破产早就决定了不会发生这种事情，即便谷歌他要做审查版的搜索引擎供大陆使用，但，美国国会也绝对不会允许谷歌的这种行为。</p>
<blockquote>
<p>大多数革命者一旦上台——只要他们能侥幸成功——就倾向于成为卑鄙的独裁者。毕竟，民主制度除了催生人民想要的政策之外，也会让领导人的政治生存变得更难。领导人不会顺从人民的意愿，除非人民有能力迫使他们。</p>
</blockquote>
<p><code>除非人民有能力迫使他们</code> ，而人民没有军队和武器，人民唯一的能力就是两个字–自由</p>
<p>人民的力量只会来自自由、即言论自由、集会自由、出版自由、新闻自由。而越是独裁的国家，越会限制人民反抗的力量，从而去限制各种自由。更甚至会使用科技手段强加限制，比如当今早已经侵犯人权的征信系统，人脸识别等。甚至我语言，未来独裁者会使用所谓的人工智能来分析我们的思想。这一点，技术上没有任何限制，根据你的聊天记录，社交账号上的好友关系，进行大数据分析，就能很准确地分析出我们的大脑中的想法，分析出我们对老大哥的忠诚度😂</p>
<blockquote>
<p>在一个民主国家，抗议相对便宜和简单。人民有集会的自由，事实上这是权利。他们也有很方便的协调组织手段。我们已从先前几章了解到，依赖大型联盟的政府创造了大量公共物品，包括统称为自由的一揽子特殊公共物品，包括新闻自由、言论自由和集会自由。这些自由权利使数量巨大的人民交换对于政府的看法、表达对任何不喜欢政策的反对意见变得容易得多<br>独裁者有两种截然相反的方法应对革命的威胁。他可以提升民主，大大改善人民的待遇，使他们不再想着反叛。他也可以加强专制独裁，让人民的境遇变得更加悲惨，同时一举扼杀人民造反成功的机会。</p>
</blockquote>
<p>通过香港返送中运动，我们很快就能明白，当权者显然加强了专制独裁</p>
<h3 id="九、战争，和平与世界秩序"><a href="#九、战争，和平与世界秩序" class="headerlink" title="九、战争，和平与世界秩序"></a>九、战争，和平与世界秩序</h3><h3 id="十、怎么办？"><a href="#十、怎么办？" class="headerlink" title="十、怎么办？"></a>十、怎么办？</h3>]]></content>
      <tags>
        <tag>阅读</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 FFmpeg 远程读取 rtsp 监控视频流</title>
    <url>/archives/ffmepg-rtsp.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>由于自己住的是价格及其便宜的民宿，四人间的合租房间。房东家住的大概有二十号人吧，人多眼杂，上月舍友丢失了一台笔记本。自己的台式机幸免遇难未被盗走。所以决定装个 IP 摄像头，防患于未然😂</p>
<h2 id="选购摄像头"><a href="#选购摄像头" class="headerlink" title="选购摄像头"></a>选购摄像头</h2><p>在闲鱼和某宝上挑了很久很久，一直没有找到合适的。有那种 WiFi 摄像头，比如小米、海康威视、大华，还有其他的。价格也相对来讲便宜些，一般都在 100 元左右。不过这种摄像头坑爹的是，远程存储需要购买他们的云服务，最便宜的也要 60元/30G/年，真他奶奶的割韭菜。而且还不能单独使用 NAS 之类的存储。因为我需要的是将监控视频远程保存到服务器上，保存到自己的服务器上，我不喜欢把数据交给国内的毒瘤厂商。</p>
<p>摄像头根据传输介质大概分为模拟传输、网络传输。模拟传输就是采用的模拟信号，把监控视频流采集到专门的录像机上，一般录像机的价格要比一个摄像头的价格贵很多。另外还要给监控录像机供电也是一笔开销，遂不考虑使用模拟摄像头。</p>
<p><img src="../img/1561802376885.jpg" alt="小米摄像头"></p>
<p>网络摄像头分为 WiFi 无线网络摄像头和网线摄像头。 WiFi 摄像头就是和小米那样的，另外房东家也是用的 WiFi 摄像头。网线摄像头分为独立供电、POE 供电两种。独立供电需要单独的 12V DC 给摄像头供电，而 POE 供电是将网线和电源绑在一起，通过 POE 交换机供电。这种 POE 供电的摄像头价格也比较贵，还需要单独购买 POE 交换机。遂也不决定购买 POE 供电的摄像头。</p>
<p><img src="../img/1561802376888.jpg" alt="POE供电摄像头"></p>
<p><img src="../img/1561802376886.jpg.jpg" alt="POE供电图解"></p>
<p>找了半天最终还是找到了一个摄像头，价格也比较便宜😂。特意问了卖家能不能通过浏览器访问、能不能不需要专用的摄像机来访问摄像头。卖家说是可以的。</p>
<p><img src="../img/1570702505815.png" alt="1570702505815"></p>
<p><img src="../img/1570702514509.png" alt="1570702514509"></p>
<h2 id="安装摄像头"><a href="#安装摄像头" class="headerlink" title="安装摄像头"></a>安装摄像头</h2><p>把路由器的电源适配器输出接口给剪了，又接了一个 DC 2.5mm 的插头，这样一个电源适配器同时供路由器和摄像头使用了😂。不用担心功率，一个摄像头和路由器总功耗还不到 8W。</p>
<p><img src="../img/1570704495847.png" alt="推荐这个12V直流电源，某宝搜关键字😂"></p>
<p><img src="../img/1570702447664.png" alt="将摄像头底座固定在一个塑料板上，再用螺丝刀插入空调海绵胶里固定住😂"></p>
<p><img src="../img/1570702472108.png" alt="路由器放在了空调上面，互不干扰"></p>
<p>穹妹哦😂，骨科？</p>
<p><img src="../img/1570702482302.png" alt="1570702482302"></p>
<p><img src="../img/1570702739896.png" alt="一个RJ45的网线接口和一个12V的DC供电接口"></p>
<h2 id="配置摄像头"><a href="#配置摄像头" class="headerlink" title="配置摄像头"></a>配置摄像头</h2><p>询问卖家怎么配置摄像头，卖家说搜索雄迈，然后下载相应的工具。<a href="https://www.xiongmaitech.com/service/down_detail1/83/176" target="_blank" rel="noopener">配套软件下载 </a> 下载安装就行。</p>
<p><img src="../img/1570704765775.png" alt="配套软件"></p>
<p><img src="../img/1570704813188.png" alt="在设备管理里添加摄像头"></p>
<p><img src="../img/1570704875787.png" alt="默认是没有密码的，设置密码了酒店及铅笔✏图标哪里设置密码"></p>
<p><img src="../img/1570704956430.png" alt="配置摄像头界面"></p>
<p><img src="../img/1570704990621.png" alt="网络设置-TCP/IP"></p>
<p><img src="../img/1570705020709.png" alt="RTSP 设置，这个后面要用到"></p>
<h2 id="路由器-FRP-穿透"><a href="#路由器-FRP-穿透" class="headerlink" title="路由器 FRP 穿透"></a>路由器 FRP 穿透</h2><p>接下来就开始配置 frp ，将摄像头 rtsp 协议的端口 554 内网穿透到服务器上</p>
<p>local_ip 设置为摄像头的 IP ，端口号就是 rtsp 协议监听的端口号，这样就能从服务器断读取 rtsp 的视频流了。</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line">root@OpenWrt:~# cat /etc/frpc.ini</span><br><span class="line"><span class="section">[common]</span></span><br><span class="line"><span class="attr">server_addr</span> =  </span><br><span class="line"><span class="attr">server_port</span> =  </span><br><span class="line"><span class="attr">token</span> =  </span><br><span class="line"></span><br><span class="line"><span class="section">[monweb]</span></span><br><span class="line"><span class="attr">type</span> = tcp</span><br><span class="line"><span class="attr">local_ip</span> = <span class="number">192.168</span>.<span class="number">0.241</span></span><br><span class="line"><span class="attr">local_port</span> = <span class="number">80</span></span><br><span class="line"><span class="attr">remote_port</span> = <span class="number">2418</span></span><br><span class="line"></span><br><span class="line"><span class="section">[monrtsp]</span></span><br><span class="line"><span class="attr">type</span> = tcp</span><br><span class="line"><span class="attr">local_ip</span> = <span class="number">192.168</span>.<span class="number">0.241</span></span><br><span class="line"><span class="attr">local_port</span> = <span class="number">554</span></span><br><span class="line"><span class="attr">remote_port</span> = <span class="number">554</span></span><br></pre></td></tr></table></figure>
<h2 id="RTSP-视频流"><a href="#RTSP-视频流" class="headerlink" title="RTSP 视频流"></a>RTSP 视频流</h2><p>访问 RTSP 视频流，可以使用 PotPlayer 或 VLC 等播放器，使用 FFmpeg 也是可以读取视频流。服务器端使用 FFmpeg 读取视频流，命令行操作比较方便，设置定时任务读取分割摄像头的 RTSP 视频流即可</p>
<p>如何访问摄像头的 RTSP 视频流？，一般摄像头的固件供应商那里会有帮助手册，总算在官方网站找到了。</p>
<blockquote>
<p><strong>使用VLC按RTSP协议连接我司的设备网络串流的格式</strong></p>
<p>——使用第3方的播放器通过RTSP连接我司设备的URL格式如下：</p>
<p><code>rtsp://$(IP):$(PORT)/user=$(USER)&amp;password=$(PWD)&amp;channel=$(Channel)&amp;stream=$(Stream).sdp?real_stream</code></p>
<p>——类似 <code>rtsp://10.6.10.25:554/user=admin&amp;password=&amp;channel=1&amp;stream=0.sdp?real_stream</code>如果是通过公网需要将RTSP端口开放（ 默认是554），这个端口在网络服务-&gt;RTSP中可以设置</p>
</blockquote>
<p>按照官方规定的 URL ，我的摄像头 RTSP 视频流访问 URL 就是如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rtsp=<span class="string">"rtsp://192.168.0.241:554/user=user&amp;password=password&amp;channel=Channel&amp;stream=Stream.sdp?real_stream"</span></span><br></pre></td></tr></table></figure>
<p><img src="../img/1570705646007.png" alt="PotPlayer 里在打开那里选择打开连接"></p>
<p><img src="../img/1570705720287.png" alt="输入上述 URL "></p>
<p>然后服务器端安装好 FFmpeg ，使用 FFmpeg读取 rtsp 视频流即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt install FFmpeg -y</span><br><span class="line"></span><br><span class="line">RTSP=<span class="string">"rtsp://127.0.0.1:554/user=user&amp;password=password&amp;channel=Channel&amp;stream=Stream.sdp?real_stream"</span></span><br><span class="line"></span><br><span class="line">ffmpeg  -rtsp_transport tcp  -i <span class="variable">$RTSP</span> -vcodec  copy -r 1 -t 60  -y $(TZ=UTC-8 date +\%m\%d\%H\%M).mp4</span><br></pre></td></tr></table></figure>
<p>其中 -r 参数是指定帧率，-t 参数是指定时间。关于 FFmpeg 的详细使用参数可以去参考一下官方手册，在此就不赘述了😂</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@sg-02 ~/<span class="built_in">log</span></span><br><span class="line">╰─<span class="comment"># ffmpeg  -rtsp_transport tcp  -i $RTSP -vcodec  copy -r 1 -t 60  -y $(TZ=UTC-8 date +\%m\%d\%H\%M).mp4     130 ↵</span></span><br><span class="line">FFmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers</span><br><span class="line">  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)</span><br><span class="line">  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --<span class="built_in">enable</span>-gpl --<span class="built_in">disable</span>-stripping --<span class="built_in">enable</span>-avresample --<span class="built_in">enable</span>-avisynth --<span class="built_in">enable</span>-gnutls --<span class="built_in">enable</span>-ladspa --<span class="built_in">enable</span>-libass --<span class="built_in">enable</span>-libbluray --<span class="built_in">enable</span>-libbs2b --<span class="built_in">enable</span>-libcaca --<span class="built_in">enable</span>-libcdio --<span class="built_in">enable</span>-libflite --<span class="built_in">enable</span>-libfontconfig --<span class="built_in">enable</span>-libfreetype --<span class="built_in">enable</span>-libfribidi --<span class="built_in">enable</span>-libgme --<span class="built_in">enable</span>-libgsm --<span class="built_in">enable</span>-libmp3lame --<span class="built_in">enable</span>-libmysofa --<span class="built_in">enable</span>-libopenjpeg --<span class="built_in">enable</span>-libopenmpt --<span class="built_in">enable</span>-libopus --<span class="built_in">enable</span>-libpulse --<span class="built_in">enable</span>-librubberband --<span class="built_in">enable</span>-librsvg --<span class="built_in">enable</span>-libshine --<span class="built_in">enable</span>-libsnappy --<span class="built_in">enable</span>-libsoxr --<span class="built_in">enable</span>-libspeex --<span class="built_in">enable</span>-libssh --<span class="built_in">enable</span>-libtheora --<span class="built_in">enable</span>-libtwolame --<span class="built_in">enable</span>-libvorbis --<span class="built_in">enable</span>-libvpx --<span class="built_in">enable</span>-libwavpack --<span class="built_in">enable</span>-libwebp --<span class="built_in">enable</span>-libx265 --<span class="built_in">enable</span>-libxml2 --<span class="built_in">enable</span>-libxvid --<span class="built_in">enable</span>-libzmq --<span class="built_in">enable</span>-libzvbi --<span class="built_in">enable</span>-omx --<span class="built_in">enable</span>-openal --<span class="built_in">enable</span>-opengl --<span class="built_in">enable</span>-sdl2 --<span class="built_in">enable</span>-libdc1394 --<span class="built_in">enable</span>-libdrm --<span class="built_in">enable</span>-libiec61883 --<span class="built_in">enable</span>-chromaprint --<span class="built_in">enable</span>-frei0r --<span class="built_in">enable</span>-libopencv --<span class="built_in">enable</span>-libx264 --<span class="built_in">enable</span>-shared</span><br><span class="line">  libavutil      55. 78.100 / 55. 78.100</span><br><span class="line">  libavcodec     57.107.100 / 57.107.100</span><br><span class="line">  libavformat    57. 83.100 / 57. 83.100</span><br><span class="line">  libavdevice    57. 10.100 / 57. 10.100</span><br><span class="line">  libavfilter     6.107.100 /  6.107.100</span><br><span class="line">  libavresample   3.  7.  0 /  3.  7.  0</span><br><span class="line">  libswscale      4.  8.100 /  4.  8.100</span><br><span class="line">  libswresample   2.  9.100 /  2.  9.100</span><br><span class="line">  libpostproc    54.  7.100 / 54.  7.100</span><br><span class="line">Input <span class="comment">#0, rtsp, from 'rtsp://127.0.0.1:554/user=user&amp;password=password&amp;channel=Channel&amp;stream=Stream.sdp?real_stream':</span></span><br><span class="line">  Metadata:</span><br><span class="line">    title           : RTSP Session</span><br><span class="line">  Duration: N/A, start: 0.600000, bitrate: N/A</span><br><span class="line">    Stream <span class="comment">#0:0: Video: h264 (Main), yuvj420p(pc, bt709, progressive), 1280x720, 10 fps, 10 tbr, 90k tbn, 20 tbc</span></span><br><span class="line">Output <span class="comment">#0, mp4, to '10101946.mp4':</span></span><br><span class="line">  Metadata:</span><br><span class="line">    title           : RTSP Session</span><br><span class="line">    encoder         : Lavf57.83.100</span><br><span class="line">    Stream <span class="comment">#0:0: Video: h264 (Main) (avc1 / 0x31637661), yuvj420p(pc, bt709, progressive), 1280x720, q=2-31, 10 fps, 10 tbr, 16384 tbn, 1 tbc</span></span><br><span class="line">Stream mapping:</span><br><span class="line">  Stream <span class="comment">#0:0 -&gt; #0:0 (copy)</span></span><br><span class="line">Press [q] to stop, [?] <span class="keyword">for</span> <span class="built_in">help</span></span><br><span class="line">[mp4 @ 0x563c634747a0] Non-monotonous DTS <span class="keyword">in</span> output stream 0:0; previous: 0, current: -8192; changing to 1. This may result <span class="keyword">in</span> incorrect timestamps <span class="keyword">in</span> the output file.</span><br><span class="line">[mp4 @ 0x563c634747a0] Non-monotonous DTS <span class="keyword">in</span> output stream 0:0; previous: 1, current: -6554; changing to 2. This may result <span class="keyword">in</span> incorrect timestamps <span class="keyword">in</span> the output file.</span><br><span class="line">[mp4 @ 0x563c634747a0] Non-monotonous DTS <span class="keyword">in</span> output stream 0:0; previous: 2, current: -4915; changing to 3. This may result <span class="keyword">in</span> incorrect timestamps <span class="keyword">in</span> the output file.</span><br><span class="line">[mp4 @ 0x563c634747a0] Non-monotonous DTS <span class="keyword">in</span> output stream 0:0; previous: 3, current: -3277; changing to 4. This may result <span class="keyword">in</span> incorrect timestamps <span class="keyword">in</span> the output file.</span><br><span class="line">[mp4 @ 0x563c634747a0] Non-monotonous DTS <span class="keyword">in</span> output stream 0:0; previous: 4, current: -1638; changing to 5. This may result <span class="keyword">in</span> incorrect timestamps <span class="keyword">in</span> the output file.</span><br><span class="line">[mp4 @ 0x563c634747a0] Non-monotonous DTS <span class="keyword">in</span> output stream 0:0; previous: 5, current: 0; changing to 6. This may result <span class="keyword">in</span> incorrect timestamps <span class="keyword">in</span> the output file.</span><br><span class="line">frame=  387 fps= 11 q=-1.0 size=    4352kB time=00:00:38.00 bitrate= 938.2kbits/s speed=1.06x</span><br><span class="line">video:6838kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.106432%</span><br></pre></td></tr></table></figure>
<h2 id="设置定时录制任务"><a href="#设置定时录制任务" class="headerlink" title="设置定时录制任务"></a>设置定时录制任务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">*/1 * * * * /root/shell/monitor.sh</span><br></pre></td></tr></table></figure>
<p>选择每一分钟录制一分钟的是视频，没有找到其他合适的录制方法，每次录制录制都要重新建立 RTSP 链接，后面可能会写一个简单的 C 服务端直接建立 RTSP 的视频流，然后再切割视频文件。</p>
<p>不得不说 FFmpeg 真是强大的，偶尔了解了 FFmpeg 作者，巨牛逼的天才啊。</p>
<blockquote>
<ul>
<li>1997年他发现了最快速的计算圆周率的算法，是Bailey-Borwein-Plouffe 公式的变体。</li>
<li>2000年他化名Gérard Lantau，创建了 FFmpeg 项目。2004年他编写了一个只有138KB的启动加载程序TCCBOOT，可以在15秒内从源代码编译并启动Linux系统。</li>
<li>2003年开发了Emacs克隆QEmacs。2005年用普通PC和VGA卡设计了一个数字电视系统。</li>
<li>2009年12月31日，他声称打破了圆周率计算的世界纪录，算出小数点后2.7万亿位，仅用一台普通PC机。</li>
<li>2011年，他单用JavaScript写了一个PC虚拟机Jslinux 。这个虚拟机仿真了一个32位的x86兼容处理器，一个8259可编程中断控制器，一个8254可编程中断计时器，和一个16450 UART。</li>
<li>Fabrice Bellard，法国著名程序员，QEMU、TinyCC、FFmpeg等作者。</li>
</ul>
</blockquote>
<p>不得不再提一嘴 FFmpeg 这个项目 <a href="http://history.programmer.com.cn/3877/" target="_blank" rel="noopener">从FFmpeg耻辱榜看开源软件的“潜规则”</a></p>
<blockquote>
<p>FFmpeg是一个开源免费跨平台的视频和音频流方案，属于自由软件，采用LGPL或GPL许可证。2009年，韩国名软KMPlayer被FFmpeg开源项目发现使用了它们的代码和二进制文件，但没有按照规定/惯例开放相应说明/源码。被人举报后，KMPlayer进入了FFmpeg官网上的耻辱黑名单。最近，国内也有同样的产品被列入黑名单比如暴风影音、QQ影音等。<br><a href="http://ffmpeg.org/index.html" target="_blank" rel="noopener">FFmpeg</a>是一个跨平台的视频和音频流方案，属于自由软件，采用LGPL或GPL许可证（依据你选择的组件）。<em>今年2月韩国播放软件KMPlayer被加入到FFmpeg耻辱名单中，随后网友yegle向FFmpeg举报，指出暴风影音使用了大量开源代码，侵犯了FFmpeg的许可证。5月10日，另一位用户cehoyos下载了暴风软件，用7z解压之后发现其安装程序内包含了大量的开源和私有解码器的dll：avcodec，avformat，avutil，x264，xvid，bass，wmvdmod等等。杀毒软件AntiVir报告lib_VoiceEngine_dll.dll是木马程序“TR\Spy.Legmir.SS.2”。之后暴风影音被正式加入到FFmpeg耻辱名单之列。</em></p>
</blockquote>
]]></content>
      <tags>
        <tag>ffmpeg</tag>
        <tag>rtsp</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 离线安装 Docker-ce</title>
    <url>/archives/centos7-offline-install-docker.html</url>
    <content><![CDATA[<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>接到新项目的机器无法访问外网，所以只能离线安装 Docker，总体思路是从一台可访问外网的机器上下载下来 docker-ce 的 rpm 包及其依赖，再把这些 rpm 传到要部署的机器上安装就行。其中踩了一些坑，在此记录一下。</p>
<p>新项目的机器是系统是 CentOS 7.5 (1804)，所以在 ESXi 上重新开一台虚拟机，装上 CentOS 7.5 (1804)，这一点比较重要。因为刚开始的时候使用的是 CentOS 7.6 (1810)，但环境不一致导致一些依赖的包版本也不一致，7.6 上一些依赖包版本要比 7.5 高一些，最主要的就是 <code>libsepol</code>、 <code>libsemanage</code>、 <code>selinux-policy</code> 等，都是和 SELinux 相关的依赖，虽然可以加个 <code>skip-broken</code> 参数强制安装，但因为是线上生产环境，为了保险起见还是决定将这几个依赖包升级到要求的版本。</p>
<h2 id="下载-rpm-包"><a href="#下载-rpm-包" class="headerlink" title="下载 rpm 包"></a>下载 rpm 包</h2><p>在另一条可访问外网的机器上下载</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/docker-ce</span><br><span class="line">yum install -y yum-utils createrepo</span><br><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"><span class="comment"># yum-utils 用来添加 docker 的 yum 源</span></span><br><span class="line"><span class="comment"># createrepo 用来创建本地 yum 源</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 yum 源中的版本</span></span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br><span class="line">yum list docker-ce-cli --showduplicates | sort -r</span><br><span class="line">yum install --downloadonly --downloaddir=/root/docker-ce docker-ce docker-ce-cli containerd.io</span><br><span class="line">mv /var/cache/yum/x86_64/7/updates/packages/* /root/docker-ce</span><br><span class="line">mv /var/cache/yum/x86_64/7/base/packages/* /root/docker-ce</span><br><span class="line">mv /var/cache/yum/x86_64/7/extras/packages/* /root/docker-ce</span><br><span class="line"><span class="comment"># 需要注意的是 --downloadonly 参数只会将所安装的包及其依赖下载到你指定的位置，但需要升级的包,即 Updating dependencies 默认下载到了# /var/cache/yum/x86_64/7/ 这几个目录下，这一点比较坑。</span></span><br></pre></td></tr></table></figure>
<p>提示要安装 3 个包 即 <code>docker-ce</code> 、<code>docker-ce-cli</code> 、<code>containerd.io</code> 加9个依赖包，一共十二个包会下载到我们指定路径下，剩余 10 个要升级的依赖包即<code>Updating dependencies</code>并不会下载到指定的路径下，而是根据对应的 <code>Repository</code>下载到 <code>/var/cache/yum/x86_64/7/</code> 目录下，所以也需要将这些包也一同移动到我们指定的路径下。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Package                            Version                Repository</span><br><span class="line">stalling:</span><br><span class="line">containerd.io                      1.2.6-3.3.el7          docker-ce-stable</span><br><span class="line">docker-ce                          3:19.03.1-3.el7        docker-ce-stable</span><br><span class="line">docker-ce-cli                      1:19.03.1-3.el7        docker-ce-stable</span><br><span class="line"></span><br><span class="line">Installing dependencies:</span><br><span class="line">audit-libs-python                  2.8.4-4.el7            base</span><br><span class="line">checkpolicy                        2.5-8.el7              base</span><br><span class="line">container-selinux                  2:2.107-1.el7_6        extras</span><br><span class="line">libcgroup                          0.41-20.el7            base</span><br><span class="line">libseccomp                         2.3.1-3.el7            base</span><br><span class="line">libsemanage-python                 2.5-14.el7             base</span><br><span class="line">policycoreutils-python             2.5-29.el7_6.1         updates</span><br><span class="line">python-IPy                         0.75-6.el7             base</span><br><span class="line">setools-libs                       3.3.8-4.el7            base</span><br><span class="line"></span><br><span class="line">Updating dependencies:</span><br><span class="line">audit                              2.8.4-4.el7            base</span><br><span class="line">audit-libs                         2.8.4-4.el7            base</span><br><span class="line">libselinux                         2.5-14.1.el7           base</span><br><span class="line">libselinux-python                  2.5-14.1.el7           base</span><br><span class="line">libselinux-utils                   2.5-14.1.el7           base</span><br><span class="line">libsemanage                        2.5-14.el7             base</span><br><span class="line">libsepol                           2.5-10.el7             base</span><br><span class="line">policycoreutils                    2.5-29.el7_6.1         updates</span><br><span class="line">selinux-policy                     3.13.1-229.el7_6.15    updates</span><br><span class="line">selinux-policy-targeted            3.13.1-229.el7_6.15    updates</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">====================================================</span><br><span class="line">Install  3 Packages (+ 9 Dependent packages)</span><br><span class="line">Upgrade             ( 10 Dependent packages)</span><br></pre></td></tr></table></figure>
<p>最终所需要的 rpm 包的如下，包含依赖机器需要升级的包，一共 29 个</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">audit-2.8.4-4.el7.x86_64.rpm</span><br><span class="line">audit-libs-2.8.4-4.el7.x86_64.rpm</span><br><span class="line">audit-libs-python-2.8.4-4.el7.x86_64.rpm</span><br><span class="line">checkpolicy-2.5-8.el7.x86_64.rpm</span><br><span class="line">containerd.io-1.2.6-3.3.el7.x86_64.rpm</span><br><span class="line">container-selinux-2.107-1.el7_6.noarch.rpm</span><br><span class="line">device-mapper-1.02.149-10.el7_6.8.x86_64.rpm</span><br><span class="line">device-mapper-event-1.02.149-10.el7_6.8.x86_64.rpm</span><br><span class="line">device-mapper-event-libs-1.02.149-10.el7_6.8.x86_64.rpm</span><br><span class="line">device-mapper-libs-1.02.149-10.el7_6.8.x86_64.rpm</span><br><span class="line">docker-ce-19.03.1-3.el7.x86_64.rpm</span><br><span class="line">docker-ce-cli-19.03.1-3.el7.x86_64.rpm</span><br><span class="line">libcgroup-0.41-20.el7.x86_64.rpm</span><br><span class="line">libseccomp-2.3.1-3.el7.x86_64.rpm</span><br><span class="line">libselinux-2.5-14.1.el7.x86_64.rpm</span><br><span class="line">libselinux-python-2.5-14.1.el7.x86_64.rpm</span><br><span class="line">libselinux-utils-2.5-14.1.el7.x86_64.rpm</span><br><span class="line">libsemanage-2.5-14.el7.x86_64.rpm</span><br><span class="line">libsemanage-python-2.5-14.el7.x86_64.rpm</span><br><span class="line">libsepol-2.5-10.el7.x86_64.rpm</span><br><span class="line">libtool-ltdl-2.4.2-22.el7_3.x86_64.rpm</span><br><span class="line">lvm2-2.02.180-10.el7_6.8.x86_64.rpm</span><br><span class="line">lvm2-libs-2.02.180-10.el7_6.8.x86_64.rpm</span><br><span class="line">policycoreutils-2.5-29.el7_6.1.x86_64.rpm</span><br><span class="line">policycoreutils-python-2.5-29.el7_6.1.x86_64.rpm</span><br><span class="line">python-IPy-0.75-6.el7.noarch.rpm</span><br><span class="line">selinux-policy-3.13.1-229.el7_6.15.noarch.rpm</span><br><span class="line">selinux-policy-targeted-3.13.1-229.el7_6.15.noarch.rpm</span><br><span class="line">setools-libs-3.3.8-4.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
<h2 id="生成本地-yum-源"><a href="#生成本地-yum-源" class="headerlink" title="生成本地 yum 源"></a>生成本地 yum 源</h2><p>这一步操作可以在本地这台机器上生成 yum 元数据信息，也可以在生产环境那台机器上执行，不过需要单独安装createrepo 工具来生成。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">createrepo -d /root/docker-ce/</span><br><span class="line"><span class="comment"># 最终会在本地 /root/docker-ce/ 目录的 repodata 目录下生成所含软件包的元数据据信息</span></span><br><span class="line">tree /root/docker-ce/repodata</span><br><span class="line">.</span><br><span class="line">├── 1a232695bdd68ade6ebd6549ef9267e1b7f870566820f627237bc3db93281aaf-filelists.xml.gz</span><br><span class="line">├── 658e130ccd8e0d62a4b1334ff65c14b223e528c50352a9e2cfc44cc4535693fd-other.sqlite.bz2</span><br><span class="line">├── 6601f7512ba24f28ce37e5afa4c5f48b812dfcb019516e630438a1d11088ecdd-other.xml.gz</span><br><span class="line">├── d3e511a8557503650c8083eb97ef7500afa0f43eb0f66db15aa155226c03054b-primary.sqlite.bz2</span><br><span class="line">├── db2fa3329ff03fd2b70814a57703502c28898ba09b548593abcce1166964554d-primary.xml.gz</span><br><span class="line">├── ff326b22deaf8f3f728203069f42476e35e5c62688fb78691087314edeaf6b13-filelists.sqlite.bz2</span><br><span class="line">└── repomd.xml</span><br><span class="line">0 directories, 7 files</span><br></pre></td></tr></table></figure>
<p><code>repomd.xml</code> 包含这些软件包的元数据信息</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">repomd</span> <span class="attr">xmlns</span>=<span class="string">"http://linux.duke.edu/metadata/repo"</span> <span class="attr">xmlns:rpm</span>=<span class="string">"http://linux.duke.edu/metadata/rpm"</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">revision</span>&gt;</span>1567506793<span class="tag">&lt;/<span class="name">revision</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span> <span class="attr">type</span>=<span class="string">"filelists"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>1a232695bdd68ade6ebd6549ef9267e1b7f870566820f627237bc3db93281aaf<span class="tag">&lt;/<span class="name">checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>9653a695d402fdd138ca4ca0ab4387e1687b67a8486af6955cdae070c0a6a7c1<span class="tag">&lt;/<span class="name">open-checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">location</span> <span class="attr">href</span>=<span class="string">"repodata/1a232695bdd68ade6ebd6549ef9267e1b7f870566820f627237bc3db93281aaf-filelists.xml.gz"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">timestamp</span>&gt;</span>1567506794<span class="tag">&lt;/<span class="name">timestamp</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">size</span>&gt;</span>15489<span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-size</span>&gt;</span>181439<span class="tag">&lt;/<span class="name">open-size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span> <span class="attr">type</span>=<span class="string">"primary"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>db2fa3329ff03fd2b70814a57703502c28898ba09b548593abcce1166964554d<span class="tag">&lt;/<span class="name">checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>1ab8f25d3566bee756fa62cf7f6c5d944d52d6440cb00ef37779d0e6a38d81fe<span class="tag">&lt;/<span class="name">open-checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">location</span> <span class="attr">href</span>=<span class="string">"repodata/db2fa3329ff03fd2b70814a57703502c28898ba09b548593abcce1166964554d-primary.xml.gz"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">timestamp</span>&gt;</span>1567506794<span class="tag">&lt;/<span class="name">timestamp</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">size</span>&gt;</span>19103<span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-size</span>&gt;</span>198571<span class="tag">&lt;/<span class="name">open-size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span> <span class="attr">type</span>=<span class="string">"primary_db"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>d3e511a8557503650c8083eb97ef7500afa0f43eb0f66db15aa155226c03054b<span class="tag">&lt;/<span class="name">checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>d6df45954bb239439baa86c486159ca009ad076107729f69df6cfb06d04b76d1<span class="tag">&lt;/<span class="name">open-checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">location</span> <span class="attr">href</span>=<span class="string">"repodata/d3e511a8557503650c8083eb97ef7500afa0f43eb0f66db15aa155226c03054b-primary.sqlite.bz2"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">timestamp</span>&gt;</span>1567506794<span class="tag">&lt;/<span class="name">timestamp</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">database_version</span>&gt;</span>10<span class="tag">&lt;/<span class="name">database_version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">size</span>&gt;</span>55692<span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-size</span>&gt;</span>344064<span class="tag">&lt;/<span class="name">open-size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span> <span class="attr">type</span>=<span class="string">"other_db"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>658e130ccd8e0d62a4b1334ff65c14b223e528c50352a9e2cfc44cc4535693fd<span class="tag">&lt;/<span class="name">checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>f0d99fae751fa3f6cd7b6e4e69cd0cf80a569b972d83103469fe21f4464aa569<span class="tag">&lt;/<span class="name">open-checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">location</span> <span class="attr">href</span>=<span class="string">"repodata/658e130ccd8e0d62a4b1334ff65c14b223e528c50352a9e2cfc44cc4535693fd-other.sqlite.bz2"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">timestamp</span>&gt;</span>1567506794<span class="tag">&lt;/<span class="name">timestamp</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">database_version</span>&gt;</span>10<span class="tag">&lt;/<span class="name">database_version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">size</span>&gt;</span>15817<span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-size</span>&gt;</span>64512<span class="tag">&lt;/<span class="name">open-size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span> <span class="attr">type</span>=<span class="string">"other"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>6601f7512ba24f28ce37e5afa4c5f48b812dfcb019516e630438a1d11088ecdd<span class="tag">&lt;/<span class="name">checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>905cc2a9cdc825e3bf9f790219661f36f5adb733b4238cf9d9f6b0db596a1936<span class="tag">&lt;/<span class="name">open-checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">location</span> <span class="attr">href</span>=<span class="string">"repodata/6601f7512ba24f28ce37e5afa4c5f48b812dfcb019516e630438a1d11088ecdd-other.xml.gz"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">timestamp</span>&gt;</span>1567506794<span class="tag">&lt;/<span class="name">timestamp</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">size</span>&gt;</span>10380<span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-size</span>&gt;</span>60522<span class="tag">&lt;/<span class="name">open-size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span> <span class="attr">type</span>=<span class="string">"filelists_db"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>ff326b22deaf8f3f728203069f42476e35e5c62688fb78691087314edeaf6b13<span class="tag">&lt;/<span class="name">checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-checksum</span> <span class="attr">type</span>=<span class="string">"sha256"</span>&gt;</span>1a2a1ddbf42881778fc5c4603545d730db0d833c711166a82ff9f589092459f0<span class="tag">&lt;/<span class="name">open-checksum</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">location</span> <span class="attr">href</span>=<span class="string">"repodata/ff326b22deaf8f3f728203069f42476e35e5c62688fb78691087314edeaf6b13-filelists.sqlite.bz2"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">timestamp</span>&gt;</span>1567506794<span class="tag">&lt;/<span class="name">timestamp</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">database_version</span>&gt;</span>10<span class="tag">&lt;/<span class="name">database_version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">size</span>&gt;</span>24426<span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">open-size</span>&gt;</span>123904<span class="tag">&lt;/<span class="name">open-size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repomd</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="离线安装-docker-ce"><a href="#离线安装-docker-ce" class="headerlink" title="离线安装 docker-ce"></a>离线安装 docker-ce</h2><p>将上面生成的文件夹 <code>/root/docker-ce</code>  利用 scp 的方式上传到需要安装的机器上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 备份原有的 yum repo</span></span><br><span class="line">ls /etc/yum.repos.d | xargs -I&#123;&#125; mv /etc/yum.repos.d/&#123;&#125; /etc/yum.repos.d/&#123;&#125;.bak</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt;&gt;/etc/yum.repos.d/docker-ce.repo &lt;&lt; EOF</span><br><span class="line">[<span class="built_in">local</span>-yum]</span><br><span class="line">name=<span class="built_in">local</span>-yum</span><br><span class="line">baseurl=file:///root/docker-ce</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum clean all</span><br><span class="line">rm -rf /var/cache/yum</span><br><span class="line">yum makecache</span><br><span class="line">yum list | grep docker</span><br><span class="line">yum install docker-ce docker-ce-cli containerd.io</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line">docker info</span><br></pre></td></tr></table></figure>
<p>这样就大功告成啦</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">docker info</span><br><span class="line">Client:</span><br><span class="line"> Debug Mode: false</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Containers: 0</span><br><span class="line">  Running: 0</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 0</span><br><span class="line"> Images: 0</span><br><span class="line"> Server Version: 19.03.1</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: extfs</span><br><span class="line">  Supports d_type: true</span><br><span class="line">  Native Overlay Diff: true</span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: cgroupfs</span><br><span class="line"> Plugins:</span><br><span class="line">  Volume: local</span><br><span class="line">  Network: bridge host ipvlan macvlan null overlay</span><br><span class="line">  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog</span><br><span class="line"> Swarm: inactive</span><br><span class="line"> Runtimes: runc</span><br><span class="line"> Default Runtime: runc</span><br><span class="line"> Init Binary: docker-init</span><br><span class="line"> containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb</span><br><span class="line"> runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f</span><br><span class="line"> init version: fec3683</span><br><span class="line"> Security Options:</span><br><span class="line">  seccomp</span><br><span class="line">   Profile: default</span><br><span class="line"> Kernel Version: 3.10.0-862.el7.x86_64</span><br><span class="line"> Operating System: CentOS Linux 7 (Core)</span><br><span class="line"> OSType: linux</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> CPUs: 2</span><br><span class="line"> Total Memory: 1.779GiB</span><br><span class="line"> Name: centos1804</span><br><span class="line"> ID: SAFG:3ERG:A52Y:NIDH:65B5:QMKS:DYPH:XVW4:CA6M:UFMR:AKDJ:WQJK</span><br><span class="line"> Docker Root Dir: /var/lib/docker</span><br><span class="line"> Debug Mode: false</span><br><span class="line"> Registry: https://index.docker.io/v1/</span><br><span class="line"> Labels:</span><br><span class="line"> Experimental: false</span><br><span class="line"> Insecure Registries:</span><br><span class="line">  127.0.0.0/8</span><br><span class="line"> Live Restore Enabled: false</span><br></pre></td></tr></table></figure>
<h2 id="经验？"><a href="#经验？" class="headerlink" title="经验？"></a>经验？</h2><ol>
<li>通过 yum history 回滚是不会回滚升级的版本的</li>
<li>需要注意的是 –downloadonly 参数只会将所安装的包及其依赖下载到你指定的位置，但需要升级的包,即 Updating dependencies 默认下载到了# /var/cache/yum/x86_64/7/ 这几个目录下，这一点比较坑</li>
<li>createrepo  创建本地 yum 源</li>
<li>此方案不仅仅是用与 docker ，离线安装其他包也是支持的</li>
</ol>
]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>手搓虚拟机模板</title>
    <url>/archives/esxi-vmbase.html</url>
    <content><![CDATA[<h3 id="0-背景"><a href="#0-背景" class="headerlink" title="0. 背景"></a>0. 背景</h3><p>由于工作环境是 ESXi 虚拟化，需要经常用一些模板开部署一些虚拟机，由于我的机器没有连接上 vCenter，只能靠上传 OVA 等虚拟机模板来部署，因此需要搓一些虚拟机模板出来。宿主机系统有 Debian 10、Debian 9、Ubuntu1804、Ubuntu 1604、CentOS7.6、Alpine 3.10、OpenWrt/LEDE ，还有 Windows 😂。一般最小化安装之后还是有可以精简的余地，删除掉一些不用的软件包，系统一般情况下都能精简到 700MB 左右，再使用 dd 暴力清零剩余空间，最后导出的 OVA 虚拟机模板在 450MB 左右。这样部署和上传的速度大大加快了。</p>
<h3 id="1-Ubuntu-1804"><a href="#1-Ubuntu-1804" class="headerlink" title="1. Ubuntu 1804"></a>1. Ubuntu 1804</h3><h4 id="1-安装镜像"><a href="#1-安装镜像" class="headerlink" title="1. 安装镜像"></a>1. 安装镜像</h4><p><a href="http://mirrors.ustc.edu.cn/ubuntu-cdimage/releases/18.04/release/ubuntu-18.04.3-server-amd64.iso" target="_blank" rel="noopener">ubuntu-18.04.3-server-amd64.iso</a></p>
<p>安装过程就不赘述了，主要是懒，安装过程图还要截图什么的，麻烦😂。建议使用 lvm 分区，安装上 openssh-server 就行，其他的组件一概不用安装，这样能减少系统占用空间的而大小。以后需要安装的话再安装就行。</p>
<p>安装进入系统后使用 <code>sudo passwd</code> 来重置 root 的密码</p>
<ol>
<li>安装 ncdu 工具结合 du 用来分析系统根分区占用大小情况</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt update &amp;&amp; apt install ncdu -y</span><br></pre></td></tr></table></figure>
<p>2.默认安装后的系统分区占用情况，虽然在安装的过程中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># df -h</span></span><br><span class="line">Filesystem                         Size  Used Avail Use% Mounted on</span><br><span class="line">udev                               1.9G     0  1.9G   0% /dev</span><br><span class="line">tmpfs                              393M  1.1M  392M   1% /run</span><br><span class="line">/dev/mapper/ubuntu--vg-ubuntu--lv   28G  5.7G   21G  22% /</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                              5.0M     0  5.0M   0% /run/lock</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda2                          976M   76M  834M   9% /boot</span><br><span class="line">/dev/loop0                          91M   91M     0 100% /snap/core/6350</span><br><span class="line">tmpfs                              393M     0  393M   0% /run/user/1000</span><br><span class="line">root@ubuntu:~<span class="comment"># free -h</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           3.8G        213M        2.9G        1.1M        759M        3.3G</span><br><span class="line">Swap:          3.8G          0B        3.8G</span><br></pre></td></tr></table></figure>
<p>3.默认给分配了个 swap 文件，使用 swapoff -a 关闭 swap 就行，再修改 fstab 文件，删除 swap 那一行，或注释掉</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># swapoff -a</span></span><br><span class="line">root@ubuntu:~<span class="comment"># rm -rf /swap.img</span></span><br><span class="line">root@ubuntu:~<span class="comment"># vi /etc/fstab</span></span><br></pre></td></tr></table></figure>
<p>4.删除 swap file 之后的分区情况，占用的 1.8GB ，如果直接导出的话，OVA 文件至少得 2GB。我们接下来精简系统不需要得包和文件，最终 OVA 大小缩小到 450MB</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># df -h</span></span><br><span class="line">Filesystem                         Size  Used Avail Use% Mounted on</span><br><span class="line">udev                               1.9G     0  1.9G   0% /dev</span><br><span class="line">tmpfs                              393M  1.1M  392M   1% /run</span><br><span class="line">/dev/mapper/ubuntu--vg-ubuntu--lv   28G  1.8G   25G   7% /</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                              5.0M     0  5.0M   0% /run/lock</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda2                          976M   76M  834M   9% /boot</span><br><span class="line">/dev/loop0                          91M   91M     0 100% /snap/core/6350</span><br><span class="line">tmpfs                              393M     0  393M   0% /run/user/1000</span><br></pre></td></tr></table></figure>
<h4 id="2-卸载不用的软件包"><a href="#2-卸载不用的软件包" class="headerlink" title="2. 卸载不用的软件包"></a>2. 卸载不用的软件包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一把梭子过去就完</span></span><br><span class="line">rm /etc/cloud</span><br><span class="line">apt purge usbutils wireless-regdb linux-modules-extra-4.15.0-58-generic vim-tiny vim-common ubuntu-advantage-tools cloud-* linux-firmware snapd lxd* linux-headers-* git-man landscape-common ubuntu-release-upgrader-core</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">snapd: snapd 从不使用果断卸载</span><br><span class="line">lxd*: 历史遗留下来得容器虚拟化，我有 docker 要你何用？</span><br><span class="line">vim-tiny: 默认安装得 vim 死难用，卸载重新装个 vim 就行</span><br><span class="line">cloud-*: 公有云用来导入私钥获取 IP 等等部署虚拟机用到得，自己用不到果断卸载</span><br><span class="line">usbutils: USB 驱动，从不使用，果断卸载。如果你使用 USB 设备得话就保留它</span><br><span class="line">wireless-regdb: 一个无线相关的，用不到</span><br><span class="line">linux-firmware: 里面大部分是网卡蓝牙USB之类得固件，虚拟机用不到</span><br><span class="line">linux-headers-*: 内核源码之类的头文件，用到的时候再安装就行</span><br><span class="line">ubuntu-advantage-tools: 用不到果断卸载</span><br><span class="line">linux-modules-extra-4.15.0-58-generic: 内核模块扩展驱动等，虚拟机很少能用到</span><br><span class="line">git-man: git 的 man 手册，一般用不到</span><br><span class="line">landscape-common: landscape 管理，用不到</span><br><span class="line">ubuntu-release-upgrader-core: 用不到</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">The following packages were automatically installed and are no longer required:</span><br><span class="line">  amd64-microcode eatmydata gdisk intel-microcode iucode-tool libdbus-glib-1-2 libeatmydata1 libuv1</span><br><span class="line">  python3-blinker python3-jinja2 python3-json-pointer python3-jsonpatch python3-jsonschema python3-jwt</span><br><span class="line">  python3-markupsafe python3-oauthlib thermald</span><br><span class="line">Use <span class="string">'apt autoremove'</span> to remove them.</span><br><span class="line">The following additional packages will be installed:</span><br><span class="line">  python3-update-manager</span><br><span class="line">Suggested packages:</span><br><span class="line">  python3-launchpadlib</span><br><span class="line">The following packages will be REMOVED:</span><br><span class="line">  cloud-guest-utils* cloud-init* cloud-initramfs-copymods* cloud-initramfs-dyn-netconf* crda* git* git-man*</span><br><span class="line">  landscape-common* linux-firmware* linux-generic* linux-headers-4.15.0-58* linux-headers-4.15.0-58-generic*</span><br><span class="line">  linux-headers-generic* linux-image-generic* linux-modules-extra-4.15.0-58-generic* lxd* lxd-client* snapd*</span><br><span class="line">  ubuntu-advantage-tools* ubuntu-minimal* ubuntu-release-upgrader-core* ubuntu-server* ubuntu-standard*</span><br><span class="line">  update-manager-core* update-notifier-common* usbutils* vim* vim-common* vim-tiny* wireless-regdb*</span><br><span class="line">The following packages will be upgraded:</span><br><span class="line">  python3-update-manager</span><br><span class="line">1 upgraded, 0 newly installed, 30 to remove and 75 not upgraded.</span><br><span class="line">Need to get 35.1 kB of archives.</span><br><span class="line">After this operation, 723 MB disk space will be freed.</span><br><span class="line">Do you want to <span class="built_in">continue</span>? [Y/n] y</span><br></pre></td></tr></table></figure>
<p><strong>清理卸载后的占用大小</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># rm -rf /var/lib/apt/lists/*</span></span><br><span class="line">root@ubuntu:~<span class="comment"># rm -rf /var/cache/apt/*</span></span><br><span class="line">root@ubuntu:~<span class="comment"># df -h</span></span><br><span class="line">Filesystem                         Size  Used Avail Use% Mounted on</span><br><span class="line">udev                               1.9G     0  1.9G   0% /dev</span><br><span class="line">tmpfs                              393M  1.1M  392M   1% /run</span><br><span class="line">/dev/mapper/ubuntu--vg-ubuntu--lv   28G  685M   26G   3% /</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                              5.0M     0  5.0M   0% /run/lock</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda2                          976M   41M  868M   5% /boot</span><br><span class="line">tmpfs                              393M     0  393M   0% /run/user/1000</span><br><span class="line">root@ubuntu:~<span class="comment">#</span></span><br></pre></td></tr></table></figure>
<h4 id="3-清理日志和缓存"><a href="#3-清理日志和缓存" class="headerlink" title="3. 清理日志和缓存"></a>3. 清理日志和缓存</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rm -rf /var/lib/apt/lists/*</span><br><span class="line">rm -rf /var/cache/apt/*</span><br><span class="line">rm -rf /var/<span class="built_in">log</span>/journal/*</span><br></pre></td></tr></table></figure>
<h4 id="4-清理不用的文件"><a href="#4-清理不用的文件" class="headerlink" title="4. 清理不用的文件"></a>4. 清理不用的文件</h4><p>剩下来能精简的只有 <code>/usr/share</code> 里面的 doc 和 locale 文件里，减小大概 40 MB</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rm -rf /usr/share/doc</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/share/locale</span><br><span class="line"><span class="comment"># 下面这条命令一定要在 /usr/share/locale 目录下执行</span></span><br><span class="line">ls | grep -v zh | grep -v en | grep -v us | grep -v @ | grep -v <span class="built_in">local</span> | xargs rm -rf</span><br><span class="line"></span><br><span class="line">root@ubuntu:/usr/share/locale<span class="comment"># du -sh</span></span><br><span class="line">1.5M</span><br></pre></td></tr></table></figure>
<p><strong>最后完毕</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:/usr/share/locale<span class="comment"># df -h</span></span><br><span class="line">Filesystem                         Size  Used Avail Use% Mounted on</span><br><span class="line">udev                               1.9G     0  1.9G   0% /dev</span><br><span class="line">tmpfs                              393M  1.1M  392M   1% /run</span><br><span class="line">/dev/mapper/ubuntu--vg-ubuntu--lv   28G  660M   26G   3% /</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                              5.0M     0  5.0M   0% /run/lock</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda2                          976M   41M  868M   5% /boot</span><br><span class="line">tmpfs                              393M     0  393M   0% /run/user/1000</span><br><span class="line">root@ubuntu:/usr/share/locale<span class="comment"># ncdu /</span></span><br><span class="line">ncdu 1.12 ~ Use the arrow keys to navigate, press ? <span class="keyword">for</span> <span class="built_in">help</span></span><br><span class="line">--- / --------------------------------------------------------------------------------------------------------------</span><br><span class="line">  407.4 MiB [<span class="comment">##########] /usr</span></span><br><span class="line">  109.6 MiB [<span class="comment">##        ] /lib</span></span><br><span class="line">   38.2 MiB [          ] /boot</span><br><span class="line">   27.5 MiB [          ] /var</span><br><span class="line">   14.9 MiB [          ] /bin</span><br><span class="line">   14.4 MiB [          ] /sbin</span><br><span class="line">    5.0 MiB [          ] /etc</span><br><span class="line">    1.1 MiB [          ] /run</span><br><span class="line">   52.0 KiB [          ] /tmp</span><br><span class="line">   32.0 KiB [          ] /home</span><br><span class="line">   20.0 KiB [          ] /root</span><br><span class="line">e  16.0 KiB [          ] /lost+found</span><br><span class="line">    4.0 KiB [          ] /lib64</span><br><span class="line">e   4.0 KiB [          ] /srv</span><br><span class="line">e   4.0 KiB [          ] /opt</span><br><span class="line">e   4.0 KiB [          ] /mnt</span><br><span class="line">e   4.0 KiB [          ] /media</span><br><span class="line">.   0.0   B [          ] /proc</span><br><span class="line">    0.0   B [          ] /sys</span><br><span class="line">    0.0   B [          ] /dev</span><br><span class="line">@   0.0   B [          ]  initrd.img.old</span><br><span class="line">@   0.0   B [          ]  initrd.img</span><br><span class="line">@   0.0   B [          ]  vmlinuz.old</span><br><span class="line">@   0.0   B [          ]  vmlinuz</span><br></pre></td></tr></table></figure>
<h4 id="5-置零剩余空间"><a href="#5-置零剩余空间" class="headerlink" title="5. 置零剩余空间"></a>5. 置零剩余空间</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:/usr/share/locale<span class="comment"># df -h</span></span><br><span class="line">Filesystem                         Size  Used Avail Use% Mounted on</span><br><span class="line">udev                               1.9G     0  1.9G   0% /dev</span><br><span class="line">tmpfs                              393M  1.1M  392M   1% /run</span><br><span class="line">/dev/mapper/ubuntu--vg-ubuntu--lv   28G  660M   26G   3% /</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                              5.0M     0  5.0M   0% /run/lock</span><br><span class="line">tmpfs                              2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda2                          976M   41M  868M   5% /boot</span><br><span class="line">tmpfs                              393M     0  393M   0% /run/user/1000</span><br></pre></td></tr></table></figure>
<p>经过上面的精简之后，根分区占用 660MB 加上 boot 分区刚好 700 MB 左右。如果现在直接导出 ova 模板的话，vmdk 的体积是很大的，至少 1GB（ <code>1.3G Aug 28 15:48 Ubuntu1804.ova</code>） ，因此在导出 ova 模板之前需要把磁盘的剩余空间置零，这样导出的 vmdk 文件大小更小，450MB 左右哈。</p>
<p>直接使用 dd 暴力清零就行啦 <code>dd if=/dev/zero of=/zero bs=4M || rm -rf /zero</code></p>
<p>这个过程比较长，时间取决于你安装虚拟机的时候给定的根分区大小，以及你的磁盘速度</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># dd if=/dev/zero of=/zero bs=4M || rm -rf /zero</span></span><br><span class="line"></span><br><span class="line">dd: error writing <span class="string">'/zero'</span>: No space left on device</span><br><span class="line">6860+0 records <span class="keyword">in</span></span><br><span class="line">6859+0 records out</span><br><span class="line">28771078144 bytes (29 GB, 27 GiB) copied, 445.634 s, 64.6 MB/s</span><br></pre></td></tr></table></figure>
<h4 id="6-导出-OVA-虚拟机模板"><a href="#6-导出-OVA-虚拟机模板" class="headerlink" title="6. 导出 OVA 虚拟机模板"></a>6. 导出 OVA 虚拟机模板</h4><p>经过置零后我们再导出 OVA 模板</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">464M Aug 28 16:15 Ubuntu1804-2.ova <span class="comment"># 置零后的大小</span></span><br><span class="line">1.3G Aug 28 15:48 Ubuntu1804.ova   <span class="comment"># 置零前的大小</span></span><br></pre></td></tr></table></figure>
<p>经过置零后，导出的 ova 虚拟机模板体积 460M 左右，骤然减少了接近 2 倍的大小😂</p>
<h3 id="2-Debian-10"><a href="#2-Debian-10" class="headerlink" title="2. Debian 10"></a>2. Debian 10</h3><h4 id="1-安装镜像-1"><a href="#1-安装镜像-1" class="headerlink" title="1. 安装镜像"></a>1. 安装镜像</h4><p>安装镜像选用 Debian 的网络版安装镜像，<a href="https://mirrors.ustc.edu.cn/debian-cd/10.0.0/amd64/iso-cd/debian-10.0.0-amd64-netinst.iso" target="_blank" rel="noopener">debian-10.0.0-amd64-netinst.iso</a> 其实选择 <a href="https://mirrors.ustc.edu.cn/debian-cd/10.0.0/amd64/iso-cd/debian-10.0.0-amd64-xfce-CD-1.iso" target="_blank" rel="noopener">debian-10.0.0-amd64-netinst.iso  </a>版的也行，在最后不要安装桌面环境就可以。</p>
<h4 id="2-卸载不用的软件包-1"><a href="#2-卸载不用的软件包-1" class="headerlink" title="2. 卸载不用的软件包"></a>2. 卸载不用的软件包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先修改一下 apt 源</span></span><br><span class="line">sed -i <span class="string">'s/deb.debian.org/mirrors.ustc.edu.cn/g'</span> /etc/apt/sources.list</span><br><span class="line">sed -i <span class="string">'s|security.debian.org/debian-security|mirrors.ustc.edu.cn/debian-security|g'</span> /etc/apt/sources.list</span><br><span class="line">apt update</span><br><span class="line"><span class="comment"># 装上一些比较实用的工具</span></span><br><span class="line">apt install --no-install-recommends --no-install-suggests -y wget  ncdu</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这几个包卸载掉影响不大，应该。。</span></span><br><span class="line">apt purge emacsen-common firmware-linux-free gcc-8-base linux-image-amd64</span><br></pre></td></tr></table></figure>
<h4 id="3-清理日志和缓存-1"><a href="#3-清理日志和缓存-1" class="headerlink" title="3. 清理日志和缓存"></a>3. 清理日志和缓存</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rm -rf /var/lib/apt/lists/*</span><br><span class="line">apt autoclean</span><br><span class="line">apt autoremove</span><br></pre></td></tr></table></figure>
<h4 id="4-清理不用的文件-1"><a href="#4-清理不用的文件-1" class="headerlink" title="4. 清理不用的文件"></a>4. 清理不用的文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/share/<span class="built_in">local</span></span><br><span class="line">du -sh * | grep -v en | grep -v zh | grep -v cn | grep -v us | awk <span class="string">'&#123;print $2&#125;'</span> | xargs rm -rf</span><br><span class="line">rm -rf /usr/share/doc/*</span><br></pre></td></tr></table></figure>
<h4 id="5-置零剩余空间-1"><a href="#5-置零剩余空间-1" class="headerlink" title="5. 置零剩余空间"></a>5. 置零剩余空间</h4><p>直接使用 dd 暴力清零就行啦 <code>dd if=/dev/zero of=/zero bs=4M || rm -rf /zero</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@debian ~</span><br><span class="line">╰─<span class="comment"># df -h</span></span><br><span class="line">Filesystem                   Size  Used Avail Use% Mounted on</span><br><span class="line">udev                         2.0G     0  2.0G   0% /dev</span><br><span class="line">tmpfs                        395M   11M  385M   3% /run</span><br><span class="line">/dev/mapper/debian--vg-root   26G  698M   24G   3% /</span><br><span class="line">tmpfs                        2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                        5.0M     0  5.0M   0% /run/lock</span><br><span class="line">tmpfs                        2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1                    236M   48M  176M  22% /boot</span><br><span class="line">tmpfs                        395M     0  395M   0% /run/user/0</span><br></pre></td></tr></table></figure>
<h4 id="6-导出-OVA-虚拟机模板-1"><a href="#6-导出-OVA-虚拟机模板-1" class="headerlink" title="6. 导出 OVA 虚拟机模板"></a>6. 导出 OVA 虚拟机模板</h4><p>最终导出的 vmdk 模板为 351M ，棒棒哒😂</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">351M Sep  1 16:17 disk-0.vmdk</span><br></pre></td></tr></table></figure>
<h3 id="3-CentOS-7-6"><a href="#3-CentOS-7-6" class="headerlink" title="3. CentOS 7.6"></a>3. CentOS 7.6</h3><h4 id="1-安装镜像-2"><a href="#1-安装镜像-2" class="headerlink" title="1. 安装镜像"></a>1. 安装镜像</h4><p>安装镜像就选择使用<a href="https://mirrors.ustc.edu.cn/centos/7.6.1810/isos/x86_64/CentOS-7-x86_64-Minimal-1810.iso" target="_blank" rel="noopener">CentOS-7-x86_64-Minimal-1810.iso</a> 版的 iso 就行，安装过程就不再赘述啦。磁盘分区建议为 lvm ，因为这个是虚拟机模板文件，并不清楚以后的用途和所占用的空间。使用 lvm 可以很方便地扩展根分区。</p>
<h4 id="2-卸载不用的软件包-2"><a href="#2-卸载不用的软件包-2" class="headerlink" title="2. 卸载不用的软件包"></a>2. 卸载不用的软件包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改 yum 源为阿里云</span></span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">yum install -y wget curl ncdu</span><br><span class="line"></span><br><span class="line">yum remove linux-firmware NetworkManager mariadb-libs NetworkManager  alsa-lib centos-logos.noarch</span><br><span class="line">yum list installed | grep firmware | xargs yum remove -y</span><br></pre></td></tr></table></figure>
<h4 id="3-清理日志和缓存-2"><a href="#3-清理日志和缓存-2" class="headerlink" title="3. 清理日志和缓存"></a>3. 清理日志和缓存</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum clean all</span><br><span class="line"></span><br><span class="line">rm -rf /var/cache</span><br></pre></td></tr></table></figure>
<h4 id="4-清理不用的文件-2"><a href="#4-清理不用的文件-2" class="headerlink" title="4. 清理不用的文件"></a>4. 清理不用的文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 精简一下 local-archive 文件</span></span><br><span class="line">localedef --list-archive  | grep -v zh  | grep -v us | grep -v en | grep -v cn | xargs localedef --delete-from-archive</span><br><span class="line">mv /usr/lib/locale/locale-archive /usr/lib/locale/locale-archive.tmpl</span><br><span class="line">build-locale-archive</span><br><span class="line"></span><br><span class="line">rm -rf /usr/share/doc</span><br><span class="line"><span class="built_in">cd</span> /usr/share/locale</span><br><span class="line"><span class="comment"># 下面这条命令一定要在 /usr/share/locale 目录下执行</span></span><br><span class="line">ls | grep -v zh | grep -v en | grep -v us | grep -v @ | grep -v <span class="built_in">local</span> | xargs rm -rf</span><br><span class="line">rm -rf /usr/share/backgrounds</span><br></pre></td></tr></table></figure>
<h4 id="5-置零剩余空间-2"><a href="#5-置零剩余空间-2" class="headerlink" title="5. 置零剩余空间"></a>5. 置零剩余空间</h4><p>直接使用 dd 暴力清零就行啦 <code>dd if=/dev/zero of=/zero bs=4M || rm -rf /zero</code></p>
<p>最后看一下磁盘空间，占用不到 700M ，还是可以的哈</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@centos ~</span><br><span class="line">╰─<span class="comment"># df -h</span></span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/centos-root   29G  594M   27G   3% /</span><br><span class="line">devtmpfs                 1.9G     0  1.9G   0% /dev</span><br><span class="line">tmpfs                    1.9G     0  1.9G   0% /dev/shm</span><br><span class="line">tmpfs                    1.9G  9.3M  1.9G   1% /run</span><br><span class="line">tmpfs                    1.9G     0  1.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1                488M  113M  340M  25% /boot</span><br><span class="line">tmpfs                    378M     0  378M   0% /run/user/0</span><br></pre></td></tr></table></figure>
<h4 id="6-导出-OVA-虚拟机模板-2"><a href="#6-导出-OVA-虚拟机模板-2" class="headerlink" title="6. 导出 OVA 虚拟机模板"></a>6. 导出 OVA 虚拟机模板</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">348M Sep  1 09:00 disk-1.vmdk</span><br></pre></td></tr></table></figure>
<p>最后导出的虚拟机模板大小不到 350M</p>
<h3 id="4-Alpine-3-10"><a href="#4-Alpine-3-10" class="headerlink" title="4. Alpine 3.10"></a>4. Alpine 3.10</h3><p>Alpine 虚拟机本来就很精简啦，其实不用搓也行</p>
]]></content>
      <tags>
        <tag>虚拟机</tag>
        <tag>VMware</tag>
        <tag>ESXi</tag>
      </tags>
  </entry>
  <entry>
    <title>生产环境如何保守地选择 kubernetes 版本</title>
    <url>/archives/How-to-choose-the-right-version-of-kubernetes.html</url>
    <content><![CDATA[<h2 id="0-要开始了？"><a href="#0-要开始了？" class="headerlink" title="0. 要开始了？"></a>0. 要开始了？</h2><p>听说汝公司准备或者正在使用 kubernetes 容器调度平台了？那么对于一些及其重要的线上环境，如何选择一个合适的 kubernetes 版本呢？Kubernetes 版本号最循着 x.y.z 的命名规范，相信大家肯定不会拿 1.15.0 这样的版本用于生产环境吧😂。如何选择一个稳定的版本号最好的方法就是参考各大云计算厂商(Google、AWS digitalocean)。他们提供 kubernetes 云平台，稳定性一般要高于我们平时的生产环境。他们如何选择 kubernetes 版本是个不错的参考依照。</p>
<p>目前绝大多数的教程或者博客都是以 1.14.3 、1.15.2 、1.13.2  等等小版本号低于 5 的版本来部署，虽说小版本号之间没有多大差异，但这样无疑就带来一种风气，就是我生产环境也选择使用这些版本。我认为这样并不恰当，在小版本号低于 5 之前的版本，存在一些漏洞或者问题是我们生产环境是无法容忍的。这也是为什么各大 kubernetes 云服务厂商在上线新版本是会经过三到六个月的测试，比如 1.13 版本，无论是 AKS、EKS、GKE 他们都是在 1.13.6 版本之才推出 1.13 版本的正式版，之前的小版本都是测试或者预览版本。选择 1.12.10 这名高的版本也合适吗？抱歉，依照现在的进度，预估计小版本 10 以后就很少在更新维护了，所以万一有什么问题 1.13.6 可以很轻松地通过升级到 1.13.7 版本能解决，但 1.12 版本升级到 1.13 版本是比较麻烦地，没有稳定升级的空间，因此接近小版本 10 的也不建议新集群部署使用。</p>
<h2 id="1-kubernetes-release-timeline"><a href="#1-kubernetes-release-timeline" class="headerlink" title="1. kubernetes release timeline"></a>1. kubernetes release timeline</h2><p>下面是我根据 kubernetes GitHub 的 release 总结汇总的一张表格</p>
<h3 id="Kubernetes-release"><a href="#Kubernetes-release" class="headerlink" title="Kubernetes release"></a>Kubernetes release</h3><table>
<thead>
<tr>
<th>month</th>
<th>stable</th>
<th>stable</th>
<th>stable</th>
<th>stable</th>
</tr>
</thead>
<tbody>
<tr>
<td>2019-12</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.17.0" target="_blank" rel="noopener">v1.17.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.16.4" target="_blank" rel="noopener">v1.16.4</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.15.7" target="_blank" rel="noopener">v1.15.7</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.10" target="_blank" rel="noopener">v1.14.10</a></td>
</tr>
<tr>
<td>2019-11</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.16.3" target="_blank" rel="noopener">v1.16.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.15.6" target="_blank" rel="noopener">v1.15.6</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.9" target="_blank" rel="noopener">v1.14.9</a></td>
<td></td>
</tr>
<tr>
<td>2019-10</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.16.1" target="_blank" rel="noopener">v1.16.1</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.16.2" target="_blank" rel="noopener">v1.16.2</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.15.5" target="_blank" rel="noopener">v1.15.5</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.8" target="_blank" rel="noopener">v1.14.8</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.12" target="_blank" rel="noopener">v1.13.12</a></td>
</tr>
<tr>
<td>2019-09</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.16.0" target="_blank" rel="noopener">v1.16.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.15.4" target="_blank" rel="noopener">v1.15.4</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.7" target="_blank" rel="noopener">v1.14.7</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.11" target="_blank" rel="noopener">v1.13.11</a></td>
</tr>
<tr>
<td>2019-08</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.15.2" target="_blank" rel="noopener">v1.15.2</a><br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.15.3" target="_blank" rel="noopener">v1.15.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.5" target="_blank" rel="noopener">v1.14.5</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.6" target="_blank" rel="noopener">v1.14.6</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.9" target="_blank" rel="noopener">v1.13.9</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.10" target="_blank" rel="noopener">v1.13.10</a></td>
<td>CVE</td>
</tr>
<tr>
<td>2019-07</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.15.1" target="_blank" rel="noopener">v1.15.1</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.4" target="_blank" rel="noopener">v1.14.4</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.8" target="_blank" rel="noopener">v1.13.8</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.10" target="_blank" rel="noopener">v1.12.10</a></td>
</tr>
<tr>
<td>2019-06</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.15.0" target="_blank" rel="noopener">v1.15.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.3" target="_blank" rel="noopener">v1.14.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.7" target="_blank" rel="noopener">v1.13.7</a></td>
<td></td>
</tr>
<tr>
<td>2019-05</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.2" target="_blank" rel="noopener">v1.14.2</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.6" target="_blank" rel="noopener">v1.13.6</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.9" target="_blank" rel="noopener">v1.12.9</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.10" target="_blank" rel="noopener">v1.11.10</a></td>
</tr>
<tr>
<td>2019-04</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.1" target="_blank" rel="noopener">v1.14.1</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.8" target="_blank" rel="noopener">v1.12.8</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2019-03</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.14.0" target="_blank" rel="noopener">v1.14.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.5" target="_blank" rel="noopener">v1.13.5</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.7" target="_blank" rel="noopener">v1.12.7</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.9" target="_blank" rel="noopener">v1.11.9</a> <br> <a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.8" target="_blank" rel="noopener">v1.11.8</a></td>
</tr>
<tr>
<td>2019-02</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.4" target="_blank" rel="noopener">v1.13.4</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.3" target="_blank" rel="noopener">v1.13.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.6" target="_blank" rel="noopener">v1.12.6</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.13" target="_blank" rel="noopener">v1.10.13</a></td>
<td></td>
</tr>
<tr>
<td>2019-01</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.2" target="_blank" rel="noopener">v1.13.2</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.5" target="_blank" rel="noopener">v1.12.5</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.7" target="_blank" rel="noopener">v1.11.7</a></td>
<td></td>
</tr>
<tr>
<td>2018-12</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.1" target="_blank" rel="noopener">v1.13.1</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.13.0" target="_blank" rel="noopener">v1.13.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.4" target="_blank" rel="noopener">v1.12.4</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.6" target="_blank" rel="noopener">v1.11.6</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.12" target="_blank" rel="noopener">v1.10.12</a></td>
</tr>
<tr>
<td>2018-11</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.3" target="_blank" rel="noopener">v1.12.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.5" target="_blank" rel="noopener">v1.11.5</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.11" target="_blank" rel="noopener">v1.10.11</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.10" target="_blank" rel="noopener">v1.10.10</a></td>
<td></td>
</tr>
<tr>
<td>2018-10</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.2" target="_blank" rel="noopener">v1.12.2</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.1" target="_blank" rel="noopener">v1.12.1</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.4" target="_blank" rel="noopener">v1.11.4</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.9" target="_blank" rel="noopener">v1.10.9</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.11" target="_blank" rel="noopener">v1.9.11</a></td>
</tr>
<tr>
<td>2018-09</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.12.0" target="_blank" rel="noopener">v1.12.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.3" target="_blank" rel="noopener">v1.11.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.8" target="_blank" rel="noopener">v1.10.8</a></td>
<td></td>
</tr>
<tr>
<td>2018-08</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.2" target="_blank" rel="noopener">v1.11.2</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.7" target="_blank" rel="noopener">v1.10.7</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.10" target="_blank" rel="noopener">v1.9.10</a></td>
<td></td>
</tr>
<tr>
<td>2018-07</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.1" target="_blank" rel="noopener">v1.11.1</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.6" target="_blank" rel="noopener">v1.10.6</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.15" target="_blank" rel="noopener">v1.8.15</a></td>
<td></td>
</tr>
<tr>
<td>2018-06</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.11.0" target="_blank" rel="noopener">v1.11.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.5" target="_blank" rel="noopener">v1.10.5</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.4" target="_blank" rel="noopener">v1.10.4</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.9" target="_blank" rel="noopener">v1.9.9</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.14" target="_blank" rel="noopener">v1.8.14</a></td>
</tr>
<tr>
<td>2018-05</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.3" target="_blank" rel="noopener">v1.10.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.8" target="_blank" rel="noopener">v1.9.8</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.13" target="_blank" rel="noopener">v1.8.13</a></td>
<td></td>
</tr>
<tr>
<td>2018-04</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.2" target="_blank" rel="noopener">v1.10.2</a> <br> <a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.1" target="_blank" rel="noopener">v1.10.1</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.7" target="_blank" rel="noopener">v1.9.7</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.11" target="_blank" rel="noopener">v1.8.11</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.12" target="_blank" rel="noopener">v1.8.12</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.16" target="_blank" rel="noopener">v1.7.16</a></td>
</tr>
<tr>
<td>2018-03</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.10.0" target="_blank" rel="noopener">v1.10.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.6" target="_blank" rel="noopener">v1.9.6</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.5" target="_blank" rel="noopener">v1.9.5</a>  <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.4" target="_blank" rel="noopener">v1.9.4</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.10" target="_blank" rel="noopener">v1.8.10</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.9" target="_blank" rel="noopener">v1.8.9</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.15" target="_blank" rel="noopener">v1.7.15</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.14" target="_blank" rel="noopener">v1.7.14</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.13" target="_blank" rel="noopener">v1.7.13</a></td>
</tr>
<tr>
<td>2018-02</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.3" target="_blank" rel="noopener">v1.9.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.8" target="_blank" rel="noopener">v1.8.8</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2018-01</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.2" target="_blank" rel="noopener">v1.9.2</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.1" target="_blank" rel="noopener">v1.9.1</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.7" target="_blank" rel="noopener">v1.8.7</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2017-12</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.9.0" target="_blank" rel="noopener">v1.9.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.6" target="_blank" rel="noopener">v1.8.6</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.5" target="_blank" rel="noopener">v1.8.5</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.12" target="_blank" rel="noopener">v1.7.12</a></td>
<td></td>
</tr>
<tr>
<td>2017-11</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.4" target="_blank" rel="noopener">v1.8.4</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.3" target="_blank" rel="noopener">v1.8.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.11" target="_blank" rel="noopener">v1.7.11</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.10" target="_blank" rel="noopener">v1.7.10</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.13" target="_blank" rel="noopener">v1.6.13</a></td>
<td></td>
</tr>
<tr>
<td>2017-10</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.2" target="_blank" rel="noopener">v1.8.2</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.1" target="_blank" rel="noopener">v1.8.1</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.9" target="_blank" rel="noopener">v1.7.9</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.8" target="_blank" rel="noopener">v1.7.8</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.12" target="_blank" rel="noopener">v1.6.12</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.5.8" target="_blank" rel="noopener">v1.5.8</a></td>
</tr>
<tr>
<td>2017-09</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.8.0" target="_blank" rel="noopener">v1.8.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.7" target="_blank" rel="noopener">v1.7.7</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.6" target="_blank" rel="noopener">v1.7.6</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.11" target="_blank" rel="noopener">v1.6.11</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.10" target="_blank" rel="noopener">v1.6.10</a></td>
<td></td>
</tr>
<tr>
<td>2017-08</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.5" target="_blank" rel="noopener">v1.7.5</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.4" target="_blank" rel="noopener">v1.7.4</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.3" target="_blank" rel="noopener">v1.7.3</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.9" target="_blank" rel="noopener">v1.6.9</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.8" target="_blank" rel="noopener">v1.6.8</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2017-07</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.2" target="_blank" rel="noopener">v1.7.2</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.1" target="_blank" rel="noopener">v1.7.1</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.7" target="_blank" rel="noopener">v1.6.7</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2017-06</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.7.0" target="_blank" rel="noopener">v1.7.0</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.6" target="_blank" rel="noopener">v1.6.6</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.5" target="_blank" rel="noopener">v1.6.5</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2017-05</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.4" target="_blank" rel="noopener">v1.6.4</a> <br><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.3" target="_blank" rel="noopener">v1.6.3</a></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2017-04</td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.6.2" target="_blank" rel="noopener">v1.6.2</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.5.7" target="_blank" rel="noopener">v1.5.7</a></td>
<td><a href="https://github.com/kubernetes/kubernetes/releases/tag/v1.4.12" target="_blank" rel="noopener">v1.4.12</a></td>
</tr>
</tbody>
</table>
<p>根据这张 kubernetes release 的时间线我们大致可以总结出一下几点：</p>
<ol>
<li>每个小版本号即 x.y.z 中的 z ，一般情况下每个月会更新一次，到 10 以后更新周期会变长</li>
<li>每个版本从 alpha 到 stable 周期为三个月，release stable 版本以后会继续更新维护 12 个月左右</li>
<li>每个 x.y.z 中的 y 版本的整个生命周期大概为 15 个月，前三个月为开发测试阶段，后 12 个月为修复阶段</li>
<li>平均每个月 kubernetes 维护的 y 版本为 4 个，现在维护的是 1.15.x、1.14x、1.13.x、1.12.x 还有 alpha 阶段的 1.16.x。1.11.x 应该已经放弃支持了，因为已经三个月没有更新了。</li>
<li>综上所述我们可以大致推断出下个月更新的版本为 1.15.3 、1.14.6 、1.13.10</li>
</ol>
<h3 id="GKE-、AKS-、EKS-支持-Kubernetes-版本情况"><a href="#GKE-、AKS-、EKS-支持-Kubernetes-版本情况" class="headerlink" title="GKE 、AKS 、EKS 支持 Kubernetes 版本情况"></a>GKE 、AKS 、EKS 支持 Kubernetes 版本情况</h3><p>截至 2019-11-05</p>
<table>
<thead>
<tr>
<th style="text-align:center">Provider</th>
<th style="text-align:center">Kubernetes</th>
<th style="text-align:center">Docker</th>
<th style="text-align:center">Kernel</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="https://cloud.google.com/kubernetes-engine/" target="_blank" rel="noopener">GKE</a></td>
<td style="text-align:center">1.15.4(alpha), 1.14.7(default), 1.13.11(stable)</td>
<td style="text-align:center">19.03</td>
<td style="text-align:center">5.2, 4.19</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://azure.microsoft.com/en-us/services/kubernetes-service/" target="_blank" rel="noopener">AKS</a></td>
<td style="text-align:center">1.15.5(GA), 1.14.8, 1.13.12, 1.12.10</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://aws.amazon.com/cn/eks/" target="_blank" rel="noopener">EKS</a></td>
<td style="text-align:center">1.14.6(default), 1.13.10, 1.12.10, 1.11.10</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h2 id="云计算厂商"><a href="#云计算厂商" class="headerlink" title="云计算厂商"></a>云计算厂商</h2><p>下面的不是最新的，是九月份时候的，已经过时了，还是参考上面的吧</p>
<h2 id="2-Google-kubernetes"><a href="#2-Google-kubernetes" class="headerlink" title="2. Google kubernetes"></a>2. Google kubernetes</h2><p><strong>Google kubernetes <a href="https://cloud.google.com/kubernetes-engine/docs/release-notes" target="_blank" rel="noopener">官方文档</a></strong></p>
<h3 id="August-1-2019"><a href="#August-1-2019" class="headerlink" title="August 1, 2019"></a>August 1, 2019</h3><figure class="highlight"><table><tr><td class="code"><pre><span class="line">1.13.7-gke.15</span><br><span class="line">1.12.9-gke.10</span><br><span class="line">1.12.7-gke.26</span><br><span class="line">1.12.8-gke.12</span><br></pre></td></tr></table></figure>
<p><strong>June 27, 2019</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">1.11.8-gke.10</span><br><span class="line">1.11.10-gke.4</span><br><span class="line">1.12.7-gke.10</span><br><span class="line">1.12.7-gke.21</span><br><span class="line">1.12.7-gke.22</span><br><span class="line">1.12.8-gke.6</span><br><span class="line">1.12.8-gke.7</span><br><span class="line">1.12.9-gke.3</span><br><span class="line">1.13.6-gke.5</span><br><span class="line">1.13.6-gke.6</span><br><span class="line">1.13.7-gke.0</span><br></pre></td></tr></table></figure>
<p><strong>June 4, 2019</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">1.11.8-gke.6</span><br><span class="line">1.11.9-gke.8</span><br><span class="line">1.11.9-gke.13</span><br><span class="line">1.14.2-gke.1 [Preview]</span><br></pre></td></tr></table></figure>
<p><strong>May 20, 2019</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">1.10.x (nodes only, completing)					1.11.8-gke.6</span><br><span class="line">1.12.6-gke.10									1.12.6-gke.11</span><br><span class="line">1.14.1-gke.4 and older 1.14.x (Alpha)			1.14.1-gke.5 (Alpha)</span><br><span class="line"></span><br><span class="line">--------</span><br><span class="line"></span><br><span class="line">1.12.x clusters v1.12.7-gke.17 and newer</span><br><span class="line">1.13.x clusters v1.13.5-gke.10 and newer</span><br><span class="line">1.14.x (Alpha) clusters v1.14.1-gke.5 and newer</span><br></pre></td></tr></table></figure>
<h2 id="3-AWS-kubernetes"><a href="#3-AWS-kubernetes" class="headerlink" title="3. AWS kubernetes"></a>3. AWS kubernetes</h2><p>AWS 的 Kubernetes 平台叫做 EKS，在创建 kubernetes 集群时可以选择的版本没有 GKE 那么详细，仅仅有 1.13 、1.12 、1.11 这样的版本号，没有最后一位修补版本号，但我收到过 EKS 的产品更新邮件提醒，当 EKS 推出 1.13 版本的时候第一个 1.13 版本是使用的 1.13.7。<a href="https://docs.aws.amazon.com/eks/latest/userguide/platform-versions.html" target="_blank" rel="noopener">这里</a> 有 EKS 版本的详细信息。目前的版本还是 1.13 、1.12、1.11。虽然 1.14.5 版本都推出了，但至今 EKS 也没有 1.14 版本的 Kubernetes 可用。由此可以推断，到 1.13之后。EKS 团队在选择 kubernetes 版本的时候更倾向于 x.y.z 中 z 大于 6 的版本。因为前面的 6 个小版本的修复已经使得这个版本的稳定性适用于生产环境了。</p>
<blockquote>
<p>Kubernetes 社区大约会每隔三个月发布次要版本。 这些版本包括新增功能和改进。 修补程序版本更为频繁（有时会每周发布），并且仅用于次要版本中的关键 Bug 修复。 这些修补程序版本包括针对影响大量客户以及在生产中基于 Kubernetes 运行的产品的安全漏洞或重大 Bug 的修复。</p>
<p>AKS 旨在完成上游版本发布后的 30 天内，根据该版本的稳定性认证和发布新的 Kubernetes 版本</p>
<p>此处剽窃 Azure 的官方文档 <a href="https://docs.microsoft.com/zh-cn/azure/aks/supported-kubernetes-versions" target="_blank" rel="noopener">Azure Kubernetes 服务 (AKS) 中支持的 Kubernetes 版本</a></p>
</blockquote>
<p>下面我就直接剽窃一下 EKS 的<a href="https://docs.aws.amazon.com/eks/latest/userguide/platform-versions.html" target="_blank" rel="noopener">官方文档</a>😂</p>
<p><strong>Kubernetes version 1.13</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">Kubernetes Version</th>
<th style="text-align:left">Release Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>1.13.8</code></td>
<td style="text-align:left">New platform version updating Amazon EKS Kubernetes 1.13 clusters to a patched version of 1.13.8 to address <a href="https://groups.google.com/forum/#!topic/kubernetes-security-announce/vUtEcSEY6SM" target="_blank" rel="noopener">CVE-2019-11247</a>.</td>
</tr>
<tr>
<td style="text-align:left"><code>1.13.7</code></td>
<td style="text-align:left">Initial release of Kubernetes 1.13 for Amazon EKS. For more information, see <a href="https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html#kubernetes-1.13" target="_blank" rel="noopener">Kubernetes 1.13</a>.</td>
</tr>
</tbody>
</table>
<p><strong>Kubernetes version 1.12</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">Kubernetes Version</th>
<th style="text-align:left">Release Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>1.12.10</code></td>
<td style="text-align:left">New platform version updating Amazon EKS Kubernetes 1.12 clusters to a patched version of 1.12.10 to address <a href="https://groups.google.com/forum/#!topic/kubernetes-security-announce/vUtEcSEY6SM" target="_blank" rel="noopener">CVE-2019-11247</a>.</td>
</tr>
<tr>
<td style="text-align:left"><code>1.12.6</code></td>
<td style="text-align:left">New platform version to support custom DNS names in the Kubelet certificate and improve <code>etcd</code> performance. This fixes a bug that caused worker node Kubelet daemons to request a new certificate every few seconds.</td>
</tr>
<tr>
<td style="text-align:left"><code>1.12.6</code></td>
<td style="text-align:left">Initial release of Kubernetes 1.12 for Amazon EKS.</td>
</tr>
</tbody>
</table>
<p><strong>Kubernetes version 1.11</strong></p>
<table>
<thead>
<tr>
<th>Kubernetes Version</th>
<th>Release Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>1.11.10</code></td>
<td>New platform version updating Amazon EKS Kubernetes 1.11 clusters to to a patched version of 1.11.10 to address <a href="https://groups.google.com/forum/#!topic/kubernetes-security-announce/vUtEcSEY6SM" target="_blank" rel="noopener">CVE-2019-11247</a>.</td>
</tr>
<tr>
<td><code>1.11.8</code></td>
<td>New platform version to support custom DNS names in the Kubelet certificate and improve <code>etcd</code>performance.</td>
</tr>
<tr>
<td><code>1.11.8</code></td>
<td>New platform version updating Amazon EKS Kubernetes 1.11 clusters to patch level 1.11.8 to address <a href="https://discuss.kubernetes.io/t/kubernetes-security-announcement-v1-11-8-1-12-6-1-13-4-released-to-address-medium-severity-cve-2019-1002100/5147" target="_blank" rel="noopener">CVE-2019-1002100</a>.</td>
</tr>
<tr>
<td><code>1.11.5</code></td>
<td>Initial release of Kubernetes 1.11 for Amazon EKS.</td>
</tr>
</tbody>
</table>
<h2 id="4-AKS"><a href="#4-AKS" class="headerlink" title="4. AKS"></a>4. AKS</h2><p>再补充一下 M$ 家的 AKS 貌似和阿里云的 kubernetes 重名？😂</p>
<p>看来 M$ 家的更新和支持挺快的，要比 kubernetes 亲爹 Google 还要快？不愧是最佳 Android 开发者😂。</p>
<p><a href="https://github.com/Azure/AKS/releases" target="_blank" rel="noopener">AKS-release</a></p>
<ol>
<li><p><a href="https://github.com/Azure/AKS/releases/tag/2019-08-05" target="_blank" rel="noopener">2019-08-05</a></p>
<p>since this release</p>
<p><strong>This release is rolling out to all regions</strong></p>
<p><strong>Please Note</strong>: This release includes new Kubernetes versions 1.13.9 &amp;<br>1.14.5 (GA today) these include the fixes for CVEs CVE-2019-11247 and<br>CVE-2019-11249. Please see our <a href="https://github.com/Azure/AKS/issues/1145" target="_blank" rel="noopener">customer guidance</a></p>
</li>
<li><p><a href="https://github.com/Azure/AKS/releases/tag/2019-07-08" target="_blank" rel="noopener">2019-07-08</a></p>
<p>since this release</p>
<ul>
<li>Preview Features<ul>
<li>Kubernetes 1.14.3 is now available for preview users.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>看来 M$ 的 kubernetes 平台比 Google 更新的还要快，版本 GA 的时候也要早于 GKE 。即便如此，各大云计算厂商仍然会倾向于等到 kubernetes 版本修复得差不了才将上线新版本。</p>
<h2 id="5-DigitalOcean-kubernetes"><a href="#5-DigitalOcean-kubernetes" class="headerlink" title="5. DigitalOcean kubernetes"></a>5. DigitalOcean kubernetes</h2><h2 id="6-宿主机系统的参考"><a href="#6-宿主机系统的参考" class="headerlink" title="6. 宿主机系统的参考"></a>6. 宿主机系统的参考</h2><p>如果汝刚开始准备使用 Kubernetes ，那就抛弃 CentOS ，因为 CentOS 7.6 (1810) 的内核是 3.10 版本的，而 3.10 版本的内核是 2013 年 <a href="https://kernelnewbies.org/Linux_3.10" target="_blank" rel="noopener">release</a> 的 ，那时候的 Docker 还在妈妈的怀抱里吃奶呢😂。如今 Docker 容器虚拟化的一些特性需要新版本的 kernel 支持才能稳定低运行，而有些特性在 3.10 版本是不稳定的。<code>新版docker启用Linux CGroup memory这个feature，但这个feature在kernel 4.0以下版本中是非稳定版本</code> <a href="http://blog.allen-mo.com/2018/08/27/kubernetes_ops_troubleshooting/" target="_blank" rel="noopener">来自</a> 。</p>
<p>综上，为了少折腾，少踩坑还是更新的长期支持的高版本内核吧。都 9102 年了，就不要再相信使用旧版本更稳定的言论了😂。你看，人家 Google GKE 的节点的宿主机系统都是使用的 4.14 的内核，没故障吧。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">System Info:</span><br><span class="line"> Machine ID:                 acd0a47b56b6a4e6f775daaf31da236b</span><br><span class="line"> System UUID:                ACD0A47B-56B6-A4E6-F775-DAAF31DA236B</span><br><span class="line"> Boot ID:                    3b811f67-58cb-40af-8d6b-6e77e951dcee</span><br><span class="line"> Kernel Version:             4.14.127+</span><br><span class="line"> OS Image:                   Container-Optimized OS from Google</span><br><span class="line"> Operating System:           linux</span><br><span class="line"> Architecture:               amd64</span><br><span class="line"> Container Runtime Version:  docker://17.3.2</span><br><span class="line"> Kubelet Version:            v1.12.8-gke.10</span><br><span class="line"> Kube-Proxy Version:         v1.12.8-gke.10</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@deploy ~</span><br><span class="line">╰─<span class="comment"># cat /etc/centos-release</span></span><br><span class="line">CentOS Linux release 7.6.1810 (Core)</span><br><span class="line">╭─root@deploy ~</span><br><span class="line">╰─<span class="comment"># uname -a</span></span><br><span class="line">Linux deploy 3.10.0-957.el7.x86_64 <span class="comment">#1 SMP Thu Nov 8 23:39:32 UTC 2018</span></span><br></pre></td></tr></table></figure>
<h2 id="6-综上"><a href="#6-综上" class="headerlink" title="6. 综上"></a>6. 综上</h2><p>综上所述，汝对 Kubernetes 版本的选择也有了个大致的方向。在此我并没有使用国内的一些云计算厂商做测试。总的来说吧 Google 对 Kubernetes 的驾驭程度肯定要秒杀其他云计算厂商吧，毕竟是亲爹嘛。所以当汝也开始选择 Kubernetes 版本时，适用于生产环境的话，还是要再小版本号 6 以上才合适，比如 1.14.6 1.15.6 1.13.8 等等，都是比较保守的选择。之前的版本可以做测试用。其实选择 1.14.5 1.15.5 等也合适，M$ 家得 kubernetes 就是从 5 开始 GA 的。</p>
]]></content>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>搓一个 Debian 透明代理/旁路网关 虚拟机</title>
    <url>/archives/debian-gateway.html</url>
    <content><![CDATA[<h2 id="ESXi-透明代理虚拟机"><a href="#ESXi-透明代理虚拟机" class="headerlink" title="ESXi 透明代理虚拟机"></a>ESXi 透明代理虚拟机</h2><p>弃坑了，太鸡儿难用了😡，还是使用了 <a href="https://blog.502.li/esxi-lede">LEDE软路由</a></p>
<h2 id="0-项目背景"><a href="#0-项目背景" class="headerlink" title="0. 项目背景"></a>0. 项目背景</h2><p>由于工作的环境是 ESXi ，上面运行着一堆虚拟机，用来做部署方案测试使用。因为要经常访问 GitHub 以及要去 gcr.k8s.io  上拉去镜像；而且在写 Dockerfile build 镜像的时候，也需要去 GitHub 下载 release 包；使用helm初始化时需要的docker 镜像无法pull那个速度比百度网盘还慢啊啊啊啊，气死人。我觉着 GFW 的存在严重第影响了我的工作效率，遂决定搓一个虚拟机来当代理网关，或者叫旁路网关。被需要代理的机器仅仅需要修改网关和 DNS 为透明代理服务器 IP 即可。</p>
<p>题外话：其实用软路由 LEDE/OpenWrt 实现最合适，而且占用资源也极低，但因为使用软路由发生了一次事故，所以就不再用软路由了。那时候刚入职实习，在 ESXi 上装了个 LEDE 软路由，然后办公室的网络就瘫痪了。。</p>
<h2 id="1-实现功能"><a href="#1-实现功能" class="headerlink" title="1.实现功能"></a>1.实现功能</h2><ol>
<li>透明代理，客户端仅仅需要修改默认网关为上游透明网关即可，无需安装其他代理软件</li>
<li>国外/国内域名分开解析，解决运营商DNS域名污染问题</li>
<li>加快客户端访问GitHub、Google等网站速度，clone速度峰值 15MB/S</li>
<li>Docker pull 镜像速度 15MB/S，clone <a href="https://github.com/torvalds/linux" target="_blank" rel="noopener">torvalds/linux</a></li>
<li>需要代理的内网机器仅仅需要修改网关和 DNS 即可实现透明代理</li>
</ol>
<h2 id="2-实现效果"><a href="#2-实现效果" class="headerlink" title="2. 实现效果"></a>2. 实现效果</h2><h3 id="1-wget-下载-GitHub-release-上的文件，以-Linux为例"><a href="#1-wget-下载-GitHub-release-上的文件，以-Linux为例" class="headerlink" title="1. wget 下载 GitHub release 上的文件，以 Linux为例"></a>1. wget 下载 GitHub release 上的文件，以 Linux为例</h3><p><code>163M Aug 23 21:35 v5.3-rc5.tar.gz</code> 163M 的文件用时不到 30s</p>
<p><img src="../img/1566567341680.png" alt="1566567341680"></p>
<h3 id="2-kubeadm-config-image-pull"><a href="#2-kubeadm-config-image-pull" class="headerlink" title="2. kubeadm config image pull"></a>2. kubeadm config image pull</h3><p>使用 kubeadm 命令加上 <code>--kubernetes-version=</code> 参数指定镜像的版本号，速度还是可以的😂</p>
<p><img src="../img/1566566813113.png" alt="1566566813113"></p>
<h3 id="3-使用-nload-命令查看网关流量情况"><a href="#3-使用-nload-命令查看网关流量情况" class="headerlink" title="3. 使用 nload 命令查看网关流量情况"></a>3. 使用 nload 命令查看网关流量情况</h3><p><img src="../img/1566566775553.png" alt="pull gcr.k8s.io 上镜像的速度"></p>
<h3 id="4-git-clone-GitHub-上的-repo"><a href="#4-git-clone-GitHub-上的-repo" class="headerlink" title="4. git clone GitHub 上的 repo"></a>4. git clone GitHub 上的 repo</h3><p>在此还是以 linux 项目为例，clone 过程速度飘忽不定，但一般都会在 10MiB/S 以上，按照这个速度，还和我物理机器的网卡有关，虽然号称是千兆网卡，但实际测试峰值就达不到 500Mbps，欲哭无泪🤦‍♂️</p>
<p><img src="../img/1566567116544.png" alt="git clone 速度"></p>
<h3 id="5-要代理的虚拟机"><a href="#5-要代理的虚拟机" class="headerlink" title="5. 要代理的虚拟机"></a>5. 要代理的虚拟机</h3><p><img src="../img/1566565577328.png" alt="1566565577328"></p>
<h3 id="5-网关占用资源"><a href="#5-网关占用资源" class="headerlink" title="5. 网关占用资源"></a>5. 网关占用资源</h3><p><img src="../img/1566565631398.png" alt="1566565631398"></p>
<p>总的来说，这个速度还是可以接受的，比那几十几百 KB/S 的龟速满意得多了，而且对于要代理的机器来说配置起来也及其的方便，仅仅修改默认网关和 DNS 就行。</p>
<h2 id="3-实现过程"><a href="#3-实现过程" class="headerlink" title="3. 实现过程"></a>3. 实现过程</h2><h3 id="0-project"><a href="#0-project" class="headerlink" title="0. project"></a>0. project</h3><p>主要使用到 <a href="https://github.com/zfl9/ss-tproxy" target="_blank" rel="noopener">ss-tproxy</a> 这个项目，按照项目上的 README 部署部署起来就 ojbk</p>
<p>大佬的博客<a href="https://www.zfl9.com/ss-redir.html" target="_blank" rel="noopener">ss/ssr/v2ray/socks5 透明代理</a> ,很详细，建议认真读完</p>
<h3 id="1-OS"><a href="#1-OS" class="headerlink" title="1. OS"></a>1. OS</h3><p>首先虚拟机的系统我是使用的 Debian 10，使用 <a href="https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-10.0.0-amd64-netinst.iso" target="_blank" rel="noopener">netinst</a> 镜像安装好的，当然你也可以使用 Ubuntu ，选择 Debian 是因为 Debian 可以再精简一些，安装后的占用不到 700MB 。至于 Alpine 可能要费点功夫，因为编译需要的包比较麻烦。</p>
<h3 id="2-安装编译环境和依赖"><a href="#2-安装编译环境和依赖" class="headerlink" title="2. 安装编译环境和依赖"></a>2. 安装编译环境和依赖</h3><p>Debian 和 Ubuntu 的话就一把梭子就行哈</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt update</span><br><span class="line">apt install -y git</span><br><span class="line">apt install -y --no-install-recommends --no-install-suggests  \</span><br><span class="line">    gettext build-essential autoconf libtool  libsodium-dev libmbedtls-dev \</span><br><span class="line">    libpcre3-dev asciidoc xmlto libev-dev libc-ares-dev automake curl wget \</span><br><span class="line">    dnsmasq iproute2 ipset perl haveged gawk</span><br></pre></td></tr></table></figure>
<h3 id="3-安装爱国软件"><a href="#3-安装爱国软件" class="headerlink" title="3. 安装爱国软件"></a>3. 安装爱国软件</h3><p>这里根据你的代理软件安装配置好就行，我就剽窃一下 shadowsocks-libev 官方的 wiki</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Installation of libsodium</span></span><br><span class="line"><span class="built_in">export</span> LIBSODIUM_VER=1.0.16</span><br><span class="line">wget https://download.libsodium.org/libsodium/releases/libsodium-<span class="variable">$LIBSODIUM_VER</span>.tar.gz</span><br><span class="line">tar xvf libsodium-<span class="variable">$LIBSODIUM_VER</span>.tar.gz</span><br><span class="line"><span class="built_in">pushd</span> libsodium-<span class="variable">$LIBSODIUM_VER</span></span><br><span class="line">./configure --prefix=/usr &amp;&amp; make</span><br><span class="line">make install</span><br><span class="line"><span class="built_in">popd</span></span><br><span class="line">ldconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># Installation of MbedTLS</span></span><br><span class="line"><span class="built_in">export</span> MBEDTLS_VER=2.6.0</span><br><span class="line">wget https://tls.mbed.org/download/mbedtls-<span class="variable">$MBEDTLS_VER</span>-gpl.tgz</span><br><span class="line">tar xvf mbedtls-<span class="variable">$MBEDTLS_VER</span>-gpl.tgz</span><br><span class="line"><span class="built_in">pushd</span> mbedtls-<span class="variable">$MBEDTLS_VER</span></span><br><span class="line">make SHARED=1 CFLAGS=<span class="string">"-O2 -fPIC"</span></span><br><span class="line">make DESTDIR=/usr install</span><br><span class="line"><span class="built_in">popd</span></span><br><span class="line">ldconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># Installation of shadowsocks-libev</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/shadowsocks/shadowsocks-libev.git --depth=1</span><br><span class="line"><span class="built_in">cd</span> shadowsocks-libev</span><br><span class="line">git submodule update --init --recursive</span><br><span class="line">./autogen.sh &amp;&amp; ./configure &amp;&amp; make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<h3 id="4-安装-Chinadns"><a href="#4-安装-Chinadns" class="headerlink" title="4. 安装 Chinadns"></a>4. 安装 Chinadns</h3><p>安装 Chinadns 实现域名分流，国内的域名交给国内的 DNS (119.29.29.29 或 223.6.6.6) 来解析，国外的域名交给 国外的 DNS (8.8.8.8 或 1.1.1.1)来解析</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Installation of chinadns-ng</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/zfl9/chinadns-ng --depth=1</span><br><span class="line"><span class="built_in">cd</span> chinadns-ng</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<h3 id="5-安装-ss-tproxy"><a href="#5-安装-ss-tproxy" class="headerlink" title="5. 安装 ss-tproxy"></a>5. 安装 ss-tproxy</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Installation of ss-tproxy</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/zfl9/ss-tproxy --depth=1</span><br><span class="line"><span class="built_in">cd</span> ss-tproxy</span><br><span class="line">chmod +x ss-tproxy</span><br><span class="line">cp -af ss-tproxy /usr/<span class="built_in">local</span>/bin</span><br><span class="line">mkdir -p /etc/ss-tproxy</span><br><span class="line">cp -af ss-tproxy.conf gfwlist* chnroute* /etc/ss-tproxy</span><br><span class="line">cp -af ss-tproxy.service /etc/systemd/system</span><br></pre></td></tr></table></figure>
<h3 id="6-配置-ss-redir"><a href="#6-配置-ss-redir" class="headerlink" title="6. 配置 ss-redir"></a>6. 配置 ss-redir</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt;&gt; /etc/ss.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"server"</span>:<span class="string">""</span>,</span><br><span class="line">    <span class="string">"mode"</span>:<span class="string">"tcp_and_udp"</span>,</span><br><span class="line">    <span class="string">"server_port"</span>:,</span><br><span class="line">    <span class="string">"local_port"</span>:,</span><br><span class="line">    <span class="string">"local_address"</span>:<span class="string">"0.0.0.0"</span>,</span><br><span class="line">    <span class="string">"reuse_port"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"no_delay"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"password"</span>:<span class="string">""</span>,</span><br><span class="line">    <span class="string">"timeout"</span>:60,</span><br><span class="line">    <span class="string">"method"</span>:<span class="string">"chacha20"</span></span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">"server":"", 代理服务器的 IP </span><br><span class="line">"mode":"tcp_and_udp", 代理协议</span><br><span class="line">"server_port":, 代理服务器端口</span><br><span class="line">"local_port":, 本地端口，要和</span><br><span class="line">"local_address":"0.0.0.0",一定要填，不然只能本机代理，其他及其用不了,坑我一次</span><br><span class="line">"reuse_port": true,</span><br><span class="line">"no_delay": true,</span><br><span class="line">"password":"", 密码</span><br><span class="line">"timeout":60,</span><br><span class="line">"method":"" 加密协议</span><br></pre></td></tr></table></figure>
<h3 id="7-配置-ss-tproxy"><a href="#7-配置-ss-tproxy" class="headerlink" title="7. 配置 ss-tproxy"></a>7. 配置 ss-tproxy</h3><p>剽窃一下官方的配置文件 <code>/etc/ss-tproxy/ss-tproxy.conf</code></p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="comment">## mode</span></span><br><span class="line"><span class="comment">#mode='gfwlist' # gfwlist 分流 (黑名单)</span></span><br><span class="line"><span class="attr">mode</span>=<span class="string">'chnroute'</span> <span class="comment"># chnroute 分流 (白名单)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ipv4/6</span></span><br><span class="line"><span class="attr">ipv4</span>=<span class="string">'true'</span>     <span class="comment"># true:启用ipv4透明代理; false:关闭ipv4透明代理</span></span><br><span class="line"><span class="attr">ipv6</span>=<span class="string">'false'</span>    <span class="comment"># true:启用ipv6透明代理; false:关闭ipv6透明代理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## tproxy</span></span><br><span class="line"><span class="attr">tproxy</span>=<span class="string">'false'</span>  <span class="comment"># true:TPROXY+TPROXY; false:REDIRECT+TPROXY</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## proxy</span></span><br><span class="line"><span class="attr">proxy_svraddr4</span>=()      <span class="comment"># 服务器的 IPv4 地址或域名，允许填写多个服务器地址，空格隔开</span></span><br><span class="line"><span class="attr">proxy_svraddr6</span>=()      <span class="comment"># 服务器的 IPv6 地址或域名，允许填写多个服务器地址，空格隔开</span></span><br><span class="line"><span class="attr">proxy_svrport</span>=<span class="string">'8080'</span>   <span class="comment"># 服务器的外网监听端口，格式同 ipts_proxy_dst_port，不可留空</span></span><br><span class="line"><span class="attr">proxy_tcpport</span>=<span class="string">'1080'</span>   <span class="comment"># ss/ssr/v2ray 等本机进程的 TCP 监听端口，该端口支持透明代理</span></span><br><span class="line"><span class="attr">proxy_udpport</span>=<span class="string">'1080'</span>   <span class="comment"># ss/ssr/v2ray 等本机进程的 UDP 监听端口，该端口支持透明代理</span></span><br><span class="line"><span class="attr">proxy_startcmd</span>=<span class="string">'cmd1'</span>  <span class="comment"># 用于启动本机代理进程的 shell 命令，该命令应该能立即执行完毕</span></span><br><span class="line"><span class="comment"># shadowsocks-libev 的启动命令是 ss-redir -c /etc/ss.json -u &lt;/dev/null &amp;&gt;&gt;/var/log/ss-redir.log  ss.json 是你 shadowsocks 的配置文件</span></span><br><span class="line"><span class="attr">proxy_stopcmd</span>=<span class="string">'cmd2'</span>   <span class="comment"># 用于关闭本机代理进程的 shell 命令，该命令应该能立即执行完毕</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## dnsmasq</span></span><br><span class="line"><span class="attr">dnsmasq_bind_port</span>=<span class="string">'53'</span>                  <span class="comment"># dnsmasq 服务器监听端口，见 README</span></span><br><span class="line"><span class="attr">dnsmasq_cache_size</span>=<span class="string">'4096'</span>               <span class="comment"># DNS 缓存条目，不建议过大，4096 足够</span></span><br><span class="line"><span class="attr">dnsmasq_cache_time</span>=<span class="string">'3600'</span>               <span class="comment"># DNS 缓存时间，单位是秒，最大 3600 秒</span></span><br><span class="line"><span class="attr">dnsmasq_log_enable</span>=<span class="string">'false'</span>              <span class="comment"># 记录详细日志，除非进行调试，否则不建议启用</span></span><br><span class="line"><span class="attr">dnsmasq_log_file</span>=<span class="string">'/var/log/dnsmasq.log'</span> <span class="comment"># 日志文件，如果不想保存日志可以改为 /dev/null</span></span><br><span class="line"><span class="attr">dnsmasq_conf_dir</span>=()                     <span class="comment"># `--conf-dir` 选项的参数，可以填多个，空格隔开</span></span><br><span class="line"><span class="attr">dnsmasq_conf_file</span>=()                    <span class="comment"># `--conf-file` 选项的参数，可以填多个，空格隔开</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## chinadns</span></span><br><span class="line"><span class="attr">chinadns_bind_port</span>=<span class="string">'65353'</span>               <span class="comment"># chinadns-ng 服务器监听端口，通常不用改动</span></span><br><span class="line"><span class="attr">chinadns_verbose</span>=<span class="string">'false'</span>                 <span class="comment"># 记录详细日志，除非进行调试，否则不建议启用</span></span><br><span class="line"><span class="attr">chinadns_logfile</span>=<span class="string">'/var/log/chinadns.log'</span> <span class="comment"># 日志文件，如果不想保存日志可以改为 /dev/null</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## dns</span></span><br><span class="line"><span class="attr">dns_direct</span>=<span class="string">'119.29.29.29'</span>          <span class="comment"># 本地 IPv4 DNS，不能指定端口，也可以填组织、公司内部 DNS</span></span><br><span class="line"><span class="attr">dns_direct6</span>=<span class="string">'240C::6666'</span>              <span class="comment"># 本地 IPv6 DNS，不能指定端口，也可以填组织、公司内部 DNS</span></span><br><span class="line"><span class="attr">dns_remote</span>=<span class="string">'8.8.8.8#53'</span>               <span class="comment"># 远程 IPv4 DNS，必须指定端口，提示：访问远程 DNS 会走代理</span></span><br><span class="line"><span class="attr">dns_remote6</span>=<span class="string">'2001:4860:4860::8888#53'</span> <span class="comment"># 远程 IPv6 DNS，必须指定端口，提示：访问远程 DNS 会走代理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ipts</span></span><br><span class="line"><span class="attr">ipts_rt_tab</span>=<span class="string">'233'</span>               <span class="comment"># iproute2 路由表名或表 ID，除非产生冲突，否则不建议改动该选项</span></span><br><span class="line"><span class="attr">ipts_rt_mark</span>=<span class="string">'0x2333'</span>           <span class="comment"># iproute2 策略路由的防火墙标记，除非产生冲突，否则不建议改动该选项</span></span><br><span class="line"><span class="attr">ipts_set_snat</span>=<span class="string">'false'</span>           <span class="comment"># 设置 iptables 的 MASQUERADE 规则，布尔值，`true/false`，详见 README</span></span><br><span class="line"><span class="attr">ipts_set_snat6</span>=<span class="string">'true'</span>           <span class="comment"># 设置 ip6tables 的 MASQUERADE 规则，布尔值，`true/false`，详见 README</span></span><br><span class="line"><span class="attr">ipts_intranet</span>=(<span class="number">10.20</span>.<span class="number">172.0</span>/<span class="number">24</span>)  <span class="comment"># 要代理的 IPv4 内网网段，可填多个，空格隔开，该选项的具体说明请看 README</span></span><br><span class="line"><span class="attr">ipts_intranet6</span>=(fd00::/<span class="number">8</span>)       <span class="comment"># 要代理的 IPv6 内网网段，可填多个，空格隔开，该选项的具体说明请看 README</span></span><br><span class="line"><span class="attr">ipts_reddns_onstop</span>=<span class="string">'true'</span>       <span class="comment"># ss-tproxy stop 后，是否将其它主机发至本机的 DNS 请求重定向至本地直连 DNS，详见 README</span></span><br><span class="line"><span class="attr">ipts_proxy_dst_port</span>=<span class="string">'1:65535'</span>   <span class="comment"># 目标 IP 的哪些端口走代理，目标 IP 就是黑名单 IP，多个用逗号隔开，冒号为端口范围(含边界)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## opts</span></span><br><span class="line"><span class="attr">opts_ss_netstat</span>=<span class="string">'auto'</span>                  <span class="comment"># auto/ss/netstat，用哪个端口检测命令，见 README</span></span><br><span class="line"><span class="attr">opts_overwrite_resolv</span>=<span class="string">'false'</span>           <span class="comment"># true/false，定义如何修改 resolv.conf，见 README</span></span><br><span class="line"><span class="attr">opts_ip_for_check_net</span>=<span class="string">'114.114.114.114'</span> <span class="comment"># 用来检测外网是否可访问的 IP，该 IP 需要允许 ping</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## file</span></span><br><span class="line"><span class="attr">file_gfwlist_txt</span>=<span class="string">'/etc/ss-tproxy/gfwlist.txt'</span>      <span class="comment"># gfwlist 黑名单文件 (默认规则)</span></span><br><span class="line"><span class="attr">file_gfwlist_ext</span>=<span class="string">'/etc/ss-tproxy/gfwlist.ext'</span>      <span class="comment"># gfwlist 黑名单文件 (扩展规则)</span></span><br><span class="line"><span class="attr">file_chnroute_set</span>=<span class="string">'/etc/ss-tproxy/chnroute.set'</span>    <span class="comment"># chnroute 地址段文件 (iptables)</span></span><br><span class="line"><span class="attr">file_chnroute6_set</span>=<span class="string">'/etc/ss-tproxy/chnroute6.set'</span>  <span class="comment"># chnroute6 地址段文件 (ip6tables)</span></span><br><span class="line"><span class="attr">file_dnsserver_pid</span>=<span class="string">'/etc/ss-tproxy/.dnsserver.pid'</span> <span class="comment"># dnsmasq 和 chinadns-ng 的 pid 文件</span></span><br></pre></td></tr></table></figure>
<h3 id="8-启动"><a href="#8-启动" class="headerlink" title="8. 启动"></a>8. 启动</h3><p>启动亲需要先关闭本机的 dnsmasq 进程，不然会提示 53 端口已占用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop dnsmasq</span><br><span class="line">systemctl <span class="built_in">disable</span> dnsmasq</span><br><span class="line">systemctl <span class="built_in">enable</span> haveged <span class="comment"># 启动 haveged 用来产生足够多的熵，供加密算法用</span></span><br><span class="line">ss-tproxy start</span><br></pre></td></tr></table></figure>
<h2 id="4-结语"><a href="#4-结语" class="headerlink" title="4. 结语"></a>4. 结语</h2><p>完成以上该能跑起来了，需要注意的是，透明网关要和需要代理的机器在同一网段，不可跨网段，只能在一个 LAN 局域网里。最后祝 GFW 早点倒吧😡</p>
<p>完整脚本，在 Debian 10 下测试通过</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">apt update</span><br><span class="line"><span class="built_in">set</span> -xue</span><br><span class="line">apt install -y git</span><br><span class="line">apt install -y --no-install-recommends --no-install-suggests  \</span><br><span class="line">    gettext build-essential autoconf libtool  libsodium-dev libmbedtls-dev \</span><br><span class="line">    libpcre3-dev asciidoc xmlto libev-dev libc-ares-dev automake curl wget \</span><br><span class="line">    dnsmasq iproute2 ipset perl haveged gawk</span><br><span class="line"></span><br><span class="line">mkdir -p ~/gateway</span><br><span class="line"><span class="built_in">cd</span> ~/gateway</span><br><span class="line"><span class="comment"># Installation of chinadns-ng</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/zfl9/chinadns-ng --depth=1</span><br><span class="line"><span class="built_in">cd</span> chinadns-ng</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="built_in">cd</span> ../</span><br><span class="line"></span><br><span class="line"><span class="comment"># Installation of libsodium</span></span><br><span class="line"><span class="built_in">export</span> LIBSODIUM_VER=1.0.16</span><br><span class="line">wget https://download.libsodium.org/libsodium/releases/libsodium-<span class="variable">$LIBSODIUM_VER</span>.tar.gz</span><br><span class="line">tar xvf libsodium-<span class="variable">$LIBSODIUM_VER</span>.tar.gz</span><br><span class="line"><span class="built_in">pushd</span> libsodium-<span class="variable">$LIBSODIUM_VER</span></span><br><span class="line">./configure --prefix=/usr &amp;&amp; make</span><br><span class="line">make install</span><br><span class="line"><span class="built_in">popd</span></span><br><span class="line">ldconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># Installation of MbedTLS</span></span><br><span class="line"><span class="built_in">export</span> MBEDTLS_VER=2.6.0</span><br><span class="line">wget https://tls.mbed.org/download/mbedtls-<span class="variable">$MBEDTLS_VER</span>-gpl.tgz</span><br><span class="line">tar xvf mbedtls-<span class="variable">$MBEDTLS_VER</span>-gpl.tgz</span><br><span class="line"><span class="built_in">pushd</span> mbedtls-<span class="variable">$MBEDTLS_VER</span></span><br><span class="line">make SHARED=1 CFLAGS=<span class="string">"-O2 -fPIC"</span></span><br><span class="line">make DESTDIR=/usr install</span><br><span class="line"><span class="built_in">popd</span></span><br><span class="line">ldconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># Installation of shadowsocks-libev</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/shadowsocks/shadowsocks-libev.git --depth=1</span><br><span class="line"><span class="built_in">cd</span> shadowsocks-libev</span><br><span class="line">git submodule update --init --recursive</span><br><span class="line">./autogen.sh &amp;&amp; ./configure &amp;&amp; make</span><br><span class="line">make install</span><br><span class="line"><span class="built_in">cd</span> ../</span><br><span class="line"></span><br><span class="line"><span class="comment"># Installation of ss-tproxy</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/zfl9/ss-tproxy --depth=1</span><br><span class="line"><span class="built_in">cd</span> ss-tproxy</span><br><span class="line">chmod +x ss-tproxy</span><br><span class="line">cp -af ss-tproxy /usr/<span class="built_in">local</span>/bin</span><br><span class="line">mkdir -p /etc/ss-tproxy</span><br><span class="line">cp -af ss-tproxy.conf gfwlist* chnroute* /etc/ss-tproxy</span><br><span class="line">cp -af ss-tproxy.service /etc/systemd/system</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/ss.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"server"</span>:<span class="string">""</span>,</span><br><span class="line">    <span class="string">"mode"</span>:<span class="string">"tcp_and_udp"</span>,</span><br><span class="line">    <span class="string">"server_port"</span>:8080,</span><br><span class="line">    <span class="string">"local_port"</span>:1080,</span><br><span class="line">    <span class="string">"local_address"</span>:<span class="string">"0.0.0.0"</span>,</span><br><span class="line">    <span class="string">"reuse_port"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"no_delay"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"password"</span>:<span class="string">""</span>,</span><br><span class="line">    <span class="string">"timeout"</span>:60,</span><br><span class="line">    <span class="string">"method"</span>:<span class="string">"chacha20"</span></span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> haveged</span><br><span class="line">systemctl start haveged</span><br><span class="line">systemctl <span class="built_in">disable</span> dnsmasq</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Debian</tag>
        <tag>proxy</tag>
        <tag>科学上网</tag>
      </tags>
  </entry>
  <entry>
    <title>一键粉红手机😂</title>
    <url>/archives/oh-my-pink.html</url>
    <content><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1.背景"></a>1.背景</h2><p>近期，不少网友曝光黑皮搜查手机的新闻，虽然不知真假，但还是为此菊花一紧。感谢党，感谢政府，感谢国家对我们关爱有加，我们感到无比地幸福😂。可是呢，像咱这种老大哥不待见的屁民，面对黑皮搜查手机取证的时候，如何如何将自己的风险讲到最小呢？</p>
<h5 id="1-坚决反抗"><a href="#1-坚决反抗" class="headerlink" title="1.坚决反抗"></a>1.坚决反抗</h5><p>这条路肯定行不通啦，屁民反抗的黑皮的话，先给你安个寻衅滋事罪把你给扣起来，拘留十五日，写个保证书。咱可不想受到社会主义铁拳的打击。</p>
<h5 id="2-销毁手机，抹除数据"><a href="#2-销毁手机，抹除数据" class="headerlink" title="2.销毁手机，抹除数据"></a>2.销毁手机，抹除数据</h5><p>这样做极大地保护我们的隐私，具有技术可行性。但这样做也会招来黑皮的关注，可能会给你安个毁灭证据罪什么的，可不好说。</p>
<h5 id="3-伪造假数据"><a href="#3-伪造假数据" class="headerlink" title="3.伪造假数据"></a>3.伪造假数据</h5><p>已经有大佬开发了 xposed 模块 <a href="https://github.com/HiedaNaKan/FuckMFS" target="_blank" rel="noopener">FuckMFS</a> ，可以优雅地 fuck 掉 MFsocket 。特点很多，联系人与SIM卡号随机生成、短信返回通知类、图片音频视频信息随机生成、应用列表返回国内白名单应用等。如果符合你的需求，可以去试一下哈。</p>
<h5 id="4-伪装成小粉红😂"><a href="#4-伪装成小粉红😂" class="headerlink" title="4.伪装成小粉红😂"></a>4.伪装成小粉红😂</h5><p>毕恭毕敬地向警察蜀黍交出手机啦，做个乖宝宝，做个普通的小粉红，将自己的风险降到最小。假如手机里装着<code>学习强国、人民日报、两学一做</code>等爱国软件，相册里保存社会主义核心价值观标语等等，那警察蜀黍对你的好感度肯定会大幅提高啊。警察叔叔肯定会认为：<code>不错不错，这才是我党的一等公民，这才是我党最需要的韭菜？😂</code>。</p>
<hr>
<h2 id="2-oh-my-pink-一键粉红"><a href="#2-oh-my-pink-一键粉红" class="headerlink" title="2.oh-my-pink 一键粉红"></a>2.oh-my-pink 一键粉红</h2><h3 id="2-1它是什么东东？"><a href="#2-1它是什么东东？" class="headerlink" title="2.1它是什么东东？"></a>2.1它是什么东东？</h3><p>根据前面的分析，做一个忠党爱国的小粉红，毕恭毕敬地交出手机，放心大胆地让警察蜀黍检查手机，这样的风险最小。但我们不是小粉红，如何在那种紧急的场景快速地将手机伪装成一个小粉红的手机呢？于是就出了 oh-my-pink 教程，将我们的手机进行社会主义改造，变成粉红版的手机，爱国手机，战狼手机😂。</p>
<h3 id="2-2它的功能及特点"><a href="#2-2它的功能及特点" class="headerlink" title="2.2它的功能及特点"></a>2.2它的功能及特点</h3><p>1.一键粉红手机，将手机转变成战狼手机，爱国手机，粉红版手机😂</p>
<p>2.速度极快，适用于时间极其紧迫的情况下。经测试，整个过程不到1分钟。</p>
<p>3.使用 iptables 禁用所有联网操作，防止下载数据</p>
<p>4.禁用开发者模式，删除手机上的 adbd 服务，使得 MFsocket 安装失败</p>
<p>5.自动卸载外置存储卡，将敏感数据隔离开来</p>
<h3 id="2-3-它的缺点"><a href="#2-3-它的缺点" class="headerlink" title="2.3 它的缺点"></a>2.3 它的缺点</h3><p>本教程不具有通用性，因为手机型号不同，配置不同，安装的 app 也不同，所以无法做到为每个人都进行适配。仅仅提供教程，以及技术可行性的实现方式。至于实现代码和脚本，请根据自己的需求进行修改。手机需要 root ，我相信就这一点就劝退了大部分人😂。但想要实现极速一键粉红操作就得需要使用 root 权限，简单粗暴直接通过 rsync 同步文件来实现。这需要一定得门槛，不如把搞机当作一项和反迷信上网的科学技能 ？ 大雾：）😂。趁现在还年轻，还有时间和精力来 hacking ，不然到老了就没精力去搞了。</p>
<hr>
<h2 id="3-可行性分析"><a href="#3-可行性分析" class="headerlink" title="3.可行性分析"></a>3.可行性分析</h2><h3 id="3-1-Android-分区"><a href="#3-1-Android-分区" class="headerlink" title="3.1. Android 分区"></a>3.1. Android 分区</h3><p>关于 Android 分区 | 下面剽窃一段<a href="https://source.android.google.cn/devices/bootloader/partitions-images" target="_blank" rel="noopener">官方文档</a></p>
<p>Android 设备包含若干个分区，这些分区在启动过程中发挥不同的作用。</p>
<ul>
<li><p><strong>system</strong>：<code>system</code> 分区主要包含 Android 框架。</p>
</li>
<li><p><strong>recovery</strong>：<code>recovery</code> 分区用于存储在 OTA 过程中启动的恢复映像。如果设备支持 <a href="https://source.android.google.cn/devices/tech/ota/ab/" target="_blank" rel="noopener">A/B 更新</a>，则恢复映像可以是启动映像中包含的 RAM 磁盘，而不是单独的映像。</p>
</li>
<li><p><strong>cache</strong>：<code>cache</code> 分区用于存储临时数据，如果设备使用 A/B 更新，则可以不要此分区。cache 分区不需要可从引导加载程序写入，而只需要可清空。大小取决于设备类型和 userdata 分区的可用空间。目前，50MB 至 100MB 应该没问题。</p>
</li>
<li><p><strong>data</strong>：data` 分区包含用户安装的应用和数据，包括自定义数据。</p>
</li>
<li><p><strong>vendor</strong>：<code>vendor</code> 分区包含所有不可分发给 Android 开源项目 (AOSP) 的二进制文件。如果没有专有信息，则可以省略此分区。</p>
</li>
</ul>
<p>以下是我的 moto z play 的分区表</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">addison:/ $ su</span><br><span class="line">addison:/ <span class="comment"># df -h</span></span><br><span class="line">Filesystem                    Size  Used Avail Use% Mounted on</span><br><span class="line">rootfs                        1.2G  2.4M  1.2G   1% /</span><br><span class="line">tmpfs                         1.3G  728K  1.3G   1% /dev</span><br><span class="line">/dev/block/mmcblk0p53         3.8G  935M  2.9G  24% /system</span><br><span class="line">tmpfs                         1.3G     0  1.3G   0% /mnt</span><br><span class="line">/dev/block/mmcblk0p52         248M  2.4M  246M   1% /cache</span><br><span class="line">/dev/block/mmcblk0p19          94M   63M   31M  67% /firmware</span><br><span class="line">/dev/block/mmcblk0p29         2.8M  2.8M  8.0K  100% /fsg</span><br><span class="line">/dev/block/mmcblk0p22          12M  8.1M  3.5M  70% /dsp</span><br><span class="line">/dev/block/mmcblk0p30          27M  624K   27M   3% /persist</span><br><span class="line">/dev/block/mmcblk0p54          24G   10G   14G  44% /data</span><br><span class="line">/data/media                    24G   10G   14G  44% /mnt/runtime/default/emulated</span><br><span class="line">/dev/block/vold/public:179_65  60G   39G   21G  65% /mnt/media_rw/A410-12F6</span><br><span class="line">/mnt/media_rw/A410-12F6        60G   39G   21G  65% /mnt/runtime/default/A410-12F6</span><br><span class="line">addison:/</span><br></pre></td></tr></table></figure>
<p>如果我们要对手机进行社会主义改造，那么 /data 分区时我们关注的重点。其中 /data/app 目录是我们手机下载 Android 的 app ，每个 app 在 /data/data 目录里都对应着自己的应用数据目录，也就是说 /data/app 和 /data/data 是单射关系。其中 /data/data 目录里也包含着系统 app 的应用数据目录。换句话来说对手机进行设社会主义改造，也就是对 /data分区进行社会主义改造。在 /data/data 和 /data/app 目录里的敌人当然要清理干净来，比如反迷信上网软件，电报，Google ，Twitter 等等，这些敌人一定要清理干净啦。接下来安装上 学习强国，两学一做，人民日报等爱国app。</p>
<p>面对查手机的时候，我们总不能挨个挨个卸载吧，这样肯定是来不及的。所以我们使用一个快速高效的工具帮我们同时完成卸载和安装操作。于是我们使用 rsync 这个工具，直接将社会主义改造过的粉红版的 /data/data 和 /data/app 目录覆盖掉 当前的 /data/data 和 /data/app 目录。在此简单地介绍一些 rsync 这个暴力的工具。</p>
<h3 id="3-2-rsync"><a href="#3-2-rsync" class="headerlink" title="3.2. rsync"></a>3.2. rsync</h3><p><a href="https://coolshell.cn/articles/7425.html" target="_blank" rel="noopener">RSYNC 的核心算法</a> | <a href="http://man.linuxde.net/rsync" target="_blank" rel="noopener">中文手册？</a></p>
<p>用法</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rsync [OPTION]... SRC DEST</span><br></pre></td></tr></table></figure>
<p>可能会用到的选项</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-v, --verbose 详细模式输出。</span><br><span class="line">-a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于 -rlptgoD。</span><br><span class="line">-r, --recursive 对子目录以递归模式处理。</span><br><span class="line">--backup-dir 将备份文件(如~filename)存放在在目录下。</span><br><span class="line">-u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。</span><br><span class="line">-l, --links 保留软链结。</span><br><span class="line">-H, --hard-links 保留硬链结。</span><br><span class="line">-p, --perms 保持文件权限。</span><br><span class="line">-o, --owner 保持文件属主信息。</span><br><span class="line">-g, --group 保持文件属组信息。</span><br><span class="line">-D, --devices 保持设备文件信息。</span><br><span class="line">-t, --<span class="built_in">times</span> 保持文件时间信息。</span><br><span class="line">-w, --whole-file 拷贝文件，不进行增量检测。</span><br><span class="line">-C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。</span><br><span class="line">--existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。</span><br><span class="line">--delete 删除那些DST中SRC没有的文件。</span><br><span class="line">--delete-excluded 同样删除接收端那些被该选项指定排除的文件。</span><br><span class="line">--delete-after 传输结束以后再删除。</span><br><span class="line">--ignore-errors 即使出现IO错误也进行删除。</span><br><span class="line">--max-delete=NUM 最多删除NUM个文件。</span><br><span class="line">--force 强制删除目录，即使不为空。</span><br><span class="line">--numeric-ids 不将数字的用户和组id匹配为用户名和组名。</span><br><span class="line">--size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。</span><br><span class="line">--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。</span><br><span class="line">--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。</span><br><span class="line">-P 等同于 --partial。</span><br><span class="line">--progress 显示备份过程。</span><br><span class="line">--exclude=PATTERN 指定排除不需要传输的文件模式。</span><br><span class="line">--exclude-from=FILE 排除FILE中指定模式的文件。</span><br><span class="line">-stats 给出某些文件的传输状态。</span><br><span class="line">--progress 在传输时现实传输过程。</span><br><span class="line">--<span class="built_in">log</span>-format=formAT 指定日志文件格式。</span><br><span class="line">-h, --<span class="built_in">help</span> 显示帮助信息。</span><br><span class="line">mkdir -p /data/pink</span><br></pre></td></tr></table></figure>
<h2 id="4-实现过程"><a href="#4-实现过程" class="headerlink" title="4.实现过程"></a>4.实现过程</h2><p>测试用的手机信息：</p>
<p><img src="/img/1561802376515.png" alt="1561802376515"></p>
<h3 id="4-1-备份数据"><a href="#4-1-备份数据" class="headerlink" title="4.1.备份数据"></a>4.1.备份数据</h3><p><strong>刷机千万条，数据第一条，备份不规范，机主两行泪</strong>😂</p>
<p>手机开启 adb 网络调试模式 设置-&gt;系统-&gt;开发者工具。这样方便在PC的终端上进行调试。</p>
<p><img src="/img/1561802425505.png" alt="1561802425505"></p>
<p><strong>PC端</strong></p>
<p>安装好<a href="https://developer.android.com/studio/releases/platform-tools" target="_blank" rel="noopener">platform-tools</a>工具，打开终端</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># adb 连接到手机</span></span><br><span class="line">adb connect 192.168.0.102:5555</span><br><span class="line">adb shell</span><br><span class="line"><span class="comment"># 获取 root 权限</span></span><br><span class="line">su</span><br><span class="line"><span class="comment"># 手机端要对 shell 进行 root 授权</span></span><br></pre></td></tr></table></figure>
<p>备份数据的工具很多啦，我最常用的就是钛备份。但今天要对 /data/data 和 /data/app整个目录进行备份，还是用 tar 进行暴力备份吧。其实用 TWRP 备份最好啦。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看系统分区情况</span></span><br><span class="line">df -h</span><br><span class="line">mkdir -p /data/pink</span><br><span class="line"><span class="comment"># 使用 rsync 备份整个 /data 目录</span></span><br><span class="line">time rsync -avlHt  --progress --exclude=/data/media /data /sdcard/data</span><br><span class="line">sent 2,546,814,512 bytes  received 439,395 bytes  26,396,413.54 bytes/sec</span><br><span class="line">total size is 2,547,073,319  speedup is 1.00</span><br><span class="line">rsync error: some files/attrs were not transferred (see previous errors) (code 23) at external/rsync/main.c(1178) [sen</span><br><span class="line">der=3.1.2]</span><br><span class="line">    1m36.63s real     0m34.66s user     0m50.07s system</span><br><span class="line"></span><br><span class="line">addison:/sdcard/data/data <span class="comment"># du -sh</span></span><br><span class="line">2.4G</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">sent 2,304,507,949 bytes  received 422,353 bytes  22,487,124.90 bytes/sec</span><br><span class="line">total size is 2,304,882,629  speedup is 1.00</span><br><span class="line">rsync error: some files/attrs were not transferred (see previous errors) (code 23) at external/rsync/main.c(1178) [sen</span><br><span class="line">der=3.1.2]</span><br><span class="line">    1m41.64s real     0m31.24s user     0m47.07s system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试删除的速度</span></span><br><span class="line">addison:/sdcard <span class="comment"># time  rsync --delete-before -avH --progress --stats tmp data</span></span><br><span class="line">Number of files: 1 (dir: 1)</span><br><span class="line">Number of created files: 0</span><br><span class="line">Number of deleted files: 23,961 (reg: 20,654, dir: 3,307)</span><br><span class="line">Number of regular files transferred: 0</span><br><span class="line">Total file size: 0 bytes</span><br><span class="line">Total transferred file size: 0 bytes</span><br><span class="line">Literal data: 0 bytes</span><br><span class="line">Matched data: 0 bytes</span><br><span class="line">File list size: 0</span><br><span class="line">File list generation time: 0.001 seconds</span><br><span class="line">File list transfer time: 0.000 seconds</span><br><span class="line">Total bytes sent: 60</span><br><span class="line">Total bytes received: 1,669,739</span><br><span class="line"></span><br><span class="line">sent 60 bytes  received 1,669,739 bytes  477,085.43 bytes/sec</span><br><span class="line">total size is 0  speedup is 0.00</span><br><span class="line">    0m03.10s real     0m00.31s user     0m02.36s system</span><br></pre></td></tr></table></figure>
<p>发现一个很僵硬的问题，使用 tar 或者 rsync 备份是无法保留所属信息的，虽然可以保留权限信息，但目录和文件的所属信息时无法保存的。那我们只好将 /data/data 目录里的内容删除了，删除 /data/data目录里第三放 app 的应用数据目录时不影响使用的。</p>
<p>原 /data 目录</p>
<p><img src="/img/1561804056692.png" alt="1561804056692"></p>
<p>rsync 复制后的目录，却发现所有的所属信息都没了😂</p>
<p><img src="../img/1561815022924.png" alt="1561815022924"></p>
<p>找到了原因，是因为跨文件系统的坑。因为 Android 内部存储 /sdcard 是使用的 fat32 文件系统，fat32 文件是没有 ext4 文件系统权限元数据信息的。所以解决办法是将这些数据备份到同一文件系统下。就设置为 /data/pink 目录吧😂。</p>
<p><img src="../img/1561822332154.png" alt="1561822332154"></p>
<h3 id="4-2-卸载敌对势力的-app"><a href="#4-2-卸载敌对势力的-app" class="headerlink" title="4.2.卸载敌对势力的 app"></a>4.2.卸载敌对势力的 app</h3><p>我是使用的 SDmaid 俗称 SD 卡女佣？ 来批量卸载 app 。卸载完成后还要删除这些 app 残留的文件，以及 app 的安装包等。这需要自己手动在 /sdcard 内部存储来查找排除这些文件。总之一定要让我们的手机正能量满满。</p>
<h3 id="4-3-安装爱国软件"><a href="#4-3-安装爱国软件" class="headerlink" title="4.3. 安装爱国软件"></a>4.3. 安装爱国软件</h3><p>第一肯定是老大哥的红宝书学习强国啦，其他的像人民日报、两学一做、智慧团建等等，也都下载下来安装上。</p>
<h3 id="4-4-备份粉红版-data-目录"><a href="#4-4-备份粉红版-data-目录" class="headerlink" title="4.4.备份粉红版 /data 目录"></a>4.4.备份粉红版 /data 目录</h3><p>以上步骤完成后，我们就动手制作一个 粉红版的 /data 目录，主要备份 /data/data 和 /data/app 目录，即卸载掉帝国软件，装有爱国软件的目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 备份 /data/data目录</span></span><br><span class="line">time rsync -avlHt  --progress /data/data /sdcard/data/data</span><br><span class="line"></span><br><span class="line">sent 189,072,151 bytes  received 50,969 bytes  16,445,488.70 bytes/sec</span><br><span class="line">total size is 413,158,141  speedup is 2.18</span><br><span class="line">rsync error: some files/attrs were not transferred (see previous errors) (code 23) at external/rsync/main.c(1178) [sen</span><br><span class="line">der=3.1.2]</span><br><span class="line">    0m10.71s real     0m02.84s user     0m05.04s system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份 /data/app 目录</span></span><br><span class="line">time rsync -avlHt  --progress /data/app /sdcard/data/app</span><br><span class="line"></span><br><span class="line">sent 1,099,653,619 bytes  received 6,928 bytes  41,496,624.42 bytes/sec</span><br><span class="line">total size is 1,099,358,469  speedup is 1.00</span><br><span class="line">    0m25.94s real     0m10.91s user     0m08.29s system</span><br><span class="line"><span class="comment">## 看来备份数据的速度还是相当快的</span></span><br></pre></td></tr></table></figure>
<h4 id="4-5拉清单？"><a href="#4-5拉清单？" class="headerlink" title="4.5拉清单？"></a>4.5拉清单？</h4><p><del>别看你今天闹得欢，小心我日后拉清单</del>😂<br>我们这个清单就老大哥不待见的东西，比如膜蛤、乳包等等你懂😜。无论时图片还是音频，我们统统把他们放在外置 SD 卡里，到时候在一件粉红的时候自动把  外置 SD 卡卸载掉，从而让取证软件识别不到外置 SD 卡。当然内部存储里的一些文件也需要删除，比如 telegram 的 /sdcard/Android/data/**telegram/ 目录，这里面有很多东西，都很危险。到时候我们使用 rsync 直接删除 /sdcard/Android 和 /mnt/media_rw/A10F-22E/Android 。因为每个 app 都可能会自己创建一些目录和文件，所以这一步主要是用来排查这些文件，把他们拉到清单里。如果文件和目录比较少的话，可以直接将这些目录修改到想要的变量。</p>
<h4 id="4-关键脚本代码"><a href="#4-关键脚本代码" class="headerlink" title="4. 关键脚本代码"></a>4. 关键脚本代码</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">time rsync -avlHt  --delete --progress /data/data /data/pink/data</span><br><span class="line">time rsync -avlHt  --delete --progress /data/app /data/pink/app</span><br><span class="line">mkdir -p /mnt/media_rw/A410-12F6/sdcard</span><br><span class="line">time rsync -avlHt --progress /data/media/0 /mnt/media_rw/A410-12F6/sdcard</span><br></pre></td></tr></table></figure>
<h3 id="5-设定-tasker-任务"><a href="#5-设定-tasker-任务" class="headerlink" title="5.设定 tasker 任务"></a>5.设定 tasker 任务</h3><p>tasker介绍和使用 | <a href="https://sspai.com/post/45759" target="_blank" rel="noopener">Tasker：Android 上的自动化标杆 </a> | 下面剽窃一段介绍</p>
<p>我们今天要介绍的自动化工具 Tasker 比 Workflow 更强大，自由。得益于 Android 系统的开放性与对系统 API 调用的宽松要求，Tasker 可以实现更多样，更复杂的自动化操作。特别是在获得 ROOT 权限之后 Tasker 能访问几乎所有数据（手机内外的皆可），甚至实现<strong>手机硬件支持的任何操作（即使系统没有）</strong>。</p>
<p><a href="https://zohead.com/archives/tasker-shell" target="_blank" rel="noopener">Android使用Shell命令配合Tasker控制手机</a></p>
<h4 id="5-1添加任务"><a href="#5-1添加任务" class="headerlink" title="5.1添加任务"></a>5.1添加任务</h4><p>打开 tasker 后点击那个大大的 + 号按钮，添加我们自定义的这些任务。输入任务名称为 pink。</p>
<p><img src="../img/1561820231312.png" alt="1561820231312"></p>
<p>再次点击那个大大的 +  号，来添加单个任务。选择操作类别为代码</p>
<p><img src="../img/1561820474017.png" alt="1561820474017"></p>
<p>选择代码操作为运行外壳</p>
<p><img src="../img/1561820507625.png" alt="1561820507625"></p>
<p>添加 shell 运行命令，所有的操作都要使用 root 运行</p>
<p><img src="../img/1561820547351.png" alt="1561820547351"></p>
<p>添加完成后，点击左下角那个开始按钮，如果任务左边为绿点，则运行成功。如果为红点，则会出现报错信息。</p>
<p><img src="../img/1561820617830.png" alt="1561820617830"></p>
<h4 id="5-2-使用-shell-开启飞行模式，防止-MFsocket-进行联网"><a href="#5-2-使用-shell-开启飞行模式，防止-MFsocket-进行联网" class="headerlink" title="5.2 使用 shell 开启飞行模式，防止 MFsocket 进行联网"></a>5.2 使用 shell 开启飞行模式，防止 MFsocket 进行联网</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 禁用数据连接</span></span><br><span class="line">svc data <span class="built_in">disable</span></span><br><span class="line">svc usb <span class="built_in">disable</span></span><br><span class="line"><span class="comment"># 开启飞行模式</span></span><br><span class="line">settings put global airplane_mode_on 1; am broadcast -a android.intent.action.AIRPLANE_MODE --ez state <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用APN</span></span><br><span class="line">adb shell settings put global airplane_mode_on 0 adb shell am broadcast -a android.intent.action.AIRPLANE_MODE </span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 usb 连接设置为 midi ，能禁用 adb ？</span></span><br><span class="line">svc usb setFunction midi</span><br><span class="line"></span><br><span class="line"><span class="comment"># down 掉所有网卡，优点暴力😂</span></span><br><span class="line"> ifconfig | grep Link | grep -v inet6 | cut -d <span class="string">' '</span> -f1</span><br><span class="line"><span class="keyword">for</span> dev <span class="keyword">in</span> \`ifconfig | grep Link | grep -v inet6 | cut -d <span class="string">' '</span> -f1\` ;<span class="keyword">do</span> ifconfig <span class="variable">$dev</span> down ;<span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<h4 id="5-3-禁用开发者模式，禁用-adb-连接"><a href="#5-3-禁用开发者模式，禁用-adb-连接" class="headerlink" title="5.3 禁用开发者模式，禁用 adb 连接"></a>5.3 禁用开发者模式，禁用 adb 连接</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">addison:/ <span class="comment"># busybox ps -T | grep adb</span></span><br><span class="line"> 5501 2000      0:00 /system/bin/adbd --root_seclabel=u:r:su:s0</span><br><span class="line"> 5502 2000      0:00 &#123;usb ffs open&#125; /system/bin/adbd --root_seclabel=u:r:su:s0</span><br><span class="line"> 5503 2000      0:00 &#123;server socket&#125; /system/bin/adbd --root_seclabel=u:r:su:s0</span><br><span class="line"> 5505 2000      0:00 &#123;-&gt;transport&#125; /system/bin/adbd --root_seclabel=u:r:su:s0</span><br><span class="line"> 5506 2000      0:00 &#123;&lt;-transport&#125; /system/bin/adbd --root_seclabel=u:r:su:s0</span><br><span class="line"> 5507 2000      0:00 &#123;-&gt;host-14&#125; /system/bin/adbd --root_seclabel=u:r:su:s0</span><br><span class="line"> 5508 2000      0:00 &#123;&lt;-host-14&#125; /system/bin/adbd --root_seclabel=u:r:su:s0</span><br><span class="line"> 6088 2000      0:00 &#123;shell svc 6087&#125; /system/bin/adbd --root_seclabel=u:r:su:s0</span><br><span class="line"> 6738 0         0:00 grep adb</span><br><span class="line">settings list system</span><br><span class="line">settings list global</span><br><span class="line">settings list secure</span><br><span class="line">settings get global/system/adb_enabled</span><br><span class="line">adb_enabled</span><br><span class="line">settings <span class="built_in">set</span> global/system/adb_enabled=</span><br></pre></td></tr></table></figure>
<h4 id="5-4-开启防火墙，禁用所有联网（重启后会失效）"><a href="#5-4-开启防火墙，禁用所有联网（重启后会失效）" class="headerlink" title="5.4 开启防火墙，禁用所有联网（重启后会失效）"></a>5.4 开启防火墙，禁用所有联网（重启后会失效）</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -t nat -A OUTPUT -p tcp -j DROP</span><br><span class="line">iptables -t nat -A OUTPUT -p udp -j DROP</span><br><span class="line">iptables -t nat -A INPUT -p tcp -j DROP</span><br><span class="line">iptables -t nat -A INPUT -p udp -j DROP</span><br></pre></td></tr></table></figure>
<p>防止 MFsocket 关闭飞行模式，来进行联网操作。经网友反应，MFsocket 会进行联网操作来下载一些数据。</p>
<h4 id="5-5卸载掉外置存储卡"><a href="#5-5卸载掉外置存储卡" class="headerlink" title="5.5卸载掉外置存储卡"></a>5.5卸载掉外置存储卡</h4><p>如果你装有外置的 SD 卡的话，可以通过 umount 命令卸载，这样可以防止读取到外置 SD 内存卡。另外平时我们可以将一些敏感的文件放到 外置 SD 内存卡里，这样在非常时期可以通过卸载 SD 卡来达到伪装的目的。另外，卸载后的外置 SD 内存卡是需要自己主动 mount或者重启手机才能重新挂载到设备，一般取证软件应该没有自己去主动挂载 SD 卡，仅仅是推测。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 选项 a 是 umount 所有设备 ，f 是强制 unmount</span></span><br><span class="line">addison:/data/pink/data/data <span class="comment"># umount -af</span></span><br><span class="line">umount: /mnt/runtime/default/emulated: Device or resource busy</span><br><span class="line">umount: /data: Device or resource busy</span><br><span class="line">umount: /sys/kernel/debug/tracing: Device or resource busy</span><br><span class="line">umount: /dev/usb-ffs/adb: Device or resource busy</span><br><span class="line">umount: /fsg: Device or resource busy</span><br><span class="line">umount: /mnt: Device or resource busy</span><br><span class="line">umount: /sys/kernel/debug: Device or resource busy</span><br><span class="line">umount: /system: Device or resource busy</span><br><span class="line">umount: /sys/fs/selinux: Device or resource busy</span><br><span class="line">umount: /sys: Device or resource busy</span><br><span class="line">umount: /proc: Device or resource busy</span><br><span class="line">umount: /dev/pts: Device or resource busy</span><br><span class="line">umount: /dev: Device or resource busy</span><br></pre></td></tr></table></figure>
<h4 id="5-6修改壁纸为战狼？😂"><a href="#5-6修改壁纸为战狼？😂" class="headerlink" title="5.6修改壁纸为战狼？😂"></a>5.6修改壁纸为战狼？😂</h4><p>通过 shell 命令将壁纸修改为一张爱国壁纸、战狼壁纸、粉红壁纸？</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">am start -d file:////data/<span class="built_in">local</span>/tmp/black_white.png -a \ android.service.wallpaper.CROP_AND_SET_WALLPAPER -f 0x1 \ ch.deletescape.lawnchair.qa/ch.deletescape.wallpaperpicker.WallpaperCropActivity</span><br></pre></td></tr></table></figure>
<p>需要注意的是这条命令的最后一个参数是根据自己使用的 Lancher 不同而不同的。要获取这个参数的话需要使用一些工具，我这里使用的是 My Android tools。还是需要 root 权限来使用这个工具。</p>
<p><img src="../img/1562110188032.png" alt="1562110188032"></p>
<p><strong>点击 about 左侧那个按钮</strong></p>
<p><img src="../img/1562110228770.png" alt="1562110228770"></p>
<p><strong>接着点击 Activity</strong></p>
<p><img src="../img/1562110273463.png" alt="1562110273463"></p>
<p><strong>找到你使用的 Lancher，拉到最下面你会找到一个 WallpaperCropActivity。</strong></p>
<p><img src="../img/1562110333067.png" alt="1562110333067"></p>
<p>然后在点击  &lt;···&gt; 这个按钮，会出现详细的路径。在点击右上角第二个复制按钮，这个参数就复制到了剪切板。</p>
<p>file后面的是壁纸的路径，修改为自己设定路径就可以。</p>
<h4 id="5-7不如保存一些战狼图片、那兔图片？"><a href="#5-7不如保存一些战狼图片、那兔图片？" class="headerlink" title="5.7不如保存一些战狼图片、那兔图片？"></a>5.7不如保存一些战狼图片、那兔图片？</h4><p>下载一些战狼图片、那年那兔那些事儿的图片到内置存储。下载抗美援朝电影？？下载老大哥红宝书？？下载价值观标语？？总之，你觉着那些老大哥喜欢，你就去下载那些。这些并不是必须的，只是将我们的手机装修的更粉红😂。</p>
]]></content>
      <tags>
        <tag>安卓</tag>
        <tag>刷机</tag>
        <tag>安卓刷机</tag>
      </tags>
  </entry>
  <entry>
    <title>《学会提问：批判性思维指南 》读书笔记</title>
    <url>/archives/Asking-the-right-questions.html</url>
    <content><![CDATA[<h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1.基本概念"></a>1.基本概念</h2><p><code>批判性思维</code>：</p>
<ol>
<li>有一套相互关联，环环相扣的关键问题的意识</li>
<li>恰如其分地提出和回答关键问题额能力</li>
<li>积极主动地利用关键问题的强烈愿望</li>
</ol>
<p><code>QA</code>:什么时关键问题呢？批判性的提问时检索信息和搜索答案的最好办法？</p>
<p><code>海绵式思维</code>:吸收更多的外界信息，吸收作者的观点<br><code>淘金式思维</code>:带着问题阅读并不断提出新的问题，质疑作者的主张，在客观理性的基础上得出结论</p>
<p><code>强批判性思维</code>:<br>1.用关键问题客观质疑一切主张（包括自己）<br>2.强迫自己辩证地看待我们的初始看法<br>3.欢迎一切针对自己现有看法的批评</p>
<hr>
<p>我们最有价值的社会交往或学习都始于那些拥有相似价值观的人，我们往往愿意接受与我们相似的观点，党同伐异。批判性思考：自主，中立，谦虚，冷静，客观，理性。改变自己看法时就像承认你从前的一切都归于失败</p>
<p>思考时都要有明确的目标，之所以思考就是为了达到这个目的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 我又没有问“为什么”别人要我相信他人的观点</span><br><span class="line">2. 在我想到别人观点有问题时，有没有把它记下来</span><br><span class="line">3. 我对别人说过的话有没有进行客观评价</span><br><span class="line">4. 针对某一特定的问题，与别人讨论前我又没有形成自己的结论和观点</span><br></pre></td></tr></table></figure>
<p>论证三要素：论题、论点、论据<br>只有当找到支持结论的理由是才能判定论点的价值<br>依靠批判性思维原则形成自己的理性判断<br>你这样说是什么意思，而不是我就是知道你是这个意思<br>只有出现在分析推理过程中，意思不明确的词才是关键<br>小心那些饱含情感色彩的词，它会让你的思维短路，欺骗人们的思想，直接联通情感路线描述性的依稀 通道。任何一个想要用语言来改变我们情感共鸣的人，都会利用到这些可能藏在我们心中的情感，以此来激发正面情感也可抑制负面情感</p>
<p>不同的参照物会衍生出不同的价值观，只有价值观的假设添加到推理中，他们的理由才能从逻辑上证实，批判性地夜读和聆听的主要目标在于判定结论和接受的度量值</p>
<p><code>谬误</code>:</p>
<p>1.推理明显错误，不能让人接受的论点毫无关系<br>2.把无关信息混淆，分散注意力<br>3.结论成为前提的证据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```txt</span><br><span class="line">偷换概念</span><br><span class="line">诉诸公众</span><br><span class="line">诉诸可疑权威</span><br><span class="line">诉诸情感</span><br><span class="line">稻草人攻击</span><br><span class="line">虚假两难选择</span><br><span class="line">光环效应</span><br><span class="line">乱扣帽子</span><br><span class="line">转移话题</span><br><span class="line">诉诸虚伪</span><br></pre></td></tr></table></figure>
<p><code>诉诸情感的推理谬误</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.源自愤怒</span><br><span class="line">2.威胁手段</span><br><span class="line">3.诉诸武力</span><br><span class="line">4.源自同情</span><br><span class="line">5.源自嫉妒</span><br><span class="line">6.阿谀奉承</span><br><span class="line">7.使人免疫</span><br><span class="line">8.一厢情愿</span><br><span class="line">9.同辈压力</span><br><span class="line">10.群体性思维</span><br><span class="line">11.民族主义</span><br><span class="line">12.转移注意力</span><br><span class="line">13.合理化</span><br><span class="line">14.诉诸众人</span><br><span class="line">15.诉诸司空见惯 ps：某为被曝光拍照使用单反造假后，说其他厂家也这么干-&gt;诉诸司空见惯😂</span><br><span class="line">16.宿主传统</span><br><span class="line">17.以错就错</span><br></pre></td></tr></table></figure>
<p><code>客观断言</code>:真或假不依赖思考着的主管臆断<br><code>ps</code>:所有的道德观念都是主观的,有难以区分高下的正确性<br><code>客观论题</code>:答案不依赖思考着是怎么想的,比如数学题<br>明确论题所指的核心对象,分清主次-&gt;文章的逻辑<br><code>QA</code>:向往自由是人类的本性,到底有那些论据支持这个说法呢?<br><code>论证</code>:是由论点和论据构成,论据为论点提供理由<br><code>论点</code>:是被前提所支持的断言</p>
<p><strong>在接受信息时,人类总是倾向于有利我们的\最接近真像的信息?</strong><br>信念形成的过程总会掺杂着一些难以察觉的人类固有的心理因素</p>
<p><code>认知偏差</code>: 通过我们的可信度判断一个结论是否正确<br><code>消极偏见</code>: 指人们相信县级信息多余积极信息的倾向<br><code>圈内偏见</code>: 认为属于自己圈内的人与圈外的人有不同的认知偏差<br><code>归因谬误</code>: 以不同的方式理解自己和他人的行为<br><code>服从权威</code>: 只听从权威指令的倾向<br><code>过度自信</code>: 过高估计自己对问题答案的正确性概率的认知偏差<br><code>错误性的共识</code>: 假定自己的观点与大多数人的想法靠拢的倾向<br><code>可靠性启发法</code>: 一句提及一个事务的频率来判断这件事情发生的可能性</p>
<h3 id="演绎推理"><a href="#演绎推理" class="headerlink" title="演绎推理"></a>演绎推理</h3><p>皆在证明结论，适用于 前提为真但结论为假。</p>
<h3 id="非演绎推理"><a href="#非演绎推理" class="headerlink" title="非演绎推理"></a>非演绎推理</h3><p>皆在支撑结论</p>
<p>任何不能以真假来衡量的</p>
<h2 id="2-批判性思维技能"><a href="#2-批判性思维技能" class="headerlink" title="2.批判性思维技能"></a>2.批判性思维技能</h2><p>1.判断信息是否前挡<br>2.区分理性断言和情感断言<br>3.区分事实与观点<br>4.识别证据的不足<br>5.洞察他人论证的陷阱和缺陷<br>6.独立分析数据或信息<br>7.识别论证的逻辑错误<br>8.发现数据和信息与其来源之间的联系<br>9.处理矛盾、不充分、模糊的信息<br>10.基于数据而不是观点建立令人信服的论证<br>11.选择支持力强的论据<br>12.避免言过其实的言论<br>13.识别论证的漏洞并建议收集其他信息<br>14.知道问题往往没有明确的答案或唯一性的解决办法<br>15.提出替代方案并在决策是给予考虑<br>16.采取行动时考虑所有利益相关的主体<br>17.清楚地表达论证及其语境<br>18.精准地应用证据为论证辩护<br>19.符合逻辑且言辞一致地组织论证<br>20.展开论证时避免无关因素<br>21.有序地呈现说服力强的论据</p>
<p>写作注意事项</p>
<p>1.避免陈词滥调</p>
<p>2.尽量具体不要抽象</p>
<p>3.避免被动语句</p>
<p>4.简明扼要不要啰嗦</p>
<p>5.夸大其词远不如谨慎陈述</p>
<p>6.保证主谓一致</p>
<p>7.为什么要运用修辞手段</p>
<p>8.句首不要用连词</p>
<p>9.仔细核对每一个字</p>
<p>10.插入主管评论不是必须的</p>
<hr>
<h2 id="数据的真实性"><a href="#数据的真实性" class="headerlink" title="数据的真实性"></a>数据的真实性</h2><p>1.对特定的目标进行估测得到精确的数据是相当困难的，因此统计数据往往只是基于事实做出的一些估计。<br>2.数据是从哪里来的？他们是怎样得出这些数据的？<br>3.遇到平均数的时候，要注意！！ 全距和数值分布的总体好处，就是大多数人或事实并不正好符合平均值<br>4.百分比的绝对值，而不是具体增长前后的数据。比如增长75%。从4到7和从12到21都是增长了75%。—&gt;数据增长的绝对值<br>5.令人心动的数字或百分比背后可能确实相对比较的信息<br>6.了解全距和数值分布的一个总体，大多数人和事实并不正好符合平均值，与平均值差异极大得结果也在意料之中<br>7.什么样的数据支持什么样的结论？</p>
<p><strong>任何一个你所遇到的信息都是有一个目的，信息的组织结构是有别人精挑细选呈现得。目的是希望从某种程度上影响到你的思维方式。</strong></p>
<hr>
<p>说想写</p>
<p>鲁莽地得出结论、或者不规范、不假思索地平下意识作出决定。不客观、不冷静、不中立、不理性地作出结论都不是批判性思维。</p>
<p>不是盲目行动或反应，不是凭各种诱惑的摆布。不是轻易受爱情、贪欲、无关考虑愚蠢、愚蠢偏见、民族主义干扰。</p>
<p>在作出民智的决定前，得出正确的结论 –&gt; 要求客观对待</p>
<p>1.形成意见</p>
<p>2.作出判断</p>
<p>3.作出决定</p>
<p>4.形成结论</p>
<p>批判上一种思维，让其接受，让思考过程接受理性评估，对思维展开思维，为了考量自己的思维是否符合逻辑客观。</p>
<p>1.对待自己所见所闻，提出一些较有力度的问题，以便对自己的经历的事物到底有多大的价值作出判断</p>
<p>2.通过合理的结论的道路往往是从问题开始并一路有问题相伴</p>
<p>3.批判性思维的三个方面</p>
]]></content>
  </entry>
  <entry>
    <title>一簇愉悦地装机 AMD YES</title>
    <url>/archives/amd-yes.html</url>
    <content><![CDATA[<h2 id="听说汝想组装台电脑？"><a href="#听说汝想组装台电脑？" class="headerlink" title="听说汝想组装台电脑？"></a>听说汝想组装台电脑？</h2><p>一直在用着 2015 年的 ThinkPad Yoga 12，因为是个低压 5300U ，性能特别差，而且 8GB 的内存开60多个 Chrome tab 就卡死。。使用 Android 模拟器打个崩坏3rd ，简直<strong>三秒一卡，卡的潇洒，一走一停，摆个造型，三步一卡，等的我傻，一心等待，缓冲失败，继续等待，闪退无奈，忍无可忍，完美卸载😂</strong></p>
<p>种种不顺就想着组装一个台式机，现在组装电脑，而且对于多年捡垃圾的垃圾佬来说，肯定是 <strong>AMD YES ！</strong></p>
<p>心里种草很久了，一直想组装个台式机用，最近看到 2600 + B450M 的 套装价格 1179￥ 了，而且三星的 8GB 内存也 269￥了。于是还是下狠心都买了下来。一共花了 2700 不到。但到后来陆续又加了些东西，与花掉了600左右。</p>
<hr>
<h2 id="0-拉清单"><a href="#0-拉清单" class="headerlink" title="0. 拉清单"></a>0. 拉清单</h2><p>别看你闹得欢，小心今后拉清单😂。咱是拉个购买列表的清单哈，不是炮决清单😘</p>
<table>
<thead>
<tr>
<th>设备</th>
<th>型号</th>
<th>价格￥</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>AMD 锐龙 5 2600</td>
<td>主板套装</td>
<td></td>
</tr>
<tr>
<td>主板</td>
<td>ASUS B450M-K</td>
<td>1179</td>
<td></td>
</tr>
<tr>
<td>内存</td>
<td>三星 DDR4 8GB 2666Mhz + 镁光 DDR4 8GB 2666Mhz</td>
<td>495</td>
<td></td>
</tr>
<tr>
<td>固态</td>
<td>西数 SN750 500GB</td>
<td>589</td>
<td></td>
</tr>
<tr>
<td>显卡</td>
<td>AMD R5 240</td>
<td>100</td>
<td></td>
</tr>
<tr>
<td>U盘</td>
<td>MLC 64GB</td>
<td>69</td>
<td></td>
</tr>
<tr>
<td>硬盘</td>
<td>500GB 2.5 7200 rpm</td>
<td>89</td>
<td>监控</td>
</tr>
<tr>
<td>显示器</td>
<td>ASUS ML229 1080P IPS</td>
<td>240</td>
<td>闲鱼</td>
</tr>
<tr>
<td>线材</td>
<td>主板开关、HMDI-&gt;DVI、USB HUB</td>
<td>30</td>
<td></td>
</tr>
<tr>
<td>OS</td>
<td>Windows 10 专业工作站版</td>
<td>15</td>
<td>密钥</td>
</tr>
<tr>
<td>Office</td>
<td>荔枝数码 Office 365 共享版</td>
<td>99</td>
<td>按年订阅</td>
</tr>
<tr>
<td>机箱电源</td>
<td>Dell 3010 DT</td>
<td>165</td>
<td></td>
</tr>
<tr>
<td>键盘</td>
<td>罗技 MK245</td>
<td>36</td>
<td></td>
</tr>
<tr>
<td>总价</td>
<td>1179+269+589+100+69+240+60+35+20+15+99</td>
<td>3106</td>
</tr>
</tbody>
</table>
<h2 id="1-CPU"><a href="#1-CPU" class="headerlink" title="1. CPU"></a>1. CPU</h2><p>本来想着要不要捡垃圾 E3 1275L V3 ，某宝售价大概 750 ，配合 Dell 9020 SFF 准系统 350，加满 32GB 内存，总成本大概也在 2000 元。但全是 15 年的垃圾啊，而且 1150 四代 CPU 不支持 NVME 启动，也就只能用  SATA 接口的固态硬盘，但哪个速度突破不了 600MB/s。现在随便一块 nvme 协议的pci-e 固态速度都能达到 3GB/s，秒天秒地的。😂。垃圾佬这次就不捡垃圾了，还是安安稳稳地上 AMD R5 2600 吧。</p>
<h4 id="AMD-yes"><a href="#AMD-yes" class="headerlink" title="AMD yes"></a>AMD yes</h4><p><img src="../img/1564309833159.png" alt="1564309833159"></p>
<h4 id="U-板套装价格"><a href="#U-板套装价格" class="headerlink" title="U 板套装价格"></a>U 板套装价格</h4><p><img src="../img/1564306493431.png" alt="1564306493431"></p>
<h4 id="苏宁盒装价格"><a href="#苏宁盒装价格" class="headerlink" title="苏宁盒装价格"></a>苏宁盒装价格</h4><p><img src="../img/1564306275967.png" alt="1564306275967"></p>
<h2 id="2-主板"><a href="#2-主板" class="headerlink" title="2. 主板"></a>2. 主板</h2><p>主板买 U 板套装其实和捡垃圾差不多，想着盒装的 R5 2600 苏宁售价 999 元， U 板套装 1179 元，差不多 179 元买个主板，你觉着能买到个好的主板不翻车？？差不多买主板就捡垃圾吧，买二手的 B450 还要担心翻车，最生事儿和省心的还是买了 U 板套装，虽然里面有猫腻，但还是买了。祝愿自己不翻车吧。</p>
<p><img src="../img/1564306377223.png" alt="1564306377223"></p>
<h2 id="3-内存条"><a href="#3-内存条" class="headerlink" title="3. 内存条"></a>3. 内存条</h2><p>内存条不选渣顿和国产就行，我第一根花了 269 买的三星的 DDR4 8GB 2666MH。后来觉着不够又加了一根 镁光的DDR4 8GB 2666MH，这根镁光的要便宜一些 229 元。本来还想再加一根同型号的三星的，但那时候三星的条子涨价了，而且涨了40，想了想还是买镁光吧，毕竟是原厂芯片，要比渣顿强一些。内存条只要频率搞了，一般都会选用原厂芯片。哎， 16GB 的三星 DDR4 售价 599 ，三丧啊！</p>
<h4 id="购买前"><a href="#购买前" class="headerlink" title="购买前"></a>购买前</h4><p><img src="../img/1564306578400.png" alt="1564306578400"></p>
<h4 id="涨价后"><a href="#涨价后" class="headerlink" title="涨价后"></a>涨价后</h4><p><img src="../img/1564306957172.png" alt="1564306957172"></p>
<h4 id="镁光内存条"><a href="#镁光内存条" class="headerlink" title="镁光内存条"></a>镁光内存条</h4><p>最后还是买了镁光，便宜将近 100 😂</p>
<p><img src="../img/1564306703517.png" alt="1564306703517"></p>
<h2 id="4-固态硬盘"><a href="#4-固态硬盘" class="headerlink" title="4. 固态硬盘"></a>4. 固态硬盘</h2><p>固态硬盘买的西数 SN750 500GB 的黑盘，用了之后才发现，根本用不了 500GB ，当系统盘 120GB 可能有点小，但 250GB 完全足够使用。而且平时我会将一些数据放到机械硬盘里存储，固态硬盘不舍得用😂。589 元好钢没有用到刀刃上，其实买 三星 970 EVO PLUS 250GB 的最好了，当系统盘无论速度和容量都合适。</p>
<p><img src="../img/1564306598457.png" alt="1564306598457"></p>
<h2 id="5-机械硬盘"><a href="#5-机械硬盘" class="headerlink" title="5. 机械硬盘"></a>5. 机械硬盘</h2><p>机械硬还是捡垃圾，暴漏了垃圾佬的本性😂。花了 89 元买了一块 500GB 的 2.5 硬盘，把我原来的 2T 盘从 ThinkPad Yoga 12 上换下来装在台式机上使用。未来可能再加两块 3TB 的二手盘。我没有太多重要的资料，大概有 200 GB 的重要文件都放在 M$ 家的 OneDrive 上了</p>
<p><img src="../img/1564307546160.png" alt="1564307546160"></p>
<h2 id="6-机箱电源"><a href="#6-机箱电源" class="headerlink" title="6. 机箱电源"></a>6. 机箱电源</h2><p>本来没想着买机箱和电源，我还是用的原来的机箱和电源。原来的是大水牛的 ITX 机箱，体积十分小，能放进书包里的那种。后来用着用着。装好机器不到一周，电源风扇就坏掉了，噪音特别大。而且大水牛的这个电源也很渣，恐怕一天会 BOOM 掉。最后还是捡垃圾吧。最后找到了 Dell OptiPlex 3010 机箱 + 电源。只能说 165 元这个机箱真 TM 值啊，完全秒某宝上那些金河田全汉什么的了。165 元很难买到像 Dell OptiPlex 3010 这种品牌机的质量了吧。电源是光宝的电源，和 R410 系列的服务器电源一样，稳定性几乎能秒那些国产金牌铜牌银牌认证了。总之性价比超级高，这个垃圾是我捡到的最牛逼的垃圾了，简直吹爆它。如果你也想组装台式机的话，那么我十分强烈推荐你买这个垃圾。简直就是个宝贝啊。需要注意的是，这个机箱只能装 24.5*24.5 以内的 MATX 或 ITX 主板。 </p>
<h4 id="十分讲究的机箱"><a href="#十分讲究的机箱" class="headerlink" title="十分讲究的机箱"></a>十分讲究的机箱</h4><p><img src="../img/1564308496121.png" alt="1564308496121"></p>
<h4 id="新旧机箱对比"><a href="#新旧机箱对比" class="headerlink" title="新旧机箱对比"></a>新旧机箱对比</h4><p>原来的机箱（上），新机箱（下）</p>
<p><img src="../img/1564308552179.png" alt="1564308552179"></p>
<h4 id="厚度大小对比"><a href="#厚度大小对比" class="headerlink" title="厚度大小对比"></a>厚度大小对比</h4><p><img src="../img/1564308589264.png" alt="1564308589264"></p>
<p><img src="../img/1564308615413.png" alt="1564308615413"></p>
<h4 id="光宝电源"><a href="#光宝电源" class="headerlink" title="光宝电源"></a>光宝电源</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">下面剽窃一段网友的评论</span><br><span class="line">早期GZ上传出来的顺口溜：</span><br><span class="line">台达、爱默生网能是本科；</span><br><span class="line">光宝、高效、康舒等是大专；</span><br><span class="line">七盟、全汉、新巨、乔威、海韵等等几家厂大概是高中；</span><br><span class="line">长城、航嘉是幼儿园；</span><br><span class="line">国内其它小杂牌TMD连个受精卵都不算！</span><br><span class="line">金河田、鑫谷、世纪之星等勉强可以认为介于幼儿园和受精卵之间。</span><br></pre></td></tr></table></figure>
<p><strong>关于光宝科技</strong> 建兴的母公司就是光宝，一般来说电源界的第一还是台达，而且台达一般不做零售，都是面向服务器领域的电源。光宝也是，一直做的电源都是 OEM 给 Dell 服务器上使用的电源。</p>
<p><img src="../img/1564308672673.png" alt="1564308672673"></p>
<p><img src="../img/1564306719920.png" alt="1564306719920"></p>
<h4 id="之前的小机箱，被暴力改装过😂"><a href="#之前的小机箱，被暴力改装过😂" class="headerlink" title="之前的小机箱，被暴力改装过😂"></a>之前的小机箱，被暴力改装过😂</h4><p>因为前置挡板被我锯掉了，开关和 USB 接口没得了，只能买一根电源开源线改装上去了，当时凑活着用😂。</p>
<p><img src="../img/1564309900993.png" alt="1564309900993"></p>
<h2 id="7-显卡"><a href="#7-显卡" class="headerlink" title="7. 显卡"></a>7. 显卡</h2><p>由于  AMD R5 2600 没得核显，所以缺一块亮机卡，性能要求并不高，能用就行。最后捡垃圾搞了个拆机卡。</p>
<p><img src="../img/1564306650263.png" alt="1564306650263"></p>
<p>后来发现，性能不够，以后可能会花个 700 左右捡垃圾搞一块 微星 GTX1050TI 4GB 的刀卡，受制于我的小机箱，只能用低功耗和半高刀卡。</p>
<h2 id="8-鼠标键盘"><a href="#8-鼠标键盘" class="headerlink" title="8. 鼠标键盘"></a>8. 鼠标键盘</h2><p>鼠标用的原来的罗技 M220 ，键盘使用的标准大小键盘。但由于桌子太小，还是捡垃圾搞块库存的罗技 MK245吧。后来发现这次买 MK245 的店，我三年钱就在这家店买过😂。因为我的鼠标 M220 的接收器和 MK240 是通用的，所以只需要 36 块钱买了键盘就行，和我这个 M220 绝配啊。</p>
<p><img src="../img/1564309200086.png" alt="1564309200086"></p>
<p><img src="../img/1564307875202.png" alt="1564307875202"></p>
<h2 id="9-其他"><a href="#9-其他" class="headerlink" title="9. 其他"></a>9. 其他</h2><h4 id="散热风扇"><a href="#散热风扇" class="headerlink" title="散热风扇"></a>散热风扇</h4><p>AMD 盒装原装的散热风扇完全足够使用，温度也没什么问题。注意，原装的风扇底部是涂好了硅脂。不用更换硅脂，用原装自带的硅脂就行。</p>
<p><img src="../img/1564309274364.png" alt="1564309274364"></p>
<p>最后花了 2 块钱给机箱加了一个服务器上的风扇，而且是三洋电机的。菲律宾制造的洋垃圾，我的最爱啊。2块钱一个三星电机的散热风扇，能秒那些国产垃圾了吧。</p>
<h4 id="MLC-U-盘"><a href="#MLC-U-盘" class="headerlink" title="MLC U 盘"></a>MLC U 盘</h4><p>因为工作需要，需要经常批量装系统，所以捡垃圾搞了一块 MLC 颗粒的 U盘是非常需要的。读取速度 200MB/s以上，写入速度 110 MB/s 左右，感觉还可以吧，基本上能秒渣顿的 U 盘了吧，这个写入速度你复制一个 60 GB 的文件，写进入去，写满到最后速度还是不变，这就是 MLC 和 SLC 颗粒牛逼的地方。可惜现在 MLC 和 SLC 颗粒已经停产了，目前三星的 MLC 颗粒的固态基本 500 元以内的都是清零盘。</p>
<p><img src="../img/1564306774261.png" alt="1564306774261"></p>
<h2 id="10-效果图"><a href="#10-效果图" class="headerlink" title="10. 效果图"></a>10. 效果图</h2><p><img src="../img/1564309732124.png" alt="1564309732124"></p>
<p><img src="../img/1564310298310.png" alt="1564310298310"></p>
]]></content>
      <tags>
        <tag>装机</tag>
        <tag>捡垃圾</tag>
        <tag>AMD</tag>
      </tags>
  </entry>
  <entry>
    <title>利用社交网络获取骗子的信息</title>
    <url>/archives/get-someone-info.html</url>
    <content><![CDATA[<h2 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h2><ul>
<li>2019-06-24 初稿</li>
<li>2019-07-10 骗子已归还钱</li>
<li>2019-12-09 修改几处 typo</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>朋友A在闲鱼上遇到骗子 B，被骗金额 1000 元。因为使用微信转账故走平台是无法解决的，能做的就是利用该骗子 B 现有的信息顺藤摸瓜搞到她的真实身份、真实姓名、学校，身份证号、家庭住址等信息。耗时巨大，将近 6 个小时，一点一点地从及其微小的线索找到了她的实名信息。同时也为自己在隐私保护方面敲响了警钟。</p>
<h2 id="1-获取真实姓名"><a href="#1-获取真实姓名" class="headerlink" title="1.获取真实姓名"></a>1.获取真实姓名</h2><p>刚开始从朋友 A 那里得到骗子 B 的信息有：手机号、闲鱼 ID、微信 ID、微博 ID。有了手机号及其方便，整条线索都是围绕这个手机号来进行的。通过闲鱼 ID 确认到她的姓应该为 [X]。接着利用支付宝转账，使用手机号搜索到她的支付宝账号，通过支付宝转账界面看到她名字最后一位是 [Y]。然后高潮来了，向她转账需要确认她的身份，而且显示的仅仅一位 [Y] ，可以判断出她的名字是两位数。于是尝试了一下，输入一个假的姓，提示转账失败。但再次尝试输入从闲鱼ID获取到的姓 [X]，提示转账成功（给她转了1分钱）！支付宝神助攻，于是确定了骗子B的真实姓名为 [X][Y]。注意：支付宝如果自己关闭了真实姓名显示的话，在转账的时候是不会显示任何姓名信息的。通常情况下一般人不会关闭，默认是开启显示真实姓名的。如果姓名有三位的话，转账页面会显示两位，其中姓会隐藏掉。</p>
<h2 id="2-获取快递收货地址"><a href="#2-获取快递收货地址" class="headerlink" title="2.获取快递收货地址"></a>2.获取快递收货地址</h2><p>在骗子B的闲鱼上，她发布了一个物品C，且通过描述在某市D可以面交，于是就确认了骗子B目前就在某市D。通过物品C的订单找到了淘宝店E，于是直接联系淘宝店主E。开门见山说要买骗子B的收货信息，当然店主E肯定是不会给的啦，我猜也是😂。于是另劈一条路出来。</p>
<h2 id="3-综合使用各大网站密码找回"><a href="#3-综合使用各大网站密码找回" class="headerlink" title="3.综合使用各大网站密码找回"></a>3.综合使用各大网站密码找回</h2><p>通过闲鱼里的个人页面确认了她是某市D某校F的大学生，于是进她学校官网了解以下她的学校。使用强大的搜索引擎搜索 [X][Y] site:*[该校域名].edu.cn 。看看能不能找到包含她名单之类的信息，比如获奖名单、奖学金名单、表彰名单之类的，然而并没有抓到任何有用的信息。于是关注了她们学校的微信，找到了她们学校的一个校友平台。利用该校的校友平台我尝试用一个虚假的手机号登录一下，发现提示没有注册。于是再用骗子B的手机号登录，提示密码错误。尝试了一下密码找回功能，发送验证码成功。从而确定骗子B确实是该校的学生。</p>
<p>想到她是学生，那肯定在学信网上有信息。于是利用学信网的密码找回功能，输入她的手机号和验证码之后，出现了三个有用的信息。第一，学信网手机号的确实她本人的手机号；第二，身份证号第一位和最后一位；第三，她的QQ邮箱前三位。</p>
<p>接着尝试了京东、百度、微博、淘宝、12306等密码找回功能，确实有账号，但通过密码找回功能，并没有其他有用的信息。</p>
<h2 id="4-从微博入手"><a href="#4-从微博入手" class="headerlink" title="4.从微博入手"></a>4.从微博入手</h2><p>就在一筹莫展的时候，突然想到她还有微博。之前大致浏览了一下，但没有发现有用的信息。于是再次仔细阅读她的每一条微博，在她的最早的一篇微博里。她转发了QQ空间里的说说截图，在这条微博里发现了一个及其重要的线索。从该微博QQ截图里可以确认到骗子的好友H和好友H的微博。于是进入到好友H的微博找线索，在好友H的微博的博客页面，找到了好友H转发的一篇QQ空间里的文章，并且有好友H的QQ空间链接。点进入后发现不是好友无法查看QQ空间，但从地址栏里的URL找到了好友H的QQ号。于是加上了好友H的QQ，居然秒通过！感谢腾讯神助攻！</p>
<h2 id="5-从QQ空间入手"><a href="#5-从QQ空间入手" class="headerlink" title="5.从QQ空间入手"></a>5.从QQ空间入手</h2><p>得到骗子好友H的QQ后，翻看他的QQ空间动态，从1000多条说说里找实在不方便，好在空间说说页面的底下有跳转翻页功能。于是翻到2017年的时候骗子好友H转发的骗子B的那个说说，也就是骗子B在微博上最早的那条说说。于是我点进骗子B的空间，居然允许陌生人查看，真实天助我也！腾讯又来一波神助攻啊😂！QQ空间里、点赞、转发、评论都等，陌生人会看到非好友的QQ昵称，但只要鼠标放在QQ昵称上，就会显示其QQ空间的URL地址，而通过QQ空间的URL地址是可以确认到QQ号的。这点腾讯又来了个大的神助攻。结合使用学信网密码找回搞来的QQ前三位，准确无误地确认到骗子B的QQ号。学信网密码找回显示的QQ邮箱前三位正好和骗子B的QQ号前三位相同，看来这个QQ号绝对是她本人的QQ号。如是进骗子B的QQ空间摸索，好在骗子B的QQ空间设置为允许陌生人访问，能一览无余她所有的QQ空间动态。</p>
<hr>
<h3 id="叨叨"><a href="#叨叨" class="headerlink" title="叨叨"></a>叨叨</h3><p>在骗子B的QQ空间里，翻了将近2个小时😭可累坏我了。撇开失信于人这件事儿，在她QQ空间里看到的她是一个很优秀的大学生，有自己喜欢的爱好，而且这个爱好和我姐一样，并始终坚持着这份热情，我内心真的很佩服佩服。但很遗憾，在金钱和利益面前，任何人都可能会沦为奴隶。她不是完美无缺的人，我也不是完美无缺的人，任何人都会犯错的。但我想到，从QQ空间里看到的她是多么的友善，有自己坚持的目标，愿意为自己所爱之物付出时间和精力。写到这里真的不忍心给她加上骗子的标签，但她确实欺骗了我的朋友。可能是一时的财迷心窍让她犯下错误，可能是她的确缺钱。我想她心里其实也是愧疚与人的。朋友A是因为骗子B说她手头紧，才信任她的，但善意不该被利用啊😞。<br>这也让我想到了厉害国的失信名单与征信系统，以后管制的也越来越严格。虽然我朋友A被骗子B欺骗了，钱没了。但我还是坚决地反对这种失信名单与征信系统。一人失信全家遭殃，这种制度在专制国家只会沦为独裁政府控制人民的工具。难道老赖就应该受到欺负吗？难道老赖的儿女就要为此付出代价，不能上学吗？这种制度早已经侵犯了人权。我对这种制度很悲观，它会和人脸识别、大数据等结合在一起，来为当权者维护社会的稳定，俗称<strong>维稳</strong>。火车霸坐上征信、公交车外放抖音上征信、欠账不还上征信、垃圾不归类上征信、发表老大哥不爱听的言论上征信等等。什么行为上征信？行为不端吗？然并没有一个明确的法律规定，就和<strong>寻衅滋事罪</strong>一样。我觉着在自由民主的社会，社会信用体系的维护不应该是通过强制性的武力，限制失信名单上人员的自由。虽然我从不失信于人，但我还是愿意为失信人维护、捍卫他们的人权和自由。</p>
<hr>
<p>闲扯这么多😂回归正题。在 <del>骗子</del> 以后用卖家B的QQ空间里，翻遍500多条说说，从大学到高中。最关键的是一条她发的一张火车票，而且没有打码。而且火车票上的姓名与她的支付宝姓名相同，身份证号第一位和最后一位正好和从学信网那里搞来的一样。但火车票上缺少出生日期。通过她发的一个她星座的说说，以及她QQ空间里的生日提醒，准确确定了生日。从而结合火车票确定了她的身份证号。</p>
<p>接下来高潮的时候到了，拿到这些信息怎么进一步确认呢？还是去学信网找回密码，不过这次不用手机号，而是用身份证号和姓名，结果一看果然和手机号找回密码的结果一样！还是不死心，再上了教师资格考试成绩查询的网站，输入她的姓名和身份证号，果然是她本人。由此判定了身份证号以及真实姓名。</p>
<p>她的QQ空间对于此时的我来说简直是个“宝藏”，挖掘到各种有用的信息，又通过她发的说说找到她是201X级的学生，某校某专业某班。某市区某中学毕业的学生。最后不忘使用chrome浏览器保存了这个个QQ空间动态的页面，这样防止她发现后而关闭陌生人允许访问。</p>
<h2 id="6-定位地址"><a href="#6-定位地址" class="headerlink" title="6.定位地址"></a>6.定位地址</h2><p>拿到准确的身份证号之后，通过身份证号查询到她户口所在的市区，但无法精确定位到是哪个曲线或街道？身份证15位和16位是可以准确知道户口所在地的派出所编号。于是询问了一下在派出所上班的哥们，他说可以通过身份证号确认到户口所在地的乡镇和街道。但他目前没有查询的权限，所以无法帮到我。于是我又在Google和baidu上搜索卖家B所在市的身份证图片和身份证号，看看能不能找到与卖家B身份证号15位和16位相同的身份证号，但是很遗憾没找到。如果报警立案的话，派出所的人很快就能搞出来，但目前还不想立案，因为这样会伤害到卖家B。我不想因为这件事儿，而让她纳入失信名单，在她的档案里留下污点。希望她能理解我的好意把钱归还。</p>
<h2 id="7-定位公司"><a href="#7-定位公司" class="headerlink" title="7.定位公司"></a>7.定位公司</h2><p>这个并不是很准确，通过卖家B的微信昵称可以确定，她在某市的一家教育机构里上班。在谷歌里搜索了一下这家公司，正好和她微博上发图片的定位地址在一个市区。但不是很确定她是否还在这家公司上班。找了一下这家公司的招聘信息，还是没有找到有用的线索。</p>
<h2 id="8-结尾"><a href="#8-结尾" class="headerlink" title="8.结尾"></a>8.结尾</h2><p>到此结束，耗时6个小时，一直在利用各种线索找找找找找，弄完后感慨万千。掌握的信息有：她的真实姓名和身份证号、手机号、学校、年级、班级、毕业高中、以及一些她舍友的QQ号，她所在社团的QQ群等。终于告一段落了。于是我使用我美国的手机号给她发了短信。</p>
<h2 id="9-忽悠短信"><a href="#9-忽悠短信" class="headerlink" title="9.忽悠短信"></a>9.忽悠短信</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">我希望你能诚实守信，你考过教师资格证，道德底线你应该明白</span><br><span class="line">你已经涉嫌欺诈犯罪，我们这儿超过500元派出所就给立案。</span><br><span class="line">但我不想走司法起诉的方式解决这件事儿。因为这样对你的前途</span><br><span class="line">有极大的影响。首先你会因为这件事被纳入失信名单，上征信系统</span><br><span class="line">往后你买火车票都买不到，整个家庭都会因为你失信而受到影响</span><br><span class="line">你当老师也会受到影响。希望你能冷静地考虑清楚，把该退款的钱</span><br><span class="line">归还与我。不要逃避，逃避是解决不了问题滴，我有充足的时间能</span><br><span class="line">弄到你父母的联系方式。但我真的不忍心打扰你的父母。为了你身</span><br><span class="line">边的朋友，以及你的辅导员，同事，舍友，还有社团里的同学等，</span><br><span class="line">我不想去打扰他们，但你要是死赖着我就不敢保证他们知道</span><br><span class="line">你失信于人后会对你有什么看法和影响。我已经得到你舍友以及社团</span><br><span class="line">还有你辅导员的联系方式。希望不要因为这点事而自毁自己的前途。</span><br></pre></td></tr></table></figure>
<p>其中有些话是危言耸听，故意吓唬她。😂</p>
<h2 id="结局"><a href="#结局" class="headerlink" title="结局"></a>结局</h2><p>第二天我朋友再次联系她，她回信息了，之前是不回的。她说下个月十五号发工资就还。但我朋友A还是再次同情她一次，允许她下个月还。这是第三次故意拖延了，我为朋友A的做法感到无奈。没有办法，卖家B比我朋友A的妹妹还小，还是个学生和老师。朋友A心太善良了，朋友A很早就辍学了所以一向很羡慕和尊重大学生和老师，所以这次再次允许卖家B拖到下个月还钱。</p>
<p>骗子 B 最终在 7 月份归还了朋友 A 钱，其实骗子 B 并不是专业的骗子，可能是一时财迷心窍或者缺钱花才不讲信用不还钱给我朋友的。</p>
<h2 id="时间线"><a href="#时间线" class="headerlink" title="时间线"></a>时间线</h2><ul>
<li>从闲鱼 ID 推测骗子 B 的姓名为 [X]</li>
<li>通过支付宝转账确认骗子 B 的全名为 [X][Y]</li>
<li>通过骗子 B 闲鱼发布的闲置确认到骗子 B 目前所在城市</li>
<li>使用手机号通过学校校友平台确认到骗子 B 所在学校</li>
<li>在骗子 B 微博上找到骗子的好友 H 并加好友秒过</li>
<li>骗子好友 H 的空间里找到骗子 B 的 QQ</li>
<li>在骗子 B 的 QQ 空间里找到未打码的火车票</li>
<li>根据 QQ 空间生日提醒确认到骗子 B 的生日</li>
<li>火车票 + 生日推断出骗子 B 的身份证号</li>
<li>在学信网确认手机号、姓名、身份证号一致</li>
<li>在教师资格证成绩查询网站确认以上信息</li>
</ul>
<h2 id="教训"><a href="#教训" class="headerlink" title="教训"></a>教训</h2><p>整个过程花了6个小时，从各种网站上提取信息，我深刻意识到隐私保护的重要性，及其重要。这篇博客的目的不是为了去人肉陷害他人，我希望是用合法的手段利用逻辑和推理来捍卫自己的权力，整个过程没有违法，没有侵害到他人权力，仅仅是利用一些 公开的信息进行推理和判断，从而找到自己想要的信息。关于隐私保护我觉着编程随想大佬总结的十分好，大家可以自己搜搜去读一下，他写过整个系列的文章，十分强烈推荐去读。在此我不贴出链接，有能力的人自然可以找到。我仅仅是补充一些，以及一些切实可行的措施来保护我们的隐私。</p>
<p><code>措施</code></p>
<p>1.关闭任何网站或社交软件使用手机号登录<br>2.不同的网站账号使用不同的邮箱注册和绑定。可以使用outlook的别名功能，为不同的账号分配不同的邮箱别名，别再用QQ邮箱啦😂。而且outlook邮箱别名功能所有的地址都会发送到一个邮箱中，十分方便。不过我使用的是自己域名的邮箱，在namecheap开启邮件转发功能，会将我域名下所有的邮件转发到我的gmail中。这样也很方便，不过这样也会暴域名。<br>3.朋友圈、QQ空间等社交网站禁止陌生人访问，虽然我早已删光了所有的QQ空间动态和朋友圈。<br>4.社交平台的生日不要设置为真的，也不要设置城市学校等敏感信息<br>5.火车票、机票、电影票等别再晒了，那点虚荣心值得晒嘛🐎<br>6.各个网站之间不要有关联，闲鱼不要链接微博等网站<br>7.还有很多待补充，欢迎在评论区留言。</p>
<h2 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h2><p>关于隐私保护的详细系统的方案墙裂建议看一下<a href="https://program-think.blogspot.com/2019/01/Security-Guide-for-Political-Activists.html" target="_blank" rel="noopener">安全经验总结</a></p>
]]></content>
      <tags>
        <tag>社会工程学实践</tag>
        <tag>隐私保护</tag>
      </tags>
  </entry>
  <entry>
    <title>deploy kubernets dashborad with https</title>
    <url>/archives/dashboard.html</url>
    <content><![CDATA[<h2 id="0-踩坑"><a href="#0-踩坑" class="headerlink" title="0.踩坑"></a>0.踩坑</h2><p>部署完kubernets dashborad后，官方给出的四种访问模式，都很坑😫。</p>
<h3 id="1-kubectl-proxy"><a href="#1-kubectl-proxy" class="headerlink" title="1.kubectl proxy"></a>1.kubectl proxy</h3><p>只能通过本机访问，部署在VPS上的是无法登录的。</p>
<h3 id="2-NodePort"><a href="#2-NodePort" class="headerlink" title="2.NodePort"></a>2.NodePort</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">In case you are trying to expose Dashboard using NodePort on a multi-node cluster, then you have to find out IP of the node on which Dashboard is running to access it. Instead of accessing https://&lt;master-ip&gt;:&lt;nodePort&gt; you should access https://&lt;node-ip&gt;:&lt;nodePort&gt;.</span><br><span class="line">暴漏node IP一个端口来访问，同样浏览器会提示证书问题拒绝访问，测试chrome edge ie均无法访问，需要自己加个证书才行。下面就讲解用自己的域名签个证书来用。NodePort是将节点直接暴露在外网的一种方式，只建议在开发环境，单节点的安装方式中使用。</span><br></pre></td></tr></table></figure>
<h3 id="3-API-Server"><a href="#3-API-Server" class="headerlink" title="3.API Server"></a>3.API Server</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">In case Kubernetes API server is exposed and accessible from outside you can directly access dashboard at: https://&lt;master-ip&gt;:&lt;apiserver-port&gt;/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br><span class="line"></span><br><span class="line">Note: This way of accessing Dashboard is only possible if you choose to install your user certificates in the browser. In example certificates used by kubeconfig file to contact API Server can be used.</span><br></pre></td></tr></table></figure>
<h3 id="4-Ingress"><a href="#4-Ingress" class="headerlink" title="4.Ingress"></a>4.Ingress</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Dashboard can be also exposed using Ingress resource. For more information check: https://kubernetes.io/docs/concepts/services-networking/ingress.</span><br></pre></td></tr></table></figure>
<h2 id="2-使用acme-sh脚本制作证书"><a href="#2-使用acme-sh脚本制作证书" class="headerlink" title="2.使用acme.sh脚本制作证书"></a>2.使用acme.sh脚本制作证书</h2><p>acme.sh脚本从 letsencrypt 可以生成免费的证书<br><a href="https://github.com/Neilpang/acme.sh" target="_blank" rel="noopener">acme</a><br><a href="https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E" target="_blank" rel="noopener">wiki</a></p>
<p>1.安装脚本<br><figure class="highlight plain"><figcaption><span>~ && curl</span><a href="https://get.acme.sh" target="_blank" rel="noopener">| sh && alias acme.sh</a></figcaption><table><tr><td class="code"><pre><span class="line">2.配置好nginx</span><br><span class="line">我的nginx在另一台机器上，需要在域名解析那里添加A记录解析到nginx服务器上。添加子域名未k8s，并在nginx那里配置好。</span><br><span class="line">这一步一定要做，不然的话无法通过http验证该域名所属。当然也可以选用dns的方式来验证，在这里就不赘述了。</span><br><span class="line"></span><br><span class="line">```conf</span><br><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        listen [::]:80;</span><br><span class="line">        server_name k8s.502.li;</span><br><span class="line">        set $base /var/www/k8s;</span><br><span class="line">        root $base/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>3.生成证书，默认会保存在~/.acme.sh/mydomain.com<br>acme.sh –issue  -d mydomain.com   –nginx</p>
<p>4.上传证书到k8s-master节点<br>只需要mydomain.com.cer和mydomain.com.key这两个文件，其中把mydomain.com.cer命名为dashboard.crt ，mydomain.com.key命名为dashboard.key。然后你想办法把这两个文件传到k8s-master机器 ~/certs目录下。</p>
<h2 id="3-部署kubernetes-dashboard"><a href="#3-部署kubernetes-dashboard" class="headerlink" title="3.部署kubernetes-dashboard"></a>3.部署kubernetes-dashboard</h2><p>1.引用官方的文档😂<br>Custom certificates have to be stored in a secret named kubernetes-dashboard-certs in kube-system namespace. Assuming that you have dashboard.crt and dashboard.key files stored under $HOME/certs directory, you should create secret with contents of these files:<br><figure class="highlight plain"><figcaption><span>create secret generic kubernetes-dashboard-certs --from-file</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">2.下载并修改kubernetes-dashboard.yaml文件</span><br><span class="line"></span><br><span class="line">```wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/alternative/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure></p>
<p>在最后添加<figure class="highlight plain"><figcaption><span>NodePort```,注意缩进。</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```yml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure></p>
<p>3.部署启动kubernetes-dashboard<br><figure class="highlight plain"><figcaption><span>create -f kubernetes-dashboard.yaml```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">4.获取kubernetes-dashboard的访问端口和IP</span><br><span class="line"></span><br><span class="line">```kubectl -n kube-system get svc kubernetes-dashboard</span><br></pre></td></tr></table></figure></p>
<p>5.创建授权用户获取token</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">&gt;</span> <span class="string">dashboard-adminuser.yaml</span> <span class="string">&lt;&lt;EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">admin-user</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubectl</span> <span class="string">apply</span> <span class="string">-f</span>  <span class="string">dashboard-adminuser.yaml</span></span><br></pre></td></tr></table></figure>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">&gt;</span> <span class="string">admin-user-role-binding.yaml</span> <span class="string">&lt;&lt;EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">admin-user</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubectl</span> <span class="string">apply</span> <span class="string">-f</span>  <span class="string">admin-user-role-binding.yaml</span></span><br></pre></td></tr></table></figure>
<p>获取登录要用到的token<br><figure class="highlight plain"><figcaption><span>-n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '&#123;print $1&#125;')```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```kubectl create secret generic kubernetes-dashboard-certs --from-file=certs -n kube-system</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 install gitlab</title>
    <url>/archives/gitlab-install.html</url>
    <content><![CDATA[<p>目前gitlab官方给出的安装方式有很多种，普遍采用Omnibus包、Docker安装。官方说的😂<figure class="highlight plain"><figcaption><span>Omnibus 包安装 GitLab ，因为它安装起来更快、更容易升级版本，而且包含了其他安装方式所没有的可靠性功能。```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">## 1.Omnibus包安装，也就是rpm包、deb包安装😂</span><br><span class="line"></span><br><span class="line">## 1.安装</span><br><span class="line"></span><br><span class="line">### 1.CentOS</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line"># 安装依赖</span><br><span class="line">sudo yum install -y curl policycoreutils-python openssh-server</span><br><span class="line">sudo systemctl enable sshd</span><br><span class="line">sudo systemctl start sshd</span><br><span class="line"></span><br><span class="line"># 配置防火墙</span><br><span class="line">sudo firewall-cmd --permanent --add-service=http</span><br><span class="line">sudo systemctl reload firewalld</span><br><span class="line"></span><br><span class="line"># 添加官方的软件包源</span><br><span class="line"># curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpm.sh | sudo bash</span><br><span class="line"></span><br><span class="line"># 国内用户添加清华大学镜像站的源，下载速度会快些。</span><br><span class="line">sudo cat &gt; /etc/yum.repos.d/gitlab-ce.repo &lt;&lt;EOF</span><br><span class="line">[gitlab-ce]</span><br><span class="line">name=Gitlab CE Repository</span><br><span class="line">baseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line">EOF</span><br><span class="line">sudo yum makecache</span><br><span class="line"># 然后安装</span><br><span class="line">yum install -y gitlab-ee</span><br></pre></td></tr></table></figure></p>
<h3 id="2-Ubuntu"><a href="#2-Ubuntu" class="headerlink" title="2.Ubuntu"></a>2.Ubuntu</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br><span class="line">curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/null</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加清华大学的镜像站源 bionic是Ubuntu18.04 xenial是16.04，根据自己的Ubuntu发行版本修改一下下</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu bionic main</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install gitlab-ce</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="2-打补丁，补充汉化的补丁"><a href="#2-打补丁，补充汉化的补丁" class="headerlink" title="2.打补丁，补充汉化的补丁"></a>2.打补丁，补充汉化的补丁</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://gitlab.com/xhang/gitlab.git</span><br><span class="line"><span class="built_in">cd</span> gitlab</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取当前安装的版本</span></span><br><span class="line">gitlab_version=$(cat /opt/gitlab/embedded/service/gitlab-rails/VERSION)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成对应版本补丁文件</span></span><br><span class="line">git diff v<span class="variable">$&#123;gitlab_version&#125;</span> v<span class="variable">$&#123;gitlab_version&#125;</span>-zh &gt; ../<span class="variable">$&#123;gitlab_version&#125;</span>-zh.diff</span><br><span class="line"></span><br><span class="line">gitlab-ctl stop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打补丁的时候会提示一些补丁文件不存在，一定要跳过这些文件，不然后面reconfig的时候会报错的。</span></span><br><span class="line"><span class="comment"># 不要一路狂奔按Enter，要一个个按Y跳过这些补丁😂</span></span><br><span class="line">patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; <span class="variable">$&#123;gitlab_version&#125;</span>-zh.diff</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启gitlab</span></span><br><span class="line">gitlab-ctl start</span><br><span class="line">gitlab-ctl reconfigure</span><br></pre></td></tr></table></figure>
<h2 id="3-进行一些配置，gitlab的配置文件在-etc-gitlab-gitlab-rb"><a href="#3-进行一些配置，gitlab的配置文件在-etc-gitlab-gitlab-rb" class="headerlink" title="3.进行一些配置，gitlab的配置文件在/etc/gitlab/gitlab.rb"></a>3.进行一些配置，gitlab的配置文件在/etc/gitlab/gitlab.rb</h2><figure class="highlight rb"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改为你自己的域名或者IP，是单引号，而且前面的http不要改</span></span><br><span class="line">external_url  <span class="string">'http://gitlab.domain'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 邮件配置，选用外部SMTP服务器</span></span><br><span class="line">gitlab_rails[<span class="string">'smtp_enable'</span>] = <span class="literal">true</span></span><br><span class="line">gitlab_rails[<span class="string">'smtp_address'</span>] = <span class="string">"smtp.office365.com"</span></span><br><span class="line">gitlab_rails[<span class="string">'smtp_port'</span>] =  <span class="number">587</span></span><br><span class="line">gitlab_rails[<span class="string">'smtp_user_name'</span>] = <span class="string">"xxxx@outlook.com"</span></span><br><span class="line">gitlab_rails[<span class="string">'smtp_password'</span>] = <span class="string">"password"</span></span><br><span class="line">gitlab_rails[<span class="string">'smtp_authentication'</span>] = <span class="string">"login"</span></span><br><span class="line">gitlab_rails[<span class="string">'smtp_enable_starttls_auto'</span>] = <span class="literal">true</span></span><br><span class="line">gitlab_rails[<span class="string">'smtp_tls'</span>] = <span class="literal">true</span></span><br><span class="line">gitlab_rails[<span class="string">'gitlab_email_from'</span>] = <span class="string">'xxxx@outlook.com'</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>清理毒瘤app在sdcard目录下拉屎产生的文件夹</title>
    <url>/archives/fuch-rush-app-dir.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>国内的这些毒瘤app，不遵守Android开发的规范，把数据不写到自己的data目录下，在私自sdcard文件目录下拉屎。每次打开文件管理器的时候就会看到这些毒瘤app拉的一堆屎，真的恶心到家。打开无线调试模式通过一系列排除操作，总算清理出来了一堆一堆的屎。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># date: 2019-05-25</span></span><br><span class="line"><span class="comment"># rm rush app dir</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># touch</span></span><br><span class="line"><span class="built_in">cd</span> /sdcard</span><br><span class="line">touch backup .backups Documents .lmsdk obb QQBrowser Tasker .tbs amap backups</span><br><span class="line">touch baidu Bmap .com.taobao.dp com.tencent.mobileqq .DataStorage ICBC media</span><br><span class="line">touch msc ICBCWAPLog obj taobao Tasker tbs .UTSystemConfig .vivo alipay</span><br><span class="line"></span><br><span class="line"><span class="comment"># rm</span></span><br><span class="line"><span class="built_in">cd</span> /sdcard</span><br><span class="line">rm -rfbackup .backups Documents .lmsdk obb QQBrowser Tasker .tbs amap backups</span><br><span class="line">rm -rfbaidu Bmap .com.taobao.dp com.tencent.mobileqq .DataStorage ICBC media</span><br><span class="line">rm -rfmsc ICBCWAPLog obj taobao Tasker tbs .UTSystemConfig .vivo alipay</span><br><span class="line"></span><br><span class="line"><span class="comment"># MobileQQ</span></span><br><span class="line"><span class="built_in">cd</span> /sdcard/tencent/MobileQQ</span><br><span class="line">touch ArkApp WebViewCheck font_info <span class="built_in">log</span> ptv_template thumb .apollo</span><br><span class="line">touch shortvideo thumb2 QWallet artfilter early funcall data</span><br><span class="line">touch qav theme_pkg webso RedPacket emoji portrait qbiz .gift .signatureTemplate</span><br><span class="line">rm -rf ArkApp WebViewCheck font_info <span class="built_in">log</span> ptv_template thumb .apollo</span><br><span class="line">rm -rf shortvideo thumb2 QWallet artfilter early funcall data</span><br><span class="line">rm -rf qav theme_pkg webso RedPacket emoji portrait qbiz .gift .signatureTemplate</span><br><span class="line">touch ArkApp WebViewCheck font_info <span class="built_in">log</span> ptv_template thumb .apollo</span><br><span class="line">touch shortvideo thumb2 QWallet artfilter early funcall data</span><br><span class="line">touch qav theme_pkg webso RedPacket emoji portrait qbiz .gift .signatureTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># weixin</span></span><br><span class="line"><span class="built_in">cd</span> /sdcard/tencent/MicroMsg</span><br><span class="line">touch Game card wallet CDNTemp Handler wxacache CheckResUpdate SQLTrace fts</span><br><span class="line">touch newyear wxanewfiles FailMsgFileCache WeiXin  vusericon xlog wxafiles</span><br><span class="line">rm -rf Game card wallet CDNTemp Handler wxacache CheckResUpdate SQLTrace fts</span><br><span class="line">rm -rf newyear wxanewfiles FailMsgFileCache WeiXin  vusericon xlog wxafiles</span><br><span class="line">touch Game card wallet CDNTemp Handler wxacache CheckResUpdate SQLTrace fts</span><br><span class="line">touch newyear wxanewfiles FailMsgFileCache WeiXin  vusericon xlog wxafiles</span><br><span class="line"></span><br><span class="line"><span class="comment"># tencent</span></span><br><span class="line"><span class="built_in">cd</span> /sdcard/tencent/</span><br><span class="line">touch msflogs wtlogin mta</span><br><span class="line">rm -rf msflogs wtlogin mta</span><br><span class="line">touch msflogs wtlogin mta</span><br></pre></td></tr></table></figure>
<p>可以保存脚本执行，建议拆分成tasker任务，在添加触发规则。当你打开文件管理器的时候自动触发清理操作，这样再用文件管理器的时候，这些屎已经自动清理完了，看着也舒服了。</p>
<p>接下来添加tasker任务</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">TaskerData</span> <span class="attr">sr</span>=<span class="string">""</span> <span class="attr">dvi</span>=<span class="string">"1"</span> <span class="attr">tv</span>=<span class="string">"5.5.bf2"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Task</span> <span class="attr">sr</span>=<span class="string">"task18"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">cdate</span>&gt;</span>1558781710970<span class="tag">&lt;/<span class="name">cdate</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">edate</span>&gt;</span>1558782246852<span class="tag">&lt;/<span class="name">edate</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">id</span>&gt;</span>18<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">nme</span>&gt;</span>清理垃圾<span class="tag">&lt;/<span class="name">nme</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">pri</span>&gt;</span>100<span class="tag">&lt;/<span class="name">pri</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act0"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">code</span>&gt;</span>123<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">se</span>&gt;</span>false<span class="tag">&lt;/<span class="name">se</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>cd /sdcard</span><br><span class="line">touch backup .backups Documents .lmsdk obb QQBrowser Tasker .tbs amap backups</span><br><span class="line">touch baidu Bmap .com.taobao.dp com.tencent.mobileqq .DataStorage ICBC media</span><br><span class="line">touch msc ICBCWAPLog obj taobao Tasker tbs .UTSystemConfig .vivo alipay</span><br><span class="line">rm -rf backup .backups Documents .lmsdk obb QQBrowser Tasker .tbs amap backups</span><br><span class="line">rm -rf baidu Bmap .com.taobao.dp com.tencent.mobileqq .DataStorage ICBC media</span><br><span class="line">rm -rf msc ICBCWAPLog obj taobao Tasker tbs .UTSystemConfig .vivo alipay<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act1"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">code</span>&gt;</span>123<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>cd /sdcardtencent/</span><br><span class="line">touch msflogs wtlogin mta</span><br><span class="line">rm -rf msflogs wtlogin mta</span><br><span class="line">touch msflogs wtlogin mta<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act2"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">code</span>&gt;</span>123<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">se</span>&gt;</span>false<span class="tag">&lt;/<span class="name">se</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>cd /sdcardtencent/MicroMsg</span><br><span class="line">touch Game card wallet CDNTemp Handler wxacache CheckResUpdate SQLTrace fts</span><br><span class="line">touch newyear wxanewfiles FailMsgFileCache WeiXin  vusericon xlog wxafiles</span><br><span class="line">rm -rf Game card wallet CDNTemp Handler wxacache CheckResUpdate SQLTrace fts</span><br><span class="line">rm -rf newyear wxanewfiles FailMsgFileCache WeiXin  vusericon xlog wxafiles</span><br><span class="line">touch Game card wallet CDNTemp Handler wxacache CheckResUpdate SQLTrace fts</span><br><span class="line">touch newyear wxanewfiles FailMsgFileCache WeiXin  vusericon xlog wxafiles<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act3"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">code</span>&gt;</span>123<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">se</span>&gt;</span>false<span class="tag">&lt;/<span class="name">se</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>cd /sdcardtencent/MobileQQ</span><br><span class="line">touch ArkApp WebViewCheck font_info log ptv_template thumb .apollo</span><br><span class="line">touch shortvideo thumb2 QWallet artfilter early funcall data</span><br><span class="line">touch qav theme_pkg webso RedPacket emoji portrait qbiz .gift .signatureTemplate</span><br><span class="line">rm -rf ArkApp WebViewCheck font_info log ptv_template thumb .apollo</span><br><span class="line">rm -rf shortvideo thumb2 QWallet artfilter early funcall data</span><br><span class="line">rm -rf qav theme_pkg webso RedPacket emoji portrait qbiz .gift .signatureTemplate</span><br><span class="line">touch ArkApp WebViewCheck font_info log ptv_template thumb .apollo</span><br><span class="line">touch shortvideo thumb2 QWallet artfilter early funcall data</span><br><span class="line">touch qav theme_pkg webso RedPacket emoji portrait qbiz .gift .signatureTemplate<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Task</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">TaskerData</span>&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>android</tag>
        <tag>安卓刷机</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 使用 kubeadm 部署 kubernetes</title>
    <url>/archives/CentOS7-install-k8s.html</url>
    <content><![CDATA[<h2 id="0-准备"><a href="#0-准备" class="headerlink" title="0.准备"></a>0.准备</h2><p>1.临时关闭swap、SELinux、防火墙。官方建议这么做。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX= disabled/'</span> /etc/selinux/config</span><br><span class="line">systemctl <span class="built_in">disable</span> iptables-services firewalld</span><br><span class="line">systemctl stop iptables-services firewalld</span><br></pre></td></tr></table></figure>
<p>2.打开bridge-nf-call-iptables</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/sysctl.d/99-kubernetes-cri.conf &lt;&lt;EOF</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">enet.ipv4.ip_forward                = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>
<p>3.加载br_netfilter内核模块，安装docker后也会默认开启</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">modprobe br_netfilter</span><br><span class="line">lsmod | grep br_netfilter</span><br></pre></td></tr></table></figure>
<h2 id="1-安装docker"><a href="#1-安装docker" class="headerlink" title="1.安装docker"></a>1.安装docker</h2><p>1.安装 yum-utils 提供 yum-config-manager 工具<br>devicemapper存储驱动依赖 device-mapper-persistent-data 和 lvm2<br><figure class="highlight plain"><figcaption><span>yum install -y yum-utils device-mapper-persistent-data lvm2```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">2.添加aliyun软件包源</span><br><span class="line">```sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></p>
<p>3.安装docker-ce-stable<br>官方文档写了建议安装18.06.2，其他版本的docker支持的不太好<br>On each of your machines, install Docker. Version 18.06.2 is recommended, but 1.11, 1.12, 1.13, 17.03 and 18.09 are known to work as well. Keep track of the latest verified Docker version in the Kubernetes release notes.<br><figure class="highlight plain"><figcaption><span>yum list docker-ce.x86_64  --showduplicates |sort -r``` 选择```docker-ce-18.06.1.ce-3.el7```版</span></figcaption><table><tr><td class="code"><pre><span class="line">```yum install -y docker-ce-18.06.1.ce-3.el7</span><br></pre></td></tr></table></figure></p>
<p>4.添加Docker 用户和用户组(可选)<br><figure class="highlight plain"><figcaption><span>usermod -aG docker $USER```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">5.修改docker daemon配置文件</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">mkdir -p /etc/docker/</span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p>不修改的话后面初始化的时候会warning😂</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[WARNING IsDockerSystemdCheck]: detected <span class="string">"cgroupfs"</span> as the Docker cgroup driver. The recommended driver is <span class="string">"systemd"</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br></pre></td></tr></table></figure>
<p>6.启动docker并添加到开机自启</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line">systemctl restart docker</span><br><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure>
<h2 id="2-在国外服务器下载所需要的镜像并传输回国内服务器上"><a href="#2-在国外服务器下载所需要的镜像并传输回国内服务器上" class="headerlink" title="2.在国外服务器下载所需要的镜像并传输回国内服务器上"></a>2.在国外服务器下载所需要的镜像并传输回国内服务器上</h2><p>我自己在aws上做了个非官方k8s镜像站，仅仅包含了kubeadm初始化k8s集群时所需要的镜像<a href="https://images.k8s.502.li" target="_blank" rel="noopener">mirror</a>，没有对镜像做任何修改，定时任务每周拉取最新的镜像。你信得过我的话也可以去我的镜像站下载。上面log有校验的校验码，下载后记得校验一下。😂。我使用IDM下载，开启16个线程下载速度能打到15Mb/s。HTTPS传输，不用注册。国内的一些博主用百度云😂来分享这些镜像，十分不友好。这才是我建这个镜像站的原因。<br>下载完成后使用 <code>docker load &lt; k8s.image.tar.gz</code> 就能加载镜像，无需解压。</p>
<p>你也可以自己在国外的服务器上下载这些镜像并传输回国内的服务器上。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@k8s-master ~</span><br><span class="line">╰─<span class="comment"># kubeadm config images pull</span></span><br><span class="line">[config/images] Pulled k8s.gcr.io/kube-apiserver:v1.14.1</span><br><span class="line">[config/images] Pulled k8s.gcr.io/kube-controller-manager:v1.14.1</span><br><span class="line">[config/images] Pulled k8s.gcr.io/kube-scheduler:v1.14.1</span><br><span class="line">[config/images] Pulled k8s.gcr.io/kube-proxy:v1.14.1</span><br><span class="line">[config/images] Pulled k8s.gcr.io/pause:3.1</span><br><span class="line">[config/images] Pulled k8s.gcr.io/etcd:3.3.10</span><br><span class="line">[config/images] Pulled k8s.gcr.io/coredns:1.3.1</span><br><span class="line"><span class="comment"># 导出镜像</span></span><br><span class="line">docker save -o k8s.tar $(docker images | grep B | cut -d <span class="string">' '</span> -f1)</span><br><span class="line">gzip k8s.tar k8s.tar.gz</span><br></pre></td></tr></table></figure>
<p>将这些镜像导出并压缩，传输回国内。http方式多线程传输最快。IDM64线程能跑满带宽😂，不到一分钟就下载到本地。然后再scp传输回国内的云服务器上。grep B是为了过滤掉输出结果第一行显示的 <figure class="highlight plain"><figcaption><span>TAG  IMAGE ID  CREATED  SIZE```😂</span></figcaption><table><tr><td class="code"><pre><span class="line">在使用docker save的时候，要指定镜像的名称，不要指定镜像的ID，不然你装载镜像的时候全是node的镜像，是启动不起来的😥</span><br><span class="line">ps：第一次我使用的是```docker save $(docker images -q)```导出了所有的镜像。在装入镜像的时候发现镜像NAME全是node😂。使用```docker images | grep B | cut -d &apos; &apos; -f1```过滤出的是带NAME的镜像。</span><br><span class="line"></span><br><span class="line">```docker save -o k8s.tar $(docker images | grep B | cut -d &apos; &apos; -f1) | gzip k8s.tar k8s.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>然后你在国内的服务器上执行<code>docker load &lt; k8s.tar.gz</code>，不用手动 gzip 解压，docker load 会自动解压并把镜像加载进去。</p>
<h2 id="3-安装-kubelet-kubeadm-kubectl"><a href="#3-安装-kubelet-kubeadm-kubectl" class="headerlink" title="3.安装 kubelet kubeadm kubectl"></a>3.安装 kubelet kubeadm kubectl</h2><p>添加国内阿里云的kubernetes镜像站点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat&gt;&gt;/etc/yum.repos.d/kubrenetes.repo&lt;&lt;EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes Repo</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">yum install -y kubelet kubeadm kubectl</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure>
<h2 id="4-初始化集群"><a href="#4-初始化集群" class="headerlink" title="4.初始化集群"></a>4.初始化集群</h2><p>使用kubeadm init初始化kubernetes集群，可以指定配置文件，把IP替换为这台机器的内网IP，要k8s-node节点能够访问得到IP。<br><figure class="highlight plain"><figcaption><span>init --pod-network-cidr</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">最后初始化成功的话会出现以下:</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: ********</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join IP:6443 --token ******i311md.mhwgl9rr3q26rc4n****** \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:2**********2a</span><br></pre></td></tr></table></figure></p>
<p>然后查看一下各个容器的运行状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@k8s-master ~</span><br><span class="line">╰─<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">38d9c698ec37        efb3887b411d           <span class="string">"kube-controller-man…"</span>   7 minutes ago       Up 7 minutes                            k8s_kube-controller-manager_kube-controller-manager-k8s-master_kube-system_f423ac50e24b65e6d66fe37e6d721912_0</span><br><span class="line">c273979e75b6        8931473d5bdb           <span class="string">"kube-scheduler --bi…"</span>   7 minutes ago       Up 7 minutes                            k8s_kube-scheduler_kube-scheduler-k8s-master_kube-system_f44110a0ca540009109bfc32a7eb0baa_0</span><br><span class="line">71f1f40dfa9e        cfaa4ad74c37           <span class="string">"kube-apiserver --ad…"</span>   7 minutes ago       Up 7 minutes                            k8s_kube-apiserver_kube-apiserver-k8s-master_kube-system_d57282173a211f69b917251534760047_0</span><br><span class="line">37636f04f5d6        2c4adeb21b4f           <span class="string">"etcd --advertise-cl…"</span>   7 minutes ago       Up 7 minutes                            k8s_etcd_etcd-k8s-master_kube-system_dcd3914b600c5e8e86b2026688cc6dc5_0</span><br><span class="line">48fc68b067de        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-scheduler-k8s-master_kube-system_f44110a0ca540009109bfc32a7eb0baa_0</span><br><span class="line">3c9f8e8224cf        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-apiserver-k8s-master_kube-system_d57282173a211f69b917251534760047_0</span><br><span class="line">b4903d8f18ee        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-controller-manager-k8s-master_kube-system_f423ac50e24b65e6d66fe37e6d721912_0</span><br><span class="line">f6d2cd0b03cd        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 7 minutes ago       Up 7 minutes                            k8s_POD_etcd-k8s-master_kube-system_dcd3914b600c5e8e86b2026688cc6dc5_0</span><br><span class="line">74a3699833bc        20a2d7035165           <span class="string">"/usr/local/bin/kube…"</span>   9 minutes ago       Up 4 seconds                            k8s_kube-proxy_kube-proxy-g4nd4_kube-system_afc4ba92-7657-11e9-b684-2aabd22d242a_1</span><br><span class="line">ba61bed68ecc        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 9 minutes ago       Up 9 minutes                            k8s_POD_kube-proxy-g4nd4_kube-system_afc4ba92-7657-11e9-b684-2aabd22d242a_4</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="5-将node加入到master管理当中来"><a href="#5-将node加入到master管理当中来" class="headerlink" title="5.将node加入到master管理当中来"></a>5.将node加入到master管理当中来</h2><p>node节点的安装过程和master一样，只是在最后一步时不相同。master为init初始化k8s集群，而node节点为join集群当中来。安装docker、kubelet 、kubeadm 、kubectl好，并导入所需要的镜像。再执行</p>
<figure class="highlight plain"><figcaption><span>join IP:6443 --token ************ \--discovery-token-ca-cert-hashsha256:******```</span></figcaption><table><tr><td class="code"><pre><span class="line">也就是master节点初始化成功后生成的那个😂。注意这个token是有有效期的，默认是3h。也可以手动生成token给node加入master来用。ttl为token有效期，为0的话就是永久生效。</span><br><span class="line">```kubeadm token create $(kubeadm token generate)  --print-join-command --ttl=0</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>kubeadm</tag>
        <tag>kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu 1804 使用 kubeadm 部署 kubernetes</title>
    <url>/archives/install-k8s-ubuntu18-04.html</url>
    <content><![CDATA[<p>注意: 这个部署在了digital ocean的VPS上，国内的机器需要代理。</p>
<h2 id="1-主机要求"><a href="#1-主机要求" class="headerlink" title="1.主机要求"></a>1.主机要求</h2><p>0.硬件要求2CPU 2GB RAM</p>
<p>1.临时关闭swap<br><figure class="highlight plain"><figcaption><span>-a```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">2.打开bridge-nf-call-iptables</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">cat &gt; /etc/sysctl.d/99-kubernetes-cri.conf &lt;&lt;EOF</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">enet.ipv4.ip_forward                = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure></p>
<p>3.加载br_netfilter内核模块，安装docker后会默认开启</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">modprobe br_netfilter</span><br><span class="line">lsmod | grep br_netfilter</span><br></pre></td></tr></table></figure>
<p>4.临时关闭一下SELinux，怎么关闭的？？貌似我的digital ocean Ubuntu18.04没有安装SELinux🤔</p>
<p>在网上找了一篇文章临时关闭SELinux的<a href="https://www.revsys.com/writings/quicktips/turn-off-selinux.html" target="_blank" rel="noopener">turn-off-selinux</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Test <span class="keyword">if</span> SELinux is running</span><br><span class="line">You can <span class="built_in">test</span> to see <span class="keyword">if</span> SELinux is currently enabled with the following <span class="built_in">command</span>:</span><br><span class="line"></span><br><span class="line">selinuxenabled &amp;&amp; <span class="built_in">echo</span> enabled || <span class="built_in">echo</span> disabled</span><br><span class="line">Turning off SELinux temporarily</span><br><span class="line">Disabling SELinux temporarily is the easiest way to determine <span class="keyword">if</span> the problem you are experiencing is related to your SELinux settings. To turn it off, you will need to become the root users on your system and execute the following <span class="built_in">command</span>:</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /sys/fs/selinux/enforce</span><br><span class="line">This temporarily turns off SELinux until it is either re-enabled or the system is rebooted. To turn it back on you simply execute this <span class="built_in">command</span>:</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /sys/fs/selinux/enforce</span><br><span class="line">As you can see from these commands what you are doing is setting the file /selinux/enforce to either <span class="string">'1'</span> or <span class="string">'0'</span> to denote <span class="string">'true'</span> and <span class="string">'false'</span>.</span><br></pre></td></tr></table></figure>
<p>5.VPS需要在国外或代理，因为需要下载gcr上的镜像。国内用户可以考虑装个软路由然后设置为旁路网关，这样能透明代理，只需要修改部署机器的网关为软路由即可。也可以在部署机器上安装代理，不过比较麻烦和坑。还是软路由、旁路网关、透明代理三连方便😂。</p>
<hr>
<h2 id="2-安装Docker或其他容器运行时"><a href="#2-安装Docker或其他容器运行时" class="headerlink" title="2.安装Docker或其他容器运行时"></a>2.安装Docker或其他容器运行时</h2><p>官方文档写了建议安装18.06.2，其他版本的docker支持的不太好<br>On each of your machines, install Docker. Version 18.06.2 is recommended, but 1.11, 1.12, 1.13, 17.03 and 18.09 are known to work as well. Keep track of the latest verified Docker version in the Kubernetes release notes.</p>
<h3 id="1-使用kubernetes官方建议的安装方式😂"><a href="#1-使用kubernetes官方建议的安装方式😂" class="headerlink" title="1.使用kubernetes官方建议的安装方式😂"></a>1.使用kubernetes官方建议的安装方式😂</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Set up the repository:</span></span><br><span class="line"><span class="comment">### Install packages to allow apt to use a repository over HTTPS</span></span><br><span class="line">apt-get update &amp;&amp; apt-get install apt-transport-https ca-certificates curl software-properties-common</span><br><span class="line"></span><br><span class="line"><span class="comment">### Add Docker’s official GPG key</span></span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -</span><br><span class="line"></span><br><span class="line"><span class="comment">### Add Docker apt repository.</span></span><br><span class="line">add-apt-repository <span class="string">"deb [arch=amd64] https://download.docker.com/linux/ubuntu <span class="variable">$(lsb_release -cs)</span> stable"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Install Docker CE.</span></span><br><span class="line">apt-get update &amp;&amp; apt-get install docker-ce=18.06.2~ce~3-0~ubuntu</span><br></pre></td></tr></table></figure>
<h3 id="2-修改一下Docker的daemon-json文件"><a href="#2-修改一下Docker的daemon-json文件" class="headerlink" title="2.修改一下Docker的daemon.json文件"></a>2.修改一下Docker的daemon.json文件</h3><p>在这里需要把<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```bash</span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p>不修改的话后面初始化的时候会warning😂</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[WARNING IsDockerSystemdCheck]: detected <span class="string">"cgroupfs"</span> as the Docker cgroup driver. The recommended driver is <span class="string">"systemd"</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br></pre></td></tr></table></figure>
<p>最后将docker加入开机自启，并重启一下docker<br><figure class="highlight plain"><figcaption><span>-p</span><a href="/etc/systemd/system/docker.service.d```">link</a></figcaption><table><tr><td class="code"><pre><span class="line">```systemctl daemon-reload</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><figcaption><span>restart docker```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">3.(可选)CRI-O 容器运行时</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">#Prerequisites</span><br><span class="line">modprobe overlay</span><br><span class="line">modprobe br_netfilter</span><br><span class="line"></span><br><span class="line"># Setup required sysctl params, these persist across reboots.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Install prerequisites</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install software-properties-common</span><br><span class="line"></span><br><span class="line">add-apt-repository ppa:projectatomic/ppa</span><br><span class="line">apt-get update</span><br><span class="line"></span><br><span class="line"># Install CRI-O</span><br><span class="line">apt-get install cri-o-1.11</span><br><span class="line"></span><br><span class="line"># Start CRI-O</span><br><span class="line">systemctl start crio</span><br></pre></td></tr></table></figure>
<p>4.(可选)Containerd</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prerequisites</span></span><br><span class="line">modprobe overlay</span><br><span class="line">modprobe br_netfilter</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup required sysctl params, these persist across reboots.</span></span><br><span class="line">cat &gt; /etc/sysctl.d/99-kubernetes-cri.conf &lt;&lt;EOF</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install containerd</span></span><br><span class="line"><span class="comment">## Set up the repository</span></span><br><span class="line"><span class="comment">### Install packages to allow apt to use a repository over HTTPS</span></span><br><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https ca-certificates curl software-properties-common</span><br><span class="line"></span><br><span class="line"><span class="comment">### Add Docker’s official GPG key</span></span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -</span><br><span class="line"></span><br><span class="line"><span class="comment">### Add Docker apt repository.</span></span><br><span class="line">add-apt-repository \</span><br><span class="line">    <span class="string">"deb [arch=amd64] https://download.docker.com/linux/ubuntu \</span></span><br><span class="line"><span class="string">    <span class="variable">$(lsb_release -cs)</span> \</span></span><br><span class="line"><span class="string">    stable"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Install containerd</span></span><br><span class="line">apt-get update &amp;&amp; apt-get install -y containerd.io</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure containerd</span></span><br><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default &gt; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Restart containerd</span></span><br><span class="line">systemctl restart containerd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用systemd</span></span><br><span class="line">systemd</span><br><span class="line">To use the systemd cgroup driver, <span class="built_in">set</span> plugins.cri.systemd_cgroup = <span class="literal">true</span> <span class="keyword">in</span> /etc/containerd/config.toml. When using kubeadm, manually configure the cgroup driver <span class="keyword">for</span> kubelet as well</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="3-安装kubelet-kubeadm-kubectl"><a href="#3-安装kubelet-kubeadm-kubectl" class="headerlink" title="3.安装kubelet kubeadm kubectl"></a>3.安装kubelet kubeadm kubectl</h2><p>官方推荐的安装方式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install packages to allow apt to use a repository over HTTPS</span></span><br><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https curl</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add Google’s official GPG key</span></span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add kubernetes apt repository.</span></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://apt.kubernetes.io/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">apt-get update &amp;&amp; apt-get install -y kubelet kubeadm kubectl</span><br><span class="line">apt-mark hold kubelet kubeadm kubectl</span><br><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart kubelet</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="4-初始化kubernetes集群"><a href="#4-初始化kubernetes集群" class="headerlink" title="4.初始化kubernetes集群"></a>4.初始化kubernetes集群</h2><p>可以先把所需要的镜像pull下来<br><figure class="highlight plain"><figcaption><span>config images pull```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">执行期间不能中断shell，不然重新弄得话很头疼，最好先开个tmux</span><br><span class="line">使用kubeadm init初始化kubernetes集群，可以指定配置文件，把IP替换为这台机器的内网IP，要k8s-node节点能够访问得到</span><br><span class="line">```kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=IP</span><br></pre></td></tr></table></figure></p>
<p>最后初始化成功的话会出现以下，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the label <span class="string">"node-role.kubernetes.io/master=''"</span></span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: i311md.mhwgl9rr3q26rc4n</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="keyword">in</span> order <span class="keyword">for</span> nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation <span class="keyword">for</span> all node client certificates <span class="keyword">in</span> the cluster</span><br><span class="line">[bootstrap-token] creating the <span class="string">"cluster-info"</span> ConfigMap <span class="keyword">in</span> the <span class="string">"kube-public"</span> namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join IP:6443 --token i311md.mhwgl9rr3q26rc4n \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:21db38130a6868b5f07be1435c5ad29c0880fea481c50005d654de06fd95db2a</span><br></pre></td></tr></table></figure>
<p>然后查看一下各个容器的运行状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@k8s-master ~</span><br><span class="line">╰─<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">38d9c698ec37        efb3887b411d           <span class="string">"kube-controller-man…"</span>   7 minutes ago       Up 7 minutes                            k8s_kube-controller-manager_kube-controller-manager-k8s-master_kube-system_f423ac50e24b65e6d66fe37e6d721912_0</span><br><span class="line">c273979e75b6        8931473d5bdb           <span class="string">"kube-scheduler --bi…"</span>   7 minutes ago       Up 7 minutes                            k8s_kube-scheduler_kube-scheduler-k8s-master_kube-system_f44110a0ca540009109bfc32a7eb0baa_0</span><br><span class="line">71f1f40dfa9e        cfaa4ad74c37           <span class="string">"kube-apiserver --ad…"</span>   7 minutes ago       Up 7 minutes                            k8s_kube-apiserver_kube-apiserver-k8s-master_kube-system_d57282173a211f69b917251534760047_0</span><br><span class="line">37636f04f5d6        2c4adeb21b4f           <span class="string">"etcd --advertise-cl…"</span>   7 minutes ago       Up 7 minutes                            k8s_etcd_etcd-k8s-master_kube-system_dcd3914b600c5e8e86b2026688cc6dc5_0</span><br><span class="line">48fc68b067de        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-scheduler-k8s-master_kube-system_f44110a0ca540009109bfc32a7eb0baa_0</span><br><span class="line">3c9f8e8224cf        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-apiserver-k8s-master_kube-system_d57282173a211f69b917251534760047_0</span><br><span class="line">b4903d8f18ee        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-controller-manager-k8s-master_kube-system_f423ac50e24b65e6d66fe37e6d721912_0</span><br><span class="line">f6d2cd0b03cd        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 7 minutes ago       Up 7 minutes                            k8s_POD_etcd-k8s-master_kube-system_dcd3914b600c5e8e86b2026688cc6dc5_0</span><br><span class="line">74a3699833bc        20a2d7035165           <span class="string">"/usr/local/bin/kube…"</span>   9 minutes ago       Up 4 seconds                            k8s_kube-proxy_kube-proxy-g4nd4_kube-system_afc4ba92-7657-11e9-b684-2aabd22d242a_1</span><br><span class="line">ba61bed68ecc        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 9 minutes ago       Up 9 minutes                            k8s_POD_kube-proxy-g4nd4_kube-system_afc4ba92-7657-11e9-b684-2aabd22d242a_4</span><br></pre></td></tr></table></figure>
<hr>
<p>我第一次初始化因为shell中断失败了😱报错</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[kubelet-check] Initial timeout of 40s passed.</span><br><span class="line">error execution phase upload-config/kubelet: Error writing Crisocket information <span class="keyword">for</span> the control-plane node: timed out waiting <span class="keyword">for</span> the condition</span><br></pre></td></tr></table></figure>
<p>第二次初始化还是失败😭</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">╭─root@k8s-master ~</span><br><span class="line">╰─<span class="comment"># kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=</span></span><br><span class="line">[init] Using Kubernetes version: v1.14.1</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">'kubeadm config images pull'</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[certs] Using certificateDir folder <span class="string">"/etc/kubernetes/pki"</span></span><br><span class="line">[certs] Generating <span class="string">"etcd/ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/server"</span> certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed <span class="keyword">for</span> DNS names [k8s-master localhost] and IPs [IP 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/peer"</span> certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed <span class="keyword">for</span> DNS names [k8s-master localhost] and IPs [IP 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/healthcheck-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver-etcd-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver-kubelet-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver"</span> certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed <span class="keyword">for</span> DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 IP]</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"sa"</span> key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">"/etc/kubernetes"</span></span><br><span class="line">[kubeconfig] Writing <span class="string">"admin.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"kubelet.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> <span class="built_in">local</span> etcd <span class="keyword">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[<span class="built_in">wait</span>-control-plane] Waiting <span class="keyword">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="string">"/etc/kubernetes/manifests"</span>. This can take up to 4m0s</span><br><span class="line">[kubelet-check] Initial timeout of 40s passed.</span><br><span class="line">[kubelet-check] It seems like the kubelet isn<span class="string">'t running or healthy.</span></span><br><span class="line"><span class="string">[kubelet-check] The HTTP call equal to '</span>curl -sSL http://localhost:10248/healthz<span class="string">' failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.</span></span><br><span class="line"><span class="string">[kubelet-check] It seems like the kubelet isn'</span>t running or healthy.</span><br><span class="line">[kubelet-check] The HTTP call equal to <span class="string">'curl -sSL http://localhost:10248/healthz'</span> failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.</span><br><span class="line">[kubelet-check] It seems like the kubelet isn<span class="string">'t running or healthy.</span></span><br><span class="line"><span class="string">[kubelet-check] The HTTP call equal to '</span>curl -sSL http://localhost:10248/healthz<span class="string">' failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.</span></span><br><span class="line"><span class="string">[kubelet-check] It seems like the kubelet isn'</span>t running or healthy.</span><br><span class="line">[kubelet-check] The HTTP call equal to <span class="string">'curl -sSL http://localhost:10248/healthz'</span> failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.</span><br><span class="line">[kubelet-check] It seems like the kubelet isn<span class="string">'t running or healthy.</span></span><br><span class="line"><span class="string">[kubelet-check] The HTTP call equal to '</span>curl -sSL http://localhost:10248/healthz<span class="string">' failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Unfortunately, an error has occurred:</span></span><br><span class="line"><span class="string">        timed out waiting for the condition</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This error is likely caused by:</span></span><br><span class="line"><span class="string">        - The kubelet is not running</span></span><br><span class="line"><span class="string">        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:</span></span><br><span class="line"><span class="string">        - '</span>systemctl status kubelet<span class="string">'</span></span><br><span class="line"><span class="string">        - '</span>journalctl -xeu kubelet<span class="string">'</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Additionally, a control plane component may have crashed or exited when started by the container runtime.</span></span><br><span class="line"><span class="string">To troubleshoot, list all containers using your preferred container runtimes CLI, e.g. docker.</span></span><br><span class="line"><span class="string">Here is one example how you may list all Kubernetes containers running in docker:</span></span><br><span class="line"><span class="string">        - '</span>docker ps -a | grep kube | grep -v pause<span class="string">'</span></span><br><span class="line"><span class="string">        Once you have found the failing container, you can inspect its logs with:</span></span><br><span class="line"><span class="string">        - '</span>docker logs CONTAINERID<span class="string">'</span></span><br><span class="line"><span class="string">error execution phase wait-control-plane: couldn'</span>t initialize a Kubernetes cluster</span><br></pre></td></tr></table></figure>
<p><del>~如果你初始化失败的话，那就删除所有的容器，删除/etc/kubernetes/<em> 删除 /var/lib/etcd/</em></del>~<br>其实进行kubeadm reset重置再执行kubeadm init也行，这样更方便些😂<br>然后再重新初始化<br><figure class="highlight plain"><figcaption><span>init --pod-network-cidr</span></figcaption><table><tr><td class="code"><pre><span class="line">加个参数```--ignore-preflight-errors=all```重新初始化</span><br><span class="line"></span><br><span class="line">----</span><br><span class="line"></span><br><span class="line">## 5.将k8s-node节点加入到k8s-master</span><br><span class="line"></span><br><span class="line">node节点也是和master节点一样，安装docker，kubelet kubeadm kubectl。不过最后不需要初始化集群，不用kubeadm init，而是直接加入到master当中来。如果master初始化后找不到kubeadm join所需要的token，可以使用以下命令重新生成一个token,注意 tty参数为0则这个token永久不会失效。可以自定义失效期限。</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">kubeadm token generate</span><br><span class="line">kubeadm token create ljfmu1.5kek1jy2xdb8sopv  --print-join-command --ttl=0</span><br><span class="line">kubeadm token create $(kubeadm token generate)  --print-join-command --ttl=0</span><br></pre></td></tr></table></figure></p>
<p>只需要一个命令就可以将k8s-node节点加入到master的管理之下<br><figure class="highlight plain"><figcaption><span>join IP:6443 --token ljfmu1.5kek1jy2xdb8sopv --discovery-token-ca-cert-hash sha256:3b18b4cc1debc63d57e03da52424a3b3bacf03cc290b94cbe5b6aaf9c152f0cf```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">加入成功后会提示以下内容😘</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.14&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; on the control-plane to see this node join the cluster.</span><br></pre></td></tr></table></figure></p>
<p>注意: 如果hostname如果是随机生成的带有<figure class="highlight plain"><figcaption><span>```hostnamectl set-hostname k8s-node2 && bash```设置一下下😂</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```bash</span><br><span class="line">name: Invalid value: &quot;vm_158_35_centos&quot;: a DNS-1123 subdomain must consist of lower case alphanumeric characters, &apos;-&apos; or &apos;.&apos;, and must start and end with an alphanumeric character (e.g. &apos;example.com&apos;, regex used for validation is &apos;[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*&apos;)</span><br></pre></td></tr></table></figure></p>
<hr>
]]></content>
      <tags>
        <tag>kubeadm</tag>
        <tag>kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix监控服务</title>
    <url>/archives/zabbix-compose.html</url>
    <content><![CDATA[<h2 id="0-运行环境"><a href="#0-运行环境" class="headerlink" title="0.运行环境"></a>0.运行环境</h2><p>(a). 要部署在docker容器中的服务：<figure class="highlight plain"><figcaption><span>、```zabbix-server``` 、 ```zabbix-web``` 、 ```zabbix-java-gateway```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">(b). zabbix服务端机器所需软件包版本</span><br><span class="line">OS: CentOS Linux release 7.6.1810 (Core)</span><br><span class="line"></span><br><span class="line">```ini</span><br><span class="line">docker-ce-stable 18.09.6</span><br><span class="line">docker-compose 1.24.0</span><br><span class="line">MySQL-server 5.7</span><br><span class="line">zabbix-server 4.0.7 LTS</span><br><span class="line">zabbix-web 4.0.7 LTS</span><br><span class="line">zabbix-get 4.0.7 LTS</span><br><span class="line">zabbix-java-gateway 4.0.7 LTS</span><br></pre></td></tr></table></figure></p>
<p>(c). zabbix服务端机器所需的docker镜像</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql:5.7</span><br><span class="line">zabbix/zabbix-java-gateway:centos-4.0-latest</span><br><span class="line">zabbix/zabbix-server-mysql:centos-4.0-latest</span><br><span class="line">zabbix/zabbix-web-nginx-mysql:centos-4.0-latest</span><br></pre></td></tr></table></figure>
<p>(d). 被监控机器所需软件包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CentOS  zabbix-agent 4.0.7 LTS</span><br><span class="line">Windows Server 2012  zabbix_agent-4.0.7-win-amd64-openssl LTS</span><br></pre></td></tr></table></figure>
<h2 id="1-安装docker和docker-compose"><a href="#1-安装docker和docker-compose" class="headerlink" title="1.安装docker和docker-compose"></a>1.安装docker和docker-compose</h2><p>1.安装 yum-utils 提供 yum-config-manager 工具<br>devicemapper存储驱动依赖 device-mapper-persistent-data 和 lvm2<br><figure class="highlight plain"><figcaption><span>yum install -y yum-utils device-mapper-persistent-data lvm2```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">2.添加aliyun软件包源</span><br><span class="line">```sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></p>
<p>3.安装docker-ce-stable<br><figure class="highlight plain"><figcaption><span>yum list docker-ce.x86_64  --showduplicates |sort -r``` 选择docker-ce-stable版</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">4.添加Docker 用户和用户组</span><br><span class="line">```sudo usermod -aG docker $USER</span><br></pre></td></tr></table></figure></p>
<p>(a)或使用官方脚本安装，aliyun镜像站点<br><figure class="highlight plain"><figcaption><span>curl -fsSL</span><a href="https://get.docker.com" target="_blank" rel="noopener">| bash -s docker --mirror Aliyun```</a></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">6.启动docker并添加到开机自启</span><br><span class="line">sudo systemctl start docker.service</span><br><span class="line">sudo systemctl enable docker.service</span><br><span class="line">5.安装docker-compose，需要在GitHub上下载二进制文件，速度会很慢，先下载到本地再scp复制到/usr/local/bin</span><br><span class="line">```sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><figcaption><span>chmod +x</span><a href="/usr/local/bin/docker-compose```">link</a></figcaption><table><tr><td class="code"><pre><span class="line">```sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose</span><br></pre></td></tr></table></figure>
<p>6.使用 docker 镜像加速器来加速下载 docker 镜像下载速度<br><figure class="highlight plain"><figcaption><span>curl -sSL</span><a href="https://get.daocloud.io/daotools/set_mirror.sh" target="_blank" rel="noopener">| sh -s http://f1361db2.m.daocloud.io```</a></figcaption><table><tr><td class="code"><pre><span class="line">```sudo systemctl restart docker.service</span><br></pre></td></tr></table></figure></p>
<h2 id="2-使用docker-compose启动"><a href="#2-使用docker-compose启动" class="headerlink" title="2.使用docker-compose启动"></a>2.使用docker-compose启动</h2><p>1.复制zabbix-compose.yml文件到工程目录<br>2.按需修改docker-compose文件中的环境变量、PSAAWORD等信息</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'3.0'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">mysql:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql:5.7</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">MYSQL_USER:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_DATABASE:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_PASSWORD:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">zabbix</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/data/mysql:/var/lib/mysql</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:3306:3306</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zabbix</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">['mysqld',</span> <span class="string">'--character-set-server=utf8'</span><span class="string">,</span> <span class="string">'--collation-server=utf8_bin'</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">zabbix-java-gateway:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zabbix/zabbix-java-gateway:centos-4.0-latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">zabbix-java-gateway</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">10052</span><span class="string">:10052</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zabbix</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">zabbix-server:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zabbix/zabbix-server-mysql:centos-4.0-latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">zabbix-server</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">ZBX_JAVAGATEWAY:</span> <span class="string">zabbix-java-gateway</span></span><br><span class="line">      <span class="attr">ZBX_JAVAGATEWAY_ENABLE:</span> <span class="string">"true"</span></span><br><span class="line">      <span class="attr">DB_SERVER_HOST:</span> <span class="string">mysql</span></span><br><span class="line">      <span class="attr">MYSQL_DATABASE:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_USER:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_PASSWORD:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">zabbix</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/data/zabbix/alertscripts:/usr/lib/zabbix/alertscripts</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/data/zabbix/externalscripts:/usr/lib/zabbix/externalscripts</span></span><br><span class="line">    <span class="attr">links:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">10051</span><span class="string">:10051</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zabbix</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">zabbix-web:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zabbix/zabbix-web-nginx-mysql:centos-4.0-latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">zabbix-web</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">PHP_TZ:</span> <span class="string">Asia/Shanghai</span></span><br><span class="line">      <span class="attr">DB_SERVER_HOST:</span> <span class="string">mysql</span></span><br><span class="line">      <span class="attr">MYSQL_DATABASE:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_USER:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_PASSWORD:</span> <span class="string">zabbix</span></span><br><span class="line">      <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">zabbix</span></span><br><span class="line">    <span class="attr">links:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">80</span><span class="string">:80</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zabbix-server</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zabbix</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">zabbix:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br></pre></td></tr></table></figure>
<p>3.启动容器<br><figure class="highlight plain"><figcaption><span>docker-compose -f zabbix-compose.yml up -d```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">4.添加监听端口防火墙规则</span><br><span class="line">zabbix web ```sudo firewall-cmd --zone=public --add-port=80/tcp --permanent</span><br></pre></td></tr></table></figure></p>
<p>zabbix-server <figure class="highlight plain"><figcaption><span>firewall-cmd --zone</span></figcaption><table><tr><td class="code"><pre><span class="line">zabbix-java-gateway ```sudo firewall-cmd --zone=public --add-port=10052/tcp --permanent</span><br></pre></td></tr></table></figure></p>
<h2 id="3-部署zabbix-agent"><a href="#3-部署zabbix-agent" class="headerlink" title="3.部署zabbix-agent"></a>3.部署zabbix-agent</h2><h3 id="1-CentOS7"><a href="#1-CentOS7" class="headerlink" title="1.CentOS7"></a>1.CentOS7</h3><p>1.下载安装 zabbix-agent rpm包<br><figure class="highlight plain"><figcaption><span>rpm -Uvh</span><a href="https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-agent-4.0.7-1.el7.x86_64.rpm```" target="_blank" rel="noopener">link</a></figcaption><table><tr><td class="code"><pre><span class="line">2.修改 /etc/zabbix/zabbix_agentd.conf 配置文件，为zabbix-server的IP</span><br><span class="line">```Server=</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">```ServerActive=</span><br></pre></td></tr></table></figure>
<p>3.为zabbix-agent监听端口10050添加添加防火墙出站规则<br><figure class="highlight plain"><figcaption><span>firewall-cmd --zone</span></figcaption><table><tr><td class="code"><pre><span class="line">```sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure></p>
<h3 id="4-Windows-Server-2012"><a href="#4-Windows-Server-2012" class="headerlink" title="4.Windows Server 2012"></a>4.Windows Server 2012</h3><p>1.下载zabbix-agent windows 安装包，安装在需要监控的Windows server机器上<br>下载地址为<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">默认安装路径为```C:\Program Files\Zabbix Agent</span><br></pre></td></tr></table></figure></p>
<p>2.修改配置文件<figure class="highlight plain"><figcaption><span>Files\Zabbix Agent\zabbix_agentd.conf``` 为zabbix-server的IP</span></figcaption><table><tr><td class="code"><pre><span class="line">```Server=</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">```ServerActive=</span><br></pre></td></tr></table></figure>
<p>3.添加zabbix-agent监听端口10050防火墙规则<br>4.打开任务管理器重新启动zabbix-agent服务</p>
<h2 id="4-进入zabbix-web管理界面添加监控主机"><a href="#4-进入zabbix-web管理界面添加监控主机" class="headerlink" title="4.进入zabbix web管理界面添加监控主机"></a>4.进入zabbix web管理界面添加监控主机</h2><p><a href="http://zabbix-webIP/zabbix" target="_blank" rel="noopener">http://zabbix-webIP/zabbix</a><br>默认用户名为<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">默认密码为```zabbix</span><br></pre></td></tr></table></figure></p>
<p>管理-&gt;主机-&gt;创建主机<br>主机名称: 自定义名称 (注意:Windows 端需要和zabbix_agentd.conf配置文件中的Hostname相同)<br>群组: -&gt;选择 按需添加<br>IP地址: 所需监控机器IP 端口10050<br>-&gt;模板 按需链接所需要的监控模板</p>
<h2 id="5-添加邮件报警"><a href="#5-添加邮件报警" class="headerlink" title="5.添加邮件报警"></a>5.添加邮件报警</h2><p>1.管理-&gt;报警媒介类型-&gt;Email<br>2.修改以下配置:<br>SMTP服务器: smtp.office365.com<br>SMTP HELO: smtp.office365.com<br>SMTP 电邮: outlook 的邮箱地址<br>安全链接: STARTTLS<br>认证: 用户和密码<br>3.创建报警动作<br>配置-&gt;动作-&gt;创建动作<br>名称: Zabbix_warning<br>计算方式: 默认<br>条件: 按需选择添加触发报警条件<br>-&gt;操作<br>默认操作步骤持续时间: 1h<br>默认标题: <figure class="highlight plain"><figcaption><span>&#123;HOST.NAME&#125;:&#123;ITEM.NAME&#125;:&#123;EVENT.NAME&#125;```</span></figcaption><table><tr><td class="code"><pre><span class="line">消息内容:</span><br><span class="line"></span><br><span class="line">```txt</span><br><span class="line">告警主机: &#123;HOSTNAME1&#125;</span><br><span class="line">告警时间: &#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;</span><br><span class="line">告警等级: &#123;TRIGGER.SEVERITY&#125;</span><br><span class="line">告警信息: &#123;TRIGGER.NAME&#125;</span><br><span class="line">告警项目: &#123;TRIGGER.KEY1&#125;</span><br><span class="line">问题详情: &#123;ITEM.NAME&#125;: &#123;ITEM.VALUE&#125;</span><br><span class="line">当前状态: &#123;TRIGGER.STATUS&#125;: &#123;ITEM.VALUE1&#125;</span><br><span class="line">事件ID: &#123;EVENT.ID&#125;</span><br></pre></td></tr></table></figure></p>
<p>-&gt;操作<br><figure class="highlight plain"><figcaption><span>Zabbix administrators 通过 Email```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">4.管理-&gt;用户-&gt;Admin-&gt;报警媒介-&gt;添加</span><br><span class="line">类型: Email</span><br><span class="line">收件人: 接收报警信息的邮件地址</span><br><span class="line"></span><br><span class="line">## 6.添加手机/短信报警</span><br><span class="line"></span><br><span class="line">1.zabbix_phone.sh</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">#!/bin/bash</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># date 2019-05-10</span><br><span class="line"># zabbix报警，通过电话通知警报信息接收人，通过短信发送警报信息</span><br><span class="line"># 修改To=+86***********为警报信息接收人手机，需要到twilio绑定该手机号</span><br><span class="line"></span><br><span class="line"># via phone</span><br><span class="line">curl -X POST https://api.twilio.com/2010-04-01/Accounts/ACe4a6468bf4ffda94718c3749/Calls.json \</span><br><span class="line">--data-urlencode &quot;Url=http://demo.twilio.com/docs/voice.xml&quot; \</span><br><span class="line">--data-urlencode &quot;To=+86***********&quot; \</span><br><span class="line">--data-urlencode &quot;From=+1**********&quot; \</span><br><span class="line">-u ACe4a6 04cd7 1970c9 ab7 &gt;&gt; twilio.log</span><br><span class="line"></span><br><span class="line"># via message</span><br><span class="line">curl -X POST https://api.twilio.com/2010-04-01/Accounts/ACe4a64b4ffda94718c3749/Messages.json \</span><br><span class="line">--data-urlencode &quot;StatusCallback=http://postb.in/1234abcd&quot; \</span><br><span class="line">--data-urlencode &quot;Body= $1 &quot; \</span><br><span class="line">--data-urlencode &quot;To=+86***********&quot; \</span><br><span class="line">--data-urlencode &quot;From=+1**********&quot; \</span><br><span class="line">-u ACe4a646 1970c93 aab7 &gt;&gt; twilio.log</span><br></pre></td></tr></table></figure></p>
<p>2.将该脚本复制到zabbix-server容器中<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zabbix-compose.yml 默认映射的存储卷为```/data/zabbix/alertscripts</span><br></pre></td></tr></table></figure></p>
<p>3.修改脚本权限<br><figure class="highlight plain"><figcaption><span>zabbix zabbix_phone.sh```</span></figcaption><table><tr><td class="code"><pre><span class="line">```chmod +x zabbix_phone.sh</span><br></pre></td></tr></table></figure></p>
<p>4.在zabbix-web管理界面 添加报警媒介规则<br>管理-&gt;报警媒介类型-&gt;创建媒体类型<br>名称: Phone_warning<br>类型: 脚本<br>脚本名称: zabbix_phone.sh<br>脚本参数: {ALERT.MESSAGE}<br>-&gt; 点击更新保存</p>
<p>5.创建报警动作<br>配置-&gt;动作-&gt;创建动作<br>名称: Zabbix_warning<br>计算方式: 默认<br>条件: 按需选择添加触发报警条件<br>-&gt;操作<br>默认操作步骤持续时间: 1h<br>默认标题: 『服务器警报』 {HOST.NAME}:{ITEM.NAME}:{EVENT.NAME}<br>消息内容:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">告警主机: &#123;HOSTNAME1&#125;</span><br><span class="line">告警时间: &#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;</span><br><span class="line">告警等级: &#123;TRIGGER.SEVERITY&#125;</span><br><span class="line">告警信息: &#123;TRIGGER.NAME&#125;</span><br><span class="line">告警项目: &#123;TRIGGER.KEY1&#125;</span><br><span class="line">问题详情: &#123;ITEM.NAME&#125;: &#123;ITEM.VALUE&#125;</span><br><span class="line">当前状态: &#123;TRIGGER.STATUS&#125;: &#123;ITEM.VALUE1&#125;</span><br><span class="line">事件ID: &#123;EVENT.ID&#125;</span><br></pre></td></tr></table></figure>
<p>-&gt;操作<br>发送消息给用户群组: Zabbix administrators 通过 Email<br>发送消息给用户: Admin (Zabbix Administrator) 通过 Phone_warning</p>
<p>3.管理-&gt;用户-&gt;Admin-&gt;报警媒介-&gt;添加<br>类型: Phone_warning<br>收件人: @ALL</p>
<h2 id="7-zabbix自动发现"><a href="#7-zabbix自动发现" class="headerlink" title="7.zabbix自动发现"></a>7.zabbix自动发现</h2><p>配置-&gt;自动发现-&gt;创建发现规则<br>名称: Local network<br>IP范围: 按需指定监控机器IP地址网段<br>更新间隔: 1h<br>检查: Zabbix客户端”system.uname”<br>设备唯一性准则: IP地址</p>
]]></content>
      <tags>
        <tag>运维</tag>
        <tag>zabbix</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle rips RedHat and &#39;sort of&#39; launches a new Linux</title>
    <url>/archives/oracle-rips-redhat.html</url>
    <content><![CDATA[<h2 id="Oracle-rips-RedHat-and-‘sort-of’-launches-a-new-Linux"><a href="#Oracle-rips-RedHat-and-‘sort-of’-launches-a-new-Linux" class="headerlink" title="Oracle rips RedHat and ‘sort of’ launches a new Linux"></a>Oracle rips RedHat and ‘sort of’ launches a new Linux</h2><p><a href="https://www.computerworld.com/article/2469218/oracle-rips-red-hat-and--sort-of--launches-a-new-linux.html" target="_blank" rel="noopener">原文链接</a></p>
<hr>
<p>今天看到推特上RedHat换了新的logo，不过还是那顶红帽子。其实RedHat曾经被Oracle绿过，换成绿帽子再适合不过了。😂<br>即兴找了一下当年Oracle撕碎RedHat的报道文章。<br>Oracle曾诚意满满地派了100多个程序员帮助红帽子公司开发RedHat Linux发行版，慢慢地Oracle公司的员工逐渐掌握了RedHat的开发，相当于把RedHat架空了。RedHat被绿了一把😂。后来Oracle推出了自己的Oracle Linux，接着收购SUN公司。拥有了硬件基础。自此Oracle从硬件到OS再到数据库都有了自己的产品。推出了Oracle一体机。<br>很难想象不可一世的RedHat被Oracle打趴在地。</p>
<hr>
<p><a href="http://www.oracle.com" target="_blank" rel="noopener">Oracle</a> made a weird announcement at its <a href="http://www.oracle.com/us/openworld/splash/index.html" target="_blank" rel="noopener">Oracle OpenWorld</a> love-fest and trade-show. The company announced that it was releasing its own Linux: the <a href="http://www.marketwatch.com/story/oracle-debuts-oracles-unbreakable-enterprise-kernel-for-oracle-linux-2010-09-20-111130" target="_blank" rel="noopener">Oracle’s Unbreakable Enterprise Kernel for Oracle Linux</a>.</p>
<p>Funny, and I thought Larry Ellison already had his own Linux, <a href="http://practical-tech.com/uncategorized/oracles-red-hat-rip-off/" target="_blank" rel="noopener">Unbreakable Linux, which Oracle introduced not quite four-years ago</a>. Of course, <a href="http://www.oracle.com/us/technologies/linux/index.html" target="_blank" rel="noopener">Oracle Unbreakable Linux</a> wasn’t really Oracle’s Linux. It was <a href="http://www.RedHat.com" target="_blank" rel="noopener">RedHat</a>‘s <a href="http://www.RedHat.com/rhel" target="_blank" rel="noopener">RedHat Enterprise Linux (RHEL)</a> with an Oracle Linux logo pasted on the front.<br><strong>[ Find your 2017 salary info and our detailed report at <a href="http://www.computerworld.com/category/it-salary-watch/" target="_blank" rel="noopener">IT Salary Watch</a> ]</strong><br>But, this time, Oracle swears its new Oracle Linux is different. The company claims that it’s been optimized for Oracle software and hardware and that Unbreakable Enterprise Kernel is faster than RHEL To be precise, Oracle claims its more than 75 percent faster, as shown by Online Transaction Processing (OLTP) performance tests; 200 percent faster at <a href="http://www.infinibandta.org/" target="_blank" rel="noopener">InfiniBand</a> messaging; and is 137 percent faster at solid state disk access than a “RedHat Compatible Kernel.”</p>
<p>Speaking as the guy who designed and ran the very <a href="http://practical-tech.com/infrastructure/linux-up-close-time-to-switch" target="_blank" rel="noopener">first Linux server benchmarks</a> back  in 1999, I’m not impressed by Oracle’s claims. An expert can make any operating system look like the greatest thing since sliced bread and its rival look like a two-day old dead dog.</p>
<p>I’m sure on Sun/Oracle hardware, tuned Unbreakable Enterprise Kernel can beat un-tuned RHEL. So what? It will take more than Oracle’s employees claiming Oracle’s new Linux is great before I buy it.</p>
<p>Oracle’s Unbreakable Enterprise Kernel for Oracle Linux–what a name!–is based on the stable 2.6.32 mainline Linux kernel. For some reason, a few idiots seem to think this represents a Linux fork. Nope. It doesn’t. When you get past all the hype, Oracle’s new Linux just a Linux distribution that’s been optimized for Sun/Oracle hardware. Specifically, Oracle sees this as their Linux for the company’s <a href="http://www.oracle.com/us/products/middleware/exalogic/index.html" target="_blank" rel="noopener">Oracle Exalogic Elastic Cloud</a> and high-end, <a href="http://practical-tech.com/infrastructure/numa-theory-and-practice" target="_blank" rel="noopener">Non-Uniform Memory Access (NUMA)</a> servers.<br><strong>[ <a href="https://pluralsight.pxf.io/c/321564/424552/7490?u=https%3A%2F%2Fwww.pluralsight.com%2Fpaths%2Fupgrading-your-technology-career" target="_blank" rel="noopener">Looking to upgrade your career in tech? This comprehensive online course teaches you how.</a> ]</strong><br>At the time though, according to Edward Scriven, Oracle’s Chief Corporate Architect, Oracle will continue to sell its RHEL-compatible Linux under the name Oracle Linux. Still, Oracle insists in its press release that “Existing Oracle Linux 5 and RedHat Enterprise Linux 5 customers can easily upgrade to the Unbreakable Enterprise Kernel. No reinstall of the operating system is required.”</p>
<p>What’s more surprising is that Oracle also asserts that “Third-party applications that run on RHEL 5 should run unchanged on Oracle Linux with the Unbreakable Enterprise Kernel, while delivering significant performance and reliability improvements for end users.”</p>
<p>So what the heck is Oracle Unbreakable Enterprise Kernel Linux? It sounds to me like it’s just Oracle-branded RHEL that been tuned up for Oracle’s hardware. Color me totally unimpressed.</p>
<p>Oh, according to reports, <a href="http://www.informationweek.com/blog/main/archives/2010/09/larry_ellison_r.html" target="_blank" rel="noopener">Ellison claims that Oracle’s new Linux “will be more modern</a>, it won’t be four years behind the mainline, there’ll be lots of timely enhancements from Oracle and the Linux community, and it will deliver much better performance.”</p>
<p>OK, riddle me this. How can you be bleeding edge, offer stability for high-end applications, and stay compatible with a Linux that you claim is four-years behind the time? The answer to this conundrum? You can’t.</p>
<p>Ellison also said, “We [Oracle] spend a lot of time finding and fixing bugs in RedHat Linux, and we have no problem with that–we do that with lots of operating systems.”But sometimes when we fix a RedHat Linux bug, RedHat can take a very long time before making the fix. We’d fix the bug for our customers, and we’d send the bug off to RedHat for them to fix, and sometimes the fix would be made very quickly but sometimes not..</p>
<p>Really? You could have fooled me. Both <a href="http://blogs.computerworld.com/14576/who_writes_linux_big_business" target="_blank" rel="noopener">RedHat and Oracle are leading Linux development companies</a>, and I’ve not noticed Oracle cleaning up RedHat’s messes. RedHat does just fine at cleaning up its own code thank you very much.</p>
<p>My take away from Oracle’s announcement is that Ellison hasn’t been able to damage RedHat nearly as much as he wanted to. So, now he’s resorting to an announcement that’s more noise than news. Sorry Oracle, RHEL’s that been tuned for your hardware and software is interesting, but it’s not much of a new distribution and the way you’re presenting it will only confuse your customers.</p>
<h2 id="quote"><a href="#quote" class="headerlink" title="quote"></a>quote</h2><p><a href="https://www.computerworld.com/article/2469218/oracle-rips-red-hat-and--sort-of--launches-a-new-linux.html" target="_blank" rel="noopener">原文链接</a><br><a href="https://liuyandong.com/2017/10/22/121/" target="_blank" rel="noopener">孤独的圣斗士————甲骨文的拉里•埃里森(下)</a></p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>高效运维社区分享系列.运维三十六计</title>
    <url>/archives/ops36.html</url>
    <content><![CDATA[<h2 id="高效运维社区分享系列-运维三十六计v0-6"><a href="#高效运维社区分享系列-运维三十六计v0-6" class="headerlink" title="高效运维社区分享系列.运维三十六计v0.6"></a>高效运维社区分享系列.运维三十六计v0.6</h2><p><a href="http://www.greatops.net/?id=190" target="_blank" rel="noopener">原文链接</a></p>
<p>专栏撰写专家（按首字母拼音顺序）：</p>
<table>
<thead>
<tr>
<th>姓名</th>
<th>公司</th>
</tr>
</thead>
<tbody>
<tr>
<td>范伦挺</td>
<td>阿里巴巴，技术专家</td>
</tr>
<tr>
<td>盖国强</td>
<td></td>
</tr>
<tr>
<td>高向冉</td>
<td>腾讯，技术总监</td>
</tr>
<tr>
<td>韩方</td>
<td>丫丫直播，安全总监</td>
</tr>
<tr>
<td>梁定安</td>
<td>腾讯，织云负责人</td>
</tr>
<tr>
<td>潘晓明</td>
<td>京东，开发测试专家</td>
</tr>
<tr>
<td>涂彦</td>
<td>腾讯，技术总监</td>
</tr>
<tr>
<td>万千一</td>
<td>京东，测试经理</td>
</tr>
<tr>
<td>王晶</td>
<td>华为，资深架构师</td>
</tr>
<tr>
<td>胥峰</td>
<td>盛大游戏，高级研究员</td>
</tr>
<tr>
<td>徐奇琛</td>
<td>京东，技术总监</td>
</tr>
<tr>
<td>口十金荣</td>
<td>知数堂，联合创始人</td>
</tr>
<tr>
<td>闫林</td>
<td>中兴通讯，IT技术学院院长</td>
</tr>
<tr>
<td>周小军</td>
<td>腾讯，运维专家</td>
</tr>
<tr>
<td>周正中</td>
<td>阿里巴巴，技术专家</td>
</tr>
<tr>
<td>张永福</td>
<td>大河云联，资深架构师</td>
</tr>
<tr>
<td>赵舜东</td>
<td></td>
</tr>
<tr>
<td>张乐</td>
<td>百度，资深敏捷教练</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="三十六计-运维管理-涂彦"><a href="#三十六计-运维管理-涂彦" class="headerlink" title="三十六计-运维管理-涂彦"></a>三十六计-运维管理-涂彦</h2><p>1.运维管理的两个主要目标，管人与理事。<br>2.运维管理需要经历的三个阶段，生存、生长、生态。<br>3.未来十年团队中坚力量是年轻一代。<br>4.认同年轻团队的五个价值观：不惧权威、自主管理、HERO、女汉子、理想现实主义者。<br>5.打好领导与领袖的组合拳，用法定权责奖赏和鼓励员工，用个人专业能力影响员工，用好事半功倍，用不好人财两空。<br>6.运维团队在企业中的角色，不是外包和救火队员可以代替的，而是要与企业和业务共同成长的角色。<br>7.不论公司规模大小，运维团队都可以从是高想象力团队还是低想象力团队，是高创造力团队还是低创造力团队来看发展潜力。<br>8.高想象力与高创造力来源于如何建立运维价值输入输出关键路径，即INPUT与.OUTPUT机制。<br>9.对于运维团队的架构职能，平台型与垂直型是驱动团队发展的内在因子，而不仅仅只是一种僵硬的组织形式。<br>10.混搭平台与垂直，是一种面向服务对象的灵活组织管理模式。<br>11.运维团队的能力体系建设应该像互联网产品一样，不断做好迭代与交付能力。<br>12.团队的发展好比一个人的成长，除了好的组织架构外，还需要好的思维模式。<br>13.成长思维模式中，需要不断挖掘与释放团队内各种成员的潜在能力，做好兼容与适配。<br>14.导师制度，对一个技术团队的人才培养非常重要，不同阶段不同领域都需要灯塔指引我.们，在学习知识同时收获友情。<br>15.营造创新环境也是成长思维模式中必不可少的环节，坚持与服务对象保持紧密沟通，特.别是对一件事的持续专注。<br>16.对遇到成长瓶颈的成员,需要让其自身成长的诉求与不断推陈出新的业务需求发生化学.反应，才能走出困惑，重拾信心。<br>17.运维团队应该根据企业的文化价值观形成带有鲜明团队自身属性的文化价值观,并且这.样的团队文化能深入人心。<br>18.团队文化可以看成是团队内各成员对于彼此工作方法的一种高度共识。<br>19.随着企业业务规模发展，不少管理者将面临远程团队管理，要正确认识远程团队在企业.发展中的真正价值。<br>20.管理远程团队要经历的三个阶段：活下去（初创期X追赶与超越（发展期X自循环（稳.健期)。<br>21.管理远程团队要解决的三个问题：时间、距离、文化。<br>22.时间：远程团队如何解决各类工作信息高效同步与任务执行。<br>23.距离：远程团队如何自我发展、外部合作如何开展。<br>24.文化：远程团队如何读懂和落地公司、部门文化。<br>25.当作为一个职业经理人空降一个运维技术团队时，首先要学会快速融入，而不是快速换人。<br>26.空降管理中，基于管理与被管理双方强烈的认知欲望，如何快速压缩认知成本，认识别人眼中的自己，是破冰的关键路径。<br>27.作为运维团队管理者，要学会培养自身与团队在核心业务上的技术洞见能力。<br>28.运维团队随着业务发展，自身在经历不同时期的建设过程中将体现出技术洞见为团队能力提升所带来的重要变化。<br>29.技术洞见在业务扩张建设和实现业务转型中，都扮演着关键角色，是管理者及团队的重.要专业能力。<br>30.运维管理者要理性看待技术洞见带来的风险,特别是失败案例以及早期技术方案雏形的.不完善。<br>31.创新与关注核心业务是可以不冲突的,运维管理者要围绕核心业务进行技术洞见的灰度.和全量。<br>32.运维团队作为面向服务对象的技术团队，要具备产品思维能力。<br>33.对于运维服务的对象，可以分为客户与用户，前者偏向于企业内部业务团队，.后者偏向于企业外部最终用户。<br>34.运维的产品思维可以体现在工具文化中：创新方式解决问题、利用该方式快速成长与扩.张、以产品为基础。<br>35.运维团队可以用创业模式来管理建设中的项目以及待评估的技术洞见。<br>36.将创业模式的项目管理引进运维团队，可以激发团队的狼性，产生更多好的运维服务与产品。</p>
<hr>
<h2 id="三十六计-曰常运维-梁定安"><a href="#三十六计-曰常运维-梁定安" class="headerlink" title="三十六计-曰常运维-梁定安"></a>三十六计-曰常运维-梁定安</h2><p>1.运维值班要保证手机电量充足，7x24为业务待命<br>2.应对故障要先恢复再排査，无计可施重启试试<br>3.对不可逆的删除或修改操作，尽量延迟或慢速执行<br>4.root操作需留神，sudo授权更安全可控<br>5.配置文件不要写死IP，巧用名字服务解耦更高效<br>6.运维脚本和工具要版本化管理<br>7.批量操作，请先灰度再全量<br>8.删除操作脚本请交叉检査二次确认<br>9.采用高可用的集群化部署，应防止单点<br>10.将重复三次以上的操作脚本化<br>11.开放外网高危端口需谨慎，网络安全要牢记<br>12.crontab写绝对路径，输入输出重定向<br>13.慎防进程D状态，及时监控保可用<br>14.一人一次只做一个变更，降低人为失误风险<br>15.变更操作先备份再修改<br>16.数据备份任务要监控，并定时检査备份档的有效性<br>17.尽量提前预警，避免告警救火<br>18.敏感权限应定期回顾和检査，及时清理离职转岗的人员权限<br>19.服务上线一定要有监控，保证质量可度量<br>20.灾难的紧急预案一定要有演练的机制，养兵千日用兵一时<br>21.修改内核参数需区分一次性修改或随机启动修改<br>22.对生产环境的变更操作后，要有持续关注机制，确保服务质量不受影响<br>23.尽可能保证发布操作能被回滚，并且发布故障要优先回滚<br>24.保持应用运行的独立性，防止交叉依赖的程序存在<br>25.运维工作互备，工作交接要留文档<br>26.从每个故障中学习和提高，避免重犯同一个错误<br>27.每个偶然的故障背后都深藏着必然的联系，找到问题根源并优化掉<br>28.运维的标配软技能：责任心、沟通力、执行力<br>29.运维规范变现步骤：文档化、工具化、系统化、自动化<br>30.日常运维口令：打补丁、传文件、批处理、改配置、包管理、看监控<br>31.容量管理要做好，每日关注高低负载<br>32.用流程保证质量，用自动化保证效率<br>33.日志管理使用轮换机制，防止硬盘空间使用率无限增大<br>34.先量化管理运维对象，再优化管理运维对象<br>35.容量规划牢记从3个角度评估：主机负载、应用性能、业务请求量<br>36.保持运维对象的标准化与一致性，如处女座般梳理整洁生产环境</p>
<hr>
<h2 id="三十六计-自动化运维-胥峰"><a href="#三十六计-自动化运维-胥峰" class="headerlink" title="三十六计-自动化运维-胥峰"></a>三十六计-自动化运维-胥峰</h2><p>1.思想上要树立以自动化运维为荣，以手动运维为耻的荣辱观。<br>2.自动化运维体系的设计以人为本，减少学习成本才能更有效的发挥作用。<br>3.自动化运维体系要涵盖所有运维需求，是全面的和完整覆盖的。<br>4.自动化运维的产物必须是平台，只有平台才能永续。<br>5.简洁的操作流程是自动化运维平台的设计原则。<br>6.自动化运维的终极目标是消灭SecureCRT和Putty等一切远程客户端，让平台成为唯.一入口。<br>7.自动化运维的第一步是脚本化，通过脚本构建可重复的基础架构和环境。<br>8.脚本加入版本控制，以能够追溯和审计变更。<br>9.脚本语言要统一，以提高脚本的可维护性。<br>10.你不用造轮子，可以先考虑开源方案加二次开发满足运维需求。<br>11.高效是自动化运维的要求，使用多进程或者事件模型等提高并行效率。<br>12.设计良好的kickstart提高物理机交付的效率和安全性。<br>13.使用不同烧制级别的虚拟机镜像提高云计算资源的交付效率。<br>14.安全必须是内置在自动化运维中的，通过主动发现和深度防御机制保障安全。<br>15.网络层面使用防火墙保障集中控制节点的安全。<br>16.采用双因素认证保障集中控制节点的系统授权访问。<br>17.持续的网络安全扫描减少误操作带来的风险。<br>18.集中控制节点和被控节点加密数据通信。<br>19.循序渐进是从头创建运维自动化体系的正确姿势，不要一开始就设计大而全的系统，从最痛的痛点开始解决。<br>20.可以使用价值流程图分析当前的效率瓶颈和确认痛点。<br>21.自动化运维的底层数据必须保证完整性，技术手段与流程保障并行。<br>22.分层设计CMDB，基础数据统一管理，业务数据向下授权。<br>23.资产流转和变更中加入流程控制和审计，防止失控和数据不一致。<br>24.以自动探测和上报提高CMDB配置的效率和维护数据准确性。<br>25.监控体系的自动化是整个体系的纽带，它贯穿着事件和故障自愈。<br>26.设计大规模监控体系的自动注册功能，不以手动添加被监控指标。<br>27.业务分组、服务器角色分组，自动匹配监控项目。<br>28.通过数据分析聚合和关联监控数据，提供故障排除和容量规划的有效信息。<br>29.监控的目标是保障业务价值,不但要监控基础架构和应用端口,而且更要监控业务数据,.比如订单数据和游戏玩家数量等。<br>30.坚持持续改进的监控目标，持续减少漏报和误报比例。<br>31.规范业务日志的格式化输出，统一日志的集中存储和分析。<br>32.设计自动化的数据备份体系，设计通用的备份客户端。<br>33.备份客户端内置加密功能，密码由服务器下发。<br>34.以并发或者UDP方式提高备份传输效率。<br>35.结合离线备份和在线备份，提供备份文件的自动化下载接口。<br>36.自动化备份数据恢复测试，检査数据有效性。</p>
<hr>
<h2 id="三十六计-基础监控-赵舜东"><a href="#三十六计-基础监控-赵舜东" class="headerlink" title="三十六计-基础监控-赵舜东"></a>三十六计-基础监控-赵舜东</h2><p>1.监控对象收集要完整，不然每次故障就刚好是忘记监控的对象。<br>2.监控对象要完全理解，这样才知道要监控哪些指标。<br>3.监控对象指标需要提前确定性能基准线。<br>4.使用IPMI监控物理服务器，建议为服务器均配置远程控制口，配备单独的网络。<br>5.使用SNMP监控物理设备，建议使用V3版本。<br>6.机房巡检不能少，设置巡检制度，节假日前一定要巡检。<br>7.机房网络情况要时刻掌握，开源的选择可以用Smokeping。<br>8.基础的网络安全监控，可以定期扫描网络端口，发现异常端口进行告警。<br>9.开源的Web漏洞扫描器w3af,定期对线上服务进行安全扫描。<br>10.CPU监控不可少的对象：CPU利用率、运行队列、上下文切换。<br>11.使用top、vmstat、mpstat监控CPU性能指标，CPU利用率中user/system比例维.持在70/30。<br>12.内存监控主要关注使用率，free、vmstat输出很详细，注意添加告警触发器。<br>13.磁盘利器iotop,有硬盘报警需及时更换，千万不能等等再说。<br>14.网络监控利器iftop,TCP状态监控不能少，time_wait多不用怕，可以调整内核参数.缓解，close_wait多才恐怖。<br>15.在性能测试场景下，nmon可以给测试工程师提供更好的性能报表。_<br>16.Apache、Nginx均有状态模块，可以直接开启，并集成到监控平台。<br>17.Memcached、Redis均自带状态命令，使用nc就可以进行通讯。<br>18.各种网络服务均提供相关的监控接口，集成到监控平台之前要理解受监控对象。<br>19.所有线上业务都要添加Web监控或者API监控，监控其存活状态。<br>20.Nagios、Cacti都不错，Zabbix可以挑大梁。<br>21.监控有痛点可以再试试open-falcon….,国外的Datadog也不错。<br>22.想要更灵活的监控：Sensu、Grafnana….+.collectd+Inf丨uxDB等多种选择。<br>23.监控也需要标准化，统一脚本、统一模板。<br>24.通过API和CMDB集成，保证监控覆盖率。<br>25.大规模监控使用Zabbix-Agent主动模式。<br>26.为相同类型的监控对象创建Screen更直观的进行展示。<br>27.Zabbix.Proxy专门为分布式监控做准备，多机房监控必备。<br>28.Zabbix.Discovery.是利器，利用好Low.Level.Discovery.会事半功倍。<br>29.使用TiDB替换MySQL作为Zabbix后端存储，解决监控数据量大的性能瓶颈。<br>30.某些重点业务指标也可以集成到Zabbix中，如日活用户、注册用户、每分钟订单等。<br>31.告警方式可以选择邮件、微信和短信，重要告警短信是必备的。<br>32.Zabbix.Agent可以自动进行注册、网络发现可以自动添加监控。<br>33.使用Zabbix….API主动管理监控对象，结合CMDB自动化管理监控。<br>34.最简单的故障自愈可以使用Zabbix….Action触发对应操作。<br>35.告警的去重可以借助于Elasticsearch….,对告警进行分词处理再去重。<br>36.使用单独的工具对监控数据进行计算，努力实现动态化告警阈值。</p>
<hr>
<h2 id="三十六计-安全运维-韩方"><a href="#三十六计-安全运维-韩方" class="headerlink" title="三十六计-安全运维-韩方"></a>三十六计-安全运维-韩方</h2><p>1.进程启动权限最小化，尽可能使用非root账号启动进程<br>2.禁用操作系统不再使用的账号，免密码登录的账号要慎重丨<br>3.关闭telnet等明文远程登录服务<br>4.停用和关闭无用的服务，系统服务最小化<br>5.Linux下的ps,.netsat系统命令看到的不一定是操作系统的返回信息，也可能是木.马伪装后的信息，系统命令有可能篡改，系统内核调用可能被替换<br>6.大量的会话状态跟踪表full日志异常也可能是被攻击导致；<br>7.CC攻击(http.flood)服务器上最简单的对抗方法就是限制单ip的同时并发请求数；<br>8.定期或不定期的漏洞扫描，可以使用开源软件，也可以自主研发<br>9.Syslog,authlog等日志定期备份，便于安全事件的追溯和审计<br>10.Linux下内核参数优化不仅仅可以提高性能，也可以提升防御攻击能力，比如：tcp_syncookie,.ip_conntrack_max.等<br>11.使用selinux或appmrmor可以提升Linux的安全防御等级，<br>12.操作系统的history条目要限制一定数量，尽可能不要过大，一旦被入侵，可以直接.看到命令历史输入，避免入侵后的战果被进一步扩大；<br>13.重要密码一定不能同其他互联网账号密码相同,特别是同其他小网站的账号密码相同，.避免被撞库<br>14.切记丨密码口令不能明文保存在服务器的某个文件上<br>15.Linux,mysql,redis等密码口令要有一定复杂度，不能过于简单；<br>16.密切关注操作系统(ubuntu.,.centos等)的0day漏洞，及时升级版本或补丁；<br>17.数据安全方面，账号等敏感数据在数据库中的保存一定不能明文，同时避免密文可逆.和碰撞分析，可以通过salt+sha1等<br>18.定期更换相关系统（操作系统、管理后台等）的密码是一个好习惯丨<br>19.多因素认证可以进一步提升安全防护等级，比如密码+证书<br>20.切记丨及时删除运行服务器上的源代码，测试代码以及文档，一旦服务器被入侵，源.代码或者测试代码将导致入侵的影响被进一步放大<br>21.运行的业务进程尽量不要输出敏感信息到日志文件中，比如避免java代码打印数据库.连接的账号信息等；<br>22.Shell或python等脚本代码的敏感逻辑一定要进行加密，比如shell中的数据库访.问使用的账号和密码就需要进行加密来提升安全性<br>23.安全意识培训要不定期宣导丨持续宣导的过程，不仅仅针对运维，也针对开发和测.试；<br>24.安全运维是一个立体工程，尽可能降低每个环节的风险，才能降低整体的风险面丨单.一防御面不可能100%<br>25.当服务器数量达到一定量级的时候，相关漏洞扫描，入侵检测很难手工实施，尽可能.自动化；<br>26.不要低估数据化和可视化对于安全运维工作的价值<br>27.Tomcat等管理后台一定要限制访问ip,敏感后台管理系统必须白名单原则丨<br>28.SSH等远程登录一定要限制访问ip或者限制跳板机IP<br>29.Iptables的防火墙规则数量过多，影响性能，可以使用其他基于hash査找的防火墙.规则实现的组件<br>30.访问控制规则最小化原则，白名单规则安全性高于黑名单规则，限制访问ip.,限制被访问port.,限制访问protocol<br>31.除非特殊要求，一定要限制缓存类Mogodb,….redis,.memcache的匿名登录默认配置<br>32.密切关注开源组件(MySQL,….Nginx,.Apache,.Openssl等)的0day漏洞，技术升级版.本<br>33.Nginx/Tomcat等容器配置访问权限尽可能最小化，比如限定于仅可读写当前目录,.避免入侵后的影响扩大到其他的目录<br>34.Nginx里面限制单ip的并发连接数可以缓解CC攻击带来的影响<br>35.PHP的相关危险函数和不需要的远程功能可以关闭<br>36.Apche/Nginx等定制统一40x或50x等错误页面返回，避免显示业务的错误敏感堆栈逻辑等；<br>37.引用Strusts,Openss丨等第三方库尽可能使用公司统一的库文件，或者相对较新版本.的第三方库文件版本，避免引入很旧的版本第三方库导致漏洞.</p>
<hr>
<h2 id="三十六计-网络运维-张永福"><a href="#三十六计-网络运维-张永福" class="headerlink" title="三十六计-网络运维-张永福"></a>三十六计-网络运维-张永福</h2><p>1.生产网络的变更切记三思而后行，一个回车敲下去是永远无法撤回。<br>2.网络运维工程师的苦逼程度直接反应了公司运维系统的自动化程度。<br>3.网络攻城狮要想解放自己，要么学会coding….,要么和程序猿搞好关系。<br>4.运维人员的经验都是通过踩坑积累出来的，你如果不想掉坑里，就需要有一颗好学好问.的心，因为运维的道路上不止有坑，坑里还有钉。<br>5.没有AAA认证的网络不是好网络。<br>6.网络中的单点设计总会在关键时刻要了你的命。<br>7.好的割接方案能让你提前2小时睡觉。不好的割接方案能让你一星期睡不好。<br>8.网络监控不是监控网络，目的是监控业务。<br>9.不要轻易相信厂商的方案，在丨ab里面验证后再上线，你比厂商懂自己网络上的业务。<br>10.割接方案提前写在纸上，而不是割接时留在脑子里<br>11.不惧怕故障，惧怕的是没有排障思路<br>12.想好方案选产品，还是选好产品组方案<br>13.重要割接最好有A/B角，包括方案评审和实施<br>14.链路的物理承载类型分清楚：裸纤直连、传输电路或是二层专线<br>15.管理网络与业务网络要理顺，不管带内还是带外，逃生路径都要准备好<br>16.链路死了不可怕，可怕的是不死不活，频繁闪断<br>17.面对闪断，要确定好抑制策略和回切策略<br>18.传输运维工程师三板斧：看告警、査光功率、环回测试<br>19.变更方案合格的定义是：交给不是写方案的人做变更也能顺利完成割接<br>20.变更执行的关键，是现场实施人员受控<br>21.意识问题，提高重视程度。往往都是小变更出现故障，大变更因为非常重视，一般不出.故障。<br>22.制定变更方案模板，统一按照模板执行。<br>23.严格按照变更方案执行，与预期不符，必须回退，并重新安排变更时间。<br>24.变更方案审批制度建立，审核不通过，必须打回去。<br>25.变更前环境检査、信息收集必须到位，变更后的前后对比。<br>26.从建设抓起，不给后续环节留坑。<br>27.明确运维红线，不能触碰高压线<br>28.运维体系化建设，利用制度保障效率<br>29.运维建设没有最好的模板，只有最适合的模式。所谓的各种体系、标准，在实际中需要.谈落地。<br>30.运维变更中的人、过程、技术都是浮云，重要的是有没有达到安全变更的目的。<br>31.建立服务化、产品化，取代人肉运维<br>32.建立完善的流程制度是运维管理的核心价值<br>33.谈网络运维要看上下游环境，下有服务器、线路，上有应用、业务<br>34.口说无凭，以工单办事<br>35.故障处理的目的不是找rootcause….,而是恢复业务<br>36.每个运维工程师都要有自己的backup</p>
<hr>
<h2 id="三十六计-数据库运维-周小军"><a href="#三十六计-数据库运维-周小军" class="headerlink" title="三十六计-数据库运维-周小军"></a>三十六计-数据库运维-周小军</h2><p>1.任何时候做好最坏的打算<br>2.坚持数据库运维定期演习<br>3.核心岗位手机24小时畅通状况，任何岗位都要主备责任人<br>4.没有规则创造规则，有规则遵守规则；<br>5.养成日常巡检核心监控属性的习惯<br>6.对生产环境保持敬畏之心<br>7.非工作时间不要实施普通变更<br>8.变更自动推送通知和报告，保持信息对齐<br>9.上线SQL先Explain….—把，执行计划可以做一定的固化<br>10.知己知彼，了解所做操作产生的结果才去做<br>11.减操作确保可逆，最少一套恢复方案，重大变更要有操作和回滚方案，要双人检验且审.批通过<br>12.数据库要具备限流能力<br>13.数据迁移后要双向记录对比匹配<br>14.角色权限要划分清楚，开发权限要最小化原则<br>15.权限管理自助化，做好审核和审计<br>16.业务初期做好分库和分表的规划<br>17.建立业务放量流程沟通机制，事前周知快速扩容，事中容量监控，事后资源总结<br>18.做好日常数据库容量度量，用历史数据推算下一个容量高峰<br>19.节假日前做好数据库容量规划<br>20.对索引要根据访问类型做战略性规划<br>21.数据下线后环境及时清理，不要残留<br>22.主动推动业务对热记录、肥胖记录的优化<br>23.避免单点：有效可恢复的数据备份，有效可切换的从节点<br>24.定期的性能优化避免业务量突增导致的雪崩<br>25.精通业务，推动业务采用更合适的架构方案<br>26.备份系统自动化，中心化调度，保障故障效率和可用性<br>27.数据备份100%覆盖，100%可恢复，每年至少2次恢复演练<br>28.数据恢复手段简单高效，提纯成WEB化工具，减少脚本使用<br>29.工具上线前要严格测试和灰度验证<br>30.工具开发要实施代码审阅，工具代码逻辑间要打好曰志<br>31.故障处理自动化，缩短影响业务质量时长<br>32.数据监控多维化，立体化，覆盖所有的监控节点和粒度<br>33.数据垂直分层自动调度（内存，SSD….,.SAS.,.SATA.),做到成本与效率的性价比最高<br>34.数据搬迁调度自动化，聚焦资源调度管理<br>35.调度任务集中化，保障关键调度任务可管理，可监控<br>36.主动分析业务数据访问行为，了解业务数据生命周期，优化业务成本并推动业务改进</p>
<hr>
<h2 id="三十六计-MySQL运维-叶金荣"><a href="#三十六计-MySQL运维-叶金荣" class="headerlink" title="三十六计-MySQL运维-叶金荣"></a>三十六计-MySQL运维-叶金荣</h2><p>1.重要事情说三遍：备份、备份、备份，定期全备+增备/差异备份，并且开启binlog<br>2.如果写成Mysql、mySQL、MySql的人，我看MySQL不适合您，改用其他的吧<br>3.如果还坚持认为MylSAM比InnoDB表好的话，也请别再使用MySQL<br>4.光做好备份还不够，还要做恢复测试，并且检査数据有效性<br>5.数据库密码要合规，弱密码等于没密码，没密码就等着被勒索吧<br>6.管理用户和业务用户区分不同权限角色，业务用户切记不可授权过高<br>7.SLAVE备库谨记关闭写入权限(read_only=1)<br>8.存储过程、触发器、表分区想用就用，用好就行，有性能瓶颈优化就是<br>9.绝不监听公网IP.,并用防火墙挡住非外部连接，降低被入侵风险<br>10.InnoDB表一定要用自增列或呈递增属性的列做主键（该列最好无业务意义），可有效.提高InnoDB表性能、避免主从数据复制延迟<br>11.总是创建合适的索引，否则InnoDB的行锁会升级成为类似表级锁<br>12.基数低的列，强烈不建议单独创建索引（可以放在联合索引中）<br>13.联合索引中，基数高的列放在前面，基数低的列放在后面<br>14.想保证宕机时数据不丟失，烧香拜佛不管用，设置双1才靠谱.(innodb_flush_log_at_trx_commit=1.sync_binlog.=.1)<br>15.命令行下写SQL时，先写好WHERE条件，或先全部写好确认再三后才提交执行<br>16.EXPLAIN.结果中重点关注type=All/Index.,或者Extra.中出现Using.temporary、.Using.filesort的情况并进行优化<br>17.性能、压力测试时，测试机客户机一定要和Server端分开<br>18.连接数爆满时更应该调低最大连接数，而非调高，并且尽快用上thread….pool<br>19.SHOW.PROCESSLIST.结果重点关注频繁出现的Sending.data、Sorting.result、.Copying.to.tmp.table、Copying.to.tmp.table.on.disk、Creating.sort.index、.Waiting.for.xx.lock<br>20.不想MySQL死得快，就赶紧关闭鸡肋的Query….Cache(query_cache_type=0)<br>21.默认开启autocommit.;需_次性写入大量数据时，则应关闭autocommit.,最后手.工提交<br>22.监控InnoDB表空间碎片率：ibd文件实际大小/(Data_length+Index_length),并决.定是否需要重整表空间<br>23.环境初始化之一：开启CPU最大性能模式<br>24.环境初始化之二：关闭NUMA<br>25.环境初始化之三：使用xfs/ext4文件系统，以及deadline/noop….io.scheduler<br>26.mysqld进程占用CPU.%user突然飙高，99.99%是因为索引不当导致<br>27.优先解决频次最高的Slow….Query.,其次核心业务高峰时段的Slow.Query<br>28.每个表都增加create_time、update_time字段，对DB运维帮助非常大<br>29.每个SQL条件都加上引号，并对用户输入强制类型转换，避免SQL注入及类型隐式转.换风险<br>30.只SELECT必要字段，不要总是SELECT….*.,避免额外I/O读<br>31.设置innodb_buffer_pool_size为物理内存的50%〜70%为宜<br>32.疑似SQL注入一般都会调用SLEEP0函数，或访问information_schema下的视图，.每见必杀<br>33.不要直接删除数据表，而是先RENAME….;•删除大表用硬链接方式更高效<br>34.要特别注意监控是否有内存泄露问题，尽早排除风险<br>35.优化的核心目标是提局I/O效率，无论是增加内存，还是换局性能I/O设备，亦或提.高CPU性能、增加索引等<br>36.少用TEXT/BLOB等大对象列，每行长度字节数尽量不超过innodb_data_page_size.的一半<br>37.最后一计，想玩好MySQL.,来知数堂（<a href="http://zhishuedu.com" target="_blank" rel="noopener">http://zhishuedu.com</a>),发现惊喜</p>
<hr>
<h2 id="三十六计-PostgreSQL运维-周正中"><a href="#三十六计-PostgreSQL运维-周正中" class="headerlink" title="三十六计-PostgreSQL运维-周正中"></a>三十六计-PostgreSQL运维-周正中</h2><p>1.任意字段组合査询有高招，GIN复合倒排索引来帮忙。<br>2.物联网、智能DNS、金融、气象范围査询很苦恼，效率低下量不少，range类型来帮.忙，一条记录顶千条，査询索引GiST来帮忙，零点几毫秒要不要。<br>3.O2O.,社交没有GIS可不得了。天气预报、导航、路由规划、宇航局、测绘局没有GIS.也要乱。PostGIS、OpenStreetMap、pgrouting.不可不知道。<br>4.监控系统要颠覆，主动问询模式能耗比低，百分之99是无用功。PostgreSQL异步消.息、流式计算一出手，能耗比提升99.,千万NVPS有木有。<br>5.DT时代数据多得不得了，传统关系数据库扛不住，来看看PostgreSQL流式实时处理.溜不溜。<br>6.支付宝AR红包闹新年，即有位置又有图片比对，敢问数据库能不能做，PostGIS、.PostgreSQL.imgsmlr.亮高招。<br>7.相似的数组、相似的文本、相似的分词、相似的图像数据库能处理吗？PostgreSQL火.眼金睛，实时辨别相似数据。盗图、盗文跑不掉。<br>8.数据库CPU杀手：模糊査询、正则匹配有解吗？….PostgreSQL.GIN,.GiST索引一把抓，.亿级数据毫秒响应很靠谱。<br>9.云端高招，冷热分离、多实例数据共享。分析师、快速试错、OLTP、OLAP—网打尽。<br>10.HTAP是趋势，〇LTP数据库能同时实现0LAP吗？PostgreSQL大补丸。多核并行、.向量计算、」IT、列式存储、聚合算子复用。提升两个数量级小case。<br>11.商业时代，广告满天飞，提高营销转化率有高招。PostgreSQL实时用户画像与圈人来.帮忙，万亿user.tags毫秒响应开心么。<br>12.危化品管理有痛点，PostgreSQL….GIS、化学类型、流计算来帮忙。<br>13.群居社会关系多，金融风控、公安刑侦、社会关系、人脉分析，图式数据搜索很头疼，.PostgreSQL函数式编程，异步消息，复杂」〇IN等手段，解决高效的图式数据査询需.求。<br>14.PostgreSQL递归査询有妙用。大量数据的求差集、最新数据搜索，最新日志数据与全.量数据的差异比对，递归收敛扫描，提升数百倍性能。<br>15.企业数据品种多，跨平台数据共享很头疼，实时性难解决。PostgreSQL流式数据泵，.延迟低，扩展性好。<br>16.PostgreSQL.ad.lock.效率高，百万/s.秒杀小CASE.<br>17.用户画像TAG多，万列宽表谁家有？PostgreSQL妙招解，bitpack支持实时用户画.像，单机支持十万亿user.tags体量，毫秒级实时圈人。<br>18.物流配送、打车软件、导航软件、出行软件、高速、高铁哪个都离不开路径规划，.PostgreSQL.PostGIS,.pgrouting,.OSM,机器学习库(madlib)—站式解决。<br>19.可靠性，要弹性，事务级可选最牛逼。PostgreSQL金融级可靠性，事务级可控多副本，.正面解决性能与可靠性的矛盾问题。<br>20.PostgreSQL.brin块级痩索引，解决物联网、金融、日志、行为轨迹类数据快速导入.与高效査询的矛盾。<br>21.数据压缩要注意，旋转门时序数据有损压缩，列存储块级压缩。<br>22.数据类型选择要注意，不要什么都用字符串，准确诠释数据类型最重要，基因类型能不.能接，PostBIS插件亮出来。<br>23.数据类型选择要注意，不要什么都用字符串，准确诠释数据类型最重要，化学类型能不.能接，RDkit插件亮出来。<br>24.数据预测、挖掘有插件,MADlib来自伯克利，几百种学习算法够你用，不够还能PLR。<br>25.数据库只能增删改査？不能处理复杂逻辑？又快又狠就不怕。数据库端编程，处理复杂.业务逻辑。解决一致性、低延迟问题好不好。<br>26.金融行业Oracle….ProC很流行，PostgreSQL.ECPG高度兼容ProC。<br>27.被裹脚式sharding吓怕了吗？这也不能那也不能要sharding干啥？….PostgreSQL.real.sharding来帮忙，裹脚布不再要，数据库水平拆分、跨平台数据融合样样行。<br>28.开发规约-命名很重要,比如不要使用小写字母、数字和下划线以外的字符作为对象名。<br>29.开发规约-设计不可忽视，比如全球化业务，建议使用UTF-8字符集。<br>30.开发规约-QUERY很重要，病从口入。比如任何地方都不要使用select….*.from.t.,.用具体的字段列表代替，不要返回用不到的任何字段。另外表结构发生变化也容易出现.问题。<br>31.管理规约-安全与审计，上市公司不可少。从密码到认证、从链路到存储、从DBA到.开发账号，一个都不能少。<br>32.管理规约-诊断少不了，活动视图、插件、日志、DEBUG、隐含参数、PERF样样都.要了如指掌。<br>33.管理规约-优化有高招，熟悉环境、数据库原理、操作系统、网络、业务逻辑必不可.少。<br>34.管理规约-备份与恢复，数据库要爰护，逻辑备份物理备份要得当。<br>35.管理规约-日常维护，制度化。保养很重要，日常小保养，月度大保养，年度复盘都.重要。<br>36.开箱即用，用为上计</p>
<hr>
<h2 id="三十六计-Orade运维-盖国强"><a href="#三十六计-Orade运维-盖国强" class="headerlink" title="三十六计-Orade运维-盖国强"></a>三十六计-Orade运维-盖国强</h2><p>1.有效的备份重于一切，有了有效的备份，即使遭遇灾难，也可以心中有底，手中不慌；<br>2.明确连续性或一致性优先原则，首要优先级在紧急故障时会直接影响决策，必须事前明.确；<br>3.制定应急预案和进行演习，这是确保方案有效可执行的必要工作，没有演练的预案全是.纸上谈兵；<br>4.建立容灾或异地备份，确保在极端情况下，可以保持数据的留存，DataGuard架构是.最简单保护手段；<br>5.数据归档和读写分离，无限累积的数据必然影响性能和备份效率，建立数据归档机制、.实现读写分离需要在架构上优先设计；<br>6.制订规范并贯彻执行，良好的规范是减少故障的基础，全面的规范提升开发和运维人员.的标准化；<br>7.部署标准和完善的监控体系，监控是一切自动化运维的基础，监控可以让我们更早发现.故障，更快应对故障；<br>8.树立安全意识和开始安全审计，安全问题最大的敌人是侥幸，制定安全方案，定期分析.数据库风险，逐步完善数据库安全；<br>9.建立顺畅的部门协作流程，数据库运维外延包括主机、存储、网络、开发等，往往需要.多个部门的协作才能有效解决或推进变革；<br>10.测试和生产环境隔离，数据网络隔离。数据库应处于应用系统最后端，避免将其置于对.外的访问连接之下，并且绝对不能在生产环境进行测试；<br>11.严格管控权限，明确用户职责。遵循最小权限授予原则，避免因为过度授权而带来的安<br>全风险；明确不同的数据库用户能够用于的工作范围，防范和隔离风险；<br>12.密码策略强化，防范弱口令带来的安全风险，定期更换密码，同时生产和测试环境严格.使用不同的密码策略；<br>13.限制登录工具，明确限制不同管理工具的使用场景和访问来源，防范未知工具的注入风.险；<br>14.监控监听日志，分析数据库访问的来源、程序等信息，确保清晰可控，记录在案；<br>15.重要数据加密，尤其是用户和密码等信息，在数据库中应当进行加密存储；<br>16.适时的软件升级，持续关注Oracle软件及更新，参考行业警示，尤其应关注已发布的.安全补丁，防范已知漏洞被恶意利用；<br>17.防范内部风险，绝大部分安全问题都来自于企业内部，通过规章、制度与技术手段规避.安全风险；<br>18.使用绑定变量，在开发过程中，严格使用绑定变量，提升性能同时防范SQL注入攻击；<br>19.审核全表扫描和隐式转换等，这是OLTP系统性能的常见问题，需要在开发端进行SQL.审核，建立开发规范；<br>20.关注新版本的新特性，尤其是版本升级之后，需要提前关注和预防新特性引起的改变，.如11g的串行直接路径读，12c的自适应LGWR等；<br>21.持续保存和记录AWR信息，建立性能基线，这是性能诊断的核心，应该持续保存或转.储重要系统的性能数据；<br>22.铭记Oracle的闪回特性，尤其是闪回査询，可以在误更新数据等操作后快速回退，纠.正错误；<br>23.优化Redo日志存储和效率，关注和优化Log.File.Sync等待，这是数据库事务的重要影响因素<br>24.禁止远程DDL和业务时间的DDL操作，限制高危DDL操作仅能在数据库服务器本地.进行，严格禁止业务时间的DDL操作；<br>25.避免任何不可回退的操作，谨记rm是危险的，在数据库内部执行DROP/TRUNCATE.等破坏性操作时，同样应当谨慎；<br>26.不要轻易删除任何一个归档日志，在归档模式一定要做好归档备份和空间监控，确保曰.志的连续性是恢复根本；<br>27.增进对业务的理解和架构规划参与，数据库的很多优化必须基于对业务的深刻理解，最.佳优化时机在于架构设计和开发环节，Oracle.DBA应该不断向前走；<br>28.对生产环境保持敬畏，不放过任何性能波动疑点，不想当然和轻视任何数据操作。针对.任何业务数据库的操作都不能草率，在接触数据时都不能掉以轻心；<br>29.严格的变更测试和流程操作，并做到变更记录审计，变更之前做到仿真系统严格验证，.形成详细流程、步骤和指令并遵照执行；记录操作日志，任何数据库操作做到有迹可査、.有踪可寻；<br>30.变更必须制定回退方案，不走单行线，确保出现异常时能够将系统恢复原貌；<br>31.选择合适的变更窗口，不可过度乐观草率，避免陷入不可预期的变更陷阱；<br>32.变更之后进行日志核査，在维护期间应当提炼摘取维护期生成的所有日志，确保无误无.错；<br>33.重要操作实现人员备份，在执行重要操作时由两个人同时在场，互相监督审核，不做疲.劳变更和草率决策；不要在维护中冒险，当数据库的表征超出了你的预期，那么停下来,.不做现场的风险性尝试；<br>34.数据恢复必须具备明确的方案和步骤，在面对灾难时，不要急于进行恢复尝试，以免导.致次生故障，需要明确分析、清晰决策，才能万无一失；<br>35.自动化，把上述的各种策略尽可能用脚本或者工具管理实现，做到自动化。<br>36.关键时刻保护现场寻求支持，在数据库出现超出常规、无法把握的问题时，要保护现场，.寻求支援，避免无序尝试带来的数据损失！</p>
<hr>
<h2 id="三十六计-存储运营-高向冉"><a href="#三十六计-存储运营-高向冉" class="headerlink" title="三十六计-存储运营-高向冉"></a>三十六计-存储运营-高向冉</h2><p>1.数据安全是底线，即使不服务也不能丟数据。<br>2.容量是根本，绝对不要让自己陷入没法扩容的境地。紹<br>3.做存储务必要理解业务，不理解业务的存储平台就是别人的垃圾站。<br>4.存储集群建立set标准，标准模型严格执行。<br>5.现网操作标准化到前台，避免后台操作<br>6.多份存储变更时先变更单份数据节点<br>7.变更先少量灰度，变更之前先准备回退方案<br>8.数据迁移是核心频繁操作，工具程序必须稳定，并且要支持各类型的迁移数据操作，不.同机型不同量级相互间迁移。<br>9.索引数据很重要，带状态的模块要注意数据安全，不要随意迁移和清cache。<br>10.格式化盘操作务必确认谨慎<br>11.业务突发要有应对预案，建立故障升级机制<br>12.对监控工具也要进行监控<br>13.更换磁盘必须检査SN号<br>14.不能过分信任自动化工具<br>15.现网环境要干净、统一，如果做不到，要定期扫描<br>16.一定要关注数据删除后回收，即时回收删除数据。<br>17.运维删除数据务必备份，并且要谨慎，禁止人工线上删除数据<br>18.磁盘更换机器死机必须在一个周期内恢复，否则无法达到N个9的要求。<br>19.存储机架和普通设备不一样，用电也不同，做好机架和交换机级别的容灾备份。<br>20.运维一定要有大招进行柔性和恢复业务，否则会死的很惨。<br>21.核心业务做到异地备份，同地多份是没用的。<br>22.存储不仅仅关注容量还要关注inode情况<br>23.数据必须要要有冷备，冷备是最后一道防线，也要监控和运营。<br>24.去单演习不可少，定期演习保稳定<br>25.热点数据分散存储，单机要能限流。<br>26.冷备修复数据要理解业务场景，记得流水和冷备一样重要。流水log也要做好备份。<br>27.存储机型要定制，存储模型要支持设备的更新换代<br>28.提早规划，存储设备制造厂商和机房建设周期都很长。<br>29.存储资源采购会受大环境影响，比如ssd.内存，不止做好容量buffer,还要做好采.购buffer<br>30.存储平台是IO操作型集群，要和计算资源一起复用做到设备最大化利用。<br>31.不同年限的设备性能不同，磁盘读写能力不一致，要区别对待，老化磁盘要定期淘汰。<br>32.存储冷热数据分离，业务一定要能识别冷数据。<br>33.有热点数据要进行资源隔离，上层业务加cache。<br>34.存储引擎特点要熟悉，不同业务文件选择不同存储引擎<br>35.对于频删业务要特殊对待，删除看似场景不多，却是最消耗资源的操作。<br>36.分片存储场景要牢记一台机器的数据或者一块磁盘的数据影响的文件数远不止单机或单盘的比例。</p>
<hr>
<h2 id="三十六计-数据中心节能运维-闫林"><a href="#三十六计-数据中心节能运维-闫林" class="headerlink" title="三十六计-数据中心节能运维-闫林"></a>三十六计-数据中心节能运维-闫林</h2><p>1.选址是第一要素。DC尽量选择高海拔、高纬度、温度低、湿度适中的地点。<br>2.大型DC制冷方式选择参考：能源利用效率是风冷、水冷、自然冷却<br>3.设计全封闭型的数据中心，提高机房密闭性能，取消外窗，防止太阳辐射消耗能量，满.足LEED要求的绿色节能建筑要求。<br>4.在机房制冷控制区域对维护结构进行保温处理，防止机房相邻区域因温度、湿度差异较.大而产生冷凝水，同时降低制冷的负荷。<br>5.合理摆放空调设备位置，风口地板与空调保持6英尺以上距离，避免气流短路。<br>6.对线缆穿出地板的开口处进行密封处理，优化机房地板下结构降低风阻。<br>7.空调摆放与机柜排垂直；避开冷通道<br>8.在数据中心机房中建设冷通道，并配置下送风机房专用风冷式精密空调；在数据中心机.房中建设热通道，并配置下送风机房专用风冷式精密空调。<br>9.在数据中心机房建设专用大型水冷式机房精密空调和芯片冷却管道，直接给IT设备芯.片散热。<br>10.在数据中心机房采用机房风冷式精密空调+大型新风机1：1配置，合理利用自然新风.冷源。<br>11.机房功率密度高时，空调机分散安放，应适当提高活动地板铺高和地板风口出风速度,.送风均匀。<br>12.有条件时可在空调机顶部接回风道，热通道上方加回风口（有吊顶机房）<br>13.空调机管线尽量布置在空调机后部<br>14.将大功率、高负荷的服务器摆放在机柜的底部或中间<br>15.选用节能的加湿系统，能耗：超声波加湿、湿膜加湿、电极加湿、红外线<br>16.设定空调最佳工况，防止出现部分空调正在加湿，部分空调正在除湿的情况<br>17.推荐空调机冷凝器自动雾化技能技术，采用磁悬浮离心冷水机组，采用太空纤维的风机.和冰蓄冷技术<br>18.空调采用高能效比压缩机，电机使用变频系统，末端空调使用，下沉EC风机<br>19.各种数据中心皆可广泛采用板式热交换器<br>20.大型数据中心采用大容量蓄冷罐<br>21.水冷背板机柜，选用高效率、模块化UPS<br>22.使用UPS的ECO模式（智能休眠），使UPS运行在经济状态下<br>23.谐波治理：加隔离变压器；对谐波进行抑制，12次脉冲附加11次滤波<br>24.对电力系统进行无功补偿<br>25.在配电柜断路器和UPS输出端加装节电器<br>26.市电直供+240V高压直流供电系统<br>27.选择节能灯具，并引入智能照明系统，提高自动化程度，减少不必要的光照强度<br>28.机柜加盲板，有效使用机柜封闭盲板，减少冷热空气的混合<br>29.推荐柜门：网孔六角形设计，通风率78%<br>30.关闭不用的IT负载。找出并且淘汰没有使用的或者利用率低的设备和应用。<br>31.选用低能耗IT设备，淘汰高能耗设备<br>32.采用耐35度高温服务器，采用液冷服务器<br>33.采用多种能源：太阳能、地热能、核能、潮汐能、风能<br>34.燃气冷热电三联供系统<br>35.采用数据中心微模块技术。<br>36.作好除尘：空调、风机尤其是风扇、滤网除尘</p>
]]></content>
      <tags>
        <tag>运维</tag>
        <tag>ops</tag>
        <tag>运维规范</tag>
      </tags>
  </entry>
  <entry>
    <title>我青年时代就--看过的动漫</title>
    <url>/archives/animal.html</url>
    <content><![CDATA[<p><del>我青年时代就读过西游记、马可波罗游记、左丘明、左传</del>😂</p>
<hr>
<h2 id="心目中的几部神作"><a href="#心目中的几部神作" class="headerlink" title="心目中的几部神作"></a>心目中的几部神作</h2><p>1.三年E班（暗杀教室）</p>
<p>2.白箱</p>
<p>3.四月是你的谎言</p>
<p>4.Angle Beats</p>
<p>5.命运石之门</p>
<hr>
<h2 id="长篇"><a href="#长篇" class="headerlink" title="长篇"></a>长篇</h2><p>1.火影忍者<br>2.海贼王<br>3.银魂</p>
<hr>
<h2 id="京阿尼"><a href="#京阿尼" class="headerlink" title="京阿尼"></a>京阿尼</h2><p>1.上低音号</p>
<p>2.声之形</p>
<p>2.声之形</p>
<hr>
<h2 id="剧场版"><a href="#剧场版" class="headerlink" title="剧场版"></a>剧场版</h2><hr>
<p>未来的未来<br>Mirai no Mirai<br>未来のミライ</p>
<hr>
<p>朝花夕誓——于离别之朝束起约定之花<br>Sayonara no Asa ni Yakusoku no Hana o Kazarou</p>
<hr>
<p>莉兹与青鸟<br>Liz to Aoi Tori</p>
<hr>
<p>White Album 2<br>白色相簿 2</p>
<hr>
<p>黑岩射手</p>
<hr>
<p>死亡笔记</p>
<hr>
<p>K</p>
<hr>
<p>打工吧!魔王</p>
<hr>
<p>Shingeki no Kyojin<br>进击的巨人</p>
<hr>
<p>Chuunibyou demo Koi ga Shitai!<br>中二病也要谈恋爱</p>
<hr>
<p>Gekijouban Hibike! Euphonium Todoketai Melody<br>吹响吧！上低音号 想要传达的旋律</p>
<hr>
<p>Saenai Heroine no Sodatekata<br>路人女主的养成方法</p>
<hr>
<p>Toaru Majutsu no Index<br>魔法禁书目录</p>
<hr>
<p>Hyouka<br>冰菓</p>
<hr>
<p>Eromanga Sensei<br>埃罗芒阿老师</p>
<hr>
<p>Akame ga Kill!<br>斩·赤红之瞳！</p>
<hr>
<p>Gochuumon wa Usagi Desuka？<br>请问您今天要来点兔子吗？</p>
<hr>
<p>Kono Subarashii Sekai ni Shukufuku wo!<br>为美好的世界献上祝福</p>
<hr>
<p>NO GAME NO LIFE ZERO<br>游戏人生 ZERO</p>
<hr>
<p>Fate/stay night: Heaven’s Feel I. presage flower</p>
<hr>
<p>Mahouka Koukou no Rettousei<br>魔法科高校的劣等生</p>
<hr>
<p>Shigatsu wa Kimi no Uso<br>四月是你的谎言</p>
<hr>
<p>Sakura Quest<br>樱花任务</p>
<hr>
<p>Machine-Doll wa Kizutsukanai<br>机巧少女不会受伤</p>
<hr>
<p>Fuuka<br>风夏</p>
<hr>
<p>Kotonoha no Niwa<br>言叶之庭</p>
<hr>
<p>Ore no Imouto ga Konna ni Kawaii Wake ga Nai.<br>我的妹妹哪有这么可爱.</p>
<hr>
<p>Shuumatsu Nani Shitemasuka? Isogashii Desuka? Sukutte Moratte Ii Desuka?<br>末日时在做什么？有没有空？可以来拯救吗？</p>
<hr>
<p>CODE GEASS Lelouch of the Rebellion<br>Code Geass 反叛的鲁鲁修</p>
<hr>
<p>Black Bullet<br>漆黑的子弹</p>
<hr>
<p>Tsuki ga Kirei<br>月色真美</p>
<hr>
<p>Tsuki ga Kirei<br>月色真美</p>
<hr>
<p>Sword Art Online I+II+EE<br>刀剑神域</p>
<hr>
<p>Kobayashi-san Chi no Maidragon<br>小林家的龙女仆</p>
<hr>
<p>Kobayashi-san Chi no Maidragon<br>小林家的龙女仆</p>
<hr>
<p>Sword Art Online: Ordinal Scale<br>刀剑神域 序列之争</p>
<hr>
<p>Amagi Brilliant Park<br>甘城光辉游乐园</p>
<hr>
<p>Hibike! Euphonium 2<br>起奏! 上低音号 2</p>
<hr>
<p>Yahari Ore no Seishun LoveCome wa Machigatte Iru.<br>我的青春恋爱物语果然有问题。</p>
<hr>
<p>Re: Zero kara Hajimeru Isekai Seikatsu<br>Re: 从零开始的异世界生活</p>
<hr>
<p>Gabriel Dropout<br>珈百璃的堕落</p>
<hr>
<p>Kimi no Na wa.<br>你的名字</p>
<hr>
<p>Guilty Crown<br>罪恶王冠</p>
<hr>
<p>Danshi Koukousei no Nichijou<br>男子高中生的日常</p>
<hr>
<p>The Asterisk War<br>学战都市六芒星</p>
<hr>
<p>Kore wa Zombie Desuka?<br>这个是僵尸吗?</p>
<hr>
<p>Tokyo Ghoul<br>东京食尸鬼</p>
<hr>
<p>One Punch Man<br>一拳超人</p>
<hr>
<p>Noragami<br>野良神</p>
<hr>
<p>Hidan no Aria AA<br>绯弹的亚里亚AA</p>
<hr>
<p>Hibike! Euphonium: Kitauji Koukou Suisougaku Bu e Youkoso<br>吹响! 上低音号 欢迎来到北宇治高中吹奏乐部</p>
<hr>
<p>Nichijou<br>日常</p>
<hr>
<p>Sakamoto Desu ga?<br>在下坂本有何贵干</p>
<hr>
<p>Sakura Trick<br>樱Trick</p>
<hr>
<p>Kyoukai no Kanata<br>境界的彼方</p>
<hr>
<p>Chuunibyou demo Koi ga Shitai! Ren<br>中二病也要谈恋爱</p>
<hr>
<p>Musaigen no Phantom World<br>无彩限的怪灵世界</p>
<hr>
<p>Yahari Ore no Seishun LoveCome wa Machigatte Iru. Zoku<br>我的青春恋爱物语果然有问题。续</p>
<hr>
<p>Accel World<br>加速世界</p>
<hr>
<p>Tamako Market<br>玉子市场</p>
<hr>
<p>Puella Magi Madoka Magica<br>魔法少女小圆</p>
<hr>
<p>Gochuumon wa Usagi Desuka??<br>请问您今天要来点兔子吗？？</p>
<hr>
<p>Seraph of the End<br>终结的炽天使</p>
<hr>
<p>Food Wars! Shokugeki no Soma<br>食戟之灵</p>
<hr>
<p>Plastic Memories<br>可塑性记忆</p>
<hr>
<p>Himouto! Umaru-chan<br>干物妹！小埋</p>
<hr>
<p>Glass no Hana to Kowasu Sekai<br>玻璃花与崩坏的世界</p>
<hr>
<p>Shigatsu wa Kimi no Uso<br>四月是你的谎言</p>
<hr>
<p>Chuunibyou demo Koi ga Shitai!<br>中二病也要谈恋爱</p>
<hr>
<p>Hibike! Euphonium<br>吹响! 上低音号</p>
<hr>
<p>Ansatsu Kyoushitsu<br>暗杀教室</p>
<hr>
<p>Nisekoi<br>伪恋</p>
<hr>
<p>Fate/Stay Night UBW<br>命运长夜:无限剑制 UBW</p>
<hr>
<p>Gochuumon wa Usagi Desuka?<br>请问您今天要来点兔子吗？</p>
<hr>
<p>SHIROBAKO<br>白箱</p>
<hr>
<p>Rakuen Tsuihou -Expelled from Paradise-<br>乐园追放</p>
<hr>
<p>Gekkan Shoujo Nozaki-kun<br>月刊少女野崎君</p>
<hr>
<p>Toaru Kagaku no Railgun<br>某科学的超电磁炮</p>
<hr>
<p>Citrus<br>柑橘味香气</p>
<hr>
<p>Sakurasou no Pet na Kanojo<br>樱花庄的宠物女孩</p>
<hr>
<p>Koi wa Ameagari no You ni<br>恋如雨止</p>
<hr>
<hr>
<ol>
<li>Angel Beats! 一番の宝物 3145.58</li>
<li>某科学的超电磁炮 late in autumn 3101.09</li>
<li>轻音少女 相遇天使 3096.59</li>
<li>某科学的超电磁炮 Only my Railgun 3094.96</li>
<li>幻想万华镜 色は匂へど散りぬるを 3090.61</li>
<li>ef ebullient future 3081.11</li>
<li>魔法少女奈叶 PHANTOM MINDS 3074.66</li>
<li>Rewrite 恋文 3056.62</li>
<li>轻音少女 No Thank You 3049.88</li>
<li>加速世界 unfinished 3048.40</li>
<li>空之境界 fairytale 3047.60</li>
<li>轻音少女 don’t say lazy 3038.00</li>
<li>Angel Beats! Brave Song 3024.00</li>
<li>超时空要塞ライオン ライオン 3022.96</li>
<li>物语系列 君の知らない物语 3022.37</li>
<li>fortissimo//Akkord:Bsusvier fortissimo -the ultimate crisis 3021.91</li>
<li>某科学的超电磁炮 LEVEL5 -Judgelight- 3016.06</li>
<li>fate/zero To The Beginning 3014.78</li>
<li>食灵·零 Paradise Lost 3013.27</li>
<li>空之境界 Oblivious 3010.62</li>
<li>某科学的超电磁炮 future gazer 3008.47</li>
<li>Little busters！EX Saya’s song 3005.03</li>
<li>薄樱鬼 君ノ记忆 2995.44</li>
<li>C3魔方少女 Endless Story 2994.71</li>
<li>白色相簿 深爱 2989.18</li>
<li>只有神才知道的世界 God Only Knows 2985.84</li>
<li>Gosick Resuscitated Hope 2979.49</li>
<li>CLANNAD after story 时を刻む呗 2977.66</li>
<li>Angel Beats! My Soul，Your Beats！ 2977.33</li>
<li>空之境界 伤迹 2975.14</li>
<li>秽翼的尤斯蒂娅 Asphodelus 2969.00</li>
<li>fate系列 Oath Sign 2965.88</li>
<li>ef A moon filled sky 2958.00</li>
<li>钢之炼金术师FA Again 2957.00</li>
<li>我的妹妹不可能那么可爱 irony 2952.02</li>
<li>罪恶王冠 エウテルペ 2951.96</li>
<li>fate系列 MEMORIA 2950.36</li>
<li>罪恶王冠 Departures ～あなたにおくるアイの歌～ 2946.00</li>
<li>赤色的约定 I miss you 2945.67</li>
<li>物语系列 恋爱サーキュレーション 2936.72</li>
<li>命运石之门 Hacking to the Gate 2932.50</li>
<li>刀剑神域 crossing field 2931.00</li>
<li>魔法少女小圆 and i’m home 2930.00</li>
<li>缘之空 道の先 空の向こう 2927.93</li>
<li>天降之物 fallen down 2926.00</li>
<li>C3魔方少女 纹 2924.54</li>
<li>gosick Destin Histoire 2911.04</li>
<li>幻想万华镜 华鸟风月 2909.96</li>
<li>魔法少女小圆 Sis puella mangical 2907.72</li>
<li>G弦上的魔王 close your eyes 2905.00</li>
<li>龙与虎 Silky heart 2893.86</li>
<li>鬼ごっこ！ 红の空 2892.54</li>
<li>隐之王 HIKARI 2892.00</li>
<li>物语系列 二言目 2891.67</li>
<li>在盛夏等待 Sign 2889.37</li>
<li>fate系列 Voice～辿りつく场所～ 2888.75</li>
<li>Angel Beats! My song 2883.12</li>
<li>轻音少女 U&amp;I 2879.40</li>
<li>军火女王 Borderland 2879.00</li>
<li>魔法禁书目录 PSI-missing 2878.00</li>
<li>学生会的一己之见 Treasure 2866.61</li>
<li>物语系列 staple stable 2866.19</li>
<li>迷茫管家与懦弱的我 be starters! 2865.00</li>
<li>物语系列 Sugar sweet nightmare 2863.45</li>
<li>魔法少女小圆 コネクト 2863.37</li>
<li>幻想万华镜 月に丛云华に 2860.86</li>
<li>旋风管家 wonder wind 2860.48</li>
<li>灼眼的夏娜 I’ll believe 2859.74</li>
<li>fate系列 满天 2856.88</li>
<li>STAR DRIVER 闪亮的塔科特 モノクローム 2855.76</li>
<li>狼と香辛料 旅の途中 2855.63</li>
<li>灼眼的夏娜 one 2854.24</li>
<li>露蒂的玩具 真夏のフォトグラフ 2853.70</li>
<li>妖精的尾巴 Gitter 2852.47</li>
<li>龙与虎 Holy Night 2851.12</li>
<li>魔法少女小圆 Magia 2849.43</li>
<li>神的记事本 カワルミライ 2848.46</li>
<li>恋爱随意链接 パラダイム 2846.59</li>
<li>小鸠 あした来る日 2846.05</li>
<li>Rewrite 伪らない君へ 2844.68</li>
<li>gosick Unity 2839.41</li>
<li>咲-saki- next legend 2838.00</li>
<li>灼眼的夏娜 光芒 2835.56</li>
<li>纯白交响曲 Authentic symphony 2834.57</li>
<li>绯色的欠片 ねぇ 2834.10</li>
<li>轻音少女 ふわふわ时间 2832.65</li>
<li>恋爱与选举与巧克力 风のなかのプリムローズ 2832.50</li>
<li>银魂 Pary 2832.07</li>
<li>轻音少女 Singing 2831.31</li>
<li>花牌情缘 そしていま 2830.53</li>
<li>绯弹的亚莉亚 Scarlet Ballet 2830.34</li>
<li>夏色奇迹 明日への帰り道 2826.67</li>
<li>神枪少女 doll 2825.00</li>
<li>加速世界 burst the gravity 2825.00</li>
<li>放浪息子 For You 2824.28</li>
<li>夏雪密会 あなたに出会わなければ ～夏雪冬花～ 2823.75</li>
<li>空之音 光の旋律 2823.20</li>
<li>Infinite Stratos STRAIGHT JET 2822.54</li>
<li>Rewrite Philosophyz 2819.36</li>
<li>缘之空 比翼の羽根 2815.41</li>
</ol>
]]></content>
      <tags>
        <tag>anmial</tag>
        <tag>acg</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐使用过的 Android 神器</title>
    <url>/archives/android-tools.html</url>
    <content><![CDATA[<p><del>我青年时代就读过西游戏、马可波罗游记、左丘明、左传</del>😂…..没读过</p>
<hr>
<p>论Android神器当属Tasker、钛备份、xposed、magisk、superSU、busybox这五个。以下总结自己多年刷机经验，谈谈这几个神器的使用。用好这些神器绝对会让你的Android更加强大！</p>
<hr>
<h2 id="1-Tasker"><a href="#1-Tasker" class="headerlink" title="1.Tasker"></a>1.Tasker</h2><p>设置各种自动化任务，例如：自动填写验证码，自动转发短信到另一个手机号，打开chrome时自动开启代理，夜间静音，锁屏进入打盹模式。</p>
<hr>
<h2 id="2-钛备份"><a href="#2-钛备份" class="headerlink" title="2.钛备份"></a>2.钛备份</h2><p>绝对的神器，备份应用数据不用再为每个app设置而烦恼了，虽然最近也出了一夜替代钛备份的工具，但我还是认为钛备份最好用，简单操作，自定义强，稳定使用了四五年，已经很依赖和信任这个工具了。</p>
<hr>
<h2 id="3-xposed"><a href="#3-xposed" class="headerlink" title="3.xposed"></a>3.xposed</h2><p>很多xposed模板可用，比如绿色守护的增强模块，存储重定向的模块，应用管理器的模块，全局渲染导航栏的模块.<br>貌似xposed作者已经弃坑了.Android 9.0已经出来一年多了还是没有正式版的xposed可用，就像当初Android 7.0一样，也是等了很久很久，不知道Android9.0要等多久。<br>到Android 9.0后不再想使用xposed了，主要是对xposed性能的考虑，不装xposed也能过得去.绿色守护可以安装到pri-app目录里，就能用到特权模式，相比xposed还更高效。</p>
<hr>
<h2 id="4-magisk"><a href="#4-magisk" class="headerlink" title="4.magisk"></a>4.magisk</h2><p>新一代root的工具，相比superSU优点很多。作者时台湾的，Android P还未发布，magisk就已经root了设备😂。</p>
<hr>
<h2 id="5-superSU"><a href="#5-superSU" class="headerlink" title="5.superSU"></a>5.superSU</h2><p>su时root必备的工具，至于root的原理和过程以前看过一本ROM编译的书讲到过。你搞机肯定需要root权限啊。</p>
<hr>
<h2 id="6-busybox"><a href="#6-busybox" class="headerlink" title="6.busybox"></a>6.busybox</h2><p>很多搞机工具都需要用到busybox，比如钛备份，幸运破解器等，对了，钛备份内置了一个busybox，想必也是使用busybox来备份应用的。</p>
<hr>
<h2 id="7-RootExpoloer-RE"><a href="#7-RootExpoloer-RE" class="headerlink" title="7.RootExpoloer(RE)"></a>7.RootExpoloer(RE)</h2><p>RE管理器时很久远的工具了，Z自从Android1.5就开始使用RE管理器，是我们刷机搞基必备的文件管理工具，特点是简洁好用。</p>
<hr>
<h2 id="8-绿色守护"><a href="#8-绿色守护" class="headerlink" title="8.绿色守护"></a>8.绿色守护</h2><p>优化电池使用，后台自动化休眠毒瘤app。尤其是使用绿色守护强制进入打盹模式，省电神器。配合hotplug特性的内核简直省电不要不要的。经待机测试绿色守护+hotplug 夜间待机8小时耗电1%。</p>
<hr>
<h2 id="9-App-Ops"><a href="#9-App-Ops" class="headerlink" title="9.App Ops"></a>9.App Ops</h2><p>用来权限管理，我对待新应用我直接禁用最大化的权限。最好禁用所有权限，结合应用管理的匿名，给app传递一个伪造的数据😂。<br>国产毒瘤app，你妈死了，不给权限不让运行，如此毒瘤的行为简直想草死你全家😡。</p>
<hr>
<h2 id="10-应用管理-github-tornaco-X-APM"><a href="#10-应用管理-github-tornaco-X-APM" class="headerlink" title="10.应用管理 github@tornaco/X-APM"></a>10.应用管理 github@tornaco/X-APM</h2><p>功能很丰富，可对新安装的应用套用自定义模板，很方便，也是神器。喜欢匿名功能，我喜欢伪造一些假数据给app😂。</p>
<hr>
<h2 id="11-XInternalSD"><a href="#11-XInternalSD" class="headerlink" title="11.XInternalSD"></a>11.XInternalSD</h2><p>xposed模块，用于重定向那些再内存存储里拉屎的app，真是国产毒瘤app，不遵守规范，乱再内部存储里拉屎，用这个模块重定向那些拉屎的app。个人有强迫症，内部存储目录我整理的很有序，绝对不容许这些app在这里乱拉屎。</p>
<hr>
<h2 id="12-MyAndroidTools-IFW"><a href="#12-MyAndroidTools-IFW" class="headerlink" title="12.MyAndroidTools / IFW"></a>12.MyAndroidTools / IFW</h2><p>二者作用效果相同，用来禁用一些毒瘤app的后台服务</p>
<hr>
<h2 id="14-BBS-betterbatterystats"><a href="#14-BBS-betterbatterystats" class="headerlink" title="14.BBS betterbatterystats"></a>14.BBS betterbatterystats</h2><p>用来检测电池电量的使用，以及查看系统唤醒锁的情况。配合另一个工具食用绝佳</p>
<hr>
<h2 id="15-Poweramp"><a href="#15-Poweramp" class="headerlink" title="15.Poweramp"></a>15.Poweramp</h2><p>离线音乐播放软件，简洁好用。受够了国内的毒瘤音乐播放软件，一个音乐播放软件里弄个商城????尼玛死了。</p>
<hr>
<h2 id="16-juiceSSH"><a href="#16-juiceSSH" class="headerlink" title="16.juiceSSH"></a>16.juiceSSH</h2><p>手机端SSH 登录软件，很好用，用来三年了😂，其实</p>
<hr>
<h2 id="17-ScanMediaPiz"><a href="#17-ScanMediaPiz" class="headerlink" title="17.ScanMediaPiz"></a>17.ScanMediaPiz</h2><p>媒体扫描，用来解决MTP一堆狗屎毛病。没有启动界面，点击一下就能启动，而且时开源的，GitHub上有源码，代码不到30行。想用tasker实现这个媒体扫描的功能，试了好几次都不行😭。</p>
<hr>
<h2 id="18-LongShot"><a href="#18-LongShot" class="headerlink" title="18.LongShot"></a>18.LongShot</h2><p>长截图，用的havos原生ROM，没得长截图的功能，只好用这个代替喽</p>
<hr>
<h2 id="19-Bmap3-9"><a href="#19-Bmap3-9" class="headerlink" title="19.Bmap3.9"></a>19.Bmap3.9</h2><p>日用的地图软件，简洁好用，开源免费。功能不强大，但够用。没有杂七杂八的功能。</p>
<hr>
<h2 id="20-Lawnchair"><a href="#20-Lawnchair" class="headerlink" title="20.Lawnchair"></a>20.Lawnchair</h2><p>有史以来我用过最简洁好用的桌面启动器，非常简洁还用！！！，没有智障的负一屏，只有桌面，应用抽屉使用。很简单，结合pixelIco的图包，能打造个简洁美观的桌面。</p>
<hr>
<h2 id="21-MXplayer"><a href="#21-MXplayer" class="headerlink" title="21.MXplayer"></a>21.MXplayer</h2><p>视频播放器，用了也是很久很久了。貌似是个印度的，公司1亿美元被收购了。</p>
<hr>
<h2 id="22-Solid-Explorer"><a href="#22-Solid-Explorer" class="headerlink" title="22.Solid Explorer"></a>22.Solid Explorer</h2><p>是我替代RE管理器的工具，主要是好看，而且也很简洁。和电脑传输文件就用它的SMB共享，尽量原理MTP吧，传输3万张图片24小时是传不完了，MTP巨慢。还是SMB稍稍快点，手机开热点传最高8MB/S，可能是我手机基带的问题。</p>
<hr>
<h2 id="23-简洁-日历"><a href="#23-简洁-日历" class="headerlink" title="23.简洁 日历"></a>23.简洁 日历</h2><p>日历app，相当简洁好用，没有杂七杂八的功能</p>
<hr>
<h2 id="24-AFWall"><a href="#24-AFWall" class="headerlink" title="24.AFWall+"></a>24.AFWall+</h2><p>防火墙，用于控制app上网权限，以及设置一些iptables规则，用来屏蔽买药的baidu不错。</p>
<hr>
<h2 id="25-Termux"><a href="#25-Termux" class="headerlink" title="25.Termux"></a>25.Termux</h2><p>打造最强大的Android终端，还可以安装oh-my-zsh哦😂。</p>
<hr>
<h2 id="26-IDM9-3"><a href="#26-IDM9-3" class="headerlink" title="26.IDM9.3"></a>26.IDM9.3</h2><p>下载神器，64线程暴力下载能跑满带宽</p>
<hr>
<h2 id="27-Pure天气"><a href="#27-Pure天气" class="headerlink" title="27.Pure天气"></a>27.Pure天气</h2><p>十分轻量简洁的天气软件</p>
<hr>
<h2 id="28-Tiny-web-server"><a href="#28-Tiny-web-server" class="headerlink" title="28.Tiny web server"></a>28.Tiny web server</h2><p>安卓端的web服务器，结合FRP使用可用于公网共享Android目录。不过服务器默认开启的是内部存储目录，为了保护好隐私，最好设置好共享的目录。</p>
<hr>
<h2 id="29-湾区日报-开源工场"><a href="#29-湾区日报-开源工场" class="headerlink" title="29.湾区日报 / 开源工场"></a>29.湾区日报 / 开源工场</h2><p>个人最主要的英文阅读媒体，学习英语呀😂。</p>
<hr>
<h2 id="30-Wakelock-Detecor"><a href="#30-Wakelock-Detecor" class="headerlink" title="30.Wakelock Detecor"></a>30.Wakelock Detecor</h2><p>用来检测统计一些唤醒锁的使用情况。</p>
]]></content>
      <tags>
        <tag>安卓</tag>
        <tag>刷机</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>tasker 神器</title>
    <url>/archives/android-tasker.html</url>
    <content><![CDATA[<h2 id="1-使用tasker自动填写验证码"><a href="#1-使用tasker自动填写验证码" class="headerlink" title="1.使用tasker自动填写验证码"></a>1.使用tasker自动填写验证码</h2><p>复制验证码 (25)<br>A1: 变量设置 [ 名称:%SYM 发往:%SMSRB Recurse Variables:关 无匹配:关 附加:关 ]<br>A2: 变量搜索替换 [ 变量:%SYM 搜索:[\d]{6}|[\d]{4} 忽略大小写:开 多行:开 只匹配一次:开 将匹配存储到:%SYM 替代匹配:关 替代为: ]<br>A3: 通知LED [ 标题:验证码 %SYM1 已复制到剪贴板 文字: 图标:null 数字:0 颜色:红色 速率:500 优先级:3 Repeat Alert:关 ]<br>A4: 设置剪贴板 [ 文字:%SYM1 添加:关 ]<br>A5: 输入 [ 文字:%SYM1 重复次数:1 ]</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">TaskerData</span> <span class="attr">sr</span>=<span class="string">""</span> <span class="attr">dvi</span>=<span class="string">"1"</span> <span class="attr">tv</span>=<span class="string">"5.5.bf2"</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">Task</span> <span class="attr">sr</span>=<span class="string">"task25"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">cdate</span>&gt;</span>1539441850928<span class="tag">&lt;/<span class="name">cdate</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">edate</span>&gt;</span>1556107366039<span class="tag">&lt;/<span class="name">edate</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>25<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">nme</span>&gt;</span>复制验证码<span class="tag">&lt;/<span class="name">nme</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">pri</span>&gt;</span>100<span class="tag">&lt;/<span class="name">pri</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act0"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>547<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>%SYM<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>%SMSRB<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act1"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>598<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>%SYM<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>[\d]&#123;6&#125;|[\d]&#123;4&#125;<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>%SYM<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg6"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg7"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act2"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>525<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>验证码 %SYM1 已复制到剪贴板<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Img</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">ve</span>=<span class="string">"2"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">val</span>=<span class="string">"500"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg6"</span> <span class="attr">val</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg7"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act3"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>105<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>%SYM1<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act4"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>702<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>%SYM1<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">Task</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">TaskerData</span>&gt;</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="2-使用tasker清除流量统计，适用于日租卡"><a href="#2-使用tasker清除流量统计，适用于日租卡" class="headerlink" title="2. 使用tasker清除流量统计，适用于日租卡"></a>2. 使用tasker清除流量统计，适用于日租卡</h2><p>数据重置 (3)<br>A1: 移动数据 [ 设置:开 ]<br>A2: 运行外壳 [ 命令:rm -rf /data/system/netstats/* 超时（秒）:0 使用Root:开 输出存储到: 错误存储到: 将结果保存到: ]<br>A3: 通知震动 [ 标题:数据重置，即将关机 文字: 图标:null 数字:0 模式: 优先级:3 Repeat Alert:关 ]<br>A4: 等待 [ MS:0 秒:1 分:0 小时:0 天:0 ]<br>A5: 状态栏 [ 设置:展开 ]<br>A6: 执行任务 [ 名称:存储移动 优先级:%priority 参数 1 (%par1): 参数 2 (%par2): 返回值变量: 停止:关 ]<br>A7: 等待 [ MS:0 秒:0 分:3 小时:0 天:0 ]<br>A8: 重启 [ 类型:常规 ]</p>
 <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">TaskerData</span> <span class="attr">sr</span>=<span class="string">""</span> <span class="attr">dvi</span>=<span class="string">"1"</span> <span class="attr">tv</span>=<span class="string">"5.5.bf2"</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">Task</span> <span class="attr">sr</span>=<span class="string">"task3"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">cdate</span>&gt;</span>1539351038664<span class="tag">&lt;/<span class="name">cdate</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">edate</span>&gt;</span>1556107131126<span class="tag">&lt;/<span class="name">edate</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>3<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">nme</span>&gt;</span>数据重置<span class="tag">&lt;/<span class="name">nme</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">pri</span>&gt;</span>100<span class="tag">&lt;/<span class="name">pri</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act0"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>433<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act1"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>123<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>rm -rf /data/system/netstats/*<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act2"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>536<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>数据重置，即将关机<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Img</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">ve</span>=<span class="string">"2"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">val</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg6"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act3"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>30<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act4"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>512<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act5"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>130<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>存储移动<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">var</span>&gt;</span>%priority<span class="tag">&lt;/<span class="name">var</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">Int</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act6"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>30<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act7"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>59<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">Task</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">TaskerData</span>&gt;</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="3-使用tasker锁屏后进入打盹模式"><a href="#3-使用tasker锁屏后进入打盹模式" class="headerlink" title="3.使用tasker锁屏后进入打盹模式"></a>3.使用tasker锁屏后进入打盹模式</h2><p>⭐️ 省电 (37)<br>A1: 停止 [ 伴随错误:关 任务:🐳 均衡 ]<br>A2: 停止 [ 伴随错误:关 任务:⭐️ 省电 ] If [ %STATUS ~ 1 ]<br>&lt;亮屏等待时间&gt;<br>A3: 等待 [ MS:0 秒:0 分:5 小时:0 天:0 ]<br>&lt;省电模式（节省一点电量带来更多卡顿，相对感知卡顿：115）&gt;<br>A4: 运行外壳 [ 命令:sh /data/powercfg powersave 超时（秒）:0 使用Root:开 输出存储到: 错误存储到: 将结果保存到: ]<br>A5: 立即休眠 [ 配置:All greenified apps 超时（秒）:0 ]<br>A6: 嗜睡模式 [ 配置:打开 超时（秒）:0 ]<br>A7: 变量设置 [ 名称:%STATUS 发往:1 Recurse Variables:关 无匹配:开 附加:关 ]<br>A8: [X] 等待 [ MS:0 秒:0 分:0 小时:1 天:0 ]<br>A9: [X] 移动数据 [ 设置:关 ]</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">TaskerData</span> <span class="attr">sr</span>=<span class="string">""</span> <span class="attr">dvi</span>=<span class="string">"1"</span> <span class="attr">tv</span>=<span class="string">"5.5.bf2"</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">Task</span> <span class="attr">sr</span>=<span class="string">"task37"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">cdate</span>&gt;</span>1528600734643<span class="tag">&lt;/<span class="name">cdate</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">edate</span>&gt;</span>1556107574089<span class="tag">&lt;/<span class="name">edate</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>37<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">nme</span>&gt;</span>⭐️ 省电<span class="tag">&lt;/<span class="name">nme</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">pri</span>&gt;</span>6<span class="tag">&lt;/<span class="name">pri</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act0"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>137<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>🐳 均衡<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act1"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>137<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>⭐️ 省电<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">ConditionList</span> <span class="attr">sr</span>=<span class="string">"if"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Condition</span> <span class="attr">sr</span>=<span class="string">"c0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">lhs</span>&gt;</span>%STATUS<span class="tag">&lt;/<span class="name">lhs</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">op</span>&gt;</span>2<span class="tag">&lt;/<span class="name">op</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">rhs</span>&gt;</span>1<span class="tag">&lt;/<span class="name">rhs</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Condition</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">ConditionList</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act2"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>30<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">label</span>&gt;</span>亮屏等待时间<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"5"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act3"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>123<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">label</span>&gt;</span>省电模式（节省一点电量带来更多卡顿，相对感知卡顿：115）<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>sh /data/powercfg powersave<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg5"</span> <span class="attr">ve</span>=<span class="string">"3"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act4"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>2056827700<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Bundle</span> <span class="attr">sr</span>=<span class="string">"arg0"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Vals</span> <span class="attr">sr</span>=<span class="string">"val"</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">com.twofortyfouram.locale.intent.extra.BLURB</span>&gt;</span>All greenified apps<span class="tag">&lt;/<span class="name">com.twofortyfouram.locale.intent.extra.BLURB</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">com.twofortyfouram.locale.intent.extra.BLURB-type</span>&gt;</span>java.lang.String<span class="tag">&lt;/<span class="name">com.twofortyfouram.locale.intent.extra.BLURB-type</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">net.dinglisch.android.tasker.subbundled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">net.dinglisch.android.tasker.subbundled</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">net.dinglisch.android.tasker.subbundled-type</span>&gt;</span>java.lang.Boolean<span class="tag">&lt;/<span class="name">net.dinglisch.android.tasker.subbundled-type</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">source</span>&gt;</span>net.dinglisch.android.taskerm<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">source-type</span>&gt;</span>java.lang.String<span class="tag">&lt;/<span class="name">source-type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Vals</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">Bundle</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>com.oasisfeng.greenify<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>com.oasisfeng.greenify.GreenifyShortcut<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act5"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>289233647<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Bundle</span> <span class="attr">sr</span>=<span class="string">"arg0"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Vals</span> <span class="attr">sr</span>=<span class="string">"val"</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">cmd</span>&gt;</span>1<span class="tag">&lt;/<span class="name">cmd</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">cmd-type</span>&gt;</span>java.lang.Integer<span class="tag">&lt;/<span class="name">cmd-type</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">com.twofortyfouram.locale.intent.extra.BLURB</span>&gt;</span>打开<span class="tag">&lt;/<span class="name">com.twofortyfouram.locale.intent.extra.BLURB</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">com.twofortyfouram.locale.intent.extra.BLURB-type</span>&gt;</span>java.lang.String<span class="tag">&lt;/<span class="name">com.twofortyfouram.locale.intent.extra.BLURB-type</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">net.dinglisch.android.tasker.subbundled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">net.dinglisch.android.tasker.subbundled</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">net.dinglisch.android.tasker.subbundled-type</span>&gt;</span>java.lang.Boolean<span class="tag">&lt;/<span class="name">net.dinglisch.android.tasker.subbundled-type</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">state</span>&gt;</span>true<span class="tag">&lt;/<span class="name">state</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">state-type</span>&gt;</span>java.lang.Boolean<span class="tag">&lt;/<span class="name">state-type</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">targetActivity</span>&gt;</span>TaskerPluginActivity<span class="tag">&lt;/<span class="name">targetActivity</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">targetActivity-type</span>&gt;</span>java.lang.String<span class="tag">&lt;/<span class="name">targetActivity-type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Vals</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">Bundle</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>com.oasisfeng.greenify<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>com.oasisfeng.greenify.TaskerAggressiveDoze<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act6"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>547<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>%STATUS<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Str</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">ve</span>=<span class="string">"3"</span>&gt;</span>1<span class="tag">&lt;/<span class="name">Str</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act7"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>30<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">on</span>&gt;</span>false<span class="tag">&lt;/<span class="name">on</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg1"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg2"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg3"</span> <span class="attr">val</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg4"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Action</span> <span class="attr">sr</span>=<span class="string">"act8"</span> <span class="attr">ve</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">code</span>&gt;</span>433<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">on</span>&gt;</span>false<span class="tag">&lt;/<span class="name">on</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Int</span> <span class="attr">sr</span>=<span class="string">"arg0"</span> <span class="attr">val</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Action</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">Task</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">TaskerData</span>&gt;</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="4-使用tasker提醒自己给lycamobile续命"><a href="#4-使用tasker提醒自己给lycamobile续命" class="headerlink" title="4.使用tasker提醒自己给lycamobile续命"></a>4.使用tasker提醒自己给lycamobile续命</h2><p>lycamobile现在需要每两个月消费一次，不然会被收回。一年至少发送六次短信才能续命。<br>使用tasker设置个定时任务，每月月次提醒自己要给lycamobile续命啦😂</p>
<hr>
<h2 id="5-使用tasker自动开启代理"><a href="#5-使用tasker自动开启代理" class="headerlink" title="5.使用tasker自动开启代理"></a>5.使用tasker自动开启代理</h2><p>当时也Google play 应用商店、magisk、IDM、下载管理器、Chrome、Telegram等应用时自动开启代理软件。</p>
<hr>
<h2 id="6-使用tasker在播放音乐是自动开启蝰蛇音效"><a href="#6-使用tasker在播放音乐是自动开启蝰蛇音效" class="headerlink" title="6.使用tasker在播放音乐是自动开启蝰蛇音效"></a>6.使用tasker在播放音乐是自动开启蝰蛇音效</h2><hr>
<h2 id="7-夜间静音，关闭移动数据，关闭蓝牙，关闭同步"><a href="#7-夜间静音，关闭移动数据，关闭蓝牙，关闭同步" class="headerlink" title="7.夜间静音，关闭移动数据，关闭蓝牙，关闭同步"></a>7.夜间静音，关闭移动数据，关闭蓝牙，关闭同步</h2><hr>
<h2 id="8-打开Chrome时自动打开代理并开启同步"><a href="#8-打开Chrome时自动打开代理并开启同步" class="headerlink" title="8.打开Chrome时自动打开代理并开启同步"></a>8.打开Chrome时自动打开代理并开启同步</h2><hr>
<h2 id="9-锁屏省电"><a href="#9-锁屏省电" class="headerlink" title="9.锁屏省电"></a>9.锁屏省电</h2><p>锁屏后等待[n]分钟后执行以下操作<br>1.关闭移动数据<br>2.将cpu频率调节为最低<br>3.将cpu调度器调节为powersave模式<br>4.关闭同步<br>5.使用绿色守护特权模式无视状态进入打盹模式<br>6.使用绿色守护休眠所有应用<br>7.命令行执行pm disable com.google.android.gms来冻结Google play service ，解锁屏幕后别忘记恢复😂</p>
]]></content>
      <tags>
        <tag>刷机</tag>
        <tag>andorid</tag>
        <tag>tasker</tag>
      </tags>
  </entry>
  <entry>
    <title>我青年时代就--用过的手机</title>
    <url>/archives/used-devices.html</url>
    <content><![CDATA[<p><del>我青年时代就读过西游记、马可波罗游记、左丘明、左传</del></p>
<hr>
<h2 id="Nokia-3310"><a href="#Nokia-3310" class="headerlink" title="Nokia 3310"></a>Nokia 3310</h2><p>很早之前的手机，记得是小学三四年级的时候，老爸老妈出门后就留下这个手机方便我弟俩联系他们。记得上面的一个飞机游戏，老弟打的分数超级高，每次都是好几十分钟。老弟从小就是个游戏天才😂。</p>
<hr>
<h2 id="SAMSUNG-E848"><a href="#SAMSUNG-E848" class="headerlink" title="SAMSUNG E848"></a>SAMSUNG E848</h2><p>也是用的老姐的，用了一段时间，那时候因为玩这个手机和老师打架被开除了。。黑历史</p>
<hr>
<h2 id="TCL"><a href="#TCL" class="headerlink" title="TCL"></a>TCL</h2><p>具体型号不太记得了，十五岁那年在郑州呆了一段时间，期间换了两三个手机，记得最清楚的就是那个TCL、直板、超薄、键盘还是平的，屏幕和键盘是一体平的。从郑州回来后，中考毕业的时候100块钱转手给了同学。那时候能用java装一些qq之类的，很是受欢迎。<br>记得那时MTK也有一种装qq的，需要在内存卡上折腾一些东西，当时国内的山寨机装qq都是用的MTK的方案。还能装QQ游戏之类的，当时帮初中同学弄了好几个，班里的同学也找我装。<br>当时我还开通的财付通的网银，充Q币，充钻之类的。那时候财付通充QQ会员之类的好像是8.8/月。也是从那时候开始网购，捡垃圾。</p>
<hr>
<h2 id="moto"><a href="#moto" class="headerlink" title="moto"></a>moto</h2><p>具体型号不太清楚了，那时候初二不让带手机，在二手店花50块钱买了一个，还是翻盖的，能装QQ。用了半年多，最后不知道去哪里了。</p>
<hr>
<h2 id="酷派"><a href="#酷派" class="headerlink" title="酷派"></a>酷派</h2><p>中考完300块买的酷派CMDA的手机，那时候用的电信卡，所以一直想买个CMDA的手机，那时候的移动和联通都在用GPRS，那时候电信CMDA上网速度超快，同学羡慕的不得了😂。<br>这个手机也是我第一个<code>Android</code>，原装的系统不是Android，但是可以刷机成Android，整个暑假都在折腾这个手机了，那时的刷机比现在要麻烦多了去了，什么基带、IMIE号、NV号等等，需要备份一堆的数据，还要查询IMIE号恢复NV号，想想那时候居然学会刷机。<br>原装的ROM用的很流畅，但是很丑😂，就像老人机一样。刷成安卓后，因为只有128MB的内存，所以很卡很卡，但是好看我也就忍了。<br>还有个功能就是，连上数据线，插在电脑上，把手机网络共享给PC上网用，流量巨贵，用了几次就没了😭钱了。<br>这个手机是我刷的第一个Android手机，在高一开学不久一次刷机过程中因为忘记恢复NV数据，导致基带丢失，手机插卡不识别，当MP3用去了。不知道什么时候把它给拆了，现在家里只有一个外壳，没舍得扔，留着传给下一代🙃。</p>
<hr>
<h2 id="LG-KX218-CDMA2000"><a href="#LG-KX218-CDMA2000" class="headerlink" title="LG KX218 CDMA2000"></a>LG KX218 CDMA2000</h2><p>高一的时候用的手机，用的两年多，那时用的电信3G、超级快、秒那些用GPRS的，电信的手机卡还是在初中学校附近办的，后来换成了联通就再也没用过电信的手机。在这个手机上听了很多现在一直在听的歌，比如should it matter。这首歌也是在这个手机上听的最多的。</p>
<hr>
<h2 id="HTC"><a href="#HTC" class="headerlink" title="HTC"></a>HTC</h2><p>高一下学期用的，具体型号忘记了，记得很清楚时侧滑盖的手机，还是触摸屏，当时淘宝279买的二手<br>原厂windows mobile的系统，能刷Android系统，当年的刷机小王子。用了一周，因为续航太差劲就原价倒手给了同学。我去，那时学校充一次电1块钱啊。充满电使劲玩两三个小时就没电了，太坑了。</p>
<hr>
<h2 id="黑莓8700"><a href="#黑莓8700" class="headerlink" title="黑莓8700"></a>黑莓8700</h2><p>也是高一时折腾的手机，买的二手一百多块，用了不久后给了老爸，老爸又给了姐夫。后来高三的时候又买了一个，用了不到一年，高考完被我埋到地下😂，等过几年再把它挖出来。</p>
<hr>
<h2 id="Nokia-5250"><a href="#Nokia-5250" class="headerlink" title="Nokia 5250"></a>Nokia 5250</h2><p>高二时用的手机，也是老姐留给我的手机，老姐是在二手店买的，还很新，那时还去网吧帮老姐安装软件，很多自己下载的软件装不上，被那时的证书折腾了不少。很是怀念那时的塞班啊，第一次用微信也是在这个手机上，微信的ID还是那时候设定的。后来老姐买了iPhone这个让我用了一段时间。</p>
<hr>
<h3 id="LG-KP501"><a href="#LG-KP501" class="headerlink" title="LG KP501"></a>LG KP501</h3><p>用的老姐留下的手机，和老姐吵架的时候摔了，想想就难受。那时候我通宵去网吧，带着手机去那里刷机，刷了两三个包感觉没啥区别。记得有个印象很深的游戏，水管工人，就是一个工人接水管，水管流通后算通关。那时候打这个游戏好几宿没睡😂。</p>
<h3 id="泛泰"><a href="#泛泰" class="headerlink" title="泛泰"></a>泛泰</h3><p>老姐从韩国带来的是手机，不能插卡，只能连WiFi上网，当个mp3用还是不错的</p>
<h3 id="LG-LU6200"><a href="#LG-LU6200" class="headerlink" title="LG LU6200"></a>LG LU6200</h3><p>老姐从韩国带来的，LTE 4G的手机，那时候移动4G 还没出，用了一段时间，800万的像素，用这个手机拍过我们冬季踢球的照片。用这个手机刷过很多CM的ROM，记得有次去洗澡的路上还刷机。</p>
<h3 id="lenove"><a href="#lenove" class="headerlink" title="lenove"></a>lenove</h3><p>用的老姐的，高考完用了一暑假，现在的手机上还存着这个手机拍的照片。</p>
<hr>
<h2 id="Nokia-104"><a href="#Nokia-104" class="headerlink" title="Nokia 104"></a>Nokia 104</h2><p>高三时用的功能机，最大的用处就是闹钟，上厕所的时候听歌。那时候喜欢挺班得瑞和林海的作曲。</p>
<hr>
<h2 id="Lumia-530"><a href="#Lumia-530" class="headerlink" title="Lumia 530"></a>Lumia 530</h2><p>陪伴我度过了遗憾的那年，陪我去过北京，去过很多地方，也陪伴我很久很久，现在还在手上，一直当备用机用，现在主要用来装一些国外的SIM卡，因为大力出奇迹，弄坏了一个SIM卡槽😱。</p>
<hr>
<h2 id="Lumia-1020"><a href="#Lumia-1020" class="headerlink" title="Lumia 1020"></a>Lumia 1020</h2><p>高考完老姐给我买的，二手花了1300，陪我去了很多地方，也用这个手机拍了很多照片，尤其时大一的时候。因为下吧碎了，大一下的时候当零件600块钱闲鱼出手了。当时每天都在期待着更新，期待着Windows 10的到来，最后巨婴放弃了Windows phone😡，破碎了我们Lumia用户们的期待。</p>
<hr>
<h2 id="moto-G2"><a href="#moto-G2" class="headerlink" title="moto G2"></a>moto G2</h2><p>出手 Lumia 1020后用的手机，当时刷的leagueOS，陪我跑了马拉松，暑假的时候，洗澡进水屏幕失灵了，100闲鱼出手了。用了不到半年。最短命的手机。</p>
<hr>
<h2 id="Lumia-630"><a href="#Lumia-630" class="headerlink" title="Lumia 630"></a>Lumia 630</h2><p>moto G2坏了之后，用的老爸的Lumia 630。买了Lumia 640 后和moto g 一块打包100块钱闲鱼出了。</p>
<hr>
<h2 id="Lumia-640"><a href="#Lumia-640" class="headerlink" title="Lumia 640"></a>Lumia 640</h2><p>大二刚开学时买的270淘宝，欧洲单卡版的，用的还很舒心，超级棒，Windows10 mobile的系统，还是可以的。就是每次升级总会出现各种莫名其妙的bug，需要重置一下手机，有时候还装不上中文输入法，被迫英文输入，很僵硬。</p>
<hr>
<h2 id="moto-G1"><a href="#moto-G1" class="headerlink" title="moto G1"></a>moto G1</h2><p>大二下买的，当时主要用来再阿里云的app，登录签到获取学生优惠资格，作死的阿里云，后来干脆放弃不用了。还主要用来闲鱼捡垃圾。因为Windows phone平台上的应用很少，支付宝好几年就不更新。</p>
<hr>
<h2 id="moto-z-play-now"><a href="#moto-z-play-now" class="headerlink" title="moto z play (now)"></a>moto z play (now)</h2><p>现在用的手机，17年7月份到现在一直在用，用了一段时间的stock ROM，后来刷上了Havos接着到现在的AOSIP 9.0 P，用着很舒心，很满意，待机杠杠的，将就着用，用到坏，希望它好好的不要坏掉。</p>
<hr>
<h2 id="iPhone-6s"><a href="#iPhone-6s" class="headerlink" title="iPhone 6s"></a>iPhone 6s</h2><p>又是我姐淘汰给我的，成色吗，伊拉克战色😂。屏幕中间两道打裂纹，还有一平方厘米左右的像素坏点，只能使用半天，轻度使用使用 12 个小时左右。不过还好，iPhone 上装的都是国产软件，另一台 moto z play 上装国外的软件。越来越觉着现在的安卓生态，国产毒瘤 app 越来越猖獗，无法无天到肆意手机用户隐私，权限滥用等等问题。安卓手机目前从隐私角度来讲，几乎不适合运行国产毒瘤软件了。iOS 系统还能稍微限制住这群国产毒瘤软件。<br>凑活着用吧，现在每天使用手机的时间也就一个小时左右，没有换手机的欲望。</p>
<h2 id="Nokia-X71-next"><a href="#Nokia-X71-next" class="headerlink" title="Nokia X71 (next)"></a>Nokia X71 (next)</h2><p>以后不会再用安卓手机当主力手机了<br><del>下一个手机吧</del>，估计最早2020年底买，反正今年不会买的，到2020年捡垃圾也就1300多吧，反正我买手机以前就300块的Lumia 640用的还很嗨。全新的2199，到明年买二手也就1300，坐等明年的车。垃圾佬从不买国行正品，也不需要质保，水货港货岂不美哉。<br>越来越多的人说诺基亚越来越不行了，没情怀了，这年头情怀当饭吃??我对品牌没有多少崇拜，只是现在不会再买任何国产品牌的手机，只要设计足够出色，能刷机我都可以接受。</p>
<hr>
<h2 id="tablet-and-PC"><a href="#tablet-and-PC" class="headerlink" title="tablet and PC"></a>tablet and PC</h2><h3 id="亚马逊Kindle-HD"><a href="#亚马逊Kindle-HD" class="headerlink" title="亚马逊Kindle HD"></a>亚马逊Kindle HD</h3><p>大一暑假在OK数码那里搞来的，用了三个月，最后刷机的时候变砖了，很僵硬，60包邮闲鱼出了。</p>
<h3 id="Dell-venue-11-pro-5130"><a href="#Dell-venue-11-pro-5130" class="headerlink" title="Dell venue 11 pro 5130"></a>Dell venue 11 pro 5130</h3><p>大二上把台式机的E3 1231 V3置换出去换来1000块，999在老欧笔记本那里搞来的，一直用到现在，我觉着还能凑活着用个一两年，到最后还是给外甥吧.他挺喜欢我这个平板的，每次来找我玩都要玩平板。</p>
<h3 id="ThinkPad-yoga12"><a href="#ThinkPad-yoga12" class="headerlink" title="ThinkPad yoga12"></a>ThinkPad yoga12</h3><p>现在用的主力机笔记本，唯一的缺点就是CPU满载的时候，温度七八十度，风扇呼呼地转也不降温，凑活着用到工作稳定存钱买surface book2吧，我还是挺喜欢用触屏二合一的笔记本。</p>
<h3 id="SONY-SBH60"><a href="#SONY-SBH60" class="headerlink" title="SONY SBH60"></a>SONY SBH60</h3><p>今年元旦时买的蓝牙耳机，待机一周没问题，听歌能抗13个小时。</p>
<hr>
<h2 id="ROM"><a href="#ROM" class="headerlink" title="ROM"></a>ROM</h2><p>从塞班到Windows mobile ，再到Android时代的CM、AOSP、RR、Havos等都折腾过。</p>
<h2 id="PS"><a href="#PS" class="headerlink" title="PS"></a>PS</h2><p>我对手机没有多大需求，一般能够用就行，我最满意的手机还算是 Lumia 640 ，没有杂七杂八的功能，Windows phone版的微信也没有杂七杂八的功能。说实在的挺喜欢 Android 刷机，用 300 块钱的moto g 我也能接受，平时浏览网页，装Google play ，telegram用的也很爽，就是用微信这种臃肿的毒瘤 app 巨卡无比。我认为手机越用越卡是个伪命题，还有些说闪存芯片用的时间长了就容易掉速之类的。虽然存在这种现象吧，但绝不是手机越来越卡的原因，并不是硬件的问题。最主要的原因当属国内这些毒瘤 app 了，一个比一个臃肿，一个比一个功能多，看谁的安装包大，看谁的后台服务多，看谁要的权限多。手机越用越卡完全时无稽之谈，老子的手机16年发布的，用了两年，经常刷机备份，刷机备份一次数据量都是三四G，备份次数没有 200 次也有 100 次了。闪存芯片读写量要比一般人多一倍，但因为用的第三方开源的 ROM，自己定制，自己调教镇压住了一些毒瘤 app，所以用的和新的没有多少区别。甚至流畅性上要超过同配置的手机。<br>手机越用越卡完全是无稽之谈，卡的原因最主要的还是毒瘤 app 们越来越臃肿，功能越来越复杂。就好比7.0.3 版本的微信 activity 数目1000多个，比一些精简过的 ROM 系统所有的 activity 还多，比一个系统ROM中的 activity 还多，你不卡才怪。你2015年的手机用 2015 年的软件，绝对不卡，你2015 年的手机用 2019 年的软件，毒瘤 app 们能卡出翔来。但是你用 telegram，chrome 等还是很丝滑般流畅使用的，用毒瘤 app 就不行了。</p>
]]></content>
      <tags>
        <tag>手机</tag>
        <tag>phone</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈保护隐私的几种方法</title>
    <url>/archives/privacy-protections.html</url>
    <content><![CDATA[<p>0.说在前面：百度李彦宏曾说过：“中国人对隐私问题的态度更加开放，相对来说也没那么敏感。如果他们可以用隐私换取便利和效率，在很多情况下他们就愿意这么做”。如果你不在乎个人隐私，愿意用个人隐私换取方便，那么这篇文章对你没有价值，浪费你的时间，请关闭退出就可以。</p>
<hr>
<p>原则：尽量使用国外或开源的软件。<br>让美帝公司掌握了隐私数据要比让老大哥掌握了风险低，在国内让baidu这些毒瘤公司拿数据去卖假药什么的会造成伤害，还有可能被查水表，喝茶什么的。<br>而让Google掌握了吧，身在中国，Google拿你的数据在美国干些坏事也影响不到你。<br>同理，美国人用中国的手机和软件比用美国的风险低<br>如果你想最大化保护你的个人隐私，那么我建议你：</p>
<hr>
<h2 id="1-浏览器"><a href="#1-浏览器" class="headerlink" title="1.浏览器"></a>1.浏览器</h2><p>无论在移动端还是PC端，坚决不要使用任何国产浏览器，推荐使用开源软件Firefox或Chromium，Firefox是Mozilla非营利性组织维护的开源浏览器，能够在某种程度上保护你的隐私数据，它是非营利性组织，不以盈利为目的，不会向第三方或政府披露你的数据。作为上网浏览新闻，博客，网站的主力工具，每个浏览器都会记录着每个你访问的网站。国产浏览器会夹带着一些其他的私货，比如屏蔽掉一些政府敏感的网站，进行言论审查和互联网封锁。不仅如此，为了盈利商业公司的浏览器会向第三方共享你的隐私数据，而且还会根据法律法规向政府披露你的数据。在用户客户端进行这种行为真的是卑鄙无耻。尤其是那些参与屏蔽996.icu的浏览器<a href="https://blog.502.li/privacy-protections#reference">1</a>，你可以完全放弃他们了。</p>
<hr>
<h2 id="2-杀毒软件"><a href="#2-杀毒软件" class="headerlink" title="2.杀毒软件"></a>2.杀毒软件</h2><p>坚决不要使用国产杀毒软件，他们会监控你的上网纪录<a href="https://blog.502.li/privacy-protections#reference">2</a>(火绒除外，微点有待观察)。<br>国产杀毒软件会以根据法律法规和危险警告识别监控上网站url,360杀毒软件曾拦截屏蔽过美国驻华大使馆某些特定网址。近期也拦截过996.icu以及github上996.icu的repo，并且做了个假的404网页，真他妈搞笑。杀毒软件有扫描磁盘全部内容的风险，如果你硬盘上有敏感隐私信息，不要使用这些国产杀毒软件。如果你在使用Windows10的话，那么自带的Windows Defence完全可以满足日常使用，有能力的也可以选择“裸奔”。如今免费盛行的国产杀毒软件早已沦为强制捆绑，广告推广，隐私收集的流氓软件。</p>
<hr>
<h2 id="3-安卓手机"><a href="#3-安卓手机" class="headerlink" title="3.安卓手机"></a>3.安卓手机</h2><p>解锁Bootloader进行root(但也面临着手机丢失后数据安全问题)。<br>拒绝使用和购买那些不提供解锁Bootloader的手机，比如华为，魅族，锤子，VIVO，OPPO等。如果你不想折腾的话，苹果无疑是最好的选择，而且要将苹果账号选择在美国，而非云上贵州。<br>因为解锁Bootloader进行root是摆脱手机厂商监控的第一步。因为安卓手机厂商为了盈利收集的隐私信息，并向第三方共享你的隐私信息以获取广告推广盈利。只有进行root才能卸载掉那些监控手机的预装app。随着大多数国产手机逐渐关闭解锁Bootloader和加大Root的难度，用户想要摆脱手机厂商的监控也越来越难。厂商希望没人Root，因为不解锁Bootloader和root，厂商就可以为所欲为了。国产手机都会自带某种“云服务”，选择和使用这些服务被手机厂商收集到的个人隐私信息也将更多。<br>对于解锁bootloader和root后的风险。使用Android手机和使用Linux并无多大区别。拥有root权限的风险只是将root权限授权给未知应用而已。只要你够细心这一点是可以避免的。<br>手机丢失后别人也可以使用你用的刷机办法解锁你的手机，窃取你手机里的隐私信息。那就祝愿你手机不会丢失吧 但也可以使用tasker解决，在手机丢失后执行一些操作，删除手机上的内容。比如设定sim卡ID以及，只要更换Sim卡就触发报警操作，发送短信触发GPS定位，返回GPS信息，摄像头拍照等等都可以通过tasker实现。</p>
<hr>
<h2 id="4-输入法"><a href="#4-输入法" class="headerlink" title="4.输入法"></a>4.输入法</h2><p>杜绝使用国产输入法，在此推荐使用Google输入法。<br>输入法作为文本信息输入的直接工具，就好比嘴一样与互联网说话沟通，如果输入法的记录被某些公司记录下来，就好比被人安装了窃听器一样。之前有报道过讯飞输入法拒绝翻译敏感词，早已证明这些党性十足的国产输入法会监控你的所有输入记录<a href="https://blog.502.li/privacy-protections#reference">4</a>，甚至监听你的麦克风<a href="https://blog.502.li/privacy-protections#reference">百度输入法监听麦克风</a>。使用google输入法的好处在于，因为墙的缘故，你的输入记录无法上传到Google服务器😂。</p>
<hr>
<h2 id="5-苹果用户"><a href="#5-苹果用户" class="headerlink" title="5.苹果用户"></a>5.苹果用户</h2><p>建议你将Apple账户进行转区到国外，国内的账户数据会存储在云上贵州那里，以供审查。Apple在隐私保护方面做的还是不错的。毕竟苹果是为了保护用户隐私敢直接和FBI硬杠的公司<a href="https://blog.502.li/privacy-protections#reference">5</a>。如果很在乎隐私保护而且不想折腾，那么苹果手机无疑是最好的选择。即便苹果收集到你的隐私数据，这些隐私数据也不会落到政府那里，前提是你的苹果账号在国外。</p>
<hr>
<h2 id="6-安卓杀毒软件"><a href="#6-安卓杀毒软件" class="headerlink" title="6.安卓杀毒软件"></a>6.安卓杀毒软件</h2><p>你可以放心大胆地卸载掉所有xx安全管家，xx安全中心，xx安全，xx大师。基于Linux内核的安卓手机不需要任何杀毒软件的。想要安全，Root才是最彻底的方法，再次重申不要相信国内所谓“Root了很危险”这样的谣言，只要你有足够多的耐心和细心去研究，你就能够使用root权限把你的Android手机打造的固若金汤。那些所谓的安全管家，只不过是监控你手机，收集你隐私数据的工具而已。</p>
<hr>
<h2 id="7-安卓手机ROM"><a href="#7-安卓手机ROM" class="headerlink" title="7.安卓手机ROM"></a>7.安卓手机ROM</h2><p>选择更换开源ROM，LineageOS，AOSP,Resurrection Remix OS等开源的ROM。<br>国产Android手机系统ROM，对原生安卓做了极大的修改以及夹带一些社会主义特色，<a href="https://blog.502.li/privacy-protections#reference">7</a>。建议刷上XDA社区的第三方开源的ROM，能力强的可以自己拿来源码来编译ROM，精简掉你不想要的app，事实证明，一个安卓7.1的AOSP ROM，仅仅需要50个系统app就可以完全满足日常使用。而国产手机ROM中系统app的数量往往在170-250个之间,其中包括大量无法卸载的垃圾流氓服务用来监控你，收集你的个人隐私。这也是为什么你的手机会越用越卡的原因。<br>开源社区的ROM不以盈利为目的，可以很少地收集你的信息，并不会向小米那样用于广告推广来盈利。当然第三方ROM质量上良莠不齐，要精心选择适合自己的ROM。</p>
<hr>
<h2 id="8-安卓权限管理"><a href="#8-安卓权限管理" class="headerlink" title="8.安卓权限管理"></a>8.安卓权限管理</h2><p>Root后使用Google原生安卓系统自带的IFW意图防火墙和App Ops（Application Operations）来对应用进行更加精细的权限管理，专治那些不给权限就不让运行的流氓app（比如支付宝，微信，QQ等）。也可以使用 MyAndroidTools，绿色守护，冰箱等 Android 神器来压制国内毒瘤 App。也可以使用开源软件<a href="https://github.com/Tornaco/X-APM" target="_blank" rel="noopener">应用管理</a>伪造一些敏感信息，比如Android ID， IMIE ,手机号码。</p>
<hr>
<h2 id="9-隐私政策"><a href="#9-隐私政策" class="headerlink" title="9.隐私政策"></a>9.隐私政策</h2><p>在注册和使用互联网服务时，一定要仔细阅读隐私政策/条款，是否有注销服务。如果临时使用可以考虑临时邮箱<a href="https://temp-mail.org" target="_blank" rel="noopener">#12</a>/短信接号网站<a href="https://www.pdflibr.com/" target="_blank" rel="noopener">#13</a>注册。</p>
<hr>
<h2 id="10-其他"><a href="#10-其他" class="headerlink" title="10.其他"></a>10.其他</h2><p>远离那些在用户手机上建墙进行言论审查、自我阉割、网络封锁、敏感词屏蔽的杀毒软件、输入法、浏览器、手机、国产ROM等。</p>
<hr>
<p>记住，个人隐私保护，保护的不是你自己，而是与你相关的人，你的家人和朋友。<br>不要以为大数据时代无隐私可言，隐私保护不当与不保护是两种完全不同的风险程度，你用隐私换取的那点便利最后也会面临隐私泄露的风险。</p>
<hr>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><p>0.<a href="https://program-think.blogspot.com/2019/01/Security-Guide-for-Political-Activists.html" target="_blank" rel="noopener">安全经验汇总</a><br>1.<a href="https://www.solidot.org/story?sid=60108" target="_blank" rel="noopener">多家国产浏览器限制访问 996.ICU</a><br>2.<a href="https://www.infoq.cn/article/3ADVAG9_uwomgr82lGet" target="_blank" rel="noopener">多款国产浏览器封锁 996.ICU，中国程序员惹谁了？</a><br>3.<a href="https://www.zhihu.com/question/313636694/answer/609135042" target="_blank" rel="noopener">如何评价新版MIUI浏览器拦截Github等网站？</a><br>4.<a href="https://www.solidot.org/story?sid=58791" target="_blank" rel="noopener">科大讯飞的应用被发现拒绝翻译敏感词</a><br>5.<a href="https://wallstreetcn.com/articles/3508008" target="_blank" rel="noopener">苹果发布了一支新广告，想告诉你手机中的“小秘密”同样需要重视</a><br>6.<a href="https://bbs.letitfly.me/d/395" target="_blank" rel="noopener">IFW介绍</a><br>7.<a href="https://t.me/notepad_by_kotomei/77" target="_blank" rel="noopener">墙已经砌造国产ROM(MIUI)中，深入人心、无处不在</a><br>8.<a href="https://www.solidot.org/story?sid=56914" target="_blank" rel="noopener">中国流行手机应用难以注销账号</a><br>9.<a href="https://sspai.com/post/42779" target="_blank" rel="noopener">不怕大厂「耍流氓」，想保护隐私的你可以这样管理 Android 权限</a><br>10.<a href="http://www.dcci.com.cn/dynamic/view/cid/2/id/1324.html" target="_blank" rel="noopener">2017年中国Android手机隐私安全报告</a><br>11.<a href="https://bbs.letitfly.me/" target="_blank" rel="noopener">letitfly</a><br>12.<a href="https://temp-mail.org" target="_blank" rel="noopener">临时邮箱</a><br>13.<a href="https://www.pdflibr.com/" target="_blank" rel="noopener">云短信-在线接收短信</a><br>14.<a href="https://bbs.letitfly.me/d/256" target="_blank" rel="noopener">MAT介绍</a><br>15.<a href="https://typeblog.net/nobody-can-protect-your-privacy-except-yourself/" target="_blank" rel="noopener">除了自己，没有人能保护你的隐私</a><br>16.<a href="https://typeblog.net/why-do-i-root-my-phone/#References" target="_blank" rel="noopener">从 root 手机说起</a></p>
]]></content>
      <tags>
        <tag>隐私保护</tag>
        <tag>privacy project</tag>
      </tags>
  </entry>
  <entry>
    <title>moto z play addsion xt1635-02 刷机指南</title>
    <url>/archives/moto-z-play-AOSIP.html</url>
    <content><![CDATA[<h2 id="0-备份数据"><a href="#0-备份数据" class="headerlink" title="0.备份数据"></a>0.备份数据</h2><p>刷机千万条，备份第一条，刷机不规范，机主两行泪😂</p>
<hr>
<h2 id="1-解锁bootloader"><a href="#1-解锁bootloader" class="headerlink" title="1.解锁bootloader"></a>1.解锁bootloader</h2><p>下载<a href="https://developer.android.com/studio/releases/platform-tools.html" target="_blank" rel="noopener">Android SDK Platform Tools</a>,解压后将platform-tools所在的绝对路径添加到环境变量。<br>安装moto驱动程序，下载地址<a href="http://www.motorola.com/getmdmwin" target="_blank" rel="noopener">win</a><br>解锁<a href="http://motorola.com/unlockbootloader" target="_blank" rel="noopener">官网</a>,需要注册账户<br>开机键 + 音量减进入bootloader<br>fastboot oem get_unlock_data 获取设备ID,粘贴复制到下面<br><a href="https://motorola-global-portal.custhelp.com/app/standalone/bootloader/unlock-your-device-b" target="_blank" rel="noopener">解锁网页</a><br>申请后获取解锁码<br>fastboot oem unlock 【解锁码】<br>下载magisk zip包和magisk manager apk方便以后使用</p>
<hr>
<h2 id="2-刷recovery-twrp-升级bootloader"><a href="#2-刷recovery-twrp-升级bootloader" class="headerlink" title="2.刷recovery  twrp /升级bootloader"></a>2.刷recovery  twrp /升级bootloader</h2><p><a href="https://twrp.me/Devices/" target="_blank" rel="noopener">TWRP官网</a><br>我的moto z play 刷 Android9.0 的 ROM 要求的 bootloader 必须为 Oreo 的0xC180 or 0xC182，下载 moto 官方固件刷入 bootloader.img 即可，官方固件 1.7GB，好大。总不能为了刷个几MB的 bootloader 下载整个固件包啊,还浪费我流量,于是保存firmware到Google Drive(还好固件分享是通过Google Drive),在挂载了 Google Drive 的 vps 上解压出来需要刷的那几个文件刷入即可.刷完 bootloader 后发现仅仅升级 bootloader 分区手机无法上网，还需要刷入基带。<br>最后在 XDA 社区找到了升级到 Oreo bootloader 的<a href="https://forum.xda-developers.com/showpost.php?p=78379116&amp;postcount=3" target="_blank" rel="noopener">帖子</a>，大佬已经帮忙准备好了要刷入的文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fastboot flash partition gpt.bin</span><br><span class="line">fastboot flash bootloader bootloader.img</span><br><span class="line">fastboot flash modem NON-HLOS.bin</span><br><span class="line">fastboot flash fsg fsg.mbn</span><br><span class="line">fastboot flash dsp adspso.bin</span><br><span class="line">fastboot flash oem oem.img</span><br></pre></td></tr></table></figure>
<p>刷上下载的 Twrp<br><code>fastboot flash recovery twrp-addison.img</code><br>reboot 到 recovery 就行</p>
<hr>
<h2 id="3-刷ROM"><a href="#3-刷ROM" class="headerlink" title="3.刷ROM"></a>3.刷ROM</h2><p>把 ROM 的 zip 包以及 magisk 放到手机内部存储目录即可,在 INSTALL 那里选择 ROM 刷入<br>接着刷入 magisk 的zip包<br>reboot system</p>
<hr>
<h2 id="4-刷magisk"><a href="#4-刷magisk" class="headerlink" title="4.刷magisk"></a>4.刷magisk</h2><p>安装 magisk manager，有些精简的 ROM 没有文件管理器，可以在设置里-&gt;存储或下载管理器里找到apk 文件安装。<br>输入经常使用的 magisk 模块主要有</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.Magisk Manager for Recovery Mode(mm)</span><br><span class="line">2.DNSCrypt-Proxy</span><br><span class="line">3.Enable doze for GMS Magisk Module</span><br><span class="line">4.GPU Turbo Boost</span><br><span class="line">5.Google Sans MOD Font</span><br><span class="line">6.Pix3lify</span><br><span class="line">7.ViPER4 Android FX Materialized</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="5-安装常用工具"><a href="#5-安装常用工具" class="headerlink" title="5.安装常用工具"></a>5.安装常用工具</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0.钛备份，每次刷完 ROM 接着 root 完后第一个装的就是钛备份，使用它来恢复下面的应用和数据</span><br><span class="line">1.绿色守护，导入处方</span><br><span class="line">2.RE 管理器，卸载删除不必要的应用，方便减少备份包大小</span><br><span class="line">3.SD Maid，配合 RE 使用，卸载删除应用，分析分区占用大小</span><br><span class="line">4.shadowsocks + obfs，你懂的</span><br><span class="line">5.Tasker，高效率神器，用过的人都说好😂!</span><br><span class="line">6.Solid Explorer，MD 风格的文件管理器，用了之后放弃RE了🙃</span><br><span class="line">7.Telegram X 跨平台，16 年开始使用到现在，已经放弃用qq了</span><br><span class="line">8.juiceSSH，用来执行 shell，同步硬件时钟用，免得 TWRP 时间回到 1970.</span><br><span class="line">9.炼妖壶 发现能在这个 ROM 上使用，好好折腾一下</span><br><span class="line">10.Lawnchair 替换掉原来的桌面，这个自从 2017 年使用后就从未更换过。精简！！！！特别适合我这种精简主义者。</span><br><span class="line">11.My Android tools，同 IFW，用来镇压毒瘤 app</span><br><span class="line">12.App Ops，用来驯服一些国内毒瘤 app，不给权限不让运行的毒瘤行为</span><br><span class="line">13.IFW，意图防火墙，用来镇压一些国内的臃肿毒瘤 app</span><br><span class="line">14.Pixel Icon Pack，图包，美化一下图标</span><br><span class="line">15.moto 相机，感觉没有 aosp 的好用</span><br><span class="line">16.快图相册，从Android4.4 开始一直使用，精简好用，速度极快</span><br><span class="line">17.谷歌拼音输入法,精简</span><br><span class="line">18.国内那些臃肿的毒瘤 app，最后再装😡！</span><br><span class="line">19.MX player 看片儿用的</span><br><span class="line">20.简洁·日历 就像名字那样，十分简洁，没有杂七杂八的功能，就是农历可能不准，记得去年的冬至吗😂</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="6-刷入opengapps"><a href="#6-刷入opengapps" class="headerlink" title="6.刷入opengapps"></a>6.刷入opengapps</h2><p>推荐pico包，虽然足够小了，但还是可以精简很多不必要的apk的。需要注意的是，仅仅刷入opengapps包是无法登录Google账户的，还需要下载最新版的Google play service APK来更新Google play service。这样才能登录到Google 账户。选择最后装opengapps的原因是，之前需要卸载删除一些系统app，删除一些app后有可能会卡机无法启动，所以每次删除之前都需要备份一下，而opengapps刷入后备份的大小将会增加很多。于是最后等到删除完不必要的系统app后再刷入opengapps。刷完之后再卸载掉opengapps里没用的app。<br>登录Google账户，同步chrome书签。使用opengapps我唯一的需求就是chrome，能同步chrome书签和密码就足够了。</p>
<hr>
<h2 id="7-个性化定义"><a href="#7-个性化定义" class="headerlink" title="7.个性化定义"></a>7.个性化定义</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.恢复导航栏布局</span><br><span class="line">2.缩小导航栏高度</span><br><span class="line">3.导航栏透明</span><br><span class="line">4.全局沉浸模式</span><br><span class="line">5.复制铃声到/system/media/ringtones,删除其他media文件</span><br><span class="line">6.设置密码，指纹解锁</span><br><span class="line">7.把一些不需要更新的app移动到/system/app</span><br><span class="line">8.个性化状态栏，扩展状态栏</span><br><span class="line">9.导航栏设定了四个虚拟按键</span><br><span class="line">    9.1.单击任务栏</span><br><span class="line">    9.2.单击home 长按休眠</span><br><span class="line">    9.3.单击返回 长按杀死应用</span><br><span class="line">    9.4。单击返回上一个应用 长按截屏</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="8-恢复Tasker里的任务"><a href="#8-恢复Tasker里的任务" class="headerlink" title="8.恢复Tasker里的任务"></a>8.恢复Tasker里的任务</h2><hr>
<h2 id="9-TWRP备份还原"><a href="#9-TWRP备份还原" class="headerlink" title="9.TWRP备份还原"></a>9.TWRP备份还原</h2><p>把之前的在twrp做的备份复制到PC，使用tar解压出备份文件。如果使用7Z或其他GUI的解压缩程序会提示错误，因为在/system分区里有一些硬链接文件，是无法解压出来的。使用tar就可以解压出来。解压出来后把/etc/hosts 文件复制到新的ROM system分区下，里面有一些自己屏蔽的一些域名，大部分是百度等一些毒瘤app SDK的域名，直接屏蔽掉。<br>复制/data/system/ifw下的ifw.xml是自己自定义的一些IFW规则，主要对付一些国内毒瘤app。<br>复制/system/media/下的开机动画，还是喜欢原来的开机动画。<br>使用钛备份还原Solid Explorer的数据，使用smba共享传输这些文件。</p>
<hr>
<h2 id="10-bug"><a href="#10-bug" class="headerlink" title="10.bug"></a>10.bug</h2><p>1.重启可能卡在开机动画那里，需要长按电源键强制关机，再开机才能正常启动<br>2.<del>开机启动后，Lawnchair会随机性地挂掉😥，最后发现不是Lawnchair挂掉了，是AOSIP自带的Quickstep</del><br>3.不能原生支持xposed框架，需要刷入其他包魔改一下，不清真，所以就没用<br>4.以前xposed我仅仅使用三个模块，绿色守护，应用管理，XinternalSD。现在不需要也能满足日常使用了。<br>5.刷入opengapps包后,所有的app权限授权记录都消失了,需要重新授权,不知道是bug还是feature😂<br>6.安装微信后,6.7.3版本不能登录,必须7.0.3以上,fuck尼玛的微信😡.无奈装7.0.3再降回6.7.3.尼玛去死吧,毒瘤app.<br>7.开热点随机性地断流<br>8.twrp里的硬件时钟经常会重设为1970–谜之bug<br>9.最后设置密码的原因是，使用twrp备份还原后密码错误，也是twrp的bug</p>
<hr>
<h2 id="吐槽Android版微信"><a href="#吐槽Android版微信" class="headerlink" title="吐槽Android版微信"></a>吐槽Android版微信</h2><p>1.微信限制低版本登录，可以使用最新版本登录，保留原数据卸载微信高版本，重启后再装低版本就能登录<br>2.Google play 最新版微信7.0.3已经很臃肿了,世界上activity数目超过1000的Android 应用也就你们这些国产毒瘤吧,也就你们微信,美团了吧.毒瘤,臃肿的体验真让人恶心到家,还不让人家用低版本的,PC端登录还要扫码登录,我扫你🐎币.<br>3.微信会产生日志文件,在/data/data/com.tencent.mm/files/xlog目录里.删除这个目录,建立一个xlog的文件,修改000权限,就可以阻止微信产生垃圾日志文件.但也会在内部存储产生xlog日志,同理删除xlog目录,建立xlog文件就行.<br>4.平时很少使用微信,因为微信真的越来越臃肿,加一些我不想用的东西,还限制低版本的登录,我用低版本日你🐎了吗?用新版本的微信你就像闻到屎一样恶心人!<br>5.微信在我眼里是一坨一坨屎堆砌的app,臃肿,毒瘤,恶心,难用,还自带墙,言论审查,删帖封号,去死吧微信!<br>6.国内互联网公司带动了一些很差的使用体验风潮,各大公司都相互模仿,比如强制扫码🐎登录;下载APP查看完整内容(比如知乎,豆瓣,CSDN等等),还有菜鸟驿站必须拿身份证拍照取件,卑鄙无耻强制收集用户隐私;为了账户安全实名认证(微信支付宝淘宝);手机端访问为安装app强制跳转到应用商店(淘宝);不给权限不让运行(国内毒瘤app一贯特色);权限滥用;音乐软件里弄个商城(QQ音乐,网易云);浏览器弄个新闻推送;浏览器自带黑名单进行言论审查(屏蔽996.icu);杀毒软件弄个金融投资(360)~~~~等等,国内互联网都被这些毒瘤厂商带坏了.哎,悲哀啊.<br>7.我是个极简主义者,也是日常重度使用debian的Linux用户,遵循unix理念.一个程序只做一件事,把它做好就行.国内的这些毒瘤app完全向unix理念相反方向发展.整天用着一堆自己极其讨厌的app,真是很让人烦心!!因为家人朋友用微信,自己只能强制绑架着使用微信.没办法,像telegram这样甩微信十条街的应用国内被屏蔽了.</p>
<hr>
<h3 id="体验-amp-收获"><a href="#体验-amp-收获" class="headerlink" title="体验&amp;收获"></a>体验&amp;收获</h3><p>1.经过精简后的AOSIP 9.0 P 的ROM，系统app的数量75个，其中包括了opengapps。相当精简了，比起国内那些魔改的ROM，要精简很多很多，这也是我为什么喜欢用原生ROM的原因，可以自己定制，精简，精简，精简再精简。以前刷moto g 2nd的时候，刷的AOSP Android 5.1 最后精简到系统app仅仅45个，system分区大小不足400MB，流畅的一批，MSM8226的Soc用的流畅的一批,精简到能够保障系统正常运行，清除data分区后，开机后可以正常初始化使用，打电话，发短信，安装应用等正常。但是无论精简再流畅,面对国内这些毒瘤app,还是招架不了.<br>2.现在插上USB线可以默认选择为MTP了,不像以前那样需要打开开发者工具-&gt;USB设置那里选择MTP,比以前方便很多<br>3.MAT还原的时候速度快了很多很多,几乎不到3秒完成还原<br>4.感觉基带信号不稳定,开热点会经常性地断流.估计是这个ROM的通病,或者是我基带的问题.<br>5.安装应用的时候速度比以前快了很多<br>6.在探索炼妖壶的使用,微信无法登录<br>7.Google TTS可以正常使用了,以前没修好,现在配合tasker能实现手机丢失后报警,朗读警告信息的功能了,改天写一个使用taker处理的文章,好好探索折腾一下,估计这个月没时间写了,时间够忙的.</p>
<hr>
<h2 id="参考-推荐阅读"><a href="#参考-推荐阅读" class="headerlink" title="参考/推荐阅读"></a>参考/推荐阅读</h2><p>1.<a href="https://bbs.letitfly.me/" target="_blank" rel="noopener">LetITFly BBS</a>，里面介绍了IFW和MAT，刷机搞<del>基</del>机常去的地方。<br>2.<a href="https://cn.apkjam.com/greenify-prescription.html" target="_blank" rel="noopener">「绿色守护」处方推荐</a></p>
]]></content>
      <tags>
        <tag>android</tag>
        <tag>moto</tag>
        <tag>ROM</tag>
      </tags>
  </entry>
  <entry>
    <title>every linux networking tool i know</title>
    <url>/archives/networktools.html</url>
    <content><![CDATA[<p>不久前在twitter上看到一张描述45个Linux网络工具的<a href="https://wizardzines.com/networking-tools-poster/" target="_blank" rel="noopener">图片</a>，于是想整理一下它们常用功能</p>
<hr>
<p>1.<code>ping</code> “are these computers even connected”</p>
<p>2.<code>curl</code> make any http request  you want</p>
<p>3.<code>httpie</code> like curl but easier (http get)</p>
<p>4.<code>wget</code> download files</p>
<p>5.<code>tc</code> one a linux router:slow down you brother’s internet(and more more)</p>
<p>6.<code>dig/nsloopup</code> what’s the ip for the domain (DNS requery)</p>
<p>7.<code>whois</code> is the domain registered</p>
<p>8.<code>ssh</code> secure shell</p>
<p>9.<code>scp</code> copy file over a SSH connection</p>
<p>10.<code>rsync</code> copy only changed files (works over SSH)</p>
<p>11.<code>ngrep</code> grep your network</p>
<p>12.<code>tcpdump</code> show me all packets on port 80</p>
<p>13.<code>wireshark</code> look at those packets in a GUI</p>
<p>14.<code>tshark</code> command line super poweroful packets analysis</p>
<p>15.<code>tcpflow</code> capture &amp; assemble TCP streams</p>
<p>16.<code>ifconfig</code> what’s my ip address</p>
<p>17.<code>route</code> view and change route and more</p>
<p>18.<code>ip</code> replace ifconfig .route and more</p>
<p>19.<code>arp</code> see your arp table</p>
<p>20.<code>mitmproxy</code>spy on SSL connetcions your programs are making</p>
<p>21.<code>nmap</code> in network scanning port</p>
<p>22.<code>zenmap</code> GUI for nmap</p>
<p>23.<code>pof</code> identify OS of hosts connetcing to you</p>
<p>24.<code>ftp/sftp</code> copy files .sftp does if over SSH</p>
<p>25.<code>netstat/ss/fuser</code> “what port are server using?”</p>
<p>26.<code>iptables</code> setup firewall and NAT !</p>
<p>27.<code>nfables</code> new versiob of iptables</p>
<p>28.<code>telnet</code> like ssh but insecure</p>
<p>29.<code>openvpn</code> a VPN</p>
<p>30.<code>wireguard</code> a newer VPN</p>
<p>31.<code>nc</code> netcat ! make TCP connections manually</p>
<p>32.<code>socat</code> proxy a tcp socket a unix domain socket + lost more</p>
<p>33.<code>hping3</code> contect ang TCP packet that server </p>
<p>34.<code>traceroute/mtr</code> what server are on the way to what server?</p>
<p>35.<code>tcptraceroute</code> use tcp packets instad of icmp to traceroute</p>
<p>36.<code>ethtool</code> manage physical Ethernet connections + network cards</p>
<p>37.<code>iw/iwconfig</code> manage wireless network settings (see speed / frquery)</p>
<p>38.<code>sysctl</code> configure linux kernel network stack</p>
<p>39.<code>openssl</code> do literally anything with ssl cerficates</p>
<p>40.<code>stunel</code> make a ssl proxy for an insecure server</p>
<p>41.<code>iptraf/nethogsl/iftop/ntop</code> see what’s is useing bandwidth</p>
<p>42.<code>ab/nload/iperf</code> benchmarking tools</p>
<p>43.<code>python3 -m http.server</code> server file from a directory</p>
<p>44.<code>ipcalc</code> easily see what</p>
<p>45.<code>nsenter</code>enter a container process’s network namespace</p>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>network</tag>
        <tag>network tools</tag>
      </tags>
  </entry>
  <entry>
    <title>Play-with-Docker --在线使用/学习Docker</title>
    <url>/archives/play-with-docker.html</url>
    <content><![CDATA[<p><code>Play With Docker</code> 是一个运行在浏览器中的Docker   Playground，只需要服务端部署好pwd服务，客户端无需安装任何环境，使用浏览器就可以在线体验 Docker。类似的还有近期上线的<code>instantbox</code>在线体验Linux发行版。<br>按照官方readme或wiki部署起来，会有不少坑，接下来就开始填坑。</p>
<hr>
<p>1.安装 Docker 以及 docker-compose ，相信你已经完成了。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt-get update &amp;&amp; apt-get install apt-transport-https ca-certificates curl</span><br><span class="line"></span><br><span class="line"><span class="comment">### Add Docker’s official GPG key</span></span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -</span><br><span class="line"></span><br><span class="line"><span class="comment">### Add Docker apt repository.</span></span><br><span class="line">add-apt-repository <span class="string">"deb [arch=amd64] https://download.docker.com/linux/ubuntu <span class="variable">$(lsb_release -cs)</span> stable"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Install Docker CE.</span></span><br><span class="line">apt-get update &amp;&amp; apt-get install docker-ce</span><br></pre></td></tr></table></figure>
<p>2.开启swarm需要指定 ip</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker swarm init --advertise-addr <span class="variable">$&#123;you-ip&#125;</span></span><br></pre></td></tr></table></figure>
<p>3.安装 golang、dep、项目依赖:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt-get install golang go-dep</span><br><span class="line"><span class="built_in">export</span> GOPATH=/root/go</span><br><span class="line">mkdir -p <span class="variable">$GOPATH</span>/src/github.com/play-with-docker/</span><br><span class="line"><span class="built_in">cd</span> !$</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/play-with-docker/play-with-docker.git</span><br><span class="line"><span class="built_in">cd</span> play-with-docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装项目依赖</span></span><br><span class="line">dep ensure -v</span><br></pre></td></tr></table></figure>
<p>4.拉取 dind 镜像，也即是工作台运行实例的模板镜像</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull franela/dind</span><br></pre></td></tr></table></figure>
<p>5.修改监听地址和域名，如果部署在 VPS 上需要把 localhost 修改为域名或 IP<br>vi api.go<br>在api.go文件的 <code>config.ParseFlags()</code> 下面添加 <code>config.PlaygroundDomain = &quot;YOU-IP or DOMAIN&quot;</code></p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    config.ParseFlags()</span><br><span class="line">    config.PlaygroundDomain = <span class="string">"YOU-IP or DOMAIN"</span></span><br></pre></td></tr></table></figure>
<p>另外附上shell脚本中获取本机公网ip的方法</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ips=`ifconfig | grep inet | grep -v inet6 | grep -v 127 | grep -v 172 |  sed 's/^[ \t]*//g' | cut -d ' ' -f2`</span><br><span class="line">IPADDR=$ips</span><br></pre></td></tr></table></figure>
<p>5.最后一步 <code>docker-compose up</code> 走起！😋</p>
<p>几个坑：<br>1.服务器RAM低于1GB 经常会提示<figure class="highlight plain"><figcaption><span>error: runtime: out of memory```,代码没问题，是你的服务器内存太少了，开启`SWAP`可解决。如果自己编译`go build`的话也会遇到同样的错误，debug了好几遍发现是物理内存不足的问题。</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```bash</span><br><span class="line">    dd if=/dev/zero of=/swapfile bs=4MB count=512</span><br><span class="line">    mkswap /swapfile</span><br><span class="line">    chmod 600 /swapfile</span><br><span class="line">    swapon /swapfile</span><br></pre></td></tr></table></figure></p>
<p>2.有些环境下会提示找不到<code>$GOPATH</code>，而<code>docker-compose.yml</code>里使用了<code>$GOPATH</code>指定目录，可以换成绝对路径。</p>
]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>RMS 的征婚启示</title>
    <url>/archives/RMS.html</url>
    <content><![CDATA[<p><a href="http://www.stallman.org/extra/personal.html" target="_blank" rel="noopener">My former Personal Ad</a><br>(Currently for amusement only.)</p>
<p>[This was last updated in early 2009. The ages are out of date now.]</p>
<p>I’m a single atheist white man, 55, reputedly intelligent, with unusual interests in politics, science, music and dance.</p>
<p>I’d like to meet a woman with varied interests, curious about the world, comfortable expressing her likes and dislikes (I hate struggling to guess), delighting in her ability to fascinate a man and in being loved tenderly, who values joy, truth, beauty and justice more than “success”–so we can share bouts of intense, passionately kind awareness of each other, alternating with tolerant warmth while we’re absorbed in other aspects of life.</p>
<p>My 25-year-old child, the Free Software Movement, occupies most of my life, leaving no room for more children, but I still have room to love a sweetheart if she doesn’t need to spend time with me every day. I spend a lot of my time traveling to give speeches, often to Europe, Asia and Latin America; it would be nice if you were free to travel with me some of the time.</p>
<p>If you are interested, write to rms at gnu dot org and we’ll see where it leads.</p>
<hr>
<p>我，单身，无神论者，白人，52岁，据说比较聪明，对于政治、科学、音乐和舞蹈有着不同寻常的兴趣。</p>
<p>我想寻找这样一位女士：爱好广泛，对世界充满好奇心，能够清晰表达她的爱憎（我痛恨动脑筋猜测），乐于使男人着迷，渴望被温柔地爱，对于快乐、真理、美和正义的评价高于“成功”。这样的话，我们就能不断对另一方产生热烈而又美好的了解，当我们被生活中其他东西吸引的时候，彼此就能感到宽容的温暖。</p>
<p>我有一个22岁的孩子——自由软件运动——他占据了我大部分的生活，没有精力再抚养更多的孩子了，但是我仍然会投入的爱我的爱人。我有大量时间花在巡回演讲上，经常要去欧洲、亚洲和拉丁美洲。如果你有空在某些时间陪我一起旅行，那就好了。</p>
<p>如果你有兴趣的话，请写信到 <a href="mailto:rms@stallman.org" target="_blank" rel="noopener">rms@stallman.org</a> ，让我们看看会有什么结果</p>
]]></content>
  </entry>
  <entry>
    <title>Code it is trivial 写代码是微不足道的</title>
    <url>/archives/Code-It-s-Trivial.html</url>
    <content><![CDATA[<p>本文转载至stack overflow 创始人 Jeff Atwood的<a href="https://blog.codinghorror.com/code-its-trivial/" target="_blank" rel="noopener">Code: It’s Trivial</a><br>背景是：当时stack overflow 刚成立不久，而且使用的技术是Windows server 及.net，就有特别多的人喷stack overflow技术垃圾，声称花一个周末的时间就能开发出像stack overflow一样的网站。 Jeff Atwood 于是写这篇文章怼回去，仔细看看hack news上的评论挺有意思的。<a href="https://news.ycombinator.com/item?id=678501" target="_blank" rel="noopener">hack news 的链接在这</a>。还有当时的<a href="https://news.ycombinator.com/item?id=8863" target="_blank" rel="noopener">droxbox</a>和<a href="https://news.ycombinator.com/item?id=426120" target="_blank" rel="noopener">Airbnb</a>也被喷的狗血淋头。十年多过去了，喷他们的人只留下了一个ID，而被喷的人留下了一个伟大的网站。<br>对于一个公司尤其是初创公司来讲，选用什么技术真的不是很重要，你看stack overflow 不就使用的Windows嘛🐎。</p>
<hr>
<p>Remember that Stack Overflow thing we’ve been working on? Some commenters on a recent Hacker News article questioned the pricing of Stack Exchange – essentially, a hosted Stack Overflow:<br>Seems really pricey for a relatively simple software like this. Someone write an open source alternative? it looks like something that can be thrown together in a weekend.<br>Ah, yes, the stereotypical programmer response to most projects: it’s trivial! I could write that in a week!*<br>It’s even easier than that. Open source alternatives to Stack Overflow already exist, so you’ve got a head start. Gentlemen, start your compilers! Er, I mean, interpreters!<br>No, I don’t take this claim seriously. Not enough to write a response. And fortunately for me, now I don’t need to, because Benjamin Pollack – one of the few people outside our core team who has access to the Stack Overflow source code – already wrote a response. Even if I had written a response, I doubt it would have been half as well written as Benjamin’s.<br>Developers think cloning a site like StackOverflow is easy for the same reason that open-source software remains such a horrible pain in the ass to use. When you put a developer in front of StackOverflow, they don’t really see StackOverflow. What they actually see is this:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> QUESTION (<span class="keyword">ID</span> <span class="keyword">identity</span> primary <span class="keyword">key</span>,</span><br><span class="line">TITLE <span class="built_in">varchar</span>(<span class="number">255</span>),</span><br><span class="line"><span class="keyword">BODY</span> <span class="built_in">text</span>,</span><br><span class="line">UPVOTES <span class="built_in">integer</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">default</span> <span class="number">0</span>,</span><br><span class="line">DOWNVOTES <span class="built_in">integer</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">default</span> <span class="number">0</span>,</span><br><span class="line"><span class="keyword">USER</span> <span class="built_in">integer</span> <span class="keyword">references</span> <span class="keyword">USER</span>(<span class="keyword">ID</span>));</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> RESPONSE (<span class="keyword">ID</span> <span class="keyword">identity</span> primary <span class="keyword">key</span>,</span><br><span class="line"><span class="keyword">BODY</span> <span class="built_in">text</span>,</span><br><span class="line">UPVOTES <span class="built_in">integer</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">default</span> <span class="number">0</span>,</span><br><span class="line">DOWNVOTES <span class="built_in">integer</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">default</span> <span class="number">0</span>,</span><br><span class="line">QUESTION <span class="built_in">integer</span> <span class="keyword">references</span> QUESTION(<span class="keyword">ID</span>))</span><br></pre></td></tr></table></figure>
<p>If you then tell a developer to replicate StackOverflow, what goes into his head are the above two SQL tables and enough HTML to display them without formatting, and that really is completely doable in a weekend. The smarter ones will realize that they need to implement login and logout, and comments, and that the votes need to be tied to a user, but that’s still totally doable in a weekend; it’s just a couple more tables in a SQL back-end, and the HTML to show their contents. Use a framework like Django, and you even get basic users and comments for free.<br>But that’s not what StackOverflow is about. Regardless of what your feelings may be on StackOverflow in general, most visitors seem to agree that the user experience is smooth, from start to finish. They feel that they’re interacting with a polished product. Even if I didn’tknow better, I would guess that very little of what actually makes StackOverflow a continuing success has to do with the database schema–and having had a chance to read through StackOverflow’s source code, I know how little really does. There is a tremendous amount of spit and polish that goes into making a major website highly usable. A developer, asked how hard something will be to clone, simply does not think about the polish, because the polish is incidental to the implementation.<br>I have zero doubt that given enough time, open source clones will begin to approximate what we’ve created with Stack Overflow. It’s as inevitable as evolution itself. Well, depending on what time scale you’re willing to look at. With a smart, motivated team of closed-source dinosaurs, it is indeed possible to outrun those teeny tiny open-source mammals. For now, anyway. Let’s say we’re those speedy, clever Velociraptor types of dinosaurs – those are cool, right?<br>Despite Benjamin’s well reasoned protests, the source code to Stack Overflow is, in fact, actually, kind of … well, trivial. Although there is starting to be quite a lot of it, as we’ve been beating on this stuff for almost a year now. That doesn’t mean our source code is good, by any means; as usual, we make crappy software, with bugs. But every day, our tiny little three person team of speedy-but-doomed Velociraptors starts out with the same goal. Not to write the best Stack Overflow code possible, but to create the best Stack Overflow experience possible. That’s our mission: make Stack Overflow better, in some small way, than it was the day before. We don’t always succeed, but we try very, very hard not to suck – and more importantly, we keep plugging away at it, day after day.<br>Building a better Stack Overflow experience does involve writing code and building cool features. But more often, it’s anything but:</p>
<ol>
<li>synthesizing cleaner, saner HTML markup</li>
<li>optimizing our pages for speed and load time efficiency</li>
<li>simplifying or improving our site layout, CSS, and graphics</li>
<li>responding to support and feedback emails</li>
<li>writing a blog post explaining some aspect of the site engine or philosophy</li>
<li>being customers of our own sites, asking our own programming questions and sysadmin questions</li>
<li>interacting with the community on our dedicated meta-discussion site to help gauge what we should be working on, and where the rough edges are that need polishing</li>
<li>electing community moderators and building moderation tools so the community can police and regulate itself as it scales</li>
<li>producing Creative Commons dumps of our user-contributed questions and answers</li>
<li>coming up with schemes for responsible advertising so we can all make a living</li>
<li>producing the Stack Overflow podcast with Joel</li>
<li>helping set up logistics for the Stack Overflow DevDays conferences</li>
<li>setting up the next site in the trilogy, and figuring out where we go next As programmers, as much as we might want to believe thatlots_of_awesome_code = success;</li>
</ol>
<hr>
<p>There’s nothing particularly magical about the production of source code. In fact, writing code is a tiny proportion of what makes most businesses successful.<br>Code is meaningless if nobody knows about your product. Code is meaningless if the IRS comes and throws you in jail because you didn’t do your taxes. Code is meaningless if you get sued because you didn’t bother having a software license created by a lawyer.<br>Writing code is trivial. And fun. And something I continue to love doing. But if you really want your code to be successful, you’ll stop coding long enough to do all that other, even more trivial stuff around the code that’s necessary to make it successful.</p>
<ul>
<li>Although, to be fair, I really could write Twitter in a week. It’s so ridiculously simple! Come on!</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>钛备份的逆向原理</title>
    <url>/archives/android-taibackup.html</url>
    <content><![CDATA[<p>经常刷机的机友一定很熟悉钛备份，简直刷机备份数据的神器。有了它刷机爽得一批，备份应用数据，还原数据，真的很爽。钛备份是我刷完ROM，接着root后装得第一个应用，用它来还原之前得应用，十分方便。<br>对钛备份得备份原理很是好奇，在钛备份的 /data/data/com.keramidas.TitaniumBackup/files/ 下发现了busybox，猜想一定是使用tar 来备份的，压缩使用设定的gzip或xd，但我一般不采用压缩，能加快备份速度。接下来就使用adb 模拟钛备份的过程</p>
<hr>
<p>1.先kill要备份应用<br><code>killall -s STOP com.music.moto</code></p>
<p>2.计算空间大小<br><code>du -H -s /storage/emulated/0/Android/data/com.music.moto</code></p>
<p>3.把sdcard下的data软连接过来<br><code>ln -s /storage/emulated/0/Android/data/com.music.moto /data/data/.external.com.music.moto</code></p>
<p>4.用tar备份，排除了lib和cache<br><code>tar -cz /data/data/com.music.moto/. /data/data/.external.com.music.moto/. --exclude data/data/com.music.moto/./lib --exclude data/data/com.music.moto/./cache</code></p>
<p>5.删除sdcard的data软连接<br><code>rm /data/data/.external.com.music.moto</code></p>
<p>6.剩下的应该是保存备份信息还有改备份文件的权限<br><code>killall -s CONT com.music.moto</code><br><code>ls --color=never -d /data/app/com.music.moto-1/base.apk</code><br><code>ls --color=never /data/data/com.music.moto/databases/</code><br><code>chown media_rw:media_rw /storage/B35D-1F87/TWRP/TitaniumBackup/com.music.moto-20190412-174942.tar.gz</code></p>
<p>2、恢复（已安装的程序）<br>1这两个命令合起来看，是把压缩文件解包<br><code>cat /storage/B35D-1F87/TWRP/TitaniumBackup/com.music.moto-e9310c14ccf910db88f0bc4c842e515a.apk.gz</code><br>bunzip2</p>
<p>2.改权限，应该有个安装应用的命令，pm没有替换，有的话应该能看到<br><code>chmod 755 /data/local/tmp/com.keramidas.TitaniumBackup-install.apk</code></p>
<p>3.删除应用<br><code>rm /data/local/tmp/com.keramidas.TitaniumBackup-install.apk</code></p>
<p>4将原来应用的data移动下<br><code>mv /data/data/com.music.moto /data/data/.com.music.moto</code></p>
<p>5删除sdcard下的data并链接过来<br><code>rm -R /storage/emulated/0/Android/data/com.music.moto</code><br><code>ln -s /storage/emulated/0/Android/data/com.music.moto /data/data/.external.com.music.moto</code></p>
<p>6解包数据，排除lib<br><code>cat /storage/emulated/0/TitaniumBackup/com.music.moto-20171004-052037.tar.gz</code><br><code>tar -C / -x --exclude data/data/com.music.moto/lib --exclude data/data/com.music.moto/./lib</code></p>
<p>7.删除sdcard的data链接<br><code>rm /data/data/.external.com.music.moto</code></p>
<p>8改用户组<br><code>chown -R media_rw:media_rw /data/media/0/Android/data/com.music.moto</code><br><code>chown -hR 10118:10118 /data/data/com.music.moto</code></p>
<p>9改权限<br><code>chmod -R u+rwx /data/data/com.music.moto</code></p>
<p>10将原应用的lib移到新恢复应用的data目录下<br><code>mv /data/data/.com.music.moto/lib /data/data/com.music.moto</code></p>
<p>11删除原应用的data<br><code>rm -R /data/data/.com.music.moto</code></p>
]]></content>
      <tags>
        <tag>安卓</tag>
        <tag>刷机</tag>
      </tags>
  </entry>
  <entry>
    <title>软件博物馆</title>
    <url>/archives/software-museum.html</url>
    <content><![CDATA[<h2 id="挖坑、未完成"><a href="#挖坑、未完成" class="headerlink" title="挖坑、未完成"></a>挖坑、未完成</h2><h2 id="软件博物馆"><a href="#软件博物馆" class="headerlink" title="软件博物馆"></a>软件博物馆</h2><p>年初总结整理了一下开源软件/自由软件相关的一些基金会和非营利性组织，但觉着仅仅这样还不够。结合软件那些事儿的电台内容，想和老刘一样，做个软件博物馆，记录整理一下互联网行业那些值得纪念的人和组织。</p>
<hr>
<p>开源基金会和组织：</p>
<hr>
<p>互联网名人堂<br>1.<a href="https://en.wikipedia.org/wiki/Tim_Berners-Lee" target="_blank" rel="noopener">万维网之父</a>– Tim Berners-Lee 蒂姆·伯纳斯-李<br>2.<a href="https://en.wikipedia.org/wiki/Aaron_Swartz" target="_blank" rel="noopener">互联网之子</a>–  Aaron 亚伦·斯沃茨<br>3.<a href="https://en.wikipedia.org/wiki/Fabrice_Bellard" target="_blank" rel="noopener">法布里斯·贝拉</a></p>
<hr>
<p>软件公司</p>
<hr>
<p>硬件公司</p>
<hr>
<p>操作系统<br>1.linux<br>2.freeBSD</p>
]]></content>
  </entry>
  <entry>
    <title>使用 namecheap 域名邮箱转发功能拥有无限个邮箱</title>
    <url>/archives/domain-email.html</url>
    <content><![CDATA[<p>从 namecheap 那里注册了 502.li 这个域名，本来是想注册另一个与我名字相同的域名，奈何在付款的时候一直提示无法注册，于是无奈就注册了 502.li 这个数字域名。三位数字的域名在我s sh 登录的时候省了打几个字符。在 namecheap 那里是可以选择邮箱服务，中的<code>REDIRECT EMAIL</code>，有<code>Catch-All</code>选项可以转发所有该域名下的邮箱。像 <a href="mailto:blog@502.li" target="_blank" rel="noopener">blog@502.li</a>,<a href="mailto:i@502.li" target="_blank" rel="noopener">i@502.li</a> <a href="mailto:*@502.li" target="_blank" rel="noopener">*@502.li</a> 这样的邮箱地址都会被转发到 Forward to 自定义的邮箱那里。这样最大的好处就是不用架设邮箱服务器或者使用第三方邮箱服务。把邮箱都转发到 gmail 或者 outlook。telegram上也有gmail 的bot，这样就可以用 telegram 接受域名邮箱的邮件，同时又不用登录邮箱，是不是很方便快捷。但最大的缺点就是不能发送邮件，但对于那些至于要接收注册验证类的邮件，这个完全足够使用了!</p>
<p> <img src="../img416815644.png" alt="img"> </p>
]]></content>
      <tags>
        <tag>域名</tag>
      </tags>
  </entry>
  <entry>
    <title>justice 公开课</title>
    <url>/archives/justic.html</url>
    <content><![CDATA[<blockquote>
<p>此文引用剽窃自互联网</p>
</blockquote>
<h2 id="1-《杀人的道德侧面》"><a href="#1-《杀人的道德侧面》" class="headerlink" title="1.《杀人的道德侧面》"></a>1.《杀人的道德侧面》</h2><hr>
<p>如果必须选择杀死1人或者杀死5人，有多数的学生投票来赞成杀死1人，来保全其余五个人的性命。如果在最后，可以有五个人活下来。那么哪怕牺牲一个人的生命也是值得的。这个例子体现了结果主义的道德推理。 事情的正确以及道德与否，取决于你的行为所产生的后果。 结果主义的道德准则中最著名的例子是功利主义功利主义不考虑一个人行为的动机与手段，仅考虑一个行为的结果对最大快乐值的影响。能增加最大快乐值的即是善；反之即为恶。即使是为了救回5条人命。杀害一个无辜者。人们在考虑是不是要这么做的时候，会考虑到这个行为的本身，无论结果如何人们觉得这是错的，而且大错特错。这就引出了第二种道德推理，绝对主义的道德推理。绝对主义的道德推理认为：道德有其绝对的道德原则，有明确的责任和权利，而无论所造成的结果是怎么样的。</p>
<hr>
<h2 id="2-《同类相残案》"><a href="#2-《同类相残案》" class="headerlink" title="2.《同类相残案》"></a>2.《同类相残案》</h2><p>人们是否也有某些基本权利？如果不是来自较大群体的福祉，或者效用或幸福？那么这些权利从何而生？为什么同意以一定的程序，公平的程序，就可以用该程序的运作来为最终带来的结果辩护？得到同意的基本思想：得到同意产生的道德影响是什么？为什么一个得到许可的行为会产生道德上是否允许的不同，使未经许可杀死一个生命是错误的，而本人同意了，在道德上就是允许的？</p>
<hr>
<h2 id="3-《给生命一个价格标签》"><a href="#3-《给生命一个价格标签》" class="headerlink" title="3.《给生命一个价格标签》"></a>3.《给生命一个价格标签》</h2><p>边沁版本的功利主义其主要思想就是：道德的最高原则，无论个人或政治道德，就是将公共福利，或集体的幸福最大化，或在快乐与痛苦的平衡中倾向快乐;简而言之就是，功利最大化。 从这个理论的整体出发，从做正确的事的观点出发，政策和法律的公正的基础就是将效用最大化。两个反对功利主义的不同意见：一是功利主义是否充分尊重了个体权利或少数群体的权利；另一个则是聚集起来的所有效益或价值，是否能将聚集起来的所有价值转换成金钱?Thorndike从他的研究中得到的结论。任何愿望或满足感都存在一个量来度量它们，因此是可度量的。狗或猫或鸡的生活都是由欲望组成，渴望，欲望，以及他们的满足。人类的生活，也是如此，虽然人类的欲望和欲求更加复杂。</p>
<hr>
<h2 id="4-《如何衡量快乐》"><a href="#4-《如何衡量快乐》" class="headerlink" title="4.《如何衡量快乐》"></a>4.《如何衡量快乐》</h2><p>功利主义哲学家密尔认为，所有人类的体验都可以量化，但某些快乐是更值得拥有，更有价值的。穆勒认为，如果社会重视更大程度的欢乐和公正，那么长远来说，社会整体终会有所进步。他说，”我质疑一切不基于效用之上的公义评判标准”但是同时， 他认为基于效用的公义评判标准”是所有道德标准中主要， 神圣且独一无二的一部分。”所以公义和个人权利在社会中的较高地位，并非因为它们脱离了功利主义的前提。公义， 作为某些道德要求的合称，其在社会范围中所能起到的正面效用被人们普遍认同。因此， 它比起其他的道德而言更为重要所以说， 公义是神圣的，是重要的， 对个人来说也是这样。它不是那种可以被简单置换的东西。但最终功利主义的原因是， 穆勒认为人类作为进取的物种，考虑长期利益的时候如果能够做到公义， 以及对权利的尊重，整个社会长期而言将会更加美好。</p>
<hr>
<h2 id="5-《自由选择》"><a href="#5-《自由选择》" class="headerlink" title="5.《自由选择》"></a>5.《自由选择》</h2><p>自由主义，它十分严肃的看待个人权利的问题。之所以叫自由主义， 是因为它认为一个人的基本权利就是享受自由的权利，因为我们是独立的个体生命，我们不一定要被社会予取予求。因为我们是独立的个体生命，我们有对自由的基本权利。也就是说，我们可以自由的选择自己想过的生活，只要在享有自由的同时也尊重他人自由的权利。自由主义者认为政府干预最少的社会是最理想的社会形态。按照自由主义的观点来看， 大部分现代政府都做了三件不合法或是不公平的事情，其中之一是家长式的立法，即制订了让人们自己保护自己的法律。<br>第二点， 不该有道德上的立法。很多法律试图起到提升公民素质或阐明社会道德价值的作用，自由主义者认为这也是一种对自由权利侵犯。第三种被自由主义哲学家踢出局的法律政策就是税收或者任何为了再分配贫富之间收入财产的政策。<br>对于诺齐克和自由主义者来说，为再分配而实施的税收就是盗窃。而且，这并不只是在道义上等同于索取一个人的部分生命和劳动的盗窃，在道义上，它等同于强制劳动。诺齐克指出，强制劳动，就是奴隶制。因为，如果我不拥有对自己劳动的全部所有权，那么，就可以毫无疑问的说，政府或是政治家群体拥有我本人的部分所有权。国家拥有我的部分所有权。由此可以推出我是一个奴隶，我不是自己的主人。<br>上述推理会为我们引出一个支撑自由主义观点的基本原则——我是自己的主人。确切的说，就是自主的思想。如果你不愿只是将人民当作偏心的集合，你就会意识到最基本的道德观点在于，我们自己的拥有者或所有人就是我们自己，这也是功利主义的错误所在。</p>
<hr>
<h2 id="6-《我属于谁？》"><a href="#6-《我属于谁？》" class="headerlink" title="6.《我属于谁？》"></a>6.《我属于谁？》</h2><p>为了普遍的福利而强迫某人，而利用某人这是错误的，因为它违背了我们是自己主人的这个基本事实，也就是违背了自我拥有或自我所有的基本道义事实。自由主义反对再分配的论据正是以“我们是自己的主人”这个基本思想为起点。自由主义者与那些为了集体的愉悦而利用人民的人斗争，是一种手段，就像在路边放一块停车牌，让利用别人的功利主义逻辑能直接察觉到一个强大的思想，即我们是我们自己的所有者。</p>
<hr>
<h2 id="7-《这片土地是我的土地》"><a href="#7-《这片土地是我的土地》" class="headerlink" title="7.《这片土地是我的土地》"></a>7.《这片土地是我的土地》</h2><p>Locke指出，在“自然状态”，在任何政治体制建立之前，每个人都享有生命，自由和财产的自然权利。然而，一旦我们同意进入社会，就同意了受法律制度的约束。因此，Locke认为，即使政府干预了个人的权力，这也是大多数人的意见赋予了它权力这么做的。我们进入社会是通过同意，通过协议来离开自然状态，并被大多数人通过法律体系，人类的法律所管辖。但这些人类法律合法的唯一前提是，他们尊重我们的自然权利，他们尊重我们不可剥夺的权利：生命、自由和财产，没有哪个议会或者立法机构或民主的全权证书可以合理地侵犯我们的自然权利。没有法律可以侵犯我们的生命权、自由权和财产权。但是，怎样才算尊重我的生命权和财产权，却是由各国政府决定和界定的。</p>
<hr>
<h2 id="8-《满合法年龄的成年人》"><a href="#8-《满合法年龄的成年人》" class="headerlink" title="8.《满合法年龄的成年人》"></a>8.《满合法年龄的成年人》</h2><p>我们正在通过社会生活对税收法律做“默认同意”，因此，税收是合法的。而且，只要政府不是特意对某一群体征税-如果不是武断专横的-那么税收并没有侵犯个人的基本权利。脱离自然状态的唯一途径就是采取一个“同意”的行动：同意放弃执法的权利，并且建立一个政府或者一个团体，在这里，有立法机关制定法律，并且每个人都事先同意，每个进来的人，也都事先同意服从多数人的决定。权利是不可分割的，并且因此，我根本没有真正地拥有自己。我不能处置我的生命、我的自由、我的财产，这样其实是侵犯了我的权利。一旦有一个合法政府，经过同意而建立的合法政府，对洛克来说，唯一的限制，就是限制对人的生命、自由和财产的任意掠夺。</p>
<hr>
<h2 id="9-《雇枪》"><a href="#9-《雇枪》" class="headerlink" title="9.《雇枪》"></a>9.《雇枪》</h2><p>用洛克的观点看，一个民主的民选政府有权向人民征税，政府征税应经过人民的同意，因为这的确涉及到公共利益，而拿走个人的财产，但它不需要在税法制定或征集时去征求每个独立个体的意见。它确实需要的是人在进入社会时，就事先默认赋予的同意权，并承担政治义务。而一旦你承担了这些义务，你就同意了大多数人的约束。<br>生命权又怎样？个人拥有自己的观念难道不是受到侵犯吗？将军可以判处临阵逃脱或不服从命令—甚至是自杀性命令，但这些长官们不能做的事情是：他们没权拿走该士兵的一分一文，因为这种做法是不合法的，因为这是专制，腐败。同意论在洛克的思想中非常重要，该同意不是个体对税收或军事命令的同意，而是在第一阶段加入政府，并受大多数人的约束时就默认同意了，这就是同意论的关键所在。而且这相当关键，即使是建立在我们有一些天赋的生存权，自由权以及财产权基础之上的有限政府，即便这个有限政府只在观念上受限，并受到普遍使用的法律的监管，政府要依法行政，政府不能专制，这就是洛克的理论。</p>
<hr>
<h2 id="10-《出售母亲》"><a href="#10-《出售母亲》" class="headerlink" title="10.《出售母亲》"></a>10.《出售母亲》</h2><p>Sandel教授把自由市场交易运用到当代颇具争议的新领域：生殖权利。一种反对意见和“不知情的同意”有关，这次不是因为明显的或隐含的强迫，而是因为不完美或者有缺陷的信息，所以“不知情的”或者“有缺陷的”同意可能产生于缺乏相关的信息。产生第一个疑问：我们要计算出自愿交换的市场在涉及讨价还价、平等的信息时有多大的自由？第二种反对执行代孕合同的声音说这多少有点没有人性通过市场来交易生育，有些没有人性是什么意思？效用……用处是用来处理事物的唯一适当方法吗？包括生命、征兵、生育、养育？如果不是，我们如何计算？是否有些无法用钱买到的事物，并非因为“不知情的同意”而也可能是因为某些事物比单纯的使用具有更高的价值。</p>
<hr>
<h2 id="11-《考虑你的动机》"><a href="#11-《考虑你的动机》" class="headerlink" title="11.《考虑你的动机》"></a>11.《考虑你的动机》</h2><p>康德：最具挑战性和最有难度的思想家之一。康德认为，我们作为个体，是神圣的，是权力的享有者，但并不是因为我们拥有自己。相反，理性和自由选择是我们的能力，使我们变得独特，使我们跟单纯的动物区别开。当我们将责任付诸行动的时候，去做正确的事，只有这样，我们的行动才有道德的价值。<br>自由的行动，就意味着自主的行动。自主的行动，就意味着遵从自己为自己设定的规则而行动，不是出于自然法则或因果定律。尊重人类的尊严，意味着不仅仅将人视为实现目的的工具，而且要将人本身也视为终极目的。由于这样的原因，为了一些人的幸福安乐而牺牲其他人，就是错误的。<br>我们之所以能作为自主的生命并给自己设定行为原则，是因为一种理性，这是一种我们作为人类而普遍拥有的理性，而非什么不同寻常的特质。我们应该敬重别人的尊严，是因为我们都是理性的生命，我们都有理性思考的能力，正是我们无差别拥有的理性思维的能力，将尊严赋予我们所有人。</p>
<hr>
<h2 id="12-《道德的最高准则》"><a href="#12-《道德的最高准则》" class="headerlink" title="12.《道德的最高准则》"></a>12.《道德的最高准则》</h2><p>康德说，就我们行为的道德价值而言，赋予它道德价值的是我们超越自身利益和偏好，将责任付诸行动的能力。康德认为只有一种动机才称得上是道德的，那就是出于义务的动机，为了正确的理由做正确的事情。只有当我是在独立自主的拿主意的时候，我才是自由的。<br>康德说理性的指导方式有两种：康德将这种理性的指导称为“律令”。简单的说，律令就是指出你应该做某件事。第一种律令，也许是我们最熟悉的，是假言律令。假言律令使用的是工具理性，如果你想得到甲，那么你必须先做乙。这是一种目的-手段的逻辑推理。如果这行动本身就有价值，一个讲究理性的头脑也会认为这是必须做的事情，那么这种动机是就是绝对律令（已所不欲，勿施于人；人就是目的；尊重）。</p>
<hr>
<h2 id="13-《谎言的教训》"><a href="#13-《谎言的教训》" class="headerlink" title="13.《谎言的教训》"></a>13.《谎言的教训》</h2><p>康德看来，人并不是因为顺从于法律而获得尊严，而是因为尊重那些法律，我是法律的作者，我附属于法律，同时我主动承担起法律，我遵循法律。如果我们依照我们的道德心，自由的选择，那么我们就能保证道德法则成为一个人人共有的道德法则。理性控制了意愿，理性主导者我的意愿，当我遵守道德法则的时候，是同样的理性让你为自己选择了道德法则，这就是为什么我们能自主为自己作出选择，我们每一个人都能为自己作出选择。我们是有自主能力的个人，我们最后都遵循同一个道德法则——绝对律令。从康德的观点看来一个谎言和一个误导的真相的差别有一个世界那么大，误导性的事实对道德律仍然有所尊重。</p>
<hr>
<h2 id="14-《协议就是协议》"><a href="#14-《协议就是协议》" class="headerlink" title="14.《协议就是协议》"></a>14.《协议就是协议》</h2><p>康德认为：缔造正义法则的契约仅仅是理性观念的产物，但是它拥有勿庸置疑的实践真实性，因为它能够促使每一位立法者在制定法律的时候都与全国人民的整体意愿相符。但这是一种虚构的契约，这种契约从来没有发生过，能有多少道德力量呢？罗尔斯认为思考正义的方法就是站在一个假想契约的角度，站在无知之幕的背后，它创造了平等的条件，通过排除，或者使我们暂时忘记权力和知识的差距。这些差距在大多数情况下会导致不公平的结果。这就是为什么对康德和罗尔斯来说，一个各方平等的假想契约是思考正义原则的唯一途径。</p>
<hr>
<h2 id="15-《什么是公平的起点》"><a href="#15-《什么是公平的起点》" class="headerlink" title="15.《什么是公平的起点》"></a>15.《什么是公平的起点》</h2><p>在“无知的面纱”背后，每个人都知道一旦遮盖掀起，现实生活开启，我们每个人都希望有尊严受尊重。即使是在我们是少数的情况下。我们不希望被压榨。所以由此，我们会同意去反对功利主义，相反的，要适用我们的首要原则，即基本自由。那些在社会地位与经济上的不平等的允许条件，只有他能适用于最不富裕人群的利益。所以我们不会反对所有的收入与财富上的不平等。我们会允许一些。但是衡量界定是，那些不平等现象是否符合所有人的利益。Rawls认为，是原则，尤其是那些最底层人们的利益。只有这样那些不平等才会在 “无知的面纱”背后被接受。因此，RAWLS主张说，那些不平等只有服从于最少数人民利益，才能算是公正。</p>
<hr>
<h2 id="16-《我们该得到什么》"><a href="#16-《我们该得到什么》" class="headerlink" title="16.《我们该得到什么》"></a>16.《我们该得到什么》</h2><p>自由主义认为，公正的分配体系是一种自由交换的体系，自由的市场经济，反对背景的一种完全平等。罗尔斯称，如果你只有完全平等，工作对每个人都敞开，结果是不会公平的。机遇会偏向于那些碰巧出生在富足家庭的人，那些碰巧能有接受优良教育机会的人，而这种出生的偶然性用于分配人生际遇是不公正的。<br>我们应得那些利益，那些游戏规则所承诺的那种基于自身天赋做出的努力所获得的成果。但，不要错误与自负地假设说，我们原本一开始就是应得的，我们一开始就值得拥有这个社会所推崇的那种我们碰巧有的素质。如果我们是生活在那种社会里，而不是我们现在的这种社会中，我们很可能会少赚很多钱。但是当我们那个时候应得的东西减少的时候，我们自身的价值不会降低。</p>
<hr>
<h2 id="17-《讨论反歧视行动》"><a href="#17-《讨论反歧视行动》" class="headerlink" title="17.《讨论反歧视行动》"></a>17.《讨论反歧视行动》</h2><p>在捍卫种族和少数民族因素作为录取因素的这一观点中，一个观点打算纠正教育劣势带来的结果，改良观点，这种观点自始至终都坚持一个原则：即学业前景和学术潜力应当在录取时加以考虑，我们只需要超越单一的测试成绩和学位，来对学业前景和学术潜力做出真实的估计。<br>第二个观点认为，平权运动是正当的，在此没有必要为了一个申请人而专门改正教育劣势，这种事情合理是因为它是历史错误的一种补偿，为了过去的非正义行为，因此，这是一个补偿观点，补偿过去的错误。<br>第三个观点，多样化观点。多样化观点有两个方面。一方面认为，为了让每个人都接受教育，重要之处在于应当多样化学生群体，而另一方面其他人则说到了更为广泛的社会。</p>
<hr>
<h2 id="18-《目的是什么》"><a href="#18-《目的是什么》" class="headerlink" title="18.《目的是什么》"></a>18.《目的是什么》</h2><p>亚里士多德关于公平和正义的理论，简单地说，是告诉人们他们该付出什么，该得到什么。亚里士多德认为，一个人在考虑分配问题的时候，必须考虑分配的目标，终点和目的。对他来说，这是关于一个人找到合适的位置来发挥他的美德的事情。对亚里士多德来说，正义是给予人们应得的东西，是给予人们本来属于他们的东西，这是一个关乎人们之间，以他们的美德，他们适宜的社会角色相互配合的问题。</p>
<hr>
<h2 id="19-《好公民》"><a href="#19-《好公民》" class="headerlink" title="19.《好公民》"></a>19.《好公民》</h2><p>亚里士多德不同意康德和罗尔斯。亚里士多德主张说，公正是一种让人们得到应得之物的事物。而亚里士多德的正义理论的中心观点就是，对正义和我们拥有的权利进行推理，就不可避免地要思考，设立社会活动的目的——需要给予相同的人们以相同的东西。<br>亚里士多德说认为“美德是我们只能通过实践才能获致的，是我们只能通过运用才能获致的。它是这样的事物，我们只能通过做才能学到。它不是能从书本学到的。”我们唯一用来获得，能建立美好生活的美德的方法，是去运用美德，是去形成确定的、由反复受教而出现的习惯，然后致力于，同公民们进行研讨的实践活动，研讨关于好的性质。那是政治生活的终极关注。</p>
<hr>
<h2 id="20-《自由与适应》"><a href="#20-《自由与适应》" class="headerlink" title="20.《自由与适应》"></a>20.《自由与适应》</h2><p>在一个多元社会中，人们在关于好的生活的本质上明显会出现分歧，我们不应该去试图将正义建筑在，任何特定的对上述问题的答案上。所以他们拒绝目的论。他们拒绝，将正义捆绑到一些善的概念的观念。罗尔斯式和康德式的自由主义者在讨论目的论时，其关键之处如下：如果你把一种特定的善的概念，捆绑到正义上的话，如果你把正义视为，一个人和他或她的社会角色间，是恰当的话，你没有给自由留下空间，而想要自由就是要独立于任何特定的角色，或独立于传统，或独立于，可能是我父母留下来的惯例，或独立于我的社会。</p>
<hr>
<h2 id="21-《社会的需求》"><a href="#21-《社会的需求》" class="headerlink" title="21.《社会的需求》"></a>21.《社会的需求》</h2><p>康德认为，支持某种在其中人们可以追随自己美好生活观念的公平的权利框架是一回事，而将法律或者正义的基本规则置于任何一种特定美好生活观念的基础上，则是另外一回事 而且还会带来强制的危险。对亚里士多德来说，法律的全部意义，包括城邦的目的就在于塑造公民的性格，在于培养公民的美德，在于引导公民发展其卓越品性，在于提供某种美好生活的可能。<br>麦金太尔的德性理论包括如下基本内容：一、当代的道德危机和道德理论危机，二、西方的德性传统，三、德性论。麦金泰尔依据他的这个实践概念对“德性”进行界定，他说，“一种德性是一种获得性品质，这种德性的拥有和践行，使我们能够获得对实践而言的内在利益，缺乏这种德性，就无从获得这些利益。”由此，可以看到他把德性与实践的关系看成是内在不可分割的关系。有着内在利益的任何实践和实践的卓越标准都必须把德性作为必要成份而包括进去。善与实践是内在统一的。</p>
<hr>
<h2 id="22-《我们的忠诚在哪里》"><a href="#22-《我们的忠诚在哪里》" class="headerlink" title="22.《我们的忠诚在哪里》"></a>22.《我们的忠诚在哪里》</h2><p>一些基本的道德义务，这些义务是源自于共同体成员的责任，正是这样的责任构成了我们的身份。如何来判断一个人所应尽的义务的是否正确，我们可以从他的目的是否公正看出，这里我们要面对一个严肃的问题。如果我们接受集体这种概念，我们是否应该坚定的认为，公正是与正确相联系的，不管一个特殊的群体或者传统都意味着公正，包括那些南方隔离主义者，这是重要的区别两种不同的方法，公正可以与正确具有联系，一种是相对论这种方法：去想这事是正确，去想这事是公正的，看看我们所推广的价值，在任何一个被给定的社会群体，与给定的时间，不要以外界标准来判断他们，通过替代从而建立公正，按照公正去理解一种特殊的传统。</p>
<hr>
<h2 id="23-《辩论同性婚姻》"><a href="#23-《辩论同性婚姻》" class="headerlink" title="23.《辩论同性婚姻》"></a>23.《辩论同性婚姻》</h2><p>如果公正的原则取决于权利服务的终点是否有道德或内在的价值。社会怎样处理不同人对“好”持有不同的想法和观念？我们做为人类是有义务的，像是普遍性义务。如果我们来执行忠诚那肯定会有主从关系，越来越多的特殊性，那么我们肯定会对朋友和陌生人进行区别对待，这些都应在观念上被克服，过份的关注你的有钱朋友也将视做一种妒忌，这是从普遍大众观注度得出的一种测量人与人之间的距离方式。米尔认为：人类行为的唯一目的是求得幸福，所以对幸福的促进就成为判断人的一切行为的标准。</p>
<hr>
<h2 id="24-《美好生活》"><a href="#24-《美好生活》" class="headerlink" title="24.《美好生活》"></a>24.《美好生活》</h2><p>Sandel作总结时指出，我们作为个体，可能永远不会同意许多道德哲学问题的争论点。不过他认为，一方面，关于这些问题的辩论是不可避免的。另一方面，这给我们提供了一个更好地了解他人价值观的好机会。我们一直都生活 在这些问题的回答中。 在我们的公共生活中，在我们的私人生活中， 即使有时候这些问题无法回答，但我们还是无法回避哲学。开始的时候，谈到了康德的一个观点，即“怀疑是人类理性的休憩之处。怀疑让理性能反省 其教条式的漫游旅程，但怀疑也并非是永久的安身之处。<br>要做到尊重其他公民的道德和宗教信仰，还有另外一种方法， 不是漠视他们，而是与之交流。对他们予以关注有的时候还需要与之争论。有的时候则需要聆听和学习。</p>
]]></content>
  </entry>
  <entry>
    <title>布封 自然史</title>
    <url>/archives/buffon.html</url>
    <content><![CDATA[<p>世界万物运转无止息，万物都在的世间洪流中相遇<br>在广袤无尽的空间中，以及物换星移的接轨瞬间<br>万物混成冥河，不拘任何形体，不拘任何被赋予的形象<br>因此，万事万物或相近，或远离，或合一，或分离<br>或相容，或相斥，或生，或灭，恒久不变的，只有交互作用的力，<br>恣意横行，却灵巧而不自伐，为宇宙燃起生命气息，让生命舞台上<br>无时无刻上演着新的戏码，写下生生不息，永无止境的诗篇</p>
<p>Did Buffon, in 1783<br>not foresee this<br>when he wrote this magnificent sentence<br>about a complex and chaotic world<br>that on has to try to understand globally?</p>
<p>“Everything happens,<br>because with time everything meets,<br>and in the free range of spaces<br>and in the continuous succession of movement,<br>all matter is stirred,<br>any form given,<br>all figures printed;<br>so everything is coming or going,<br>all is joined or running away,<br>all is combined or opposed,<br>everything happens or is destroyed<br>by relative or contrary forces,<br>that are the only constants,<br>and balancing without harm,<br>they animate the universe<br>and make it into a theater<br>with ever new scenes<br>and objects incessantly reborn”</p>
]]></content>
  </entry>
  <entry>
    <title>一个简单的 python 爬虫</title>
    <url>/archives/python-cnni.html</url>
    <content><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_url</span><span class="params">(i)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        url = <span class="string">"http://www.cnnic.net.cn/hlwfzyj/hlwxzbg/index"</span> + <span class="string">".htm"</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url = <span class="string">"http://www.cnnic.net.cn/hlwfzyj/hlwxzbg/index_"</span> + str(i) + <span class="string">".htm"</span></span><br><span class="line">    res = requests.get(url)</span><br><span class="line">    urls = re.findall(<span class="string">"&lt;a href=\'./(.*?).pdf\'.*?target=\"_blank\"&gt;"</span>, res.content.decode(<span class="string">"utf-8"</span>) , re.M)</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(<span class="number">0</span>, len(urls)):</span><br><span class="line">        dome = <span class="string">"http://www.cnnic.net.cn/hlwfzyj/hlwxzbg/"</span></span><br><span class="line">        html = urls[m]</span><br><span class="line">        urls[m] = dome + html + <span class="string">".pdf"</span></span><br><span class="line">    <span class="keyword">return</span> urls</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    file = open(<span class="string">"pdf.json"</span>, <span class="string">"w"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">7</span>):</span><br><span class="line">        pdf = input_url(i)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> pdf:</span><br><span class="line">                file.write(i)</span><br><span class="line">                file.write(<span class="string">"\n"</span>)</span><br><span class="line">    file.close()</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
</search>
